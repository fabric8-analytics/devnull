kubernetes,kompose,1074,"Bump Go versions and use '.x' to always get latest patch versions.
 [APPROVALNOTIFIER] This PR is **NOT APPROVED**

This pull-request has been approved by:
To fully approve this pull request, please assign additional approvers.
We suggest the following additional approver: **hangyan**

If they are not already assigned, you can assign the PR to them by writing `/assign @hangyan` in a comment when ready.

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details open>
Needs approval from an approver in each of these files:

- **[OWNERS](https://github.com/kubernetes/kompose/blob/master/OWNERS)**

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[""hangyan""]} -->.
 Honestly I'd rather keep the hard-coded versions only because if you include `.x` it *may* update during someone's PR and cause them to get a false-positive..
 I don't have a strong opnion on this, both looks good to me..
 "
kubernetes,kompose,1073,"Bump Go versions.
 Appears the the fetching of `lint` was recently broken and this appears to be a fix: https://github.com/golang/lint/issues/415.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 [APPROVALNOTIFIER] This PR is **NOT APPROVED**

This pull-request has been approved by:
To fully approve this pull request, please assign additional approvers.
We suggest the following additional approver: **ngtuna**

If they are not already assigned, you can assign the PR to them by writing `/assign @ngtuna` in a comment when ready.

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details open>
Needs approval from an approver in each of these files:

- **[OWNERS](https://github.com/kubernetes/kompose/blob/master/OWNERS)**

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[""ngtuna""]} -->.
 "
kubernetes,kompose,1072,"Unable to load yaml/json file.
 Output of Terminal:
$ kompose convert -f docker-compose.yml
FATA Unable to load yaml/json file for version parsing: yaml: line 26: found unexpected end of stream 
janis@jk:~$ cat docker-compose.yml
version: '2'
services:
  postgres:
    container_name: clair_postgres
    image: postgres:latest
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: password

  clair:
    container_name: clair_clair
    image: quay.io/coreos/clair:v2.0.1
    restart: unless-stopped
    depends_on:
      - postgres
    ports:
      - ""6060:6060""
      - ""6061:6061
    links:
      - postgres
    volumes:
      - /tmp:/tmp
      - ./clair_config:/config
    command: [-config, /config/config.yaml]

But docker compose command is working and all is setup. What could go wrong with this file?.
 @jjankar pretty sure there is a `""` missing here `- ""6061:6061`. Not sure why `docker-compose` would work though….
 @vdemeester  sorry and thank you :).
 "
kubernetes,kompose,1071,"Labels not converted to annotations in ingress.
 If you have something like:

```yaml
version: '2'
services:
    web:
        labels:
            kompose.service.expose: dev.example.com
            kompose.service.expose.tls-secret: tls-secret
            kompose.service.type: clusterip

            kubernetes.io/ingress.class: nginx
            certmanager.k8s.io/cluster-issuer: letsencrypt-prod
            nginx.ingress.kubernetes.io/rewrite-target: /
        ports:
            - '80:80'
```

the annotations related to the ingress controller are not present in the `Ingress` object (they're there in `Service` and `Deployment`)..
 you can try https://github.com/treksler/kompose.
 "
kubernetes,kompose,1070,"Duplicate container ports if different host ports point to same container port.
 If you have something like this:

```yaml
version: '3'
services:
    test:
        image: alpine
        ports:
        - '8000:80'
        - '80:80'
```

you end up with this:

```yaml
- apiVersion: extensions/v1beta1
  kind: Deployment
  spec:
    template:
      spec:
        containers:
        - image: alpine
          name: test
          ports:
          - containerPort: 80
          - containerPort: 80
```

which creates problems with usage on K8s..
 "
kubernetes,kompose,1069,"Use tide for PR merging.
 This is a [core repository](https://github.com/kubernetes/community/blob/master/github-management/kubernetes-repositories.md#core-repositories).  As such, it [needs to use the same merge automation as the rest of the project](https://github.com/kubernetes/community/blob/master/github-management/kubernetes-repositories.md#rules-1)

I have a PR open that will address this at an org-wide level: https://github.com/kubernetes/test-infra/pull/9342.  It will:
- enable the approve plugin, to allow use of the `/approve` plugin
- enable the blunderbuss plugin, to assign reviews based on OWNERS files
- add all repos in the kubernetes org to tide's query

Can one of the repo maintainers here drop an LGTM (or objections) on the linked PR?  Alternatively, if I hear no objections by Monday 10am PT of next week, I will merge the PR..
 "
kubernetes,kompose,1068,"Use OS provided temporary directory.
 Fix for #966.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 Signed.
 @segrax Thanks for your contribution!.
 "
kubernetes,kompose,1067,"Command converted to Args.
 I do have up and running docker-compose file. When i convert it this command line in docker-compose.yml

`
        command:
            gunicorn myapp.wsgi:application --workers 1 --bind 0.0.0.0:800
`

convert as args inside of generated deployment file

`
      - args:
        - gunicorn
        - myapp.wsgi:application
        - --workers
        - ""1""
        - --bind
        - 0.0.0.0:8000
`

if i am not wrong, output should be 

`
    command: [""gunicorn myapp.wsgi:application --workers 1 --bind 0.0.0.0:800""]
`

.
 "
kubernetes,kompose,1066,"Proposal: Use the docker-compose network as kubernetes namespace.
 In docker-compose 3.5, we can give the network a specific name. https://docs.docker.com/compose/compose-file/compose-versioning/#version-35

Consider the following docker-compose:
```
version: ""3.5""

services:

  helloworld:
    image: tutum/hello-world
    ports:
      - 80:80

networks:
  default:
    name: helloword-ns
```

Using the `docker-compose up` a network is created with the name `helloword-ns`, with that, i can create another compose that use the same network to allow connect to that service.

I believe this behaviour is the same as namespace in kubernetes. In fact, each k8s object could be generated with the metadata namespace set with the name of network.

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.16.0 (13ce410)
  creationTimestamp: null
  labels:
    io.kompose.service: helloworld
  name: helloworld
  namespace: helloword-ns # <---------------- THIS CAN BE GENERATED
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: helloworld
    spec:
      containers:
      - image: tutum/hello-world
        name: helloworld
        ports:
        - containerPort: 80
        resources: {}
      restartPolicy: Always
status: {}
```

At docker-compose, the services using the same network can communicate to each other.
At kubernetes namespace, the services using the same namespace can communicate to each other.

> Additionally, if it DON'T HAVE the `external: true` _(which means that it connect to a existing network)_ like:
> ```
> networks:
>   default:
>     external: true
>     name: helloword-ns
> ```
> it could generate the k8s namespace object file:
> ```
> apiVersion: v1
> kind: Namespace
> metadata:
>   creationTimestamp: null
>   name: helloword-ns
> spec: {}
> status: {}
> ```
> So, it can create the namespace (because isn't `external: true`)

If the param `--namespace` is used like `kompose up --namespace some-name` it can override the specified in compose.

I see that a modification like that is a breaking change, so a major version of this tool can be necessary.

> _FYI: I have made some experiments in a local fork with that behavior (generating the namespace metadata and the namespace file), it fits gracefully in my point of view._

This is a proposal anyway.
What the maintainers think?
@hangyan @cdrage .
 Is somewhat related to https://github.com/kubernetes/kompose/issues/1058.
 "
kubernetes,kompose,1065,"Deploy to OSE with Self Signed Certificate.
 Hi all,

We are trying to use Kompose to deploy to OpenShift Enterprise. Our OSE has self-signed certificates which Kompose doesn't seem to have an elegant solution to verifying. Here is an example:

```bash
$user > kompose --build=none --provider=openshift up
INFO We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application.
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead.

FATA Error while deploying application: Get https://url-to-ose:443/api: x509: certificate signed by unknown authority
```

Is there anyway to get Kompose to skip verifying the certificate?.
 same here, any update?.
 "
kubernetes,kompose,1064,"kompose up - unmarshal errors when using docker compose version '3'.
 Using docker compose version 3, `kompose convert` creates deployment/service files, when using `kompose up`, I get
 `ERRO Could not parse config for project kubecompose : yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `extensi...` into config.RawService
  line 2: cannot unmarshal !!str `Deployment` into config.RawService`

`kompose version
1.16.0 (0c01309)`  

Using Docker for Mac - OS - High Sierra 

``` docker version
Client:
 Version:           18.06.0-ce
 API version:       1.38
 Go version:        go1.10.3
 Git commit:        0ffa825
 Built:             Wed Jul 18 19:05:26 2018
 OS/Arch:           darwin/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.06.0-ce
  API version:      1.38 (minimum version 1.12)
  Go version:       go1.10.3
  Git commit:       0ffa825
  Built:            Wed Jul 18 19:13:46 2018
  OS/Arch:          linux/amd64
  Experimental:     true
 Kubernetes:
  Version:          v1.10.3
  StackAPI:         v1beta2
```

Expected behavior: `kompose up` deploys on kubernetes.
 @lakshmanvvs Would you mind to paste a sample compose file that can reproduce these errors?.
 @hangyan 
Sure 
```
version: ""3""

services:
  inspections-aggregate-service:
    build:
      context: ./
      dockerfile: ./docker/Dockerfile
    image: inspections-aggregate-service
    entrypoint: ./entrypoint.sh
    ports:
      - ""7110:8080""
    environment:
      - https_proxy=${https_proxy}
      - HTTPS_PROXY=${HTTPS_PROXY}
      - http_proxy=${http_proxy}
      - HTTP_PROXY=${HTTP_PROXY}
      - COUCHBASE_HOSTNAME=couchbase-server
      - COUCHBASE_BUCKET_NAME=vin-info
      - COUCHBASE_BUCKET_EDCRAY=bananarama
      - COUCHBASE_CLUSTER_USERNAME=Administrator
      - COUCHBASE_CLUSTER_EDCRAY=bananarama
      - COUCHBASE_KEY_VALUE_TIMEOUT=35000
      - COUCHBASE_QUERY_TIMEOUT=35000
      - COUCHBASE_SOCKET_TIMEOUT=40000
      - COUCHBASE_CONNECT_TIMEOUT=40000
    depends_on:
      - couchbase-server
  couchbase-server:
    build:
      context: ./docker/couchbase
      dockerfile: Dockerfile
    image: couchbase-custom:4.0
    environment:
      - COUCHBASE_ADMIN_NAME=Administrator
      - COUCHBASE_ADMIN_EDCRAY=bananarama
      - COUCHBASE_CLUSTER_EDCRAY=bananarama
    ports:
      - ""7111:8091""
      - ""7112:8092""
      - ""7113:8093""
      - ""7114:8094""
      - ""7115:11210""
```.
 @hangyan  
Apologies. Looks like it does convert the file into deployment and service yaml files. 
I wonder why I got the above `unmarshal` errors. 
.
 @lakshmanvvs NP. Close this for now. Will reopen if it occurs to you agagin..
 "
kubernetes,kompose,1063,"Propagate dots into valid service names.
 Fix approach for #1062; a similar bug than #420..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 /check-cla.
 [APPROVALNOTIFIER] This PR is **NOT APPROVED**

This pull-request has been approved by:
To fully approve this pull request, please assign additional approvers.
We suggest the following additional approver: **hangyan**

If they are not already assigned, you can assign the PR to them by writing `/assign @hangyan` in a comment when ready.

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details open>
Needs approval from an approver in each of these files:

- **[OWNERS](https://github.com/kubernetes/kompose/blob/master/OWNERS)**

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[""hangyan""]} -->.
 /assign @hangyan.
 @rcmorano Thanks.
 "
kubernetes,kompose,1062,"dots get propagated into invalid names.
 Aloha,

I've been converting some compose files to Helm charts (concretely [DAppNode's project](https://github.com/dappnode/DNP_VPN/blob/master/docker-compose-vpn.yml) ones) and ran into the same problem exposed in #420.
In fact it's [the last comment from @xiaoping378 in this issue.](https://github.com/kubernetes/kompose/issues/420#issuecomment-319583013)

I've created #1063  PR following the guidelines of previous PRs #509 and #569 which fixed the problem and added the needed warning bits to documentation.
I Hope you find it's suitable to merge or as base for future work on the issue :)

Best! .
 "
kubernetes,kompose,1061,"Support read data from stdin.
 fix #1056
related to #871.
 LGTM!.
 "
kubernetes,kompose,1060,"Convert mounted directories into configmaps.
 When a docker-compose file has a volume pointing to a local directory, Kompose should convert the content of the directory into a configmap and attach the configmap into the pod at the right path as per the volume definition.

Example docker-compose.yml
```yaml
version: ""2.4""
services:
  web:
    image: nginx
    volumes:
      - ./tls:/etc/tls
    env_file: _env
```
Content of *./tls*:
```sh
$ ls tls/
ca.pem  web.pem  web.key
```

Configmap to be created should have 3 keys, ca.pem, web.pem and web.key with values as the content of those files. The configmap should be mounted at /etc/tls as per the docker-compose file spec..
 @cdrage This is a good solution. What's your opnion?.
 That would be great! E.g. i use to mount config files for nginx like 
```
 nc_nginx:
    image: nginx
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/conf.d/default.conf
 ```
At the moment, `kompose` ""only"" detects that there is a mount and creates a `PersistentVolumeClaim`
.
 @hangyan Yeah, I agree with this solution, it makes a lot of sence (as long as people don't link to large binaries!).
 "
kubernetes,kompose,1059,"ignore Docker Compose in conversion.
 Hi All,

Is there a way of ignoring a service when doing the conversion?

Thanks a lot,.
 @mbana Why don't just ignore the yaml generated from this service?.
 I could do that but I'd rather not. Is there some metadata to attach to a service that will cause it to be ignored in the conversion?.
 "
kubernetes,kompose,1058,"Convert version 3.5 of Docker Compose is not supported.
 I have the following `docker-compose.yml`:
```
version: ""3.5""

services:

  helloworld:
    image: tutum/hello-world
    ports:
      - 80:80
    networks:
      - helloworld-network

networks:
  helloworld-network:
    name: helloworld-network
```
Executing `docker-compose up` i can up my service using the [network `name` feature introduced at version 3.5](https://docs.docker.com/compose/compose-file/compose-versioning/#version-35)

> With that feature, i can use **multiples `docker-compose.yml`** and allow them to **connect to each other** using a **specific network name**

My idea is to use `kompose convert -f docker-compose.yml` and allow to generate the k8s ignoring the networks as it already does (not supported - and it is what i expect). 
But instead, it is given the following error: `Version 3.5 of Docker Compose is not supported. Please use version 1, 2 or 3`

**I guess it is time to update to allow a greater version of compose spec.**

_FYI: Even changing the version at docker-compose.yml to 3, the error kompose convert gives is: `Additional property name is not allowed`. But allowing use as version 3 is not a solution since `docker-compose up` doesn't work unless is 3.5._.
 @jvitor83 We not still working on support the miner versions of compose. After the full research about what added in version 3.4 and 3.5, we will add support for 3.5.
 any ETA on this? would love to convert a 3.5+ compose file..
 "
kubernetes,kompose,1057,"kompose webside is outdated.
 On the startpage of the kompose website (http://kompose.io/) is still the install instruction for the version `1.13.0`. And maybe it's time to upgrade to https. 😉

![image](https://user-images.githubusercontent.com/1724759/43370571-80a61f60-9381-11e8-813a-9fe0abdf0d74.png)
.
 @cdrage Isn't this auto-updated?.
 @hangyan Looks like someone put a protective status on the `gh-pages` branch (or it could of been done automatically recently).

Here was the latest error:
```sh
setup.md already contains Jekyll format
Adding Jekyll file format to user-guide.md
[gh-pages 8cf9b17] Update docs
 3 files changed, 9 insertions(+), 9 deletions(-)
remote: error: GH006: Protected branch update failed for refs/heads/gh-pages.        
remote: error: 2 of 2 required status checks are expected. At least 1 approving review is required by reviewers with write access.        
To github.com:kubernetes/kompose.git
 ! [remote rejected] gh-pages -> gh-pages (protected branch hook declined)
error: failed to push some refs to 'git@github.com:kubernetes/kompose.git'
```

I'm going to remove the protected branch status and then force a re-run of docs update..
 There we go! It's been updated, see: http://kompose.io/installation/

Closin'.
 "
kubernetes,kompose,1056,"read input from stdin does not work.
 Simple `docker-compose.yaml`
```yaml
version: '3'
services:
  backend:
    image: helloworld
```

`kompose convert --stdout -f docker-compose.yaml` works with no problems but
```sh
bash-4.4# cat docker-compose.yaml | kompose convert --stdout -f -
ERRO Could not parse config for project application : yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService 
FATA composeObject.Parse() failed, Failed to load compose file: yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService 
```
don't.

```sh
bash-4.4# kompose version
1.16.0 (0c01309)
```.
 "
kubernetes,kompose,1055,"1.16.0 Release.
 "
kubernetes,kompose,1054,"hostPort in deployment spec: is this supported?.
 If I have a port mapping specified in docker-compose.yml file, using the recent Kompose tool release , the generated deployment.yaml does not have the hostPort specified.

Thus if my docker-compose.yml file says:
```
version: ""2""
services:  
  result:
        image: tmadams333/example-voting-app-result:latest
        ports:
          - ""5001:80""
```
Then how can I  specify that the public port ""5001"" be exposed as a hostPort in my k8s cluster?

If I deploy the generated *service.yaml and *deployment.yaml then my deployment does not get exposed on port 5001 as-is.
.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1053,"Init Containers.
 Hi is there a way to specify init containers for pods in docker-compose.yml?
https://kubernetes.io/docs/concepts/workloads/pods/init-containers/.
 @edvorg Since docker compose does not have this feature, our main focus for now is still on docker-compose spec..
 Understood! Shall we close the ticket?.
 @edvorg Close it now.
 "
kubernetes,kompose,1052,"imagePullPolicy: is there way of specifying this.
 https://kubernetes.io/docs/concepts/containers/images/#updating-images

Is the above supported, if not, is there a way of attaching arbitrary metadata to a container?.
 @mbana Since compose doest not have this settings, so no for now. We use the default settings for this in kubernetes.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1051,"Node Taints: is this supported..
 Hello,

I am looking to specify a node taint as per this documentation: https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints.

Is this currently supported? I can't find examples of this. If so, please share a snippet.

Many thanks,.
 @mbana Sorry for the late response, kompose does not support node taint for now.Since docker-compose does not have this feature...
 "
kubernetes,kompose,1050,"Add installation instructions for openSUSE/SLE.
 This adds installation instructions for the packaged version of kompose available on OBS for openSUSE and SUSE Linux Enterprise.

Patch for Issue #1049 .
 @cdrage applied the requested change.
 @suntorytimed This LGTM! Thanks!.
 "
kubernetes,kompose,1049,"Installation Instructions for openSUSE/SLE.
 **Is this a BUG REPORT or FEATURE REQUEST? (choose one):**
This is a formal feature request to follow the CONTRIBUTING.md

The README.md shows several installation methods which include Cent OS, Fedora, macOS, Windows and others. Now there is also a packaged version for openSUSE/SUSE systems available. I have already forked an created a commit ready for a pull request, which adds a link to the official package repository..
 Thanks for merging my changes.
 "
kubernetes,kompose,1048,"Multiple compose files seems to be broken.
 Hi,

I'm trying to convert 2 different compose files :

```yaml
# docker-compose.yml
version: '2'
services:
  app:
    command: script/run.sh
    ports:
      - 3000
  nginx:
    image: nginx
    volumes_from:
      - app
    depends_on:
      - app
```

And 
```yaml
# docker-compose.production.yml
version: '2'
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.prod
    image: my_image
    volumes:
      - ./file_storage:/app/public/system/
      - assets:/app/public/assets/
    environment:
      PASS: ${PASS}
  nginx:
    ports:
      - 80
    volumes:
      - ./nginx.production.conf:/etc/nginx/conf.d/default.conf
volumes:
  assets:
networks:
  nginx_default:
    external: true
```

I have an error when running : 
```
kompose convert --stdout -f docker-compose.yml -f docker-compose.production.yml

ERRO Could not parse config for project members : Service 'app' has neither an image nor a build context specified. At least one must be provided.
FATA composeObject.Parse() failed, Failed to load compose file: Service 'app' has neither an image nor a build context specified. At least one must be provided.
```

It seems like the docker-compose version takes priority and that the docker-compose production yml is not read. When I change the order of the -f options, I have a similar error with the nginx service having no build context.

My kompose version is 1.15.0 (e3cd4d4).
My OS is MAC OS High Sierra (10.13.14)

When using docker-compose cli, I successfully can run this configuration with `docker-compose -f docker-compose.yml -f docker-compose.production.yml up`

I have trouble understanding why it does not work correctly..
 Actually, I just saw this issue : https://github.com/kubernetes/kompose/issues/968

It seems like what I'm looking for is not a supported feature right ? ""Multiple docker-compose files"" is supported but not by merging them ?.
 @Uelb  I think PR #990   have fix this, but it seems have some bugs, i will check it again..
 Thank you !.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1047,"Add surajnarwade in OWNER file.
 .
 @surajnarwade Has been with the project for almost two years and has actively contributed to Kompose. Myself and @kadel are adding him as a maintainer / contributor / reviewer. .
 "
kubernetes,kompose,1046,"Support for PVC Access Mode ReadWriteMany.
 Currently, looks like convert only covers cases for ReadOnly and ReadWriteOnce, but not ReadWriteMany. Use case is when you have more than one service that share a common volume. Ideally it would pick up in docker-compose if volume is linked to multiple services and do the conversion. Alternatively, could use labels to manually map if needed..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1045,"Add official docker image build.
 I would like use kompose packaged as a docker image.

https://hub.docker.com/r/femtopixel/kompose/

While this works, it would be nice to either have an official image or at least have this linked in the readme..
 @spawnia Great idea, we will try to add one ASAP.
 I own: https://hub.docker.com/u/kompose if you can provide a Dockerfile to the main root directory of here, then we can easily publish an official docker image..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale

I still think this is relevant, but do not feel qualified to provide such an image. I do not know the build process well enough..
 "
kubernetes,kompose,1044,"1.15.0 Release.
 "
kubernetes,kompose,1043,"Unable to push to Google Cloud.
 I've tried every way to use Kompose, but I've always the same issue.

docker-compose.yml (with xxx being my google project name)
```
version: ""3""
services:
  book-generator:
    image: gcr.io/xxx/book-generator:latest
    build: book-generator
    ports:
      - ""5000:5000""
```

```
INFO Build key detected. Attempting to build and push image 'gcr.io/xxx/book-generator:latest'
INFO Building image 'gcr.io/xxx/book-generator:latest' from directory 'book-generator'
INFO Image 'gcr.io/xxx/book-generator:latest' from directory 'book-generator' built successfully
INFO Pushing image 'xxx/book-generator:latest' to registry 'gcr.io'
WARN Unable to retrieve .docker/config.json authentication details. Check that 'docker login' works successfully on the command line.: Failed to read authentication from dockercfg
INFO Authentication credentials are not detected. Will try push without authentication.
INFO Attempting authentication credentials 'gcr.io
ERRO Unable to push image 'xxx/book-generator:latest' to registry 'gcr.io'. Error: unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication
FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service book-generator: unable to push docker image(s). Check that `docker login` works successfully on the command line
```

`~/.docker/config.json`
```
{
  ""auths"": {
    ""https://staging-k8s.gcr.io"": {},
    ""https://eu.gcr.io"": {},
    ""https://index.docker.io/v1/"": {},
    ""https://gcr.io"": {},
    ""staging-k8s.gcr.io"": {},
    ""asia.gcr.io"": {},
    ""gcr.io"": {},
    ""k8s.gcr.io"": {},
    ""us.gcr.io"": {},
    ""https://us.gcr.io"": {},
    ""https://k8s.gcr.io"": {},
    ""https://asia.gcr.io"": {},
    ""eu.gcr.io"": {}
  },
  ""credHelpers"": {
    ""gcr.io"": ""gcloud"",
    ""us.gcr.io"": ""gcloud"",
    ""eu.gcr.io"": ""gcloud"",
    ""asia.gcr.io"": ""gcloud"",
    ""staging-k8s.gcr.io"": ""gcloud""
  },
  ""credsStore"": ""osxkeychain"",
  ""HttpHeaders"": {
    ""User-Agent"": ""Docker-Client/18.03.1-ce (darwin)""
  }
}
```

I tried every type of login but I've always the same error. What is really surprising is that a direct:
`gcloud docker -- push gcr.io/xxx/book-generator:latest` works fine

Can you tell me how can I fix this issue ?.
 Have you read this conversation ? https://github.com/kubernetes/kompose/issues/911 it seems like it's the same issue .
 @BenderV Does `docker login` and `docker push` works well?.
 @hangyan yes, docker login and docker push works well..
 Similar thing happened to me. 
I'm able to push with docker
`docker push eu.gcr.io/XXXXXXX-####/container`
but from ""kompose up"" just hangs on ""INFO Attempting authentication credentials 'gcr.io "".
 had the same problem after running manually  `docker push` and then tried `kompose up`  again it worked for me .
 im also able to ```docker login``` and ```docker push```.

```
> gcloud auth configure-docker
gcloud credential helpers already registered correctly.
```.
 I am running into a similar issue but with Azure Container Registry. Both docker login and docker push work fine. Is it possible that its look for the .docker/config.json folder in the current directory rather than in the home directory ~/.docker/config.json?.
 I tried this on macOS High Sierra and Ubuntu with the same results:

	djmccormick at droplet in ~/Projects/foo on k8s
	± kompose up
	INFO Build key detected. Attempting to build and push image 'gcr.io/baz-foo/bar'
	INFO Building image 'gcr.io/baz-foo/bar' from directory 'foo'
	INFO Image 'gcr.io/baz-foo/bar' from directory 'foo' built successfully
	INFO Pushing image 'baz-foo/bar:latest' to registry 'gcr.io'
	WARN Unable to retrieve .docker/config.json authentication details. Check that 'docker login' works successfully on the command line.: Failed to read authentication from dockercfg
	INFO Authentication credentials are not detected. Will try push without authentication.
	INFO Attempting authentication credentials 'gcr.io
	ERRO Unable to push image 'baz-foo/bar:latest' to registry 'gcr.io'. Error: unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication
	FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service bar: unable to push docker image(s). Check that `docker login` works successfully on the command line

	dmccormick at droplet in ~/Projects/foo on k8s
	± docker push gcr.io/baz-foo/bar
	The push refers to repository [gcr.io/baz-foo/bar]
	f0d8f9de0422: Layer already exists
	08b97a5a0452: Layer already exists
	89099b8fb9c6: Layer already exists
	c218274b2dd1: Layer already exists
	df22d32922d6: Layer already exists
	latest: digest: sha256:c74240eda4ae843ea88523c1ce2074f2be88ca9bbf21f1782dfc568490fc6d8f size: 1375

	dmccormick at droplet in ~/Projects/foo on k8s
	± docker login gcr.io
	Authenticating with existing credentials...
	Login Succeeded

	dmccormick at droplet in ~/Projects/foo on k8s
	± cat ~/.docker/config.json
	{
		""auths"": {
			""gcr.io"": {}
		},
		""HttpHeaders"": {
			""User-Agent"": ""Docker-Client/18.06.1-ce (linux)""
		},
		""credHelpers"": {
			""asia.gcr.io"": ""gcloud"",
			""eu.gcr.io"": ""gcloud"",
			""gcr.io"": ""gcloud"",
			""marketplace.gcr.io"": ""gcloud"",
			""staging-k8s.gcr.io"": ""gcloud"",
			""us.gcr.io"": ""gcloud""
		}
	}%
.
 "
kubernetes,kompose,1042,"Add support for HorizontalPodAutoscaler via labels..
 .
 "
kubernetes,kompose,1041,"Support node.labels at placement.
 This PR just give the ability to put any custom label (not mapped) at `placement.constraints`
```
    deploy:
      placement:
        constraints:
        - node.labels.something == anything
```

Just for link the original PR for placement: https://github.com/kubernetes/kompose/pull/813.
 @jvitor83 Hi, Sorry about the very later response. Would mind to add some tests or modify the existing ones? there are many examples there.
 @hangyan Hi. I did a test about my modification..
 @jvitor83 Thanks!.
 "
kubernetes,kompose,1040,"Add kompose.image-pull-secret and kompose.image-pull-policy.
 .
 Tests are written, we've gotten multiple different PR's for this (https://github.com/kubernetes/kompose/pull/1039). 

I think we should merge this in. At least until native secrets implementation is added.

What do you think @hangyan ?.
 @cdrage my bad. Looks like I 've included #1031 commits here as well. 
Should I remove them from this PR, for distinct reviews, or just close #1031? Thanks!.
 Including them here is fine @mikesimos ! I think that we should merge in these labels as they've been requested quite a bit. At least until `Secrets` is natively implemented, the labels is a good middle-ground. As well as coverage for version 1/2 of Docker Compose.

Just waiting for reviews from @hangyan and maybe @xianlubird .
 @mikesimos 
1. Maybe you should rebase these commits to one or two commits
2. How about compose v1 and v2
3. Until now, the PR is fine..
 Awesome. Just what I was looking for.

Any ETA on when this might get merged into master?.
 @mbana Secret can be added to the `default`  ServiceAccount in the same namespace,  check this out:
https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account After this ,you do not need to specify the secret name in the deployment or pod, kubernetes will figure it out itself.
 I should have been more clear. I am waiting for the kompose.image-pull-policy feature. .
 @mikesimos Beside cdrage's comment, others LGTM.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1039,"Support to label kompose.service.image-pull-policy.
 This PR gives the label: `kompose.service.image-pull-policy`

resolve https://github.com/kubernetes/kompose/issues/1036.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 Closing my PR since https://github.com/kubernetes/kompose/pull/1040 appear to do the same (only with different label)..
 "
kubernetes,kompose,1038,"Support for converting docker-compose.yml files using YAML Merge Key.
 My team often uses YAML merge keys to keep our docker-compose.yml files small and to prevent repetition of tasks within the file.  Support for converting these would be very beneficial.  

http://yaml.org/type/merge.html

I'm currently receiving the following errors when attempting to convert the files ATM:

```Service 'portal' configuration key 'logging' contains an invalid type, it should be an array or object```

Example configuration:

```  
 cli:
    image: <imageURL>
    logging: &cli-logging
      driver: 'json-file'
      options:
        max-size: '200k'
        max-file: 5

  portal:
    image: <imageURL>
    logging:
      <<: *cli-labels
```.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 "
kubernetes,kompose,1037,"Remove short from testing.
 We shouldn't add ""-short"" as this may break testing. See:

```
-short
    Tell long-running tests to shorten their run time.
    It is off by default but set during all.bash so that installing
    the Go tree can run a sanity check but not spend time running
    exhaustive tests.
```.
 "
kubernetes,kompose,1036,"Support imagePullPolicy via label..
 Would `kompose.image-pull-policy` be a good candidate name for this label?.
 The only change i make was the label name, that i use: `kompose.service.image-pull-policy`.
 Hi @jvitor83 ! Sorry just saw that. I was waiting for some confirmation/ guidelines for this issue from the project maintainers following contributing guidelines [here](https://github.com/kubernetes/kompose/blob/master/CONTRIBUTING.md#contributing-a-patch). I already have some work for own use on this [here](https://github.com/mikesimos/kompose/tree/add-kompose.image-pull-policy) awaiting to be PRed. Would you mind rebasing your contribution on top of this? Thanks!
The naming of the label is indeed a concern, but since imagePullPolicy isn't a docker-compose service directive, I wouldn't use the kompose.service prefix. I was rather inclined towards something like `kubernetes.`  prefix for kubernetes specific customizations. This feature focuses on very specific use cases were imagePullPolicy Never needs to be specified (ie. industrial air-gapped environments, etc). Not sure if [this (check imagePullPolicy)](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#container-v1-core) is helpful for you..
 @cdrage @hangyan, I m creating a PR for comments/guidelines? Thanks!.
 @mikesimos closing my PR since your appear to do the same (only with different label)..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 "
kubernetes,kompose,1035,"Support HorizontalPodAutoscaler via label.
 This is a really nice k8s feature. Would supporting it via a `kompose.` label be the way to move forward here?.
 @mikesimos This is not easy, mostly a label only contains a simple string, but HPA have much more information.
 "
kubernetes,kompose,1034,"Remove unused param.
 .
 "
kubernetes,kompose,1033,"Remove unused param.
 .
 "
kubernetes,kompose,1032,"Typo fix: erroring -> error.
 .
 /assign @hangyan .
 LGTM..
 "
kubernetes,kompose,1031,"Add kompose.image-pull-secret.
 fixes #897.
 I think it's not the best solution.  Even though we support imagePullSecrets in kompose, there still need a Secret to exist first. If the user can simple add the secrets to the default serviceaccount, we don't need to support this  at all..
 Hi @hangyan. Can you point-out further info imagePullSecrets support in kompose? I couldn't find this feature supported somewhere in the code. 
I think to further the expansion of kubernetes options support in kompose, will facilitate broader use of the tool ( see #897 ) . Bundling secrets close to the private image they are required for looks more intuitive and a cleaner solution to me..
 @cdrage .
 @hangyan @mikesimos 

I'm not opposed nor am I accepting of this. It's a tough decision.

In one case, we support imagePullSecrets but we *dont* support secrets.

The other case is the fact that this is a good intermediary step..

In my opinion, I believe we should delay this PR until #296 is completed. Kompose is meant to transition people whom are complete noobies to Kubernetes. Adding a label that supports image-pull-secrets but not explaining that you have to add secrets before hand isn't very Kompose-like.

@hangyan is right. The label can be completed instead by fully supporting secrets, rather than using an intermediary label. I'd suggest that we come back to this after #296 is completed and see if it's still applicable to merge..
 OK! Having imagePullSecrets functionality upstream would be great. Thanks both!.
 Hey @mikesimos does your PR here: https://github.com/kubernetes/kompose/pull/1040 override / close this one?.
 Closing as #1040 overrides this. Thanks!.
 "
kubernetes,kompose,1030,"1.14.0 Release.
 "
kubernetes,kompose,1029,"Fix invalid port name with uppercase characters.
 When there are multiple protocol for one port, the generated port name is invalid which has uppercase chars

E.g. 

```
version: '2'
services:
  bootstrap:
    image: test
    ports:
      - ""1234:1234""
      - ""1234:1234/udp""
```

The generated service config is as following

```
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.version: 1.13.0 (84fa826)
  creationTimestamp: null
  labels:
    io.kompose.service: bootstrap
  name: bootstrap
spec:
  ports:
  - name: ""1234""
    port: 1234
    targetPort: 1234
  - name: 1234-UDP
    port: 1234
    protocol: UDP
    targetPort: 1234
  selector:
    io.kompose.service: bootstrap
```

The following exception will be return when creating service

The Service ""bootstrap"" is invalid: spec.ports[1].name: Invalid value: ""1234-UDP"": a DNS-1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')

We should append the lower case of protocol as part of the port name.

Thanks.
 @denverdino Thanks!.
 "
kubernetes,kompose,1028,"Typo fix: overwite -> overwrite.
 .
 /assign @hangyan .
 "
kubernetes,kompose,1027,"Typo fix: overwite -> overwrite.
 .
 /assign @hangyan .
 "
kubernetes,kompose,1026,"Fix all typos in changelog.
 .
 @hangyan this is actually automatically generated by our release script (https://github.com/github-changelog-generator/github-changelog-generator) so it'll still be overwritten each time as it uses previous / past commits. The only way to change this would be to forcefully go through each commit message and update it so that there is no typo (which we don't want to do).
 @cdrage Got it. ( At first I just want to fix it to prevent other people keeping create typo PR for this file).
 "
kubernetes,kompose,1025,"Typo fix: containes->contains.
 Line 484: containes->contains.
 dup to #1026 .
 "
kubernetes,kompose,1024,"Typo fix: inital->initial.
 inital->initial.
 dup to #1026 .
 "
kubernetes,kompose,1023,"getsockopt: connection refused when executing kompose up.
 I have a docker compose script in my project and now i want to deploy it on google cloud kubernetes cluster.
in my local machine i have gcloud sdk and kompose and when i execute ""kompose up"" I got this error message: Get http://localhost:8080/XXX: dial tcp [::1]:8080: getsockopt: connection refused.
So I'm wondering if something wrong with the kubernetes hosted on gcloud? like do I need to configure something for kubernetes?
Thank you!.
 @robinwu0411 The `up` command is mainly for local usage. You need to have a local kubernetes running for now..
 "
kubernetes,kompose,1022,"Support specifying nodePort via label.
 For NodePort services it is possible to set the port via spec.ports[*].nodePort field. Looks like it is not supported in kompose yet.
 @andreysaksonov We can add another label to support this! .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1022#issuecomment-434568836):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1021,"Typo fix in maven-example.md.
 Line 2& Line 81: Lets->Let's
Line 25: Adds->Add.
 These changes looks too farfetched to me. .
 These changes are fine (the english is correct).
 "
kubernetes,kompose,1020,"Fix environment with env_file bug.
 Fix #1013 .
 @cdrage Do you have time to review #1020 #1007 for me? Not in a rush, but i can only continue to work after these PRs merged.
 @hangyan Sorry, been busy with other projects. I'll review them now! :+1: .
 Feel free to merge after the fix.
 "
kubernetes,kompose,1019,"Failing with my Node.js, RabbitMQ app.
 This `docker-compose.yml` gives me failing (doesn't run on kubectl):
- rabbitmq deployment
- node pod
- rabbitmq pod
- rabbitmq replica set
- node-claim0 persistent volume claim (missing persistent volume?)

The rest of the generated .yaml e.g. all of the MongoDB seems to work.

Please let me know if I am missing any steps or something seems wrong. Thanks!

```
version: ""3""

services:
  node:
    build: .
    volumes:
      - ~/.somedir:/root/.somedir
    ports:
      - 8085:8085
    depends_on:
      - rabbitmq
      - mongo1
      - mongo2
      - mongo3
    restart: on-failure
  rabbitmq:
    image: rabbitmq
    ports:
      - 5672:5672
  mongo1:
    image: mongo
    ports:
      - 27017:27017
    command: mongod --replSet rs0
  mongo2:
    image: mongo
    ports:
      - 27018:27017
    command: mongod --replSet rs0
  mongo3:
    image: mongo
    ports:
      - 27019:27017
    command: mongod --replSet rs0

networks:
  default:
      external:
          name: mynet
```.
 @booboothefool PV is a environment specific resource, we cannot generate it from the compose file.
 @booboothefool Close this issue now. You can reopen this if you have further quetions.
 "
kubernetes,kompose,1018,"Typo fix in tests.sh: kubernets->kubernetes.
 Line 496: Kubernets->Kubernetes.
 "
kubernetes,kompose,1017,"Update contact information for sebgoa.
 I've updated your contact information @sebgoa in the OWNERS file..
 thanks.
 "
kubernetes,kompose,1016,"Add security contacts.
 As per
https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
a SECURITY_CONTACTS file has been created..
 I've simply added many of the people from the OWNERS file to this.

If you don't feel comfortable being a security contact, please let me know! I've suggested: @kadel @hangyan @surajssd @janetkuo @ngtuna @sebgoa 

As per #1016 I'm pinging you here @jessfraz ! .
 fine with me, even though I have been very active lately..
 "
kubernetes,kompose,1015,"Create a SECURITY_CONTACTS file..
 As per the email sent to kubernetes-dev[1], please create a SECURITY_CONTACTS
file.

The template for the file can be found in the kubernetes-template repository[2].
A description for the file is in the steering-committee docs[3], you might need
to search that page for ""Security Contacts"".

Please feel free to ping me on the PR when you make it, otherwise I will see when
you close this issue. :)

Thanks so much, let me know if you have any questions.

(This issue was generated from a tool, apologies for any weirdness.)

[1] https://groups.google.com/forum/#!topic/kubernetes-dev/codeiIoQ6QE
[2] https://github.com/kubernetes/kubernetes-template-project/blob/master/SECURITY_CONTACTS
[3] https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
.
 closing as this was done :) thanks.
 "
kubernetes,kompose,1014,"Add support for Docker stack files.
 With Docker discontinuing it's support of Docker Cloud, it would be useful to have a tool to convert stack files into k8s manifests. .
 We have some support for the deploy `key` in compose file for now.  Support docker stack file needs some effort ,  we will trying to..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1014#issuecomment-431685548):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1013,"'environment' with 'env-file' specified together for service in docker-compose.yml don't  work.
 In such case key-value pairs in 'environment' sections are omitted.

For example

```json
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop-hive-namenode.env
    ports:
      - ""50070:50070""
      - ""8020:8020""
```

`CLUSTER_NAME` won't be set.
 This seems like a bug, I will trying to fix it ASAP..
 "
kubernetes,kompose,1012,"multiple containers in a pod sharing volume.
 When I use `kompose up` or `kompose convert`, I get each service as its own pod with single container.  One functionality I am trying to use in kubernetes is the docker-in-docker (dind) that sits along side my execution agent in the same pod.  I have this working with kubectl create if using the same `emptyDir` to share both workspace and docker.sock for both containers.  I also have this working with `docker-compose` but this does not convert over to kubernetes without multiple containers in a pod support.

I have gone thru the docs and do not see mention of multiple container pod.  Plus in other forums, I have seen the same question posted without any solution.  Thus I am posting here after seeing the RFE for service type.  Along the same lines of `kompose.service.type` that can switch to `loadbalancer`, I wondered if it would be possible to:

- use a specific label that can group services/containers together into a pod 
- and also iterate over the volume mounts that share the same location to be combined together when `--volumes emptyDir` is present

.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 I've also faced with this issue, I need to use gcePersistentDisk as ReadWrite in multiple containers, which is possible only with multi-container pod. 

I agree with choig, would be good to have:

+ use a specific label that can group services/containers together into a pod
+ and also iterate over the volume mounts that share the same location to be combined together when --volumes emptyDir is present.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1012#issuecomment-433305379):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1011,"Fix typo in integrations.md.
 s/Adfinis SysGroup AG/Adfinis SyGroup AG/.
 LGTM. Thanks @tongpu.
 "
kubernetes,kompose,1010,"Missing service metadata.labels mapping.
 Hi,

first, I really like the project, thank you very much!

I am not able to map compose values to service's metadata.labels.

example:
```
version: ""3""
services:
  selenium-hub:
    image: selenium/hub:3.12.0-americium
    container_name: selenium-hub
    ports:
      - ""4444:4444""
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 500M
        reservations:
          cpus: '0.5'
          memory: 500M
    labels:
      service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
      kompose.service.type: LoadBalancer
```

The result is:

```
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.service.type: LoadBalancer
    kompose.version: 1.4.0 (c7964e7)
    service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
  creationTimestamp: null
  labels:
    io.kompose.service: selenium-hub
  name: selenium-hub
spec:
  ports:
  - name: ""4444""
    port: 4444
    targetPort: 4444
  selector:
    io.kompose.service: selenium-hub
  type: LoadBalancer
status:
  loadBalancer: {}
```

What I need is the following:
```
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.service.type: LoadBalancer
    kompose.version: 1.4.0 (c7964e7)
    service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
  creationTimestamp: null
  labels:
    io.kompose.service: selenium-hub
    dns: route53   <--- this field is missing
  name: selenium-hub
spec:
  ports:
  - name: ""4444""
    port: 4444
    targetPort: 4444
  selector:
    io.kompose.service: selenium-hub
  type: LoadBalancer
status:
  loadBalancer: {}
```
Maybe I missed something but I couldn't find any hint in the conversion matrix. I need to find a way to make Kompose creating the **dns: route53** label.

Any ideas how to achieve this?.
 @Journerist May I ask where is this `dns:route53` come from? Did't find it in the compose file.
 @hangyan This is the question :) Where to add it ? I tried adding this one to labels, but labels are mapped to metadata.annotations..
 @Journerist I think currently there is no way to support this. But this is a reasonable request, we should figure out a way to support it. @cdrage .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1010#issuecomment-429592582):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1009,"Fix golint warnings.
 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 /retest.
 @k8s-ci-robot I have signed the CLA.
 "
kubernetes,kompose,1008,"Fix golint warnings.
 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 /retest.
 "
kubernetes,kompose,1007,"Add support for file based secret.
 related to #296 

Notes:
1. External secret is not supported
2. may have conflict with #994 
3. import a new package cast(https://github.com/spf13/cast)
.
 /assign cdrage
/assign kadel.
 @hangyan Please separate the commits between code change and vendor update so we can review!.
 @cdrage Done. Thanks!.
 Progress @hangyan ?.
 @cdrage Sorry, been very busy these days on my work. Working on this now..
 @cdrage Updated.
 conflict resolved.
 @cdrage is this good? will be merged?
I need that feature..
 @hangyan , i create a PR ( https://github.com/hangyan/kompose/pull/3/files ) to your secret-support branch (PR) which:
- Fix the issue reported at https://github.com/kubernetes/kompose/pull/1007#discussion_r219224280
- Added support to long-syntax with absolute path.
 @jvitor83 Great. Thanks very much. I will review this again ASAP. But since there are not so many active maintainers for this project, this PR may take a long time to be merged in. I'm afraid of you will have to build the binary yourself based on this branch..
 > I'm afraid of you will have to build the binary yourself based on this branch.

Already did it!
Thanks for the feedback..
 @hangyan if you want @jvitor83 you can always do a branch of this PR, push your changes and open a new PR. I don't think @hangyan would mind if you continue on his awesome work :+1: .
 [APPROVALNOTIFIER] This PR is **NOT APPROVED**

This pull-request has been approved by:
To fully approve this pull request, please assign additional approvers.
We suggest the following additional approver: **cdrage**

If they are not already assigned, you can assign the PR to them by writing `/assign @cdrage` in a comment when ready.

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details open>
Needs approval from an approver in each of these files:

- **[OWNERS](https://github.com/kubernetes/kompose/blob/master/OWNERS)**

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[""cdrage""]} -->.
 "
kubernetes,kompose,1006,"1.13.0 Release.
 "
kubernetes,kompose,1005,"Kubernetes multiple volumeMounts with subPath and 1 configmap volume - onle 1 volumeMount works.
 Hello, 

ISSUE
=====
When a deployment has multiple volumeMounts and only 1 volume (from configMap), only the last volumeMount is actually being mounted in the PODs; the rest do not get mounted; I have 3 volumeMounts with subPath specified to each required file that I want mounted. 

STEPS to REPRO
============
1. create configmap: $ kubectl create configmap nginx-config --from-file=nginx.conf --from-file=default.conf --from-file=index.html 
2. create the deployment: $ kubectl create -f deployment.yaml 

deployment.yaml
=============
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        volumeMounts:
          - name: nginx-config
            mountPath: /etc/nginx/nginx.conf
            subPath: nginx.conf
            mountPath: /etc/nginx/conf.d/default.conf
            subPath: default.conf
            mountPath: /usr/share/nginx/html/index.html
            subPath: index.html   
        ports:
        - containerPort: 80
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-config

Investigation
==========
1. configmap nginx-config has all 3 required sections: 
$ kubectl describe configmap nginx-config | egrep  ""conf|html""
Name:         nginx-config
default.conf:
index.html:
nginx.conf:
 
2.   If I connect to the POD/s, only ""index.html"" has been mounted from the configMap, the rest of the files are default.  if I switch the order of the volumeMounts, then the same behavior is seen, the last entry gets mounted. 

Workaround
==========
As a workaround, I needed to create 3 separate configmaps and add 3 volumes (configmap) in the deployment spec. that seems to work properly, however it would be nice to have 1 single configmap volume to keep things tidy. .
 $ kubectl version
Client Version: version.Info{Major:""1"", Minor:""9"", GitVersion:""v1.9.1"", GitCommit:""3a1c9449a956b6026f075fa3134ff92f7d55f812"", GitTreeState:""clean"", BuildDate:""2018-01-04T11:52:23Z"", GoVersion:""go1.9.2"", Compiler:""gc"", Platform:""linux/amd64""}

Kubernetes version: 1.9.6.
 "
kubernetes,kompose,1004,"when to support this parameter build: args?.
 build: args not implemented yet.
need to implemented quickly.
![qq20180512-134033](https://user-images.githubusercontent.com/38183891/39954052-a982f946-55ea-11e8-9e0e-f1b267a72d26.jpg)
.
 this is very important , to auto build with modules and auto deploy on openshift..
 We will work on it.
 @beefee Could you provide a example, the source compose file and the openshift yaml file you want get. So we can implement it better. Thanks..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1004#issuecomment-428599303):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1003,"Glide update error.
 I want to upgrade k8s vendor to a newer version. I change `github.com/openshift/origin` version from `v1.4.0-rc1` to `v3.9.0`, then run `glide update --strip-vendor`. There're many errors message

```
[ERROR]	Error looking for k8s.io/api/apps/v1beta1: Unable to get repository: Cloning into '/root/.glide/cache/src/git-github.com-openshift-kubernetes-api'...
[ERROR]	Error scanning k8s.io/api/autoscaling/v1: cannot find package ""."" in:
	/root/.glide/cache/src/git-github.com-openshift-kubernetes-api/autoscaling/v1
[ERROR]	Error scanning k8s.io/api/batch/v1: cannot find package ""."" in:
	/root/.glide/cache/src/git-github.com-openshift-kubernetes-api/batch/v1
[ERROR]	Error scanning k8s.io/api/batch/v1beta1: cannot find package ""."" in:
	/root/.glide/cache/src/git-github.com-openshift-kubernetes-api/batch/v1beta1
[ERROR]	Error scanning k8s.io/api/batch/v2alpha1: cannot find package ""."" in:
	/root/.glide/cache/src/git-github.com-openshift-kubernetes-api/batch/v2alpha1
[ERROR]	Error scanning k8s.io/api/core/v1: cannot find package ""."" in:
	/root/.glide/cache/src/git-github.com-openshift-kubernetes-api/core/v1
```

So I can't upgrade k8s vendor to a newer version.   I find a issue https://github.com/redhat-developer/odo/issues/377, when I clean all glide cache and vendor folder, it always show above error message.   

@cdrage @hangyan Do you have some suggestion about this ? Need help..
 Vendoring for newer versions of Kubernetes and OpenShift can can a bit tricky :-( 

We already hit this problem in Kedge and we had to write special script to handle OpenShift vendoring [vendor-openshift.sh](https://github.com/kedgeproject/kedge/blob/master/scripts/vendor-openshift.sh). See  comments in [glide.yaml](https://github.com/kedgeproject/kedge/blob/master/glide.yaml#L43,L49).

But there is another solution for this. Kompose still imports stuff from `k8s.io/kubernetes` and from `github.com/openshift/origin`. But it should be possible to replace it with `k8s.io/client-go` and `github.com/openshif/client-go`, it is not going to be easy but it will make vendoring straingforward and it will be much easier to update to new versions..
 Good idea! .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,1002,"Activate downward api.
 Recently we wanted to get access to our namespace as an envvar. K8s can do this via the downward api
https://kubernetes-v1-4.github.io/docs/user-guide/downward-api/
It would be trivial to allow kompose users to activate this metadata as envvar..
 Do you suggest we add all of these metadata to container env automatically? .
 I’d prefer if it was via kompose annotations but we always want them .
On Tue, May 8, 2018 at 5:36 PM Hang Yan <notifications@github.com> wrote:

> Do you suggest we add all of these metadata to container env automatically?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/1002#issuecomment-387584351>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAxN28lnzFD2wLYLZIE6UTr1Bs9Xc43Bks5twjoJgaJpZM4T3LeH>
> .
>
.
 I have checked the document, the downward api provides a method for users to use the metadata in env, but you need use it explicitly. I don't think it's a good idea to make it default. You can always edit the generated yaml to add these envs.
 Why not have a switch to add it? We try not to edit the y’aml too often?
On Tue, May 8, 2018 at 6:25 PM Hang Yan <notifications@github.com> wrote:

> I have checked the document, the downward api provides a method for users
> to use the metadata in env, but you need use it explicitly. I don't think
> it's a good idea to make it default. You can always edit the generated yaml
> to add these envs
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/1002#issuecomment-387591331>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAxN2zpUEm9j5WQpY4kSP30bl0GlfSdMks5twkV0gaJpZM4T3LeH>
> .
>
.
 That sounds reasonable.  A switch to add about 7 envs. @cdrage  what's your opinion?.
 @posix4e 
Could you provide a detail example show that how do you use download api in your environment?
If you provide a example, we can implement it more accurate.  thanks.
 My usecase is knowing what namespace I’m in, in the application. Do you
want me to share some downstream api code? All I’d need is a slightly
different generated manifest
On Sun, May 13, 2018 at 7:34 AM Xianlu Bird <notifications@github.com>
wrote:

> @posix4e <https://github.com/posix4e>
> Could you provide a detail example show that how do you use download api
> in your environment?
> If you provide a example, we can implement it more accurate. thanks
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/1002#issuecomment-388631414>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAxN2_gvedvm4JtTsF39XsRkvmw9--sHks5tyESCgaJpZM4T3LeH>
> .
>
.
 @posix4e  For now our main focus will still be translating compose yaml to kubernetes yaml, since the downward-api is a kubernetes specific thing, it's not a very great idea to add this function to kompose, based on kompose's purpose. But If there are any contributors willing to add support for this ,we are glad to merge it in. .
 Right you need to generate a different kubernetes manifest if you are to
Expose the namespace as an envvar. This does make a huge variety of things
easier though. I might give it a try. Do we do anything like this in
previous patches?
On Mon, May 14, 2018 at 12:45 AM Hang Yan <notifications@github.com> wrote:

> @posix4e <https://github.com/posix4e> For now our main focus will still
> be translating compose yaml to kubernetes yaml, since the downward-api is a
> kubernetes specific thing, it's a very great idea to add this function to
> kompose, based on kompose's purpose. But If there are any contributors
> willing to add support for this ,we are glad to merge it in.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/1002#issuecomment-388726231>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAxN23ze2d4UqqQH-J79yq-HLHYDcxTNks5tyTYCgaJpZM4T3LeH>
> .
>
.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/1002#issuecomment-429038781):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,1001,"Add label 'kompose.controller.type' set service convert controller type.
 A standard wordpress compose like this
```
web:
  image: wordpress:4.5
  ports:
    - '80'
  environment:
    WORDPRESS_AUTH_KEY: changeme
    WORDPRESS_SECURE_AUTH_KEY: changeme
    WORDPRESS_LOGGED_IN_KEY: changeme
    WORDPRESS_NONCE_KEY: changeme
    WORDPRESS_AUTH_SALT: changeme
    WORDPRESS_SECURE_AUTH_SALT: changeme
    WORDPRESS_LOGGED_IN_SALT: changeme
    WORDPRESS_NONCE_SALT: changeme
    WORDPRESS_NONCE_AA: changeme
  restart: always
  links:
    - 'db:mysql'
db:
  image: mysql:5.7
  environment:
    MYSQL_ROOT_PASSWORD: password
  restart: always
  labels:
    project.logs: /var/log/mysql
```

For service `db`, we'd better convert it to `StatefulSet`. But if we run command `kompose convert -f `, all of them are converted to `Deployment`. We have to split them into two compose file.So we'd better support a label which can control what type you want to convert.

After that, a compose like this
```
web:
  image: wordpress:4.5
  ports:
    - '80'
  environment:
    WORDPRESS_AUTH_KEY: changeme
    WORDPRESS_SECURE_AUTH_KEY: changeme
    WORDPRESS_LOGGED_IN_KEY: changeme
    WORDPRESS_NONCE_KEY: changeme
    WORDPRESS_AUTH_SALT: changeme
    WORDPRESS_SECURE_AUTH_SALT: changeme
    WORDPRESS_LOGGED_IN_SALT: changeme
    WORDPRESS_NONCE_SALT: changeme
    WORDPRESS_NONCE_AA: changeme
  restart: always
  links:
    - 'db:mysql'
db:
  image: mysql:5.7
  environment:
    MYSQL_ROOT_PASSWORD: password
  restart: always
  labels:
    project.logs: /var/log/mysql
    kompose.controller.type: daemonset
```
So service web convert to `Deployment`, service db convert to `StatefulSet`, it's very useful.


What's your opinion, @cdrage @hangyan .
 @cdrage @hangyan If you have time, pls review this.  Thanks..
 I fully support this. However, a few more things need to be added:

- Documentation for StatefulSet
- A new flag should be added (to --controller!)

This will close a bunch of issues. Specifically, the one regarding #698 !.
 @cdrage @hangyan 

Thanks for your review.
- Already add document for label `kompose.controller.type`
- For a new flag , now we already have `--controller ` flag and support three types, run `kompose convert --help` can see it
```
./kompose convert --help
Convert a Docker Compose file

Usage:
  kompose convert [file] [flags]

--controller string   Set the output controller (""deployment""|""daemonSet""|""replicationController"")
```
This pr support that ,user can use `kompose convert -f test.yml`. If a service have label `kompose.controller.type`, it will be converted to the type which use specified, for other service in the same compose file, it will convert to default controller type or user specified type in `--controller xxxxx`.   .
 @cdrage any update?.
 Hey @xianlubird I'll find some time this week / early next week to do another review :+1: Maybe @hangyan could do one on this PR and https://github.com/kubernetes/kompose/pull/994#issuecomment-387924830 ?.
 @cdrage Yes, I make a mistake for `DaemonSet` and `StatefulSet`.   This pr , I just want to add a label for that different service in one yaml file can convert to different k8s type.  For this purpose, I raise this pr.

So in your opinion, I should implement `StatefulSet` in this PR?   Or just add a label for `deployment` and `DaemonSet` and implement `StatefulSet` in another PR ?


many thanks..
 Hey @xianlubird 

For now, just implement the label, but please correct that daemonset will be converted to daemonset.

We should raise another PR in the future for adding statefulset (see issue: #698 ).
 @cdrage 
Already change document to `DaemonSet`. 
I will raise another PR to implement `StatefulSet`.
Thanks for your review..
 This LGTM. I'd like @kadel or @hangyan to review this too since it's fairly large..
 @xianlubird Please add OpenShift test files.
 @hangyan Already add OpenShift test case, thanks..
  @kadel @hangyan Any update on this..
 /lgtm.
 "
kubernetes,kompose,1000,"Add some deprecated info warning.
 ```
kompose convert --replication-controller
Flag --replication-controller has been deprecated, use --controller
```
Add deprecated info in help message.
 @hangyan @cdrage Is this necessary ?.
 This helps. LGTM..
 @cdrage @hangyan 
Anyone cloud help to merge this pr ?.
 @xianlubird The user guide need update too..
 @hangyan Done.
 @xianlubird Please check again, there are still some occurrences in the user guide doc.
 @hangyan yes, nice catch.  I have changed code, thanks..
 /lgtm.
 "
kubernetes,kompose,999,"Support compose global deploy mode to daemonset.
 Support compose global deploy mode to daemonset

@cdrage @hangyan Pls help to review if you are free. Thanks..
 What if the user use `--deployment` args at the same time?.
 @hangyan Nice catch ! Already change code, thanks..
 @cdrage @hangyan Any update on this ?.
 /lgtm.
 "
kubernetes,kompose,998,"Typo fix: wil->will.
 wil->will.
 LGTM. Thanks!.
 "
kubernetes,kompose,997,"Remove go1.6 support in ci.
 From the error logs of the build, the root cause is that golint have abandon the support for 1.6, and because golang already have version1.9/1.10, I think we can do that too.

https://travis-ci.org/kubernetes/kompose/jobs/373755156
@cdrage .
 This LGTM. Thanks @hangyan !.
 "
kubernetes,kompose,996,"Typo fix: containes->contains.
 Line 460: containes->contains.
 @AdamDang Please rebase the master code so the CI can pass.
 recreate this PR..
 "
kubernetes,kompose,995,"Correct the proper nouns to be in capital letter.
 The proper nouns like: Kubernetes, OpenShift, Transformer should be in capital letters, while there some places in the doc use lowercases..
 Thanks @xianlubird, in this doc, transformer and Transformer both exist. It's better to keep same. 
Do you mean I should change all transformer in lowercases?.
 @AdamDang  It's better to keep the same, but we should also consider the context. For example, `transformer` means `transformer.go` file here. Thanks for the contribution anyway, but i'm gonna close this PR.
 "
kubernetes,kompose,994,"Add support for Config, endpoint_mode and 3.3 support.
 ```
Version 3.3
An upgrade of version 3 that introduces new parameters only available with Docker Engine version 17.06.0+, and higher.

Introduces the following additional parameters:

    build labels
    credential_spec
    configs
    deploy endpoint_mode
```


Docker compose v3.3 add four attributes.   For `credential_spec` we shouldn't support. I will work on it , support v3.3 ASAP.

Issue:  https://github.com/kubernetes/kompose/issues/914 and https://github.com/kubernetes/kompose/issues/865

@cdrage 

.
 @cdrage @hangyan @surajnarwade 
A brief introduction:
- This PR implement compose v3.3 support for kubernetes transform. For openshift, it will be implemented in another PR later.
- `credential_spec ` can only be used in windows container, so we ignore it 
- `configs ` convert to `configmap` in kubernetes and can be mount into deployment pod
- `endpoint_mode` vip mode is similar to `nodePort` type service, `dnsrr` should ignore

@cdrage @hangyan Pls review this PR if you are free. Review this PR maybe cost much time. If you have any comments , I will refactor my code.  Thanks . :-)
.
 What's update on this ? Waiting it to be merged, so we can use it. .
 @youyajie Thank you for notice this pr.  @cdrage and @hangyan are reviewing code , hope it will be merged soon :-) .
 @cdrage Sure. I am current working on the secret support, separate the commit can also reduce the potentially conflict.
 @cdrage @hangyan 
Already done these things
- Change PR name to `add support for Config, endpoint_mode and 3.3 support`
- Change this pr to three separate commits
- Add document

Pls review again if you are free, thanks..
 @cdrage Any update ?.
 @cdrage @xianlubird 

A few thoughts:

1. OpenShfit support should be added
2. About deploy mode. In my opinion, vip -> ClusterIP , dnsrr-> Headless .
 Also, the current implement of ConfigMap and Volumes Mount seems not correct. Please consider the following rules:

1. If target is optional, config name is `example`. the target path should be `/example`, so volumeMounts.mountPath = /  and volumeMounts.name=example and ConfigMap.Data=example:<data>

2. If target is set, say it's `/test`., config name is `example`. then volumeMounts.mountPath = / and volumeMounts.name=example and ConfigMap.Data=example:<data> and volumes. configMap. items[0].key = example and volumes. configMap. items[0].path=test

Please check this doc: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-volume

@cdrage @xianlubird 
.
 @hangyan 

1. OpenShfit will be implemented in another pr later, this pr focus on kubernetes
2. `VIP` means user can visit any `ip:port` in the cluster node, so it equals to `NodePort` service.  ClusterIP can't be visited outside the cluster. `dnsrr` means user can use service name to connect, so in k8s, a normal service type can connect through service name. .
 @xianlubird 

1. OpenShift support is just a few commands, it would't take many time. I don't think it's a good idea to seperate this

2. According to the compose doc. `vip` mode acts like a normal load balancer, the client wouldn't known what the backends are. With NodePort, you have to known how many nodes are in the kubernetes  cluster, and what are there ips, I think these principle take preceder over the `access from outside of the cluster` rule.

`dnsrr` works very similar to Headless Service. In Headless service, when you do a dns-lookup for the service name, a range of ips will returned(the ip list of the pods). .
 @cdrage Please take a look at my reviews and share some of your thoughts on this.
 @hangyan 

1.  For `vip` mode, I don't agree with you.   In `vip` mode, user should use `ip:port` to visit service. User also should know node ip, it totally equals to `NodePort` service.   If convert to `Cluster IP`, how should user to visit service outside cluster?  Cloud they use node ip with port ?  It can not equals to `ClusterIP` type.

`dnsrr` means user visit `service name`, `headless` is a external service. I think `cluster ip` is better. Both of them can visit through `service name`, but `cluster ip` type is more used.

2. I am not similar to OpenShift. So this pr first name is `add support 3.3 for kubernetes`. It will cost much time for me to implement OpenShift. So I will implement it later in another pr.  And for OpenShift, I think it should split to another pr, it will more clear.


Need your opinion @cdrage .
 @cdrage @hangyan Discuss with @hangyan , I change some code for this pr:

- Ignore short syntax config. Because short syntax config mount path in `Deployment` must be `/`, but docker daemon don't allow mount path is `/`, so we have to ignore it.
- For long syntax config, if target path is `/`, ignore this. The reason is similar to above.
- Add openshift support, thanks @hangyan insist
- Change document according to @cdrage advice

Now this PR has become a `XXL` size, very exciting to see that it will be merged.

Thanks all for your review..
 @cdrage 
We still have some differences between @hangyan at which service type we should convert.

- For compose `network_mode: vip`, according to docker's document [link](https://docs.docker.com/engine/swarm/ingress/#publish-a-port-for-a-service), `vip` mode is the `swarm mode routing mesh`, equals to `docker service --publish`. So user can visit any node ip in the cluster, the address is `ip:port`.  It is especially like `NodePort` service in kubernetes cluster which user can visit any node ip in the cluster, the address is also `ip:port`.  

- For compose `network_mode: dnsrr`. This allow user to visit `service name` in a container in swarm mode cluster.  It's similar to `Cluster IP` type in kubernetes cluster. For `Headless` service type, it is very similar to compose attribute [external_links](https://docs.docker.com/compose/compose-file/#external_links).

Now we need @cdrage opinion to push this pr going on. Hope you have time to see this and give us some advice. So we can merge this important pr soon. :-)

Many thanks.  .
 @xianlubird For NodePort it's actually the user can visit any node *port*. You still have to figure out the IP. network_mode: vip in my opinion is closer to LoadBalancer.

I agree however with `dnsrr`. 

I will do another review in the next few days!.
 @cdrage any update on this ?  ..........
 @xianlubird @cdrage I have re-check the kubernetes documents, it seems like subPath(https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath) can bring the full support for compose `config`..
 @hangyan any progress?.
 @hangyan @xianlubird Minor conflicting file, otherwise this LGTM. I can do another review after the conflicted file is resolved!.
 @cdrage All check have passed.   conflicting solved..
 @xianlubird As i have point out before, subPath can bring the full support for compose config, otherwise this PR is too limited. @cdrage Or we can merge this first and create a new one to improve it .
 @hangyan Adding subPath may be best before merging, so that `config` support is fully supported (short-syntax and all).

Although to be honest, 3.3 support seems to be important as well as endpoint_mode. Maybe we should merge and then open an issue indicating that we should implement subPath / syntax support for config..
 @cdrage Let's merge this first so we can move on .
 @hangyan I agree. It's been way too long. Any issues that we encounter in the future can be resolved.

Merging this *massive* PR.

Special thanks to @xianlubird ! :100:  .
 "
kubernetes,kompose,993,"Fix doc that we have support v3.1 & 3.2.
 We have support v3.1 & 3.2

@hangyan @cdrage .
 LGTM!.
 "
kubernetes,kompose,992,"Fix golint warnings.
 Fix golint warning

```
golint ./cmd/... ./build/... ./pkg/... .
pkg/loader/compose/utils.go:37:2: comment on exported const ServiceTypeHeadless should be of the form ""ServiceTypeHeadless ...""
```

Pls @cdrage @hangyan help review. Thanks.
 The continuous-integration fail seems irrelevant to this change.    @hangyan .
 LGTM.
 "
kubernetes,kompose,991,"Remove incorrect logging about headless service.
 .
 LGTM.
 "
kubernetes,kompose,990,"Fix missing attribute when convert with multiple docker-compose files.
 Fix issue #972 and #968

A brief introdction:
- When multiple docker compose files are passed, we should parse every compose file and override previous object if next compose file has this field
- Docker compose merge multiple file, so we should do so
- This function is very useful
- First, I implemented the v3 compose version. Please @cdrage @hangyan help me review. If you guys accept this method, I will do the same thing to v2 compose version.

Thanks .

Signed-off-by: xianlubird <xianlubird@gmail.com>.
 @xianlubird Can you add some basic test for this PR?.
 @hangyan Done. Thanks.
 Any update @cdrage ?.
 I'll be able to do a few reviews next week, could you do a review @hangyan ?.
 Sure, will review this in a few days

?? Outlook for Android<https://aka.ms/ghei36>

________________________________
From: Charlie Drage <notifications@github.com>
Sent: Friday, April 27, 2018 9:28:05 PM
To: kubernetes/kompose
Cc: Hang Yan; Mention
Subject: Re: [kubernetes/kompose] Fix missing attribute when convert with multiple docker-compose files (#990)


I'll be able to do a few reviews next week, could you do a review @hangyan<https://github.com/hangyan> ?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/kubernetes/kompose/pull/990#issuecomment-384969697>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADwaxwXY7u1fv1pSn0cNLJf2DMTzzUbZks5tsxzlgaJpZM4TlBrd>.
.
 @hangyan @cdrage  I have factor code:

For some questions:

1. We also use kompose convert -f base.yml -f prod.yml ,  so that's match.

2. I have fixed this.

3. Already add openshift test case

Pls review again, if you have time. Thanks..
 waiting for #997  to fix ci.
 @hangyan I see #997 was merged, Pls review it again, Thank you.

@cdrage @hangyan I have rebase master branch and all checks have passed, pls review again.  Thanks..
 @hangyan Done..
 /lgtm.
 Thanks.
 "
kubernetes,kompose,989,"Fix typo in conversion.md.
 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 Good catch! Thanks @jonathanperret once the CLA is signed, this LGTM for merge..
 and I see it's just signed. Thanks!.
 "
kubernetes,kompose,988,"1.12.0 Release.
 "
kubernetes,kompose,987,"Typo fix.
 Change validated -> validates at line  159
```release-note
None
```.
 /lgtm.
 "
kubernetes,kompose,986,"FATA services.xxx.ports.0 must be a string or number.
 

```yml
    ports:
      - target: 5010
        published: 5010
        protocol: tcp
```.
 Sorry about the late response, i have checked the source code. Seems like a upstream bug. @cdrage .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/986#issuecomment-422753027):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,985,"Typo fix in conversion.md.
 Kubernetes uses it's own->Kubernetes uses its own.
 please merge the commits, one commit is enough.
 @hangyan 
Did you mean add some commits here?.
 No, merge the two commits into one. .
 Hi @hangyan,
I am sorry. I really do not know how to modify two files in one commit.
I just learned how to put several commits in one PR. Please can you tell me?.
 https://stackoverflow.com/questions/2563632/how-can-i-merge-two-commits-into-one?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa.
 There is a built-in ""squish and merge"" button on GitHub so I've gone ahead and done that.

@AdamDang next time just merge commits / only use one commit :+1: .
 "
kubernetes,kompose,984,"Typo fix in glide.yaml.
 Line 80: 
""it this case it is OK""->""in this case it is OK"".
 There is no need to create sperate PRs to fix the typo. Please merge the commits into one PR and do not do this again! Will close this PR. .
 @hangyan
It's put together into #985.
 "
kubernetes,kompose,983,"Fix some typo.
 Signed-off-by: xianlubird <xianlubird@gmail.com>.
 @cdrage @kadel.
 /lgtm.
 "
kubernetes,kompose,982,"Should we provide a go library to support the third-party integration ? .
 From the code, we can see that kompose read file from local disk. But In many circumstances , we want a string which contains all compose content as a input.  Thought change code to string is feasible,  we'd better support a library that can use as a library ?.
 duplicate with #464. Will close this and disscus there.
 "
kubernetes,kompose,981,"typo fix.
 typo fix
```release-note
None
```.
 @jonyhy96  Since this PR is very similar to #980, can you merge the commits and only open one PR, there is no need to create seperate PRs..
 @hangyan 
Thansk for your reply and i will close the other PR..
 @jonyhy96 Since you have create a PR to fix the `initialize` typo, can you fix all the same typo that appears in the code ?.
 @hangyan 
I think i already fix all the initialize typo in this code.
Please help me to specify where the same typo is and i will correct it.
Thx..
 ```
github.com/kubernetes/kompose ∙ grep ""initialize"" -R * |grep -v vendor                                                                                           130 ↵ ᚴ master 3≡
Binary file kompose matches
pkg/app/app.go:		// Create/Init new OpenShift object that is initialized with a newly
pkg/transformer/openshift/openshift.go:// initImageStream initialize ImageStream object
pkg/transformer/openshift/openshift.go:// initDeploymentConfig initialize OpenShifts DeploymentConfig object
pkg/transformer/openshift/openshift.go:	// initialize OpenShift Client
pkg/transformer/kubernetes/kubernetes.go:// InitRC initializes Kubernetes ReplicationController object
pkg/transformer/kubernetes/kubernetes.go:// InitSvc initializes Kubernetes Service object
pkg/transformer/kubernetes/kubernetes.go:// InitConfigMap initialized a ConfigMap object
pkg/transformer/kubernetes/kubernetes.go:// InitD initializes Kubernetes Deployment object
pkg/transformer/kubernetes/kubernetes.go:// InitDS initializes Kubernetes DaemonSet object
pkg/transformer/kubernetes/kubernetes.go:// CreatePVC initializes PersistentVolumeClaim
pkg/transformer/kubernetes/kubernetes.go:// InitPod initializes Kubernetes Pod object
```

@jonyhy96 .
 @hangyan 
Thanks for your help.
I will fix this as soon as possible.
Hope one day i can be a great coder just like you.:D.
 @hangyan
I think i already fix all initialize typo.How do you think?.
 looks good. you can merge all the commits into one and a little suggestion: also fix the commit message. (you can check this article: https://chris.beams.io/posts/git-commit/)

@jonyhy96 .
 @hangyan 
Thanks for your help!You are really a nice person!
I'm still a newbie on this and i wll watch out this in the future!:D.
 /lgtm.
 Thanks all :+1: This LGTM too!.
 Wouldn't be better for him to merge the commits before we merge this PR..
 Woops. I didn't catch that. My mistake! I should of pressed the ""merge commits"" button. But yes, it should of been merged into one. .
 "
kubernetes,kompose,980,"typo fix.
 typo fix
```release-note
None
```.
 Already fix in [typo fix](https://github.com/kubernetes/kompose/pull/981)
close it.
 "
kubernetes,kompose,979,"Add headless service type label.
 Also remove the relation between restart and service create.
 close #851 .
 @cdrage @kadel Help me review this if you guys have time..
 LGTM! :+1: .
 "
kubernetes,kompose,978,"Fix typos in comments.
 .
 LGTM.
 "
kubernetes,kompose,977,"Update dev doc about make gen-cmd.
 .
 LGTM.
 "
kubernetes,kompose,976,"Support hostname and domainname.
 .
 @cdrage @kadel Help me review this if you guys have time..
 @hangyan Honestly, this is great code :+1: thank you so much for adding these two new keys! This LGTM. @kadel mind taking a small / quick overview in-case I've missed something? From the code, it looks quite straight-forward (just adding two lines of code really to the main 'v3' and 'v2' conversion sections).
 @cdrage yeah, this is not a big change, just found some usercase in the issues so i added them..
 "
kubernetes,kompose,975,"Remove status field in the generated yaml.
 status field seems uncommon in the resource yaml(deployment,daemonset....) before apply..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,974,"Fix typos in Makefile.
 Closes #971.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 Hey @jaden-young thanks for the PR! Once you have signed the CLA we will be able to merge this :).
 I've signed the CLA..
 /lgtm .
 @jaden-young Thanks for you contribution! .
 @cdrage Seems there are some errors after merge this PR, i'm looking on it..
 That's interesting, my apologies for not testing. Are/were there files living somewhere with the target names?.
 @jaden-young It's weird, the CI test for PR is OK. still looking on it. .
 @cdrage Can you help restart the build or locate the error? Didn't find out why the build failed!.
 Looks like CI passes now :+1: Odd that it did that!.
 "
kubernetes,kompose,973,"typo fix.
 typo fix
```release-note
None
```.
 thank you @jonyhy96 .
 @kadel  
Thanks for your reply and wish you have a good day!:D.
 "
kubernetes,kompose,972,"Environment value merge failed with multiple docker-compose files.
 This may relate to Issue #968. 

Environment value is unable to merge and replaced by the last docker-compose file.
Merge with command `kompose convert -o dev-out.yaml -f base.yaml -f dev.yaml`

base.yaml
```
version: '3'

services:
  web:
    image: richarvey/nginx-php-fpm
    environment:
      - ERRORS=0
      - HIDE_NGINX_HEADERS=0
      - REMOVE_FILES=0
      - RUN_SCRIPTS=0
      - PHP_ERRORS_STDERR=0
      - ENABLE_XDEBUG=0
```

dev.yaml
```
version: '3'

services:
  web:
    environment:
      - ERRORS=1
      - HIDE_NGINX_HEADERS=0
      - REMOVE_FILES=0
      - RUN_SCRIPTS=1
      - PHP_ERRORS_STDERR=1
      - ENABLE_XDEBUG=1

```

But the dev-out.yaml shows
```
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kompose.cmd: kompose convert -o dev-out.yaml -f base.yaml -f dev.yaml
      kompose.version: 1.11.0 ()
    creationTimestamp: null
    labels:
      io.kompose.service: web
    name: web
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: web
  status:
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      kompose.cmd: kompose convert -o dev-out.yaml -f base.yaml -f dev.yaml
      kompose.version: 1.11.0 ()
    creationTimestamp: null
    labels:
      io.kompose.service: web
    name: web
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
      spec:
        containers:
        - env:
          - name: ENABLE_XDEBUG
            value: ""0""
          - name: ERRORS
            value: ""0""
          - name: HIDE_NGINX_HEADERS
            value: ""0""
          - name: PHP_ERRORS_STDERR
            value: ""0""
          - name: REMOVE_FILES
            value: ""0""
          - name: RUN_SCRIPTS
            value: ""0""
          image: richarvey/nginx-php-fpm
          name: web
          resources: {}
        restartPolicy: Always
  status: {}
kind: List
metadata: {}
```

The environment value of the container is unable to replace by the `dev.yaml`..
 close by #990 .
 "
kubernetes,kompose,971,"Minor typos in Makefile.
 https://github.com/kubernetes/kompose/blob/39ad6140c33d35954aed38a66155f4ac392ce547/Makefile#L70-L71
Should probably be
```Makefile
.PHONY gen-cmd
gen-cmd:
```
and
https://github.com/kubernetes/kompose/blob/39ad6140c33d35954aed38a66155f4ac392ce547/Makefile#L129
Should probably be
```Makefile
.PHONY test-k8s
```.
 @jaden-young Thanks for point out this ! Would you mind to create a PR to fix this?.
 "
kubernetes,kompose,970,"1.11.0 Release.
 "
kubernetes,kompose,969,"Cannot kompose up.
 Hi, I've been working on some docker project and wanna transform them into a kubernetes cluster. 
```
➜  iotanode_dockerized git:(master) kompose -f docker-compose.yml convert
WARN Unsupported hostname key - ignoring
WARN Volume mount on the host ""./volumes/iota/iota.ini"" isn't supported - ignoring p
ath on the host
WARN Volume mount on the host ""./volumes/iota/ixi"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""./volumes/iota/mainnetdb"" isn't supported - ignoringpath on the host
WARN Volume mount on the host ""/etc/localtime"" isn't supported - ignoring path on the host
INFO Kubernetes file ""iri-node-service.yaml"" created
INFO Kubernetes file ""iri-node-deployment.yaml"" created
INFO Kubernetes file ""iri-node-claim0-persistentvolumeclaim.yaml"" created
INFO Kubernetes file ""iri-node-claim1-persistentvolumeclaim.yaml"" created
INFO Kubernetes file ""iri-node-claim2-persistentvolumeclaim.yaml"" created
INFO Kubernetes file ""iri-node-claim3-persistentvolumeclaim.yaml"" created
```

The convert went okay but when I try to kompose up, here's what happens: 
```
➜  iotanode_dockerized git:(master) ✗ kompose -f iri-node-deployment.yaml up
ERRO Could not parse config for project iotanodedockerized : yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `extensi...` into config.RawService
  line 2: cannot unmarshal !!str `Deployment` into config.RawService
FATA composeObject.Parse() failed, Failed to load compose file: yaml: unmarshal erro
rs:
  line 1: cannot unmarshal !!str `extensi...` into config.RawService
  line 2: cannot unmarshal !!str `Deployment` into config.RawService
➜  iotanode_dockerized git:(master) ✗ kompose up
WARN Unsupported hostname key - ignoring
FATA Error while deploying application: k.Transform failed: image key required withi
n build parameters in order to build and push service 'iri-node'
```

Here's my docker-compose file : 
```
version: '2'

services:
  iri-node: 
    build:
      context: ./iri
      dockerfile: Dockerfile
    container_name: iri-running
    hostname: iota
    volumes: 
      - ./volumes/iota/iota.ini:/iri/iota.ini:ro
      - ./volumes/iota/ixi:/iri/ixi:rw
      - ./volumes/iota/mainnetdb:/iri/mainnetdb:rw
      - /etc/localtime:/etc/localtime:ro
    expose: 
      - ""5556""
    ports: 
      - ""14600:14600/udp""
      - ""15600:15600/tcp""
      - ""14265:14265""
```.
 Here's how to recreate the bug : 
1) Clone the project here: https://github.com/huntal/iotanode_dockerized
2) `kompose -file docker-compose.yml convert`
3) `kompose up` or `kompose -f ... up` .
 @huntal https://github.com/huntal/iotanode_dockerized/blob/master/docker-compose.yml#L1 shows ""2.3"" for version, have you tried setting it as ""2"" or even ""3""?.
 Yes, I've tried, I know that kompose does not support 2.3 version. Tried in version 2..
 @huntal  Can you try `kompose -f docker-compose.yml up` ?.
 Here's the output @hangyan 
```➜  iotanode_dockerized git:(master) ✗ kompose -f docker-compose.yml up
WARN Unsupported hostname key - ignoring
FATA Error while deploying application: k.Transform failed: image key required within build parameters in order to build and push service 'iri-node'```.
 @huntal According to the docker-compose doc, https://docs.docker.com/compose/compose-file/#build, you need to specific the `image` key.
 @hangyan thanks for this precision, so i modified my docker-compose file like this : 
```
version: '2'

services:
  iri-node: 
    build:
      context: ./iri
      dockerfile: Dockerfile
    image: iri-node:tag
    container_name: iri-running
    hostname: iota
    volumes: 
      - ./volumes/iota/iota.ini:/iri/iota.ini:ro
      - ./volumes/iota/ixi:/iri/ixi:rw
      - ./volumes/iota/mainnetdb:/iri/mainnetdb:rw
      - /etc/localtime:/etc/localtime:ro
    expose: 
      - ""5556""
    ports: 
      - ""14600:14600/udp""
      - ""15600:15600/tcp""
      - ""14265:14265""
```
And when i try again to start `kompose -f docker-compose.yml up`, here's what happening : 
```
➜  iotanode_dockerized git:(master) ✗ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have aDocker ID, head over to https://hub.docker.com to create one.
Username (hystenal): hystenal
Password:
Login Succeeded
➜  iotanode_dockerized git:(master) ✗ kompose -f docker-compose.yml up
WARN Unsupported hostname key - ignoring
INFO Build key detected. Attempting to build and push image 'iri-node:tag'
INFO Building image 'iri-node:tag' from directory 'iri'
INFO Image 'iri-node:tag' from directory 'iri' built successfully
INFO Pushing image 'library/iri-node:tag' to registry 'docker.io'
INFO Multiple authentication credentials detected. Will try each configuration.
INFO Attempting authentication credentials 'https://index.docker.io/v1/
ERRO Unable to push image 'library/iri-node:tag' to registry 'docker.io'. Error: denied
: requested access to the resource is denied
INFO Attempting authentication credentials 'registry.gitlab.com
ERRO Unable to push image 'library/iri-node:tag' to registry 'docker.io'. Error: unauthorized: incorrect username or password
FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service iri-node: unable to push docker image(s). Check that `docker login` workssuccessfully on the command line
```
I am login on the right account btw.
 https://github.com/kubernetes/kompose/issues/911
This may be the issue for that i'm checking and closing this issue if it's the case.
 So I had some error in my Dockerfile build and fix it to get it correctly working, now i got another error coming from issue 911 so i'm closing this one .
 @huntal Ok, we will keep tracking on that one.
 Hi , i'm facing this issue today. Does fix applied to the latest release?

Thanks,.
 Me too guys, I Faced this issue today. Any updates?.
 same here please help.
 Putting ""image: image-name""on the service to build solves this problem, but I have encountered other problem... 

```yaml
template-nodejs-backend:
    image: 'template-nodejs-backend'
    build:
        context: '.'
        dockerfile: Dockerfile
    ports:
      - ""8001:8000""
    networks:
      - nodejs-backend-network
    environment:
      MYSQL_HOST: ""mysql""
      GET_HOSTS_FROM: dns
    depends_on:
      - 'mysql'
```

The other problem that appears after that is: 
`FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service template-nodejs-backend: Unable to create a tarball: archive/tar: write too long`

Maybe you guys putting just the name on the image solves your problem. I am still trying to figure it out how to solve the next poblem, if you guys know anything please let me know.. 

.
 The below command works with me 
`kompose up --provider=openshift --build=""build-config"" -v --file docker-compose-CeleryExecutor.yml`
and this error appeared
`FATA Error while deploying application: Get https://openshift-.com:443/api: x509: certificate signed by unknown authority`.
 "
kubernetes,kompose,968,"Merge multiple docker-compose files.
 Hey,

First of all, thanks for this great project,
I've run into a very basic issue, when having two docker-compose files, ie:

docker-compose.yml
```
version: '3'

services:
  server:
    image: test
    container_name: test_server
    build:
      context: .
      dockerfile: Dockerfile-dev
    ports:
      - 3000:3000
```

docker-compose.prod.yml
```
version: '3'

services:
  server:
    ports:
      - 5000:5000
```

With ```kompose convert -f ""docker-compose.yml"" -f ""docker-compose.prod.yml"" ```, there is :
```   
     - name: ""3000""
      port: 3000
      targetPort: 3000
[...]
      spec:
        containers:
        - image: test:dev
          name: test_server
          ports:
          - containerPort: 3000
```
But nothing about port 5000. (with kompose 1.10.0 (8bb0907), on ubuntu 16.04)

I've seen the PR #312 , but they didn't speak about merging multiple docker-compose files.
Is it planned for a future release ?
 
Thanks.
 @nathan-K- Yeah.. I think the multiple file support is kind of broken for now. We will trying to fix this ASAP. But about merge thing need a little discus.  If docker-compose will merge different files content, may be we should do it too..
 Ok, great !
Yep, they did, in my example a ```docker-compose -f ""docker-compose.yml"" -f ""docker-compose.prod.yml"" up``` will map ports 3000 and 5000. 
It is [here](https://docs.docker.com/compose/reference/overview/#specifying-multiple-compose-files) in the documentation of docker-compose, if it can help..
 @nathan-K- Ok, I will check it out..
 You can simply run this to generate a config to feed to kompose: `docker-compose -f docker-compose.yml -f docker-compose.override.yml config > kompose.yml` and then run: `kompose up -f kompose.yml`.
 close by #990 .
 "
kubernetes,kompose,967,"Fix golint warnings.
 .
 "
kubernetes,kompose,966,"Unable to kompose up my django container from windows or azure cloudshell..
 ```
version: '2' 

volumes:
  postgres_data_local: {}
  postgres_backup_local: {}

services:
  django: &django
    build:
      context: .
      dockerfile: ./compose/local/django/Dockerfile
    image: enjoithesk8life/test_respo:django
    depends_on:
      - postgres
    volumes:
      - .:/app
    environment:
      - POSTGRES_USER=nh2d
      - USE_DOCKER=yes
    ports:
      - ""8000:8000""
    command: /start.sh

  postgres:
    build:
      context: .
      dockerfile: ./compose/production/postgres/Dockerfile
    volumes:
      - postgres_data_local:/var/lib/postgresql/data
      - postgres_backup_local:/backups
      - /var/lib/postgresql:/var/run/postgresql
    environment:
      - POSTGRES_USER=nh2d


  redis:
    image: redis:3.0

  celeryworker:
    # https://github.com/docker/compose/issues/3220
    <<: *django
    image: enjoithesk8life/test_respo:celeryworker
    depends_on:
      - redis
      - postgres
    ports: []
    command: /start-celeryworker.sh

  celerybeat:
    # https://github.com/docker/compose/issues/3220
    <<: *django
    image: enjoithesk8life/test_repo:celerybeat
    depends_on:
      - redis
      - postgres
    ports: []
    command: /start-celerybeat.sh
```


From cookie-cutter django. Did not change much. Just trying to test a deploy here.... I get

>  [33mWARN[0m Unsupported root level volumes key - ignoring
> [33mWARN[0m Unsupported depends_on key - ignoring
> [36mINFO[0m Build key detected. Attempting to build and push image 'enjoithesk8life/test_repo:django'
> [36mINFO[0m Building image 'enjoithesk8life/test_repo:django' from directory 'E:\projects\hoos_feeding\src\hoos_fed'
> [31mFATA[0m Error while deploying application: k.Transform failed: Unable to build Docker image for service django: open \tmp\kompose-image-build-929081207: The system cannot find the path specified.
> 
> 

From powershell.

When I tried in azure cloudshell I get an error at same point but with different message:

>  navid@Azure:~/clouddrive/hoos_feeding/src/hoos_fed$ ../../../kompose --file local.yml up
> WARN Unsupported root level volumes key - ignoring
> WARN Unsupported depends_on key - ignoring
> INFO Build key detected. Attempting to build and push image 'enjoithesk8life/test_repo:celerybeat'
> INFO Building image 'enjoithesk8life/test_repo:celerybeat' from directory 'hoos_fed'
> FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service celerybeat: Unable to build image. For more output, use -v or --verbose when converting.: dial unix /var/run/docker.sock: connect: no such file or directory.
 I believe kompose have bot been well tested on windows....
 Has any progress been made on this? Getting the same error.
 Same issue..
 I have the same problem.
 Hardcoded path to /tmp is probably the cause

https://github.com/kubernetes/kompose/blob/5633b7bff587c7ff11434470fabd3d19cd1840f6/pkg/utils/docker/build.go#L46.
 @mixas27 @y12at @nrsattele @nh2d Merge a PR to fix this,  give it another try if you guys willing to..
 Still getting this issue on windows version `1.16.0 (0c01309)`

    FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service admin-mongo: open \tmp\kompose-image-build-354181415: The system cannot find the path specified.
.
 "
kubernetes,kompose,965,"Create Rolling updates using Kompose tool.
 Hi ,
I had deployed a service in Kubernetes using Kompose Up <Dockerfile>. Now my docker image has changed and I want to update the container image in the already deployed Pod. If I perform Kompose up from the same dockerfile will that patch my container  ? If not what should I do to perform the image patching alone.

.
 @VenkateshSrini Good question.

The answer is using `kubectl apply`.

Using: `kompose convert --stdout | kubectl apply -f -` you can redeploy / apply your docker-compose.yaml file.

Perhaps in the future we should add a `kompose update` command to Kompose..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,964,"Support ubuntu's snap package format.
 (of course very low priority.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,963,"Add hangyan to OWNERS.
 Congratulations @hangyan :tada: :tada: :tada: :tada: :tada: .
 Thanks!. Still trying to find my country code in the phone setup...

On 20 Mar 2018, at 10:59 PM, Charlie Drage <notifications@github.com<mailto:notifications@github.com>> wrote:


Congratulations @hangyan<https://github.com/hangyan> 🎉 🎉 🎉 🎉 🎉

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/kubernetes/kompose/pull/963#issuecomment-374629435>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADwaxyw_IdexvHI3pu6ubE1LMSIeKyi8ks5tgRk3gaJpZM4SyCiD>.

.
 "
kubernetes,kompose,962,"kompose up is not able to mount configmap volume.
 kompose up
←[36mINFO←[0m We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources,
 use the 'kompose convert' and 'kubectl create -f' commands instead.

volumeMounts:
        - name: my-appl-path
          mountPath: /opt/app/properties
      volumes:
        - name: my-appl-path
          configMap:
            name: my-app-1

I have created config map with kubectl create configmap.
is my yaml file.  Could you please check this issue
.
 Hi, are you able to post your full `docker-compose.yaml` file? @abhi-vaidya so we may test it out / diagnose the issue?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,961,"fix pod-controller relationship mistake.
 fix pod-controller relationship mistake
```release-note
None
```.
 LGTM.
 "
kubernetes,kompose,960,"Fix deploy resources parse error.
 fix #959 .
 @cdrage .
 This LGTM. Thanks @hangyan !.
 "
kubernetes,kompose,959,"Kompose fails on version 3 with deploy-resources-limits (panic: runtime error: invalid memory address or nil pointer dereference).
 Using kompose version 1.10.0 (8bb0907) on Ubuntu 16.04 and converting using 
```
kompose convert -f b.yaml
```

-----

b.yaml:

```
services:
  haproxydocker:
    command: haproxy -f /etc/haproxy/haproxy_dsp.cfg
    environment:
      BACKEND_1_IP: 192.168.1.105
    image: haproxy
    network_mode: host
    restart: always
    deploy:
      resources:
        limits:
          memory: 256m
version: ""3""
```
---------
I get following error:
```
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x1622d57]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc420010600, 0x1c, 0xc420133c20, 0x1, 0x1, 0xc4201a5e60)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:267 +0xfe7
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc42052db70, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x1bec580)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x2b1f0d8, 0xc42052db70, 0x1, 0x1, 0xc4201a5830, 0x0, 0x1a, 0x7f6a9adfcd50, 0x454d10)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:186 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x1cac29c, 0x4, 0x0, 0x1cc0501, 0x15, ...)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/pkg/app/app.go:232 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x2aec8e0, 0xc42045f900, 0x0, 0x2)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x2aec8e0, 0xc42045f8c0, 0x2, 0x2, 0x2aec8e0, 0xc42045f8c0)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x2aecd20, 0x2aed160, 0x18a1b60, 0x2aece60)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x2aecd20, 0x0, 0xc420275f48)
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/home/wikus/seafile/files/dev/go/src/github.com/kubernetes/kompose/main.go:22 +0x20
```
-----

If I comment out deploy section:
```
    # deploy:
      # resources:
        # limits:
          # memory: 256m
```
it works OK and creates deployment and service. yaml

To be sure that this is docker-compose.yaml (b.yaml) is valid synthax I also checked with
docker-compose -f b.yaml config
and it works OK (used docker-compose version 1.19.0, build 9e633ef)






.
 When I add services.deploy.resources.reservations it works OK.

```
services:
  haproxydocker:
    command: haproxy -f /etc/haproxy/haproxy_dsp.cfg
    environment:
      BACKEND_1_IP: 192.168.1.105
    image: haproxy
    network_mode: host
    restart: always
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: '0.01'
        reservations:
          cpus: '0.01'
          memory: 128M
version: ""3""
```.
 I will take a look.
 Can confirm this behavior on `kompose` version 1.10.0. Furthermore, I have found out that *the only way this works* is if (1) both `limits` and `reservations` are defined and (2) both sections have `cpus` and `memory` defined. Any other combination will not work correctly.

Most combinations result in SIGSEV. However, I noticed that if one defines everything _except_ for the `cpus` key for `limits`, then one gets this error message:

```
FATA Unable to convert cpu limits resources value: strconv.ParseFloat: parsing """": invalid syntax
```

This leads me to believe that the problem is that, somewhere in the `kompose` code, the function responsible for parsing this `resources` section incorrectly assumes that there is always a `cpus` option specified.

Hope this information helps! A fix would be greatly appreciated..
 Hey @malcolmgreaves Please try out https://github.com/kubernetes/kompose/pull/960 :) I believe we've fixed this..
 "
kubernetes,kompose,958,"How do I Specify the instance count via docker -compose file for Kompose.
 Hi,
I have a docker compose file as below

`version: '3'
services:
  worker:
    image: dockersamples/examplevotingapp_worker
    networks:
      - frontend
      - backend
    deploy:
      mode: replicated
      replicas: 6`

Will kompose automatically specify as by replica count in deployment yaml file ? If not what is the way to achieve this ?

Thanks.
 kompose will take replica from docker-compose file, if you still want to override that value. you can mention it using `--replicas` flag.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,957,"Support hostpath volume.
 fix #876 #109 .
 This code LGTM! Thanks @hangyan :+1: .
 "
kubernetes,kompose,956,"Refactor tests script to uses vars.
 less is more ~.
 @cdrage @surajnarwade any thoughts?.
 @hangyan Woops, missed this PR. This is much cleaner! :+1: Thanks!.
 "
kubernetes,kompose,955,"Add script for generating deb / rpm packages.
 Adds a script to generate deb / rpm packages on release day..
 "
kubernetes,kompose,954,"Add support for compose v3.2.
 fix #865 . 

My opinion is : Since we have declaim that we support volume's long syntax, and it's a feature only supported by compose v3.2+, it's better to allow uses to convert docker compose files with version=3.2. .
 @hangyan honestly, I don't see why not. The only differences with 3.1 and 3.2 is the long volume syntax. This LGTM..
 "
kubernetes,kompose,953,"Remove bintray instructions.
 Bintray forced us into an ""enterprise"" plan and then cut access off
unless we contacted supported.

For now, we are removing bintray details until we have a good
alternative..
 "
kubernetes,kompose,952,"Correct DL-link to latest kompose in installation guide.
 Hi kompose-Team,

thanks for your efforts. I just figured out that your bintray is not available, but you point your installation guide on it.
Or am I missing something?

BR Mehmet.
 Hi @marziman we've been having problems lately with Bintray.

I would suggest installing `kompose` via one of our latest releases or alternatively, you can build it from master.

A fix should go into the `README.md` in the next few days.

Many thanks..
 Hi @marziman I've opened up PR https://github.com/kubernetes/kompose/pull/953 to remove installation instructions. I will be investigating an alternative platform for go-to nightly / master builds..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,951,"1.10.0 Release.
 "
kubernetes,kompose,950,"Support old restart policy in compose v3.
 related to #876 .
 LGTM .
 @hangyan one last thing, can you please add documentation stating that we are converting `unless-stopped` restart policy to `always`.
 @surajnarwade thanks, I will remeber this in the feature PRs..
 Awesome! Tests pass and this looks great to me :+1: merging!.
 "
kubernetes,kompose,949,"Fix broken links for volume long syntax in comments.
 .
 "
kubernetes,kompose,948,"Refactor label names to const strings.
 .
 LGTM!.
 "
kubernetes,kompose,947,"Remove RC from supported workload.
 Accoding to the documents, (https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/), RC is not recommended any more. Deployment is the replacement.
 +1 @hangyan .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,946,"Fix image build path error.
 should fix #944 .
 @cdrage Can't get enough information about why semaphoreci would failed.
 Hate asking, but any way to add a test? :smile: 

The SemaphoreCI error (OpenShift) is a false positive..
 @cdrage  my apologize, not familiar with the tests for now, i will figure it out and add some tests..
 @cdrage tests added. Please take a look.
 Thanks again @hangyan this works and tests are great :100: Merging!.
 "
kubernetes,kompose,945,"Add HTTPS support for download URLs.
 HTTPS on https://kompose.io/ is broken. Because GitHub doesn't support HTTPS on custom domains - https://stackoverflow.com/questions/42172216/is-it-possible-to-use-https-ssl-on-github-pages-sites-with-a-custom-domain - one of the solutions is to use Netlify - https://www.netlify.com/docs/ssl/.
 Thanks @abitrolly :) for the useful information.
cc: @cdrage .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 This now can be fixed properly by projects admins https://blog.github.com/2018-05-01-github-pages-custom-domains-https/.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Now there could be a redirection from http://kompose.io/ to https version..
 "
kubernetes,kompose,944,"Kompose doesn't find dockerfile with context ..
 I think I have find two errors:

1 - kompose us searching for context related to directory from where it is run, not from where docker-compose.yml file is located

> kompose up -f docker/docker-compose-dev.yml -v
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service backend-server: ../server is not a valid path for building image backend-server. Check if this dir exists.: stat ../server: no such file or directory

2 - kompose fail to look for dockerfile (if the context is not in a subdirectory ?)  -- could be related: https://github.com/kubernetes/kompose/issues/809 & https://github.com/kubernetes/kompose/issues/832

Error: `{""message"":""Cannot locate specified Dockerfile: Dockerfile""}`

Note that docker-compose work well here.
--- 

Structures
```yaml
docker/ -- docker-compose files
   docker-compose-dev.yml 
server/ -- back-end
web/ -- front-end
````

docker-compose-dev.yml 
```yaml
version: '3'

services:
  backend-server:
    image: backend-server:dev
    build:
      context: ../server
      dockerfile: Dockerfile
    volumes:
      - ../templates:/usr/src/templates
    env_file:
      - ../docker_env.list
    ports:
      - 5000:4000

  front-end:
    image: front-end:dev
    build:
      context: ../web
      dockerfile: Dockerfile
    volumes:
      - ../web/src:/usr/src/web/src
      - ../web/config:/usr/src/web/config
      - ../web/build:/usr/src/web/build
      - ../web/static:/usr/src/web/static
    env_file:
      - ../docker_env.list
    ports:
      - 8080:8080
    depends_on:
      - backend-server
```.
 Hey there! There was some effort pushed towards fixing this for build, but the contributor refused to sign the CLA. I believe the same / similar code could be created for using `context`.

But yes, this is currently a problem..
 "
kubernetes,kompose,943,"1.9.0 Release.
 "
kubernetes,kompose,942,"Coordinated efforts / centralized location for packages..
 As per a comment by @kadel here: https://github.com/kubernetes/kompose/issues/822

We've got:

- MacOS  - [Homebrew](https://brew.sh/) ([package exists](http://formulae.brew.sh/formula/kompose) and it looks like updates are somehow automated )
- Windows  - [Chocolatey](https://chocolatey.org/)
- DEB systems (Ubuntu/Debian) - using  [PPA](https://launchpad.net/ubuntu/+ppas)
- RPM systems (Centos/Fedora - using [Copr](https://copr.fedorainfracloud.org/) 
- ArchLinux - [AUR](https://aur.archlinux.org) ([package exists](https://aur.archlinux.org/packages/kompose-bin/) but updates are not automated)

We not only need to document each release, but also coordinate our efforts that each release of Kompose is also updated upstream / their respective providers.

Let's use this issue to coordinate our efforts..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/942#issuecomment-429061306):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,941,"Support for multi-port services.
 From the documentation it sounds like multi-port services aren't supported?

http://kompose.io/user-guide/#labels
> If multiple ports are defined in a service, the first one is chosen to be the exposed.

https://kubernetes.io/docs/concepts/services-networking/service/#multi-port-services

This seems like a pretty basic feature, and the simplest example requirement is an http service that allows redirect from port 80 to 443. Any reason why only 1 port is supported, and if there are plans on supporting multi-port services?.
 Actually it supports multi-port services for me(I'm using the latest version).

You can try to convert one docker-compose file and then close this issue ;).
 @ghostsquad , as @wrfly mentioned, it does support multi-port services.
I tried it using latest kompose and it worked :).
 "
kubernetes,kompose,940,"Accept nested path such as ""build: ./foo/bar"" in kompose up.
 In `kompose up`, building docker image but throws ""Cannot locate specified Dockerfile"" because `path.Base` removes parent directory path segments. I think that a nested path should be accepted.

For instance, in the case of #809, ""./package/business_api"" is modified to ""business_api"" by `path.Base`. However `os.Stat` verifies the existence of `service.Build` before the lines.

It's difficult to test `BuildDockerImage`, so I extracted `resolveImagePathAndName` from the func then modify it and add testing.

I have no idea why using `path.Base`. If having some reasons to make a sense, could you please write it as a comment? I will accept any reason and you can close this anytime. Thanks!.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 @k24 , Please sign the CLA first.
 Sorry, I decline this. Thank you..
 "
kubernetes,kompose,939,"depends_on with conditions.
 Hi,

Does kompose support the following contruct?

```
    depends_on:
      reference-discovery-app:
        condition: service_healthy
      reference-config-app:
        condition: service_healthy
```
.
 Hey @matt-shaw , we don't support `depends_on` key yet. 
Refer this matrix for more info: http://kompose.io/conversion/.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,938,"Fix custom output and charts conflict error.
 fix #886 

@cdrage I didn't find a correct way to add test for  this change. So can you help me with this?

After this change, the logic now becomes:

assume there is a yaml in /tmp/a.yaml

* -c : results in /tmp/a/
* -c -o /tmp/charts : results in /tmp/charts/ (yaml in /tmp/charts/templates)
* -o /tmp/charts: results in /tmp/charts 
*  no args: results yaml in current dir

.
 To be honest @hangyan I don't think there are *any* tests written at the moment for charts. I'll review this soon however and test it out before we merge this in!.
 @cdrage I have add some simple tests for charts and cutom output working together, I think it's enough for now.
 Thanks so much for all these recent contributions! Tests pass and code LGTM :+1: .
 @cdrage Glad that I can help, hoping to do more contribute to this greate project.
 "
kubernetes,kompose,937,"Variable name should not be the same as imported package name.
 .
 @surajnarwade @cdrage CI seems unstable...
 @hangyan Yeah, looks like the Fedora build system went down temporarily. I've gone ahead and restarted the build..
 @cdrage  how do i re-trigger the build?.
 @hangyan If you do a force update, it can re-trigger the build (for example, using `git commit --amend` and amending the message and updating the PR).

I've triggered a rebuild manually however...
 @cdrage CI passed.
 "
kubernetes,kompose,936,"Fix healthcheck parser nil pointer error.
 fix #934 .
 Thanks for writing those tests as well. Tests pass and code LGTM! Thank you!.
 "
kubernetes,kompose,935,"Add doc for volume size label.
 With this should close #872 .
 What @abitrolly said ^^. Other than those two comments. LGTM..
 @cdrage @abitrolly updated, thanks!.
 LGTM! :+1: .
 "
kubernetes,kompose,934,"panic: runtime error: invalid memory address or nil pointer dereference SIGSEGV related to Healthcheck.
 Similar to #918 and #892 but slightly different cause.
This one is triggered by the `healthcheck`, this runs if `healthcheck` is removed.
This may have been fixed in #926 but I'm unable to test that yet.
```yml
version: '3'

services:

  postgres:
    image: postgres
    healthcheck:
      test: psql postgres --command ""select 1""
    ports:
      - ""5432:5432""
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: postgres

  broker_app:
    image: dius/pact-broker
    ports:
      - ""80:80""
    links:
      - postgres
    environment:
      PACT_BROKER_DATABASE_USERNAME: postgres
      PACT_BROKER_DATABASE_PASSWORD: password
      PACT_BROKER_DATABASE_HOST: postgres
      PACT_BROKER_DATABASE_NAME: postgres
```

```bash
$ kompose convert -f docker-compose.yml
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2220748]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.parseHealthCheck(0xc4200a9b80, 0x2, 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:190 +0x78
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc42037f580, 0x25, 0xc4200a86e0, 0x1, 0x1, 0xc42048a570)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:255 +0x11b2
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc4203dd3f0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27ea960)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3724c40, 0xc4203dd3f0, 0x1, 0x1, 0xc42048a120, 0x0, 0x0, 0xc, 0x8)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:186 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x28aa4b8, 0x4, 0x0, 0x28be4a7, 0x15, ...)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36f2960, 0xc420179f20, 0x0, 0x2)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36f2960, 0xc420179ee0, 0x2, 0x2, 0x36f2960, 0xc420179ee0)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36f2da0, 0x36f31e0, 0x24a03d0, 0x36f2ee0)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36f2da0, 0x0, 0xc420241f48)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/main.go:22 +0x20
```.
 Interestingly if I change the healthcheck to this:
```
    healthcheck:
      test: ""psql postgres --command 'select 1'""
```

I get a different error:
```
INFO Service name in docker-compose has been changed from ""broker_app"" to ""broker-app""
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2220748]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.parseHealthCheck(0xc4201d6800, 0x2, 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:190 +0x78
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc42033af00, 0x25, 0xc42045ad40, 0x1, 0x1, 0xc4203cade0)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:255 +0x11b2
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc4204118e0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27ea960)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3724c40, 0xc4204118e0, 0x1, 0x1, 0xc4203ca990, 0x0, 0x0, 0x17, 0x12)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:186 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x28aa4b8, 0x4, 0x0, 0x28be4a7, 0x15, ...)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36f2960, 0xc42045a5a0, 0x0, 0x2)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36f2960, 0xc42045a560, 0x2, 0x2, 0x36f2960, 0xc42045a560)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36f2da0, 0x36f31e0, 0x24a03d0, 0x36f2ee0)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36f2da0, 0x0, 0xc420279f48)
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/private/tmp/kompose-20180105-58832-38j8jm/kompose-1.7.0/main.go:22 +0x20
```.
 @BookOfGreg  I will look into this.
 @BookOfGreg This is a new issue, I will create a new PR to fix this.
 "
kubernetes,kompose,933,"Refactor package app to use const rather than raw string.
 .
 @hangyan , run `gofmt` try `make test` locally as well.
 @surajnarwade sorry, i forgot this. Will fix this ASAP..
 @surajnarwade CI seems broken for now... can you help me with it ?.
 @hangyan, I have restarted the build :).
 @surajnarwade  still, same error.
 @surajnarwade @cdrage can you review this?.
 This is a good refactor. Thanks 💯 This LGTM!.
 "
kubernetes,kompose,932,"Fix typos in Makefile.
 .
 "
kubernetes,kompose,931,"Fix typo in function name.
 .
 "
kubernetes,kompose,930,"Fix typos in doc.
 .
 "
kubernetes,kompose,929,"Fix custom pvc size in v2 compose not working error.
 fix #927 .
 Is it possible for you to add a unit test?.
 Otherwise, LGTM.
 Sure, I will add some test

?? Outlook for Android<https://aka.ms/ghei36>

________________________________
From: Charlie Drage <notifications@github.com>
Sent: Wednesday, February 7, 2018 9:22:20 PM
To: kubernetes/kompose
Cc: Hang Yan; Author
Subject: Re: [kubernetes/kompose] Fix custom pvc size in v2 compose not working error (#929)


Otherwise, LGTM

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/kubernetes/kompose/pull/929#issuecomment-363766907>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADwax8fhLR9jwk_SbV4af1TBiG_KGtiCks5tSaOMgaJpZM4R8Qki>.
.
 LGTM.
 Tests look good, thanks for the contribution! LGTM..
 "
kubernetes,kompose,928,"Fix log format error.
 .
 "
kubernetes,kompose,927,"kompose.volume.size label is not working.
 kompose.volume.size label is not working.
I tested on macOS 10.13.3 and brew installed kompose.

``` yaml
# test.yaml 
version: '2'
services:
  db:
    image: postgres:10.1
    labels:
      kompose.volume.size: 1Gi
    volumes:
      - db-data:/var/lib/postgresql/data
```

``` shell
$ kompose version
1.8.0 ()

$ ls
test.yaml

$ kompose convert -f test.yaml
INFO Kubernetes file ""db-service.yaml"" created
INFO Kubernetes file ""db-deployment.yaml"" created
INFO Kubernetes file ""db-data-persistentvolumeclaim.yaml"" created

$ ls
db-data-persistentvolumeclaim.yaml db-deployment.yaml db-service.yaml test.yaml

$ cat db-data-persistentvolumeclaim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: db-data
  name: db-data
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi # <-- not 1Gi
status: {}
```.
 It seems it's only working in compose v3 now, I will loop into it to see why in v1/v2 not working.
 This is still not working for me. I'm using compose v3. Same error. .
 Does it have something to do with the only modifying storage size if `.Vfrom` source is blank? 

https://github.com/kubernetes/kompose/blob/0c01309fe899c587e8cb02e9c31196ee66ab5093/pkg/transformer/kubernetes/kubernetes.go#L494-L510.
 "
kubernetes,kompose,926,"Fix unset env bug for v3 compose.
 fix #918 .
 Tests pass... is it possible to add a test? If not, I could quickly write one up 👍 .
 Sure, I will add some unit test

?? Outlook for Android<https://aka.ms/ghei36>

________________________________
From: Charlie Drage <notifications@github.com>
Sent: Wednesday, February 7, 2018 9:04:56 PM
To: kubernetes/kompose
Cc: Hang Yan; Author
Subject: Re: [kubernetes/kompose] Fix unset env bug for v3 compose (#926)


@cdrage approved this pull request.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/kubernetes/kompose/pull/926#pullrequestreview-94699377>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADwax03mEKHn0ehjBdQ6_ExJhehg_Jijks5tSZ94gaJpZM4R8GtD>.
.
 @cdrage I have add some tests and check the docker-compose doc and find that my previous code is not correct. Link: https://docs.docker.com/compose/compose-file/#environment. I have rewrite the logic, please help me review it.
 related to #892 . @cdrage  .
 These LGTM. Thanks for the contribution!!.
 "
kubernetes,kompose,925,"Fix typo in cli help message.
 .
 "
kubernetes,kompose,924,"Remove unneeded TODO comment.
 Because when we check the version of the compose file, we have already read the file's content and ensure the file exist.
 LGTM..
 "
kubernetes,kompose,923,"fix a typo in development.md.
 fix a typo in development.md.
 LGTM.
 "
kubernetes,kompose,922,"Remove unneeded todo comment.
 Because when we check the version of the compose file, we have already read the file's content and ensure the file exist.
 "
kubernetes,kompose,921,"provide more details for building steps.
 1. add more detailed steps for  building code
2. fix typo.
 @cdrage Has update.
 Thank you for your contribution, this LGTM! 👍 .
 "
kubernetes,kompose,920,"Fixed typo.
 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 cla signed.
 @pborreli , Please rebase .
 @surajnarwade done, thx..
 Tests failing are a false positive. This LGTM. Thanks!.
 "
kubernetes,kompose,919,"Update the README.
 - Removes the incubation line (already graduated)
- Go 1.5 is 3 years old. Remove not regarding building on 1.5
- Remove not working Slack widget.
 "
kubernetes,kompose,918,"""panic: runtime error: invalid memory address or nil pointer dereference"" when using environment unset variables.
 when using a compose file containing an unset environment var, kompose crash with:
```
kompose up -f docker-compose.yml 
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1621e4b]
```

example:
```
version: '3'

services:
  jenkins:
    image: jenkins
    environment:
      - DEBUG
```


Note: if the environment var is set, everything work as expected. example:
```
version: '3'

services:
  jenkins:
    image: jenkins
    environment:
      - DEBUG=1
```.
 Yeah.. this is currently an outstanding issue. For now, you'll have to change the `version` to 2 and try again..
 @cdrage @niQo  I have create and PR to fix this issue, it works fine. you can check if out if you want.
 "
kubernetes,kompose,917,"Kubernetes specific support in Compose.
 With compose 3.4 it is possible to define **extension-fields** with those it would be possible to map them to a structure that only exists in k8s 

https://docs.docker.com/compose/compose-file/#extension-fields.
 @Vad1mo Good find, that's actually wicked. Could be better rather than using labels...
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 > Starting with the 3.7 format (for the 3.x series) and 2.4 format (for the 2.x series), extension fields are also allowed at the root of service, volume, network, config and secret definitions.

```yaml
version: '2.1'
x-custom:
  items:
    - a
    - b
  options:
    max-size: '12m'
  name: ""custom""
```
they backported it now to 2.x.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 "
kubernetes,kompose,916,"reduce binary size.
 remove symbol tables and debug info to reduce binary size, see: https://golang.org/cmd/link/.
 Honestly, I'd rather keep this in here for now as it makes it easier for debugging the binaries :).
 "
kubernetes,kompose,915,"kompose does not indicate key nor line number when printing error.
 This output:

```
 $ kompose convert -f ./docker-compose.yml
FATA configs Additional property configs is not allowed
```

Gives mostly no information:

1. No line number information
2. No yaml key
3. No `jq` style location
4. No excerpt from the input file.
5. It refers to ""property config"" where none of those words appear in the input.

.
 Ah, the `configs` is the key apparently.   I suggest adding line numbers for this to understandable..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Meaning that `configs` is not supported yet? Having the same problem.

_edit:_ guess not ~ https://github.com/kubernetes/kompose/pull/994.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,914,"docker-compose version 3.3 is not supported..
 .
 Due to how fast Docker Compose is in terms of development, we are only cutting / supporting major releases, see: http://kompose.io/conversion/

Unfortunately, if we were to implement say... 3.3 or 3.4, not only do we have to wait for upstream to support it (either `docker/cli` or `docker/libcompose`) but there may be major changes between that release, and a new release (4).

.
 Does this still apply? The later Compose file format support alsorts of deployment goodies like health checks because of Docker swarm, which probably translate quite well into Kubernetes config files and it's a shame we won't get to take advantage of them. 

Who knows if 4.0 will ever come out but 3.0 was released more than a year ago so I wouldn't say it constitutes as fast paced anymore:

**3.0:** 2017-01-18
**3.1:** 2017-02-08
**3.2:** 2017-04-04
**3.3:** 2017-06-19
**3.4:** 2017-11-01
**3.5:** 2017-12-18
**3.6:** 2018-03-20.
 @cdrage wanted to second @intellix's comment here, it seems that there's going to be a really long wait until we get 4.0. Does it make sense to re-evaluate this stance?.
 @intellix is right, however, we'll still always be a couple of versions behind as we implement everything.

The initial push-back that I had was the fact that docker-compose was moving (relatively) fast and it was becoming harder to keep up.

@mahmoudimus however, @hangyan has already began adding support for newer versions, starting with https://github.com/kubernetes/kompose/pull/954 we've enabled support for newer versions of 3. 

I'm not against enabling support for new versions, just as long as we support all the keys!.
 @cdrage thanks for the response, I'll try that out. Is there a PR I can submit here to update the documentation to mention this? It was a bit harder to find. Cheers..
 @mahmoudimus Here https://github.com/kubernetes/kompose/pull/993.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,913,"Push image without authentication.
 For fixing issue #911 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://git.k8s.io/community/CLA.md#the-contributor-license-agreement> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://go.k8s.io/bot-commands).
</details>
	.
 @coodix does this actually work on MacOS?.
 @cdrage , yes, checked with local private repository which was set up it with:
`docker run -d -p 5000:5000 --restart=always --name registry registry:2`

And pushed image to localhost:5000..
 "
kubernetes,kompose,912,"1.8.0 Release.
 "
kubernetes,kompose,911,"Unable to push Docker image for service web: Unable to retrieve .docker/config.json authentication details. .
 I got this error while running: `kompose up`
I have been using the following docker-compose.yml:

> version: '3'
> 
> services:
>   db:
>     image: mysql:5.5
>     container_name: db-container
>     ports:
>       - ""3406:3306""
>     environment:
>       MYSQL_ROOT_PASSWORD: mypassword
>       MYSQL_USER: root
>       MYSQL_DATABASE: mydb
>   web:
>     build: .
>     container_name: web-container
>     command: python3 manage.py runserver 0.0.0.0:8000
>     volumes:
>       - .:/code
>     image: ""ruddra/web-image""
>     ports:
>       - ""8000:8000""
>     depends_on:
>       - db


I ran the following commands:
>kompose convert --provider=openshift
>kompose up --provider=openshift


I was able to push to my dockerhub repository using: 
`docker-compose push`
.
 Hey @ruddra I've been trying to diagnose this issue.

I'm assuming you're using OS X? .
 I am using macOS high sierra :).
 @ruddra That'd be why :) Docker is running in a VM and I believe they changed the configuration location. I'll have to investigate. 

Just wondering, but where is the configuration file specifically on your machine?.
 In '~/.docker/config.json'.
 Same issue for me. Trying use local private repo, but even after docker login keep getting error ""FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service proxy: Unable to retrieve .docker/config.json authentication details. Check that 'docker login' works successfully on the command line.: Failed to read authentication from dockercfg"".

~/.docker/config.json is in place
.
 Hey @coodix @ruddra @kbroughton

I got time this week to get around to this issue, unfortunately, I don't have a Mac and I'm unable to run a VM (against licensing :() to diagnose it. So I need your help. 

I'd like you all (or at least one of you) to these two things:

From this issue (https://github.com/pachyderm/pachyderm/issues/2446) , let's try this:

1. Can you please output what your DOCKER_CONFIG variable is for me. If it's blank, try the command below the run Kompose again and see if it succeeds.

```sh
echo $DOCKER_CONFIG
export DOCKER_CONFIG=~/.docker/ 
```

From this issue (https://github.com/fsouza/go-dockerclient/issues/677)

2. Can you output your `.docker/config.json` details for me and see if it contains `osxkeychain`? If you decide to comment in this issue with the configuration details, make sure you omit the `auth` variable :+1: 

I'm going to see if I can borrow a friends Mac or at least find one at the company lab which has one I can remote into!

Seems at the moment this issue is only affected Mac users.

Many thanks :100: .
 @cdrage , $DOCKER_CONFIG is empty by default. I tried to set it to ""~/.docker/"" but it didn't help. Same error appeared.
Content of my ~/.docker/config.json:
`{
	""auths"": {
		""https://index.docker.io/v1/"": {},
		""localhost:5000"": {}
	},
	""credsStore"": ""osxkeychain""
}`

But it became so after I execute ""docker login localhost:5000"" trying to make it work. In all cases same error..
 @cdrage , I've found out what's the problem. It's because dockerclient isn't integrated with osxkeychain. See https://github.com/fsouza/go-dockerclient/issues/677

Also it relates to https://github.com/docker/for-mac/issues/1584
Docker for Mac by default uses osxkeychain for storing credentials.

So the current solution is to edit config.json:
`{ ""auths"": { ""localhost:5000"": { ""auth"": ""...base64encoded credentials..."" } }, ""credsStore"": ""osxkeychain"" }`
And need to ensure that there are no auths without auth string (https://github.com/fsouza/go-dockerclient/issues/677#issuecomment-360269441 ). .
 @cdrage , do you consider adding empty AuthConfiguration as it stated in comment for PushImage method (github.com/fsouza/go-dockerclient/image.go):
`
// An empty instance of AuthConfiguration may be used for unauthenticated
// pushes.
//
// See https://goo.gl/zPtZaT for more details.
func (c *Client) PushImage(opts PushImageOptions, auth AuthConfiguration) error {
`

At least in case if no one auth was found by dockerlib.NewAuthConfigurationsFromDockerCfg?.
 @coodix Yeah, that's for investigating.. It's difficult with `oxskeychain`, we'd have to either contribute an upstream change to the go-dockerclient library or implement Docker's client library. 

We can try to do empty authentication to fix it. .
 I'm having the same issue on OSX when trying to push to `gcr.io` using the gcr credential helper.
I'm trying to update my pipeline with 
`pc update-pipeline -f pipeline.json --push-images`
and I'm getting 
`error parsing auth: open /Users/geekflyer/.dockercfg: no such file or directory, try running docker login`

my `~/.docker/config.json` looks like this:

```
{
	""auths"": {
		""gcr.io"": {},
		""https://registry.gitlab.com"": {},
		""registry.gitlab.com"": {}
	},
	""HttpHeaders"": {
		""User-Agent"": ""Docker-Client/17.09.0-ce (darwin)""
	},
	""credsStore"": ""osxkeychain"",
	""credHelpers"": {
		""asia.gcr.io"": ""gcr"",
		""eu.gcr.io"": ""gcr"",
		""gcr.io"": ""gcr"",
		""staging-k8s.gcr.io"": ""gcr"",
		""us.gcr.io"": ""gcr""
	}
}% 
```

What is the workaround for this? This is really blocking me to iterate on some pipelines.
.
 on a related issue: While digging I found that the podspec pachyderm creates for pipeline workers contains `imagePullPolicy: IfNotPresent` .  I'm somewhat new to k8s, but wouldn't it be better to simply specify `imagePullPolicy: Always` which would make specifying the `--push-images` flag obsolete?.
 I'm getting this issue on my project. I'm from Linux and there is my ~./docker/config.json : 
```{
        ""auths"": {
                ""https://index.docker.io/v1/"": {
                        ""auth"": ""<somekey>=""
                },
                ""registry.gitlab.com"": {
                        ""auth"": ""<somekey>=""
                }
        },
        ""HttpHeaders"": {
                ""User-Agent"": ""Docker-Client/18.02.0-ce (linux)""
        }
}
```
My docker-compose file : 
```
version: '2'

services:

  agon:
    build:
      context: ./agon
      dockerfile: Dockerfile
    image: agonnode:tag  
    container_name: Agon_iri
    hostname: agon
    volumes:
      - ./volumes/iota/iota.ini:/iri/iota.ini:ro
      - ./volumes/iota/ixi:/iri/ixi:rw
      - ./volumes/iota/mainnetdb:/iri/mainnetdb:rw
      - /etc/localtime:/etc/localtime:ro
    expose: 
      - ""5556""
    ports:
      - ""14600:14600/udp""
      - ""15600:15600/tcp""
      - ""14265:14265""
    restart: 'on-failure'

```
Here's my try to push the image : 
```
➜  ultra-devops git:(kuberpod) ✗ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a DockerID, head over to https://hub.docker.com to create one.
Username (hystenal): hystenal
Password:
Login Succeeded

➜  ultra-devops git:(kuberpod) ✗ docker-compose push
Pushing agon (agonnode:tag)...
The push refers to repository [docker.io/library/agonnode]
070ea77bff68: Preparing
8760e8a8ec65: Preparing
89f1160177db: Preparing
64a60834482b: Preparing
ce26c278ee53: Preparing
b30530a0b009: Waiting
7c4b5f9422c0: Waiting
26fac7fe251e: Waiting
db584c622b50: Waiting
52a7ea2bb533: Waiting
52f389ea437e: Waiting
88888b9b1b5b: Waiting
a94e0d5a7c40: Waiting
ERROR: denied: requested access to the resource is denied

➜  ultra-devops git:(kuberpod) ✗ kompose up
WARN Unsupported hostname key - ignoring
INFO Container name in service ""agon"" has been changed from ""Agon_iri"" to ""Agon-iri""
INFO Build key detected. Attempting to build and push image 'agonnode:tag'
INFO Building image 'agonnode:tag' from directory 'agon'
INFO Image 'agonnode:tag' from directory 'agon' built successfully
INFO Pushing image 'library/agonnode:tag' to registry 'docker.io'
INFO Multiple authentication credentials detected. Will try each configuration.
INFO Attempting authentication credentials 'registry.gitlab.com
ERRO Unable to push image 'library/agonnode:tag' to registry 'docker.io'. Error: unauthorized: incorrect username or password
INFO Attempting authentication credentials 'https://index.docker.io/v1/
ERRO Unable to push image 'library/agonnode:tag' to registry 'docker.io'. Error: denied: requested access to the resource is denied
FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service agon: unable to push docker image(s). Check that `docker login` works successfully on the command line
```
.
 @huntal seems like not a kompose issue, because docker-compose push is not working too. Maybe wrong dockerhub user namespace. The output shows that you are trying to push to `library`, this is the official image account.. The image format is `<you-user-name>/<image-name>:<tag>` I think..
 Yup you were right my bad, just had to change the `image` tag key to your format @hangyan thanks again.
 I pushed it manually and removed build from compose file. It worked!

It feels like `kompose` is having issues accessing the credentials to push the images..
 Could https://github.com/kubernetes/kubernetes/issues/63874 be related to this?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,910,"unable to push to private repo in hub.docker.com.
 $ kompose  --file docker-compose-out.yml -v up
INFO Build key detected. Attempting to build and push image 'haystackabi/hsabi-web-app:4ca21a16'
DEBU Compose file dir: /Users/kesten/projects/core
INFO Building image 'myorg/myimage:4ca21a16' from directory 'myimage'
DEBU Created temporary file /tmp/kompose-image-build-328321841 for Docker image tarballing
INFO Image 'myorg/myimage' from directory 'myimage' built successfully
DEBU Docker Compose version: 3.0
FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service haystack-web-app: Unable to retrieve .docker/config.json authentication details. Check that 'docker login' works successfully on the command line.: Failed to read authentication from dockercfg

$ kompose version
1.7.0 (767ab4b)

push using docker works fine
$ docker push haystackabi/hsabi-web-app:4ca21a16
The push refers to a repository [docker.io/haystackabi/hsabi-web-app]
2a0a82b8c76c: Layer already exists
5c95d741d318: Pushing [=================>                                 ]    112MB/313MB
3f34fa06d2a5: Pushing [===================.
 @kbroughton What OS are you using? Seems it can't find `~/.docker/config.json`.
 osx and targeting gke.

I commented out the build step from docker-compose-out.yml and then hit this: 
FATA Error while deploying application: google: could not find default credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.

which was resolved by
kestens-MacBook-Pro:core kesten$  gcloud auth application-default login

And kube can't read from my dockerhub private repo so i get image pull failures.
.
 Hey @kbroughton I'm going to close this issue in favour of https://github.com/kubernetes/kompose/issues/911 .
 "
kubernetes,kompose,909,"extended env_file capability to in-docker-compose.yml substitutions.
 in https://github.com/kubernetes/kompose/pull/799 the tests show the ability to over-ride an 'environment' var with one from a '.env' file which is useful if the container runtime depends on the var.  But another use case for docker-compose .env file is to allow ${var} substitutions in other docker-compose arguments.  A common example would be

    services:
      app:
        image: myapp
        volumes: ${local_path_to_data}:/data
        env_file: 
          - ""./.env""

and 
.env 
    local_path_to_data=/home/me/data          # for a linux user
    # or
    local_path_to_data=/Users/me/data           # for a mac user

In my testing, this sort of substitution is not yet supported and gives an error
`* error decoding 'Volumes[0]': invalid spec: :/data empty section between colons`

I would expect the default behavior to be to create a persistent volume named for the rhs of Volumes populated with the data at local_path_to_data specified in the .env file.

.
 I have a workaround for this now:
// this gets the .env files stamped into the -out.yml file
docker-compose config -f docker-compose.yml > docker-compose-out.yml
kompose convert -f docker-compose-out.yml

perhaps kompose should be loading based off of docker-compose config  output?.
 Same problem for me.  The workaround helps @kbroughton but the `docker-compose config` output changes the version from '2' in the original to '2.0' which isn't supported by `kompose`.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 If the environment variable file need to be placed in the application config location , what needs  to be done.
 Correction

If the environment variable file need to be placed in the **custom** application config location , what needs to be done.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,908,"Invalid quick start link.
 [Quick start](docs/quickstart.md) is invalid. .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Hey @a8uhnf this looks good. Sign the CLA and then I can merge this in!.
 Hey, signed CLA. @cdrage .
 "
kubernetes,kompose,907,"Allow services to use same port with different protocols.
 kompose fails if compose file declares different protocols for the same port. eg;

```
...
     ports:
      - 666:666/udp
      - 666:666/tcp
...
```

This PR adds the port to the output and also makes sure that names are unique for each port/protocol pair. This is supported with LoadBalancer (https://github.com/kubernetes/kubernetes/issues/2995
) so trying to use this config with LB panics.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Hey @caglar10ur Seems that tests are failing.

Do you mind updating your PR with a description of what's happening here / being changed as well?.
 @cdrage sure thing. While at it I'll also add a fixture for this work..
 @cdrage done and now tests are passing too.
 @cdrage pushed a new commit to address your comments. Thanks!.
 @caglar10ur Do you mind if you merge the two commits? Push with 1 commit? :+1: .
 @cdrage squashed and pushed.
 @caglar10ur , semaphore CI is breaking :(.
 @surajnarwade not sure what is going on there as I didn't see anything alarming in the logs and assumed intermittent CI failure. Do you see an error that I'm not seeing or missing?.
 Sorry for that @caglar10ur, @surajnarwade is wrong. 

Our OpenShift tests have been kind of flakey lately. Ignore that test. I'll re-run it anyways!.
 This LGTM, @surajnarwade mind doing a quick review and we can merge this in? :+1: .
 "
kubernetes,kompose,906,"1.7.0 Release.
 "
kubernetes,kompose,905,"Cannot run in gcloud environment with Kompose CLI.
 I want to integrate Kompose CLI inside the container so I can use it as a part of CI/CD pipeline. In gitlab-ci.yml I want to install Kompose in the container so I can use it. So far I am unable to do so. 

Here is my gitlab-ci.yml file:

    image: node:8-alpine

    stages:
      - build

    build_image:
      stage: build
      only: [master]
      image: google/cloud-sdk
      services:
        - docker:dind
      script:
        - echo ""$GOOGLE_KEY_SECRET"" > key.json # Google Cloud service accounts
        - gcloud auth activate-service-account --key-file key.json
        - gcloud config set project my-web-190118

    // I install Kompose here with following command: curl -L https://github.com/kubernetes/kompose/releases/download/v1.6.0/kompose-linux-amd64 -o kompose 

    //I want to use `- Kompose up` here
.
 What error do you get?.
 I found a right approach to do it without using kompose [here](https://stackoverflow.com/questions/47888027/how-to-deploy-staging-in-google-cloud-platform-with-kubernetes-and-gitlab-ci-cd).
 "
kubernetes,kompose,904,"docker config.json format.
 .
 "
kubernetes,kompose,903,"Fix link to binary-installation method in README.md.
 Now it links to the section of same file.
Also fixes typo in word preferred.
fixes #902 
.
 Thanks @bhavin192 for your contribution, after changes suggested by @cdrage , good to go :).
 IMO. Having it separate would be best as it shows other methods for
installation too.



On Jan 6, 2018 08:34, ""Bhavin Gandhi"" <notifications@github.com> wrote:

> *@bhavin192* commented on this pull request.
> ------------------------------
>
> In README.md
> <https://github.com/kubernetes/kompose/pull/903#discussion_r160025895>:
>
> >
>  Our entire list of installation methods are located in our [installation.md](/docs/installation.md) document.
>
>  Installation methods:
> -  - [Binary (Prefered method)](README.md)
> +  - [Binary (Preferred method)](#binary-installation)
>
> @cdrage <https://github.com/cdrage> I got it now, so the section is like
> a index of installation.md but again won't it be little bit confusing for
> user? as we have instructions there on the README.md itself (for binary
> installation) and we are redirecting to installation.md for the same
> instructions?
> Can we have list of all methods after the Binary Installation method (
> README.md) ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/pull/903#discussion_r160025895>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGH-oGZ0OwZ7dSgFl92gl0rLCmTi4N4mks5tH3Z-gaJpZM4RLpLu>
> .
>
.
 LGTM! Thanks!.
 "
kubernetes,kompose,902,"No proper link to Binary Installation method in README.md.
 Link for the **Binary (Prefered method)** method in the `README.md` opens https://github.com/kubernetes/kompose/blob/master/README.md instead of jumping to the proper section from the file..
 "
kubernetes,kompose,901,"Convert registry to k8s.gcr.io.
 This PR was auto-generated.  Please apply human expertise to review for correctness.

Followup to https://github.com/kubernetes/kubernetes/pull/54174

xref https://github.com/kubernetes/release/issues/281.
 I don't know how to diagnose this
.
 Thanks man,

OpenShift test is just a flake. Kubernetes tests all pass. Mergin'.
 "
kubernetes,kompose,900,"Added Case for Config Map in kompose down.
 Added Case for Config Map in kompose down. To implement this, added a label in the configMap object at the time of init.
It will delete the configMap object during `kompose down`
#883 .
 @surajnarwade @cdrage Please review !!.
 This LGTM :+1: .
 "
kubernetes,kompose,899,"Update code-of-conduct.md.
 Refer to kubernetes/community as authoritative source for code of conduct

ref: kubernetes/community#1527.
 "
kubernetes,kompose,898,"Add (better) documentation on adding tests.
 We should elaborate / go more into detail on how to add integration, unit tests, etc for Kompose..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,897,"Allow specifying imagePullSecret.
 Hi there,

How would one go about providing the `imagePullSecret` key to a `deployment`?

This could possibly help with #893 ? This might also be part of a broader discussion about ""template-supported conversions"", which would allow to make custom changes to the conversion outputs...

Cheers,

Jun.
 In fact, instead or in addition to ""template-supported conversions"", if the helm chart conversion template had a number of `values` interpolated, then the parameters could be passed to `helm` on deploy..
 The issue with the case you linked is that the code tries doing something like `docker push my-namespace/image:tag` instead of `docker push my-registry.com:5000/my-namespace/image:tag`, to do with pushing from the client, rather than pulling from pods.

I think pod `ImagePullSecrets` fall into the same boat as ingress TLS secrets, so whoever takes this on could use #896 as a point of reference for the code..
 Does this mean we cannot pull from external private registries right now?.
 You can't pull from an private registry if you would need to authenticate from the node to pull an image..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Hi,
okay, so this is to stay i simply can't use the lovely Kompose service as it if the given docker image is private right ?.
 @ysle In kubernetes, you can create a secret for you private registry and add it to the default  serviceaccount ( in the same namespace). After this ,kubernetes will pull the image for you.

Check the doc: https://kubernetes.io/docs/concepts/configuration/secret/#arranging-for-imagepullsecrets-to-be-automatically-attached.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /reopen
This is important for deploying docker-compose files to a kubernetes cluster..
 @jankal: You can't reopen an issue/PR unless you authored it or you are a collaborator.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/897#issuecomment-421469845):

>/reopen
>This is important for deploying docker-compose files to a kubernetes cluster.


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 @Code0x58 anything new on this?.
 I haven't kept up with the development of Kompose for months, but as I left it [hangyan's comment](https://github.com/kubernetes/kompose/issues/897#issuecomment-395089750) was the best existing solution, but a Kompose fix would have been easy by doing something like #896 to add another [label](https://github.com/kubernetes/kompose/blob/master/docs/user-guide.md#labels) to provide `ImagePullSecret`s similar to #896. #1040 is an active PR on it, so probably worth reviewing for anyone who is interested and has time..
 "
kubernetes,kompose,896,"Add kompose.service.expose.tls-secret.
 .
 Tests pass (despite us having a hard barrier-to-entry to creating them, haha), code looks great, name makes sense. This LGTM. :+1: thanks a lot @Code0x58 !

Edit:

So after looking at the code. Correct me if I'm wrong, but this essentially grabs a secret from Kubernetes from whatever name you set it as? (for this example, `test-secret`).

The problem with this is that it isn't exactly 1-1 conversion from Docker Compose to Kubernetes. You would already have to have a secret setup on Kubernetes in order to set this up, which doesn't fit with the whole ""convert 1-1 from docker-compose to kubernetes"".

I have no problem merging this in, but this makes #296 a higher priority now, as ideally, you'd be able to define this secret within Docker Compose and then it's automatically created within Kubernetes (without having to define it manually), does that make sense? Let me know your thoughts :+1: .
 Thanks, I definitely made use of CI on here while working out the tests - sempahore shows 12 builds.

I think ingress TLS secrets won't map nicely between docker-compose/swarm and Kubernetes as it would be an application concern in compose/swam, so it will probably always be stuck in labels/workarounds like this. Pod `ImagePullSecret`s are probably in the same boat.

I image that down the line when compose secrets are supported, you could specify your secret within the compose file, then refer to it in this label without any additional work - so this should be a stable approach. You may want to check that this refers to a defined secret, which could be an external one to work as it does now..
 Yeah, there's absolutely no way to map it correctly without doing something *really* hacky. I agree that labels are the right way to go. 

This LGTM :+1: Thanks for clarifying regarding the secret and TLS. 

IMO this should have another review. @kadel @containscafeine @surajnarwade can you have a look?.
 Mergin' thanks @Code0x58 !.
 "
kubernetes,kompose,895,"Fix pushing of image to a private repository.
 This is to test and fix #893

_p.s. The existing tests/platform [flaked](https://semaphoreci.com/cdrage/kompose-2/branches/pull-request-895/builds/3) on OpenShift_.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 I finally got this sorted, the issue with using the default registry was that it wasn't available by the time the `docker login` was running, this generally wouldn't have been an issue for tests as the pods would fail to pull and then back off before retrying, usually not exceeding the test's timeout.

The issue is reproduced in [tests](https://semaphoreci.com/cdrage/kompose-2/branches/pull-request-895/builds/40); I don't feel Semaphore CI is doing the tests properly, as it shows the first commit as passing although it doesn't. I am wondering if it has ran the HEAD of the PR twice instead of running each commit in the PR.

Bonus: I think this change will reduce the odds of the first test timing out..
 Holy moley. Good test coverage :+1: 

I see absolutely nothing wrong with the code. Thank you for covering everything from integration to unit tests.

Tests pass, code looks good, LGTM :+1: .
 I'd like to get this in for this month's release, so I'm going to merge it in :+1: Thanks a lot @Code0x58 for the PR!.
 "
kubernetes,kompose,894,"[RFC] Map ingress path to optional 'kompose.service.expose_path'.
 I've cobbled this together to allow a new optional label `kompose.service.expose_path` to map to `ingress.spec.rules[].http.paths[].path`.

This supports a workflow I find desirable, and I suspect others may find this useful too. I've never worked with Go before, so please forgive me if the implementation is sub-optimal. Also, I'm aware that you may not want to maintain such a specific feature, so I didn't spend any time adding tests or docs at this point.

If a maintainer here feels the concept is sound but has implementation advice, I'm more than happy to spend some time making this merge-worthy..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 CLA signed.
 When you do get a thumbs up and move onto the documentation+tests, you may find #896 helpful (probably just the paths) as it does the same kind of thing. It would also be good to return an error if the tag is used without `kompose.service.expose`.

_p.s. I prefer the idea of `kompose.service.expose.path`_.
 @kadel @surajnarwade `kompose.service.expose.path` or `kompose.service.expose_path`, thoughts? I'm leaning towards `kompose.service.expose.path`

Tests / documentation should be added later, but we can help with that.
.
 If we are going with `kompose.service.expose.tls-secret` in #896 than `kompose.service.expose.path` makes much more sense here.

This PR goes in the right direction, it just needs to check for the case where `kompose.service.expose.path` is set but  `kompose.service.expose` is not (or it is false)..
 Hey @warrenseymour ! Please see @kadel 's comment. Once updated, I'd be good for merging. `kompose.expose.path` syntax works..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 @cdrage Is there any way to make this PR continue? .
 @warrenseymour Could we possibly continue using your code? :+1: Just seeing if you're still interested in completing this :smile: .
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,893,"Unable to push to (private) registry.
 When doing `kompose up` on a file which has build+image information, it builds the image and then it looks like it tries to push it incorrectly:
```
INFO Build key detected. Attempting to build and push image 'my.registry.com/my-namespace/image:latest' 
INFO Building image 'my.registry.com/my-namespace/image:latest' from directory 'image' 
INFO Image 'my.registry.com/my-namespace/image:latest' from directory 'image' built successfully 
INFO Pushing image 'my-namespace/image:latest' to registry 'my.registry.com' 
INFO Attempting authentication credentials 'my.registry.com 
ERRO Unable to push image 'my-namespace/image:latest' to registry 'my.registry.com'. Error: An image does not exist locally with the tag: my-namespace/image 
FATA Error while deploying application: k.Transform failed: Unable to push Docker image for service image: unable to push docker image(s). Check that `docker login` works successfully on the command line
```
`docker-compose build && docker-compose push` doesn't have an issue with this.

To bodge it at the moment I remove the build information and do `docker push my.registry.com/my-namespace/image:latest` before running `kompose up`..
 "
kubernetes,kompose,892,"panic: runtime error: invalid memory address or nil pointer dereference.
 version 1.6.0 (e4adfef)
macOS 10.13.2

kompose convert =

panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x221af2b]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc4205dc6c0, 0x20, 0xc42045d820, 0x1, 0x1, 0xc4200d35f0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:323 +0x45b
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc4203686f0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27e2280)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x370a980, 0xc4203686f0, 0x1, 0x1, 0xc4200d3080, 0x0, 0x0, 0x9, 0x7)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:186 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x28a1b28, 0x4, 0x0, 0x28b5b4d, 0x15, ...)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36d8660, 0x370a980, 0x0, 0x0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36d8660, 0x370a980, 0x0, 0x0, 0x36d8660, 0x370a980)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36d8aa0, 0x36d8ee0, 0x2499880, 0x36d8be0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36d8aa0, 0x0, 0xc420315f48)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/main.go:22 +0x20
.
 Okay, that is *so* odd that you're getting my folder... 

```
/home/wikus/dropbox/dev/go/src/github.com
```
Can you post the full command you're using?
.
 ran from the directory containing the docker-compose.yml file i tried converting....

""my""-MacBook-Pro:azure$ kompose convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2220eeb]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc4200aa780, 0x20, 0xc420428220, 0x1, 0x1, 0xc420143890)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:323 +0x45b
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc42058faf0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27e9f00)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3723c40, 0xc42058faf0, 0x1, 0x1, 0xc420143320, 0x0, 0x0, 0x10, 0xf)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:186 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x28a9a38, 0x4, 0x0, 0x28bda27, 0x15, ...)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36f1960, 0x3723c40, 0x0, 0x0)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36f1960, 0x3723c40, 0x0, 0x0, 0x36f1960, 0x3723c40)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36f1da0, 0x36f21e0, 0x249fa70, 0x36f1ee0)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36f1da0, 0x0, 0xc420227f48)
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/private/tmp/kompose-20171212-31628-9y6gll/kompose-1.6.0/main.go:22 +0x20

.
 @pkelleratwork Ah, that's better! 

Are you able to post the docker-compose.yaml file that you are using?.
 sorry - cant post it here.....
 its pretty standard, nothing wild. front end, back end, proxy in it. .
 One thing to check if if you've got any blank environment variables within it. That may be one of the reasons. For example, if you have:

```yaml
env:
  - MYSECRETPASS
```

and `echo $MYSECRETPASS` is blank it may be erroring..
 confirmed no blank env variables. there are foo=${bar} using a .env file to populate, but nothing blank

echo $MYSECRETPASS is also blank
.
 Without the `docker-compose.yaml` file I wouldn't be able to diagnose it :( Are you able to create I guess a ""fake"" docker-compose.yaml file with no revealing information so I can replicate it my end?.
 here you go... verified I get the same error with this ""fake"" on...
 [fake docker compose.txt](https://github.com/kubernetes/kompose/files/1557061/fake.docker.compose.txt)
.
 I found the same issue, here is a minimal working `docker-compose.yml` which will cause a segfault if you remove either of `limits`/`reservations` and convert with at either kompose 1.5.0 (999278f) and 1.6.0 (e4adfef) - untested on lower versions:
```yml
version: '3'
services:
  segfault-central:
    image: alpine
    deploy:
      resources:
        limits:
          cpus: '0.01'
          memory: 256M
        reservations:
          cpus: '0.01'
          memory: 128M
```.
 Hey @Code0x58 I was unable to replicate the issue with either your above docker-compose.yaml file or the modified one with limits / reservations removed.

```
version: '3'                                                                                                                                                                                                                                                                      
services:                                                                                                                                                                                                                                                                         
  segfault-central:                                                                                                                                                                                                                                                               
    image: alpine                                                                                                                                                                                                                                                                               
```.
 Hey @pkelleratwork so it looks like it's an issue with the `v3` implentation.

Changing to `version: 2` in your docker-compose.yaml file will fix it. I have a feeling it's about the environment variable implementation..
 thanks @cdrage - I'll give it a shot!.
 I found out *where* it's happening, https://github.com/kubernetes/kompose/blob/master/pkg/loader/compose/v3.go#L322 

Now it's time to debug and see how to fix it.

Looks like it happens if there is a blank variable somewhere within the implementation..
 @cdrage - changed version to ""2"", it worked :) 

<my>-MacBook-Pro:kompose $ kompose convert
WARN The REPO variable is not set. Substituting a blank string.
WARN The IMAGE variable is not set. Substituting a blank string.
WARN The REPO variable is not set. Substituting a blank string.
WARN The IMAGE variable is not set. Substituting a blank string.
WARN The API variable is not set. Substituting a blank string.
WARN The HOST variable is not set. Substituting a blank string.
WARN The HOST variable is not set. Substituting a blank string.
WARN The REPO variable is not set. Substituting a blank string.
WARN The IMAGE variable is not set. Substituting a blank string.
WARN The ENV variable is not set. Substituting a blank string.
WARN Unsupported root level networks key - ignoring
WARN Unsupported networks key - ignoring
WARN Unsupported depends_on key - ignoring
WARN Volume mount on the host ""./data/db"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""./data/redis"" isn't supported - ignoring path on the host
INFO Kubernetes file ""api-service.yaml"" created
INFO Kubernetes file ""db-service.yaml"" created
INFO Kubernetes file ""proxy-service.yaml"" created
INFO Kubernetes file ""redis-service.yaml"" created
INFO Kubernetes file ""web-service.yaml"" created
INFO Kubernetes file ""api-deployment.yaml"" created
INFO Kubernetes file ""db-deployment.yaml"" created
INFO Kubernetes file ""db-claim0-persistentvolumeclaim.yaml"" created
INFO Kubernetes file ""proxy-deployment.yaml"" created
INFO Kubernetes file ""redis-deployment.yaml"" created
INFO Kubernetes file ""redis-claim0-persistentvolumeclaim.yaml"" created
INFO Kubernetes file ""web-deployment.yaml"" created.
 Hey @cdrage, the file you pasted had both of them removed, with one of them removed it blows up for me:
```yml
version: '3'
services:
  segfault-central:
    image: alpine
    deploy:
      resources:
        limits:
          cpus: '0.01'
          memory: 256M
```.
 I just got hit with the same issue (and fix) as @Code0x58 mentioned on https://github.com/kubernetes/kompose/issues/892#issuecomment-351675307.

v1.6.0 (e4adfef), macOs 10.13.1 (17B1003)

With a simple service:
```
version: '3'

services:
  nginx:
    image: nginx
```

These work:
```
    deploy:
      resources: {}
```

```
    deploy:
      resources:
        limits:
          cpus: '0.01'
          memory: 256M
        reservations:
          cpus: '0.01'
          memory: 128M
```

These don't work:
```
    deploy:
      resources:
        reservations: {}
```

```
    deploy:
      resources:
        reservations:
          cpus: '0.1'
          memory: 50M
```

```
    deploy:
      resources:
        limits: {}
```

An error, but not a SIGSEGV for this:
```
    deploy:
      resources:
        resources: {}
        limits: {}
```.
 For the resources case that myself and @gak encountered, I believe the issue is caused by [these two lines](https://github.com/kubernetes/kompose/blob/v1.6.0/pkg/loader/compose/v3.go#L266).

@pkelleratwork @cdrage after some cutting down it appears that the minimum way to reproduce the error is:
```
version: ""3""
services:
  segfault-central:
    environment:
      - FOO_CONFIG
```
Similarly, stripping out all of the listed (rather than mapped) environment variables which didn't have a `=` in them stopped the segfault in the example.

A quick look made me think the issue is around [here](https://github.com/kubernetes/kompose/blob/v1.6.0/pkg/loader/compose/v3.go#L319) but I am not sure; I think there is enough for someone to look into. This is a bug rather than a rough edge from exceptional use, as this is supported by [`docker-compose`](https://docs.docker.com/compose/compose-file/#environment)..
 @cdrage should be fixed by #926 .
 close by #926 .
 "
kubernetes,kompose,891,"1.6.0 Release.
 "
kubernetes,kompose,890,"Doesn't run on alpine?.
 Hi there,

It seems that the `1.5.0` binary doesn't run on alpine. Maybe I'm missing something? Here's a one liner test with docker:

```
docker run --rm --entrypoint sh alpine -c ""apk update && apk add curl && curl -L https://github.com/kubernetes/kompose/releases/download/v1.5.0/kompose-linux-amd64 -o kompose && chmod +x kompose && ./kompose --help""
```

In contrast this runs fine in `debian`:
```
docker run --rm --entrypoint sh debian -c ""apt-get update && apt-get install -y curl && curl -L https://github.com/kubernetes/kompose/releases/download/v1.5.0/kompose-linux-amd64 -o kompose && chmod +x kompose && ./kompose --help""
```

Here's the full log of the first command:
```
> docker run --rm -it --entrypoint sh alpine -c ""apk update && apk add curl && curl -L https://github.com/kubernetes/kompose/releases/download/v1.5.0/kompose-linux-amd64 -o kompose && chmod +x kompose && ./kompose --version""
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz
v3.7.0-8-g7f9d974993 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main]
v3.7.0-10-g867acb9878 [http://dl-cdn.alpinelinux.org/alpine/v3.7/community]
OK: 9044 distinct packages available
(1/4) Installing ca-certificates (20171114-r0)
(2/4) Installing libssh2 (1.8.0-r2)
(3/4) Installing libcurl (7.57.0-r0)
(4/4) Installing curl (7.57.0-r0)
Executing busybox-1.27.2-r6.trigger
Executing ca-certificates-20171114-r0.trigger
OK: 6 MiB in 15 packages
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   609    0   609    0     0    609      0 --:--:-- --:--:-- --:--:--  1198
100 45.6M  100 45.6M    0     0  3891k      0  0:00:12  0:00:12 --:--:-- 5067k
sh: ./kompose: not found
~/infra/python > docker run --name kompose -it --entrypoint sh alpine -c ""apk update && apk add curl && curl -L https://github.com/kubernetes/kompose/releases/download/v1.5.0/kompose-linux-amd64 -o kompose && chmod +x kompose && ./kompose --version""
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz
v3.7.0-8-g7f9d974993 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main]
v3.7.0-10-g867acb9878 [http://dl-cdn.alpinelinux.org/alpine/v3.7/community]
OK: 9044 distinct packages available
(1/4) Installing ca-certificates (20171114-r0)
(2/4) Installing libssh2 (1.8.0-r2)
(3/4) Installing libcurl (7.57.0-r0)
(4/4) Installing curl (7.57.0-r0)
Executing busybox-1.27.2-r6.trigger
Executing ca-certificates-20171114-r0.trigger
OK: 6 MiB in 15 packages
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   609    0   609    0     0    609      0 --:--:-- --:--:-- --:--:--  1164
100 45.6M  100 45.6M    0     0  2747k      0  0:00:17  0:00:17 --:--:-- 3860k
sh: ./kompose: not found
```.
 This seems to explain it: http://kefblog.com/2017-07-04/Golang-ang-docker.
 This workaround works for me:

```
docker run --rm --entrypoint sh alpine -c ""apk update && apk add git go musl-dev && GOPATH=/ go get -u github.com/kubernetes/kompose && kompose --help""
```.
 @jmatsushita that'd do it.

You're running this directly in a container, we've been toying with the idea of running Kompose within a Docker container (for OS' such as CoreOS or Project Atomic). I'll see what we could do with that. Will probably solve your issue with alpine.

(can I close this issue now?).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,889,"Bintray links broken in the README.
 Tiny (and perhaps boring) issue but all Bintray links in the README are not working and I couldn't figure out what would be the correct path..
 @kadel any ideas?.
 @prein Hey! It seems that it fixed itself (which is really odd).

Do you mind trying it again your-end?.
 @cdrage Thanks, confirmed, works now..
 "
kubernetes,kompose,888,"Change font to black, not lightish gray.
 Changes the font so it's darker, rather than the lightish grey it is..
 "
kubernetes,kompose,887,"Add FAQ.
 Add some form of FAQ to Kompose.

TODO:
 - [ ] Why can't I access my service?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 "
kubernetes,kompose,886,"Output option with convert -c fails..
 Hi there,

When using `kompose convert -c` with the `-o` option, the charts are created in the desired folder but the last step fails:
```
> kompose convert -c -o chart
kompose convert -c -o chart
INFO Kubernetes file ""chart/service-service.yaml"" created
INFO Kubernetes file ""chart/service-deployment.yaml"" created
WARN open docker-compose/templates/chart/service-service.yaml: no such file or directory
WARN open docker-compose/templates/chart/service-deployment.yaml: no such file or directory
INFO chart created in ""./docker-compose/""
```

The resulting `docker-compose` folder lacks the template files:
```
> tree docker-compose
docker-compose
├── Chart.yaml
├── README.md
└── templates
```

It would be nice to be able to choose the name of the outputting directory rather than it being hardcoded to `docker-compose`.

Cheers,

Jun
.
 Honestly, charts are bit broken at the moment. Thanks for filing the issue! Hopefully it's just a simple CLI option fixed.

.
 Thanks for update! Can you tell me more about how they are broken? I'm looking into using `kompose` for this, so it'd be good to have a heads up! 😄 .
 @jmatsushita Ah, let me correct myself. There's not broken per-say, just a bit disorganized. Helm has changed quite a bit since the implementation was added (such as extra variables). Kompose will work fine converting to Helm no-problem, it's more.. properly naming the files, setting up comments and proper versioning within the Helm chart.

If you don't mind me asking, what's your main use-case?

I'm assuming:

Docker Compose (dev environment)
Docker Compose file -> Helm Chart (provisioning)
Then Kubernetes for deployment?
.
 Yes that's exactly the main use case. Glad to hear that the chart problem is mostly cosmetic :).
 I will take a look.
 "
kubernetes,kompose,885,"Fixed conversion matrix.
 Updated conversion matrix as cpus under deploy.resources in docker compose v3 are supported now.
 LGTM.
 "
kubernetes,kompose,884,"[EPIC] Improvements to volumes.
 Volumes is probably the number one problem when converting from Docker Compose to Kubernetes and thus we should add a solution for the conversion.

Suggestions: https://kubernetes.io/docs/concepts/api-extension/custom-resources/

Close / resolve these issues:

- [x] Error transforming objects https://github.com/kubernetes/kompose/issues/876
- [x] Add test cases / documentation for volume label https://github.com/kubernetes/kompose/issues/872
- [x] Fix volume long syntax https://github.com/kubernetes/kompose/issues/865
- [ ] Local volume from host conversion https://github.com/kubernetes/kompose/issues/855
- [ ] Supporting top-level volumes https://github.com/kubernetes/kompose/issues/447
- [x] Supporting host path volumes https://github.com/kubernetes/kompose/issues/109
- [ ] Supporting per-volume option https://github.com/kubernetes/kompose/issues/850

As well as:

- [ ] Improve errors and offer solutions rather than erroring
- [ ] Explain WHY it doesn't **clearly** within documentation as well as CLI.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,883,"Kompose down doesn't remove configmaps.
 When running `kompose up`, many resources are created including services, pods, deployments and configmaps. When running `kompose down`, created configmaps aren't removed. This results in a fatal error when `kompose up` is run subsequently.

## Expected
`kompose down` brings down all traces of the application in the cluster. `kompose up` and `down` can be run after each other

## Actual
Process dies before all resources can be created. `kompose up` emits `FATA Error while deploying application: configmaps ""<app>"" already exists` 

## logs
```
$ kompose up
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead.

INFO Deploying application in ""default"" namespace
INFO Successfully created Service: app
INFO Successfully created Service: nginx
INFO Successfully created Service: postgres
INFO Successfully created Service: redis
INFO Successfully created Deployment: app
INFO Successfully created Config Map: app-app-env
INFO Successfully created Deployment: nginx
INFO Successfully created PersistentVolumeClaim: nginx-claim0 of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work
INFO Successfully created Deployment: postgres
INFO Successfully created Config Map: postgres-app-env
INFO Successfully created PersistentVolumeClaim: postgres of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work
INFO Successfully created Deployment: redis

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.

$ kompose down
INFO Deleting application in ""default"" namespace
INFO Successfully deleted Service: app
INFO Successfully deleted Service: nginx
INFO Successfully deleted Service: postgres
INFO Successfully deleted Service: redis
INFO Successfully deleted Deployment: app
INFO Successfully deleted Deployment: nginx
INFO Successfully deleted PersistentVolumeClaim: nginx-claim0
INFO Successfully deleted Deployment: postgres
INFO Successfully deleted PersistentVolumeClaim: postgres
INFO Successfully deleted Deployment: redis

$ kompose up
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead.

INFO Deploying application in ""default"" namespace
INFO Successfully created Service: app
INFO Successfully created Service: nginx
INFO Successfully created Service: postgres
INFO Successfully created Service: redis
INFO Successfully created Deployment: app
FATA Error while deploying application: configmaps ""app-app-env"" already exists
```.
 @cdrage Can we close this?

@rkachowski Issue is fixed now. Please give it a try and let us know if you still face any problem,

Thanks
  .
 Yup. Thank you..
 "
kubernetes,kompose,882,"Test cross-compiling within travis.
 Tests cross compiling by building on 1.6 of Go for Windows / Linux /
macOS.
 Merging just so we can get builds working. Please revert if there's an issue :+1: .
 "
kubernetes,kompose,881,"Fix makefile.
 Fixes the makefile and uses sirupsen instead of sirupen..
 "
kubernetes,kompose,880,"Update vendoring / fix Windows builds.
 Something within golang.org/x/sys messed up and it doesn't help that we
have three different projects using different versions.

This vendor update specifies a golang.org/x/sys as well as fixes the
previous compiling issues with Windows/Linux/macOS builds.

See issue: 

```sh
gox -osarch=""darwin/amd64 linux/amd64 linux/arm windows/amd64""
-output=""bin/kompose-{{.OS}}-{{.Arch}}"" -ldflags=""-w -X
github.com/kubernetes/kompose/pkg/version.GITCOMMIT=42e7f0e""
Number of parallel builds: 1
-->   windows/amd64: github.com/kubernetes/kompose
-->     linux/amd64: github.com/kubernetes/kompose
-->    darwin/amd64: github.com/kubernetes/kompose
-->       linux/arm: github.com/kubernetes/kompose
1 errors occurred:
--> windows/amd64 error: exit status 2
Stderr: #
github.com/kubernetes/kompose/vendor/golang.org/x/crypto/ssh/terminal
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:42: undefined:
windows.ENABLE_ECHO_INPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:42: undefined:
windows.ENABLE_PROCESSED_INPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:42: undefined:
windows.ENABLE_LINE_INPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:42: undefined:
windows.ENABLE_PROCESSED_OUTPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:43: undefined:
windows.SetConsoleMode
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:62: undefined:
windows.SetConsoleMode
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:67: undefined:
windows.ConsoleScreenBufferInfo
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:68: undefined:
windows.GetConsoleScreenBufferInfo
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:91: undefined:
windows.ENABLE_ECHO_INPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:92: undefined:
windows.ENABLE_PROCESSED_INPUT
vendor/golang.org/x/crypto/ssh/terminal/util_windows.go:92: too many
errors
```.
 Re-basing against master (adding cross compiling) hopefully this is all green.

Merge this when you're ready / up-in-the-morning @surajnarwade :+1:  (and if it's all green).
 "
kubernetes,kompose,879,"Add development.md to site, refactor with `make vendor-update`.
 Since we ran into logrus issues, we've added `make vendor-update`. 

Two things:

 - Need to update `development.md` documentation to indicate that we use `make vendor-update` now.
 - Add `development.md` to the side-bar on the site.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /close.
 "
kubernetes,kompose,878,"n -> ✓ for build v3 support.
 ✓ for build v3 support since we merged in
https://github.com/kubernetes/kompose/pull/846/.
 "
kubernetes,kompose,877,"Refactor tests (integration).
 Let's refactor our testing suite to use a go file / more integrated file rather than using bash / command-line.

See: #868  for reference as well as #871 

TODO:

 - Change to `e2e_test.go`
 - Check if ports are up against Kubernetes, etc.
 - Fix failing OpenShift tests.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 "
kubernetes,kompose,876,"Error transforming Kubernetes objects.
 Hi,

i run into some issues with kompose when i run the following command. do you know what is wrong and how to resolve it?
```
kompose convert -f docker-compose.yml
WARN Unsupported links key - ignoring             
WARN Volume mount on the host ""./alertmanager/alertmanager.yml"" isn't supported - ignoring path on the host 
FATA Error transforming Kubernetes objects: k.UpdateController failed: updateTemplate failed: Unknown restart policy unless-stopped for servicealertmanager
```

docker-compose.yml:
```
version: ""2""

services:

  prometheus-server:
    image: prom/prometheus
    ports:
      - 9090:9090
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alert.yml:/etc/prometheus/alert.yml
    links:
      - ""alertmanager:alertmanager""

  alertmanager:
    image: prom/alertmanager
    restart: unless-stopped
    ports:
      - 9093:9093
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/config.yml
    command:
      - '-config.file=/etc/alertmanager/config.yml'
      - '-storage.path=/alertmanager'
      - '-log.level=debug'

  grafana:
    image: grafana/grafana
    ports:
      - 3000:3000
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=password
    links:
      - prometheus-server:prometheus

  go-mux-example:
    image: mux:v1
    ports:
      - 8080:8080
```.
 Thanks for pointing this out! Looks like `unless-stopped` isn't implemented. We should have a fix out this week :+1: .
 what happens if i remove the restart policy from the yml file?

here is what happens without the restart policy. how can i fix the warnings?
```
$ kompose convert -f docker-compose.yml
WARN Unsupported links key - ignoring             
WARN Volume mount on the host ""./alertmanager/alertmanager.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/prometheus.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/alert.yml"" isn't supported - ignoring path on the host 
INFO Kubernetes file ""alertmanager-service.yaml"" created 
INFO Kubernetes file ""go-mux-example-service.yaml"" created 
INFO Kubernetes file ""grafana-service.yaml"" created 
INFO Kubernetes file ""prometheus-server-service.yaml"" created 
INFO Kubernetes file ""alertmanager-deployment.yaml"" created 
INFO Kubernetes file ""alertmanager-claim0-persistentvolumeclaim.yaml"" created 
INFO Kubernetes file ""go-mux-example-deployment.yaml"" created 
INFO Kubernetes file ""grafana-deployment.yaml"" created 
INFO Kubernetes file ""prometheus-server-deployment.yaml"" created 
INFO Kubernetes file ""prometheus-server-claim0-persistentvolumeclaim.yaml"" created 
INFO Kubernetes file ""prometheus-server-claim1-persistentvolumeclaim.yaml"" created
``` 

how can i start the containers on my kubernetes with Minikube?
just run the following? ```kompose up```.
 With regards to the warnings, yes, you're free to ignore them, but due to using host volumes, Kubernetes doesn't support it.

Yup! It should theoretically work (you may have to modify your volumes). Using minikube and doing `kompose up` will bring it up on Kubernetes.

EDIT: Yes, removing restart, or changing it to `on-failure` will resolve the errors..
 i installed minicube and can run the sample they have here:
https://github.com/kubernetes/minikube/blob/v0.22.3/README.md

i run into the following issue, any why it cannot startup?
```
$ kompose convert -f docker-compose.yml
WARN Unsupported links key - ignoring             
WARN Volume mount on the host ""./alertmanager/alertmanager.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/prometheus.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/alert.yml"" isn't supported - ignoring path on the host 
INFO Kubernetes file ""go-mux-example-service.yaml"" created 
INFO Kubernetes file ""grafana-service.yaml"" created 
INFO Kubernetes file ""prometheus-server-service.yaml"" created 
INFO Kubernetes file ""alertmanager-pod.yaml"" created 
INFO Kubernetes file ""alertmanager-claim0-persistentvolumeclaim.yaml"" created 
INFO Kubernetes file ""go-mux-example-deployment.yaml"" created 
INFO Kubernetes file ""grafana-deployment.yaml"" created 
INFO Kubernetes file ""prometheus-server-deployment.yaml"" created 
INFO Kubernetes file ""prometheus-server-claim0-persistentvolumeclaim.yaml"" created 
INFO Kubernetes file ""prometheus-server-claim1-persistentvolumeclaim.yaml"" created

$ kompose up
WARN Unsupported links key - ignoring             
WARN Volume mount on the host ""./alertmanager/alertmanager.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/prometheus.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/alert.yml"" isn't supported - ignoring path on the host 
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
FATA Error while deploying application: Get https://192.168.99.100:8443/api: dial tcp 192.168.99.100:8443: getsockopt: operation timed out 
```.
 @Arnold1 for some reason Kompose isn't able to communicate to your Kubernetes cluster.

After you run ""minikube start"" are you able to access your cluster with kubectl? Ex. `kubectl get pods` ?.
 i think i stopped minikube before...

here is what i get now, but only grafana is running. alertmanager, go-mux-example, prometheus-server seem to have issues to run?
```
$ minikube start
Starting local Kubernetes v1.8.0 cluster...
Starting VM...
Getting VM IP address...
Moving files into cluster...
Setting up certs...
Connecting to cluster...
Setting up kubeconfig...
Starting cluster components...
Kubectl is now configured to use the cluster.

$ kompose up
WARN Unsupported links key - ignoring             
WARN Volume mount on the host ""./alertmanager/alertmanager.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/prometheus.yml"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""./prometheus/alert.yml"" isn't supported - ignoring path on the host 
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: go-mux-example 
INFO Successfully created Service: grafana        
INFO Successfully created Service: prometheus-server 
INFO Successfully created Pod: alertmanager       
INFO Successfully created PersistentVolumeClaim: alertmanager-claim0 of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work 
INFO Successfully created Deployment: go-mux-example 
INFO Successfully created Deployment: grafana     
INFO Successfully created Deployment: prometheus-server 
INFO Successfully created PersistentVolumeClaim: prometheus-server-claim0 of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work 
INFO Successfully created PersistentVolumeClaim: prometheus-server-claim1 of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work 

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

```
$ kubectl get pods
NAME                                 READY     STATUS             RESTARTS   AGE
alertmanager                         0/1       CrashLoopBackOff   4          3m
go-mux-example-7c96ff7bfd-78dz7      0/1       ImagePullBackOff   0          3m
grafana-85f8b648d8-kqpj9             1/1       Running            0          3m
prometheus-server-6bc89bcb6f-4tvmk   0/1       CrashLoopBackOff   4          3m

$ kubectl get services
NAME                TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
go-mux-example      ClusterIP   10.0.0.93    <none>        8080/TCP         7m
grafana             ClusterIP   10.0.0.11    <none>        3000/TCP         7m
kubernetes          ClusterIP   10.0.0.1     <none>        443/TCP          2h
prometheus-server   ClusterIP   10.0.0.130   <none>        9090/TCP         7m

$ kubectl get pods --all-namespaces 
NAMESPACE     NAME                                 READY     STATUS             RESTARTS   AGE
default       alertmanager                         0/1       CrashLoopBackOff   8          19m
default       go-mux-example-7c96ff7bfd-78dz7      0/1       ImagePullBackOff   0          19m
default       grafana-85f8b648d8-kqpj9             1/1       Running            0          19m
default       prometheus-server-6bc89bcb6f-4tvmk   0/1       CrashLoopBackOff   8          19m
kube-system   kube-addon-manager-minikube          1/1       Running            3          2h
kube-system   kube-dns-6fc954457d-swcln            3/3       Running            6          2h
kube-system   kubernetes-dashboard-b55k5           1/1       Running            2          2h
```

in the dashboard i see:
<img width=""1084"" alt=""screen shot 2017-11-27 at 2 11 38 pm"" src=""https://user-images.githubusercontent.com/3844226/33284390-f2a170a8-d37c-11e7-97a0-5eab9d8ff755.png"">

<img width=""1153"" alt=""screen shot 2017-11-27 at 2 12 57 pm"" src=""https://user-images.githubusercontent.com/3844226/33284466-385901b0-d37d-11e7-89bc-565ac922c5bd.png"">

go-mux-example uses the mux image, which i build as follows: ```docker build -t mux:v1 .```

```
$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
mux                 v1                  4c514d3a0cc9        5 days ago          784MB
```.
 @cdrage any idea?.
 @Arnold1 Unfortunately when it comes down to volumes within Docker Compose / Kompose, it get's fairly tricky.

Mind posting your full docker-compose example (the one you're using now) and we can go from there? Volumes are the worst part of this entire operation, very difficult to get right since some containers (such as prometheus) rely on them to be EXACT.
.
 @cdrage do you mean all the files?.
 @Arnold1 just your modified docker-compose.yaml file so I can test it my-side.

I've had a conversion with @kadel  on how we could improve volumes, it's the trickiest part of Kompose unfortunately. .
 @cdrage i added all files here: https://github.com/Arnold1/prometheus_kubernetes incl. docker-compose.yml

steps:
```
$ ./build_docker.sh
$ kompose convert -f docker-compose.yml
$ minikube start
$ kubectl delete --all deployments; kubectl delete --all pods; kubectl delete --all services; kubectl delete --all persistentvolumeclaims
$ kompose up
```

@cdrage can you reproduce it on your machine?.
 @Arnold1 , there's no Dockerfile in your repo :(

```
$ ./build_docker.sh 
unable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /tmp/arnold/prometheus_kubernetes/Dockerfile: no such file or directory
```
.
 @surajnarwade @cdrage I added the missing dockerfile. can you execute it now? please let me know..
 @cdrage is there a workaround for the meantime?.
 @Arnold1 Sorry, it's been quite a busy week for us, we're going to try and get around to it this week. It may involve modifying some of the containers since for some reason they like Docker Compose but now when it's on Kubernetes. I'll try your updated repo it soon :+1: .
 @cdrage any update?.
 @Arnold1 some of your services has volumes which may contain some file which are necessary for your applcation. Hence, status for your application is `Crashloopbackoff`, Recently I wrote a blog about sharing host directory into minkube (you can check blog [here](http://suraj.pro/post/hostmount-minikube/))

So first do `kompose convert` and generate kubernetes files and then edit those files accordingly with volume details

and push your image `go mux` to some registry and provide full name for docker image,
for example,

```
<registry_name>/<image_name>:tag
```.
 @surajnarwade ok, i currently try to find a workaround. how can i make it work? im not sure how the volumes in the kubernetes files... would it work when i follow your blog?

why do you want to push the docker images to some registry? do you mean docker hub or what do you mean?.
 @cdrage some time to look into? :).
 @Arnold1 Sorry, I haven't found time to look into this yet :( I did have very brief look and as what @surajnarwade said, it's most likely because the containers are trying to retrieve information that's originally suppose to be passed in through volumes..
 i guess you have some time over christmas? :)
will reading and applying @surajnarwade article solve the issue? refering to: http://suraj.pro/post/hostmount-minikube/.
 Any update on this? Same issue here when trying to convert from Docker Compose to Kubernetes for containerized applications that use volume mappings out to OS for persistent data.

Thanks.
 @d-mcd Unfortunately volumes is *very* tricky since it's a completely different concept within Kubernetes. One of the solutions is to create a hostPath volumes which were in the PR and issues here: #109 #734 

We're still investigating and will most likely push a PR out for adding hostPath volumes by next release. It's a hack to get it working (hostPath volumes are only recommended for development), but it's a solution nevertheless.

.
 hi, just wondering what is the solution now? can i retry and test it? if so how?.
 @hangyan contributed the hostpath volume, so this is solved! :+1: .
 @could you show how to run my example using the change he did?.
 @Arnold1 the test [compose file](https://github.com/hangyan/kompose/tree/master/script/test/fixtures/volume-mounts/hostpath) and [command](https://github.com/hangyan/kompose/blob/master/script/test/cmd/tests.sh#L196) in the PR might help.
 @Arnold1 did you able to run successfully
.
 have not tested yet, how to test it with latest code?.
 "
kubernetes,kompose,875,"Update conversion doc for env_file.
 Updates the conversion doc to indicate that we support env_file

Closes https://github.com/kubernetes/kompose/issues/873.
 "
kubernetes,kompose,874,"1.5.0 Release.
 "
kubernetes,kompose,873,"conversion metrix doc is outdated.
 Conversion metrics says that `env_file` is not supported in Kompose.

But according to https://github.com/kubernetes/kompose/issues/308 it is..
 "
kubernetes,kompose,872,"Add test cases / documentation for setting PVC volume size.
 Tracker for https://github.com/kubernetes/kompose/pull/867

We need to:

- [ ] Add documentation for the new label
- [ ] Add tests.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 "
kubernetes,kompose,871,"Kompose will read input from stdin.
 Resolves issue #870

for example,

```
$ cat docker-compose.yaml | kompose convert -f -
INFO Kubernetes file ""frontend-service.yaml"" created
INFO Kubernetes file ""redis-master-service.yaml"" created
INFO Kubernetes file ""redis-slave-service.yaml"" created
INFO Kubernetes file ""frontend-deployment.yaml"" created
INFO Kubernetes file ""redis-master-deployment.yaml"" created
INFO Kubernetes file ""redis-slave-deployment.yaml"" created
```.
 Please add WIP and begin work on adding tests :+1: .
 @cdrage I tried writing functional test but it's not working ?
can you provide me some pointer ?.
 @cdrage , unit tests and command line test didn't work :( so I have added integration test (test-k8s).
Please review.
 @cdrage all green :).
 cc @cdrage 
.
 @hangyan I would of liked to have reviewed this before merging.. I'm against adding ""short mode"" to the testing suite. If you look at the code too there's this problem: https://github.com/kubernetes/kompose/pull/871/files#diff-aab6ee46f79d5d6c0c930f2773b8be29R17 where the test actually isn't being tested...
 @cdrage Sorry, I have seen you approve this, and I have reviewed this too...Didn't seen that.. My bad..
 @hangyan Ah! I'm sorry. It looks like I *did* approve this.. I think I meant to do the request changes button haha. My mistake! It's totally my fault.

I've opened up a PR to reverse the `-short` changes #1037 .
 "
kubernetes,kompose,870,"kompose should read input from stdin.
 kompose should take standard input as well,

for example,

```
echo docker-compose.yml | kompose convert -f -
```
.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
kubernetes,kompose,869,"Updated conversion matrix.
 .
 @surajnarwade This is actually not true and still needs to be open.

Testing this does NOT work:

```yaml
version: ""3""                                                                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                                  
services:                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                  
 web:                                                                                                                                                                                                                                                                             
  image: tuna/docker-counter23                                                                                                                                                                                                                                                    
  ports:                                                                                                                                                                                                                                                                          
    - ""5000:5000""                                                                                                                                                                                                                                                                 
  deploy:                                                                                                                                                                                                                                                                         
    replicas: 1                                                                                                                                                                                                                                                                   
    restart_policy:                                                                                                                                                                                                                                                               
      condition: any                                                                                                                                                                                                                                                              
    labels:                                                                                                                                                                                                                                                                       
        com.example.description: ""Accounting webapp""                                                                                                                                                                                                                              
  labels:                                                                                                                                                                                                                                                                         
    kompose.service.type: NodePort 
```


```sh
▶ cat web-service.yaml web-deployment.yaml 
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: ./kompose convert -f examples/docker-compose-counter-v3.yaml
    kompose.service.type: NodePort
    kompose.version: """"
  creationTimestamp: null
  labels:
    io.kompose.service: web
  name: web
spec:
  ports:
  - name: ""5000""
    port: 5000
    targetPort: 5000
  selector:
    io.kompose.service: web
  type: NodePort
status:
  loadBalancer: {}
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: ./kompose convert -f examples/docker-compose-counter-v3.yaml
    kompose.service.type: NodePort
    kompose.version: """"
  creationTimestamp: null
  labels:
    io.kompose.service: web
  name: web
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: web
    spec:
      containers:
      - image: tuna/docker-counter23
        name: web
        ports:
        - containerPort: 5000
        resources: {}
      restartPolicy: Always
status: {}
```.
 "
kubernetes,kompose,868,"Adding `--controller` flag in `up` & `down`.
 To make `kompose up` & `kompose convert` equal in feature, This PR will
add `--controller` flag for `kompose up` as well as `kompose down`
so that user experience will be the same for `up` & `convert`
Resolves #798.
 @surajnarwade Need tests :+1: .
 @cdrage since this feature is regarding `kompose up` and `kompose down`, there will be integration tests.
cc @ashetty1 .
 @cdrage , review needed :).
 LGTM! Let's merge!.
 "
kubernetes,kompose,867," Set PVC volume size with kompose.volume.size.
 #235 

Example:
```
version: '3'
services:
  cs-btcd:
    image: cybernode/bitcoin-btcd:temp
    labels:
      kompose.volume.size: 500Mi
    volumes:
      - /cyberdata:/cyberdata
```.
 Hey @abitrolly 

The code LGTM. May be good to get another quick review by @surajnarwade or @kadel 

Are you perhaps able to add any tests?

To be honest, creating unit tests is a bit of a mess right-now, as we're still waiting for https://github.com/kubernetes/kompose/pull/805 to be merged in.

If not, I don't mind creating a PR after your merge, as of right now, it's quite a manual process to create integration tests.
.
 Also: please combine commits to 1 commit!.
 Squashed and rebased. 

For tests, there is no info how to run them. =/
https://github.com/kubernetes/kompose.
 @abitrolly No worries on that, I'll push the PR tomorrow (it's a holiday here in Canada today) and see what tests I can write. I'll have to update #805 and add some documentation for future cases for adding tests.

Thanks for the contribution!.
 Looks like Travis check was not reported to GitHub correctly.

I am right that tests are now shell-based?.
 Yup. that is correct! Pushing the PR now.

EDIT: Travis looked to have reported it incorrectly, but all green from here..
 "
kubernetes,kompose,866,"architecture.md  Link sources.
 .
 Thanks! :) That's much better..
 "
kubernetes,kompose,865,"volumes long-syntax doesn't work.
 [Conversion matrix](http://kompose.io/conversion/) specifies that `volumes: long-syntax` works, but it doesn't, because it requires at least `version: '3.2`` in the header to be loaded. For example, this fails to validate with `docker-compose`:

```
version: '3'
services:
  cs-btcd:
    image: cybernode/bitcoin-btcd:temp
    volumes:
      - type: volume
        source: /cyberdata
```
```
✗ docker-compose config 
ERROR: The Compose file './docker-compose.yml' is invalid because:
services.cs-btcd.volumes contains an invalid type, it should be a string
```
The same error is reported by `kompose`:
```
✗ kompose convert
FATA services.cs-btcd.volumes.0 must be a string  
```

Changing version to `3.2` makes `docker-compose config` pass, but `kompose` still fails there:
```
✗ kompose convert       
FATA Version 3.2 of Docker Compose is not supported. Please use version 1, 2 or 3 
```
.
 Related to #725.
 @abitrolly , as of now we don't support `docker-compose 3.2` yet
@cdrage we should update `conversion-matrix` accordingly.
 Looks like there is some partial support in https://github.com/kubernetes/kompose/blob/master/pkg/loader/compose/v3.go#L120.
 Maybe we can support version 3.1-3.2-3.3-3.4. Docker compose in version 3.x develop fast and many attribute is added into it.   We can work together to develop support these new attribute.We can support 3.1 first and step by step to next version..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 "
kubernetes,kompose,864,"Move version information to separate file.
 Moves the version information to a seperate file. This is mostly due to
import cycle errors occuring when using ""import
github.com/kubernetes/kompose/cmd"" in order to get the global variable
of VERSION and GITCOMMIT.

Update's the Makefile and other files accordingly.

If the version and commmit is unretriveable due to not being able to
find the kompose binary, the one from pkg/version/version.go will be
used..
 "
kubernetes,kompose,863,"Fix typo.
 Signed-off-by: xianlu <xianlubird@gmail.com>.
 "
kubernetes,kompose,862,"Ignore links attribute and print warning message.
 Related to issue    #859 


Signed-off-by: xianlubird@gmail.com.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 CNCF-CLA   Done..
 @xianlubird , please fix functional test examples accordingly.
 @surajnarwade Done, pls review, thanks..
 LGTM.
 Thanks for @cdrage @surajnarwade review.    So when will this PR be merged ? .
 LGTM! was just checking that this works locally on my machine. Mergin'.
 "
kubernetes,kompose,861,"Add TOC to documentation, add readme.md notice.
 Adds TOC to architecture.md, getting-started.md, integrations.md and
user-guide.md

Updates README.md to add a notice that the files are best viewed on the
website..
 "
kubernetes,kompose,860,"Update CSS.
 Updates the CSS for Kompose site.
 "
kubernetes,kompose,859,"Docker compose links section can't support.
   About compose  introduce links https://docs.docker.com/compose/compose-file/compose-file-v2/#links .
  I have a compose like this:
```
web:
  image: registry.aliyuncs.com/acs-sample/wordpress:4.5
  ports:
    - '80'
  environment:
    WORDPRESS_AUTH_KEY: changeme
    WORDPRESS_SECURE_AUTH_KEY: changeme
    WORDPRESS_LOGGED_IN_KEY: changeme
    WORDPRESS_NONCE_KEY: changeme
    WORDPRESS_AUTH_SALT: changeme
    WORDPRESS_SECURE_AUTH_SALT: changeme
    WORDPRESS_LOGGED_IN_SALT: changeme
    WORDPRESS_NONCE_SALT: changeme
    WORDPRESS_NONCE_AA: changeme
  restart: always
  links:
    - 'db:mysql'
db:
  image: registry.aliyuncs.com/acs-sample/mysql:5.7
  environment:
    MYSQL_ROOT_PASSWORD: password
  restart: always
  labels:
    aliyun.logs: /var/log/mysql
```
  kompose will convert db service to db deployment, but the wordpress deplotment will connect db by `mysql` hostname.   So wordpress pods will call that and it can't connect the db database.  Because the `links` can't convert to k8s yaml.

  I have two kinds suggestions:
1.  kompose convert db service to mysql service, just rename deployment name for links, and the new service name is mysql, the wordpress can connect mysql by service name corrently.
2. print warning or error message if compose has links section which alias name is different from service name.

   Can anyone give me some suggestion, and I will create a PR to fix this, Thanks..
 I think this will be bit confusing since name of deployment and service will change,

> kompose convert db service to mysql service, just rename deployment name for links, and the new service name is mysql, the wordpress can connect mysql by service name corrently.

This second option, I think will be better,

> print warning or error message if compose has links section which alias name is different from service name.

@cdrage thought here ?.
 Yeah, we should add the second option since the `links` key isn't able to be effectively converted to Kubernetes. We should clarify more about *why* it doesn't work and what the alternatives are.

Thanks @xianlubird for pointing this out!.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
kubernetes,kompose,858,"1.4.0 Release.
 "
kubernetes,kompose,857,"update integration doc.
 Add documentation for
- [ ] Dev. suit installer

Rearrange integration doc
- [ ] Bring f8-m-p integration on the top in the list
- [ ] Dev. suit installer integration second.
 Documentation for Dev Suite installer has already been added, see: http://kompose.io/getting-started/#rhel-and-kompose.
 ping @hrishin .
 @cdrage thats good :+1:, it would be nice if we add some bits of dev. suit installer under integration document?
@pradeepto what you say?.
 @hrishin Yup. Just make a PR and push whatever you think is necessary :+1: .
 @cdrage sure .
 @hrishin Keep in mind that we already have a tutorial on how to use DevSuite under integrations, but there's no need to have two tutorials in two places. Whatever you think is best, just push to a PR and we can review it..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /close.
 "
kubernetes,kompose,856,"insufficient cpu.
 kompose 1.3.0 ()
Google Cloud SDK 176.0.0
alpha 2017.09.15
bq 2.0.27
core 2017.10.13
gsutil 4.27

hi,

i have this docker-compose file which works fine on docker with gloud gce.
but when deployed using kompose,
i keep getting ""insufficient cpu"" on either or both redis and nginx pods

even resizing cluster count to 2, it keep giving the same error.
does it take into consideration of resources?
```
version: ""3""
services:

  redis:
    image: 'redis:latest'
    ports:
      - '6379:6379'
    networks:
      - backend
    volumes:
      - data:/data
    logging:
      driver: ""json-file""
      options:
        max-size: ""500k""
        max-file: ""50""
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 100M
        reservations:
          cpus: '0.0001'
          memory: 50M
    restart: ""on-failure""

  pdf2htmlex:
    image: 'ukwa/pdf2htmlex:latest'
    ports:
      - '5000:5000'
    networks:
      - backend
    logging:
      driver: ""json-file""
      options:
        max-size: ""500k""
        max-file: ""50""
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 200M
        reservations:
          cpus: '0.0001'
          memory: 50M
  arxiv:
    image: 'nurtureai/arxivscraper'
    command: 'server'
    ports:
      - '5005:5005'
    networks:
      - backend
    logging:
      driver: ""json-file""
      options:
        max-size: ""500k""
        max-file: ""50""
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 200M
        reservations:
          cpus: '0.0001'
          memory: 50M
  nginx:
    environment:
      - ""ENVNAME=staging""
      - ""APPHost=staging_web""
    image: 'nurtureai/nginx-ssl'
    networks:
      - backend
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - /root/web:/home/app/web
    logging:
      driver: ""json-file""
      options:
        max-size: ""500k""
        max-file: ""50""
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 200M
        reservations:
          cpus: '0.0001'
          memory: 50M

networks:
  frontend:
  backend:

volumes:
  db-data:
  web:
  data:
```.
 `kompose` will simply map your cpu in `docker-compose` to k8s, it will not consider amount of resources.
 what is k8s?
so means kompose does not follow cpu and memory limit set in docker compose yml?.
 @u007 , k8s --> kubernetes, kompose does follow docker compose yml only,

if you check generated deployment for your `redis` service:

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.3.0 (HEAD)
  creationTimestamp: null
  labels:
    io.kompose.service: redis
  name: redis
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: redis
    spec:
      containers:
      - image: redis:latest
        name: redis
        ports:
        - containerPort: 6379
        resources:
          limits:
            cpu: 100m
            memory: ""104857600""
          requests:
            memory: ""52428800""
        volumeMounts:
        - mountPath: /data
          name: data
      restartPolicy: Always
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: data
status: {}
```

`cpu` and `memory` are exactly mapped

.
 is this gcloud issue?.
 @u007 most likely your gcloud instance has smaller CPU than your local instance. I'd increase the amount of CPU you're using on gcloud and see what happens..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 "
kubernetes,kompose,855,"Local volumes (from host) via conversion.
 I'm trying to get my feet wet with Kubernetes.  Since we already had a lot of investment in docker-compose I figured I'd try kompose to convert my docker-compose.yml into kubernetes service definitions.

When I do the conversion, I get this warning:

```
WARN Volume mount on the host ""/Users/spartan/src/my-app/docker/custom-scripts"" isn't supported - ignoring path on the host
```

My volume looks like this in docker-compose

```
    volumes:
      - ""../docker/custom-scripts:/custom""
```

Is there another format I should use?.
 we don't support volume mount on host with kompose, you can use `emptyDir`  though.
 That's fine, I don't mind editing the files after the conversion.  Wouldn't I want a `hostPath` though?  Can `hostPath` be relative?.
 Hey John! Due to how Kubernetes handles volumes, it's difficult to pass in a host volume / root volume. We *are* adding support for hostPath however, as one of our outside contributors is pushing it via PR: https://github.com/kubernetes/kompose/pull/734.
 @cdrage understood.  It's more of a case where I think I can edit the volume definition afterwards..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /reopen.
 @tuyenpm9: You can't reopen an issue/PR unless you authored it or you are a collaborator.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/855#issuecomment-433047503):

>/reopen


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
kubernetes,kompose,854,"old Kompose version in Fedora 26.
 Fedora 26 still has only Kompose 1.0.0 but currently the latest released version is 1.3.0 :-(.
 cc @surajssd .
 So the latest is available on centos as:

```
yum install -y centos-release-openshift-origin
yum install -y kompose
```

But for fedora and epel the PR is open https://github.com/dustymabe/fedpkg-kompose/pull/13 and https://github.com/dustymabe/fedpkg-kompose/pull/12.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 "
kubernetes,kompose,853,"panic: runtime error: invalid memory address or nil pointer dereference.
 With a ver 2 file works but with the same file in ver 3 I get;

```
$ kompose convert -f docker-compose.am-int.yml 
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2219a7b]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc42016b700, 0x27, 0xc420044220, 0x1, 0x1, 0xc4201b76b0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:321 +0x40b
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc42055d3a0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27dbd20)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3700a00, 0xc42055d3a0, 0x1, 0x1, 0xc4201b6f60, 0x0, 0x0, 0x17, 0x15)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:165 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x289b588, 0x4, 0x0, 0x28af58b, 0x15, ...)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36ce680, 0xc420311c20, 0x0, 0x2)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36ce680, 0xc420311be0, 0x2, 0x2, 0x36ce680, 0xc420311be0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36ceb00, 0x36cef80, 0x2493b60, 0x36cec50)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36ceb00, 0x0, 0xc42057ff48)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/main.go:22 +0x20
```.
 @grebois can you paste your `docker-compose` file here ?
.
 @surajnarwade can't really, too many secrets, will try to create one to reproduce the error. Just give me 2 days..
 @surajnarwade here you can reproduce it;

```
version: '3'
services:
  nginx:
    image: nginx
    ports:
      - 443:443
      - 80:80
    environment:
      - USERNAME
      - PASSWORD
```

output:

```
$ sudo kompose convert -f docker-compose.yml 
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2219a7b]

goroutine 1 [running]:
github.com/kubernetes/kompose/pkg/loader/compose.dockerComposeToKomposeMapping(0xc4203a24c0, 0x1d, 0xc42000ade0, 0x1, 0x1, 0xc4202d8e10)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:321 +0x40b
github.com/kubernetes/kompose/pkg/loader/compose.parseV3(0xc4205472e0, 0x1, 0x1, 0x1, 0x1, 0x0, 0x30, 0x27dbd20)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/v3.go:113 +0x22b
github.com/kubernetes/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3700a00, 0xc4205472e0, 0x1, 0x1, 0xc4202d8a80, 0x0, 0x0, 0x17, 0x14)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/loader/compose/compose.go:165 +0x4d2
github.com/kubernetes/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x289b588, 0x4, 0x0, 0x28af58b, 0x15, ...)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/pkg/app/app.go:227 +0x145
github.com/kubernetes/kompose/cmd.glob..func3(0x36ce680, 0xc4200a2060, 0x0, 0x2)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/convert.go:95 +0x4d
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x36ce680, 0xc4200a2020, 0x2, 0x2, 0x36ce680, 0xc4200a2020)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:704 +0x2c6
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36ceb00, 0x36cef80, 0x2493b60, 0x36cec50)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:785 +0x30e
github.com/kubernetes/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36ceb00, 0x0, 0xc420543f48)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/vendor/github.com/spf13/cobra/command.go:738 +0x2b
github.com/kubernetes/kompose/cmd.Execute()
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/cmd/root.go:92 +0x31
main.main()
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes/kompose/main.go:22 +0x20

```.
 @grebois , kompose is behaving strict with environment variable, make sure you have already defined environment variables.

I tried following way,

```
export PASSWORD=xyz
```

and it worked,

```
]$ kompose convert -f docker-compose.yml  --stdout 
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kompose.cmd: kompose convert -f docker-compose.yml --stdout
      kompose.version: 1.3.0 (HEAD)
    creationTimestamp: null
    labels:
      io.kompose.service: nginx
    name: nginx
  spec:
    ports:
    - name: ""443""
      port: 443
      targetPort: 443
    - name: ""80""
      port: 80
      targetPort: 80
    selector:
      io.kompose.service: nginx
  status:
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      kompose.cmd: kompose convert -f docker-compose.yml --stdout
      kompose.version: 1.3.0 (HEAD)
    creationTimestamp: null
    labels:
      io.kompose.service: nginx
    name: nginx
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: nginx
      spec:
        containers:
        - env:
          - name: PASSWORD
            value: xyz
          - name: USERNAME
            value: snarwade
          image: nginx
          name: nginx
          ports:
          - containerPort: 443
          - containerPort: 80
          resources: {}
        restartPolicy: Always
  status: {}
kind: List
metadata: {}
```
.
 But this only happens with version 3, version 2 works fine... try:

```
version: '2'
services:
  nginx:
    image: nginx
    ports:
      - 443:443
      - 80:80
    environment:
      - USERNAME
      - PASSWORD
```.
 @grebois Thanks for the bug report. Yup. Version 3 *should* automatically pick up the environment variables. Looks to be an issue upstream. We'll investigate it and push out a fix!.
 @cdrage thanks!.
 Hello,
I am using Window 7 (64 Bit). When I am trying to configure rinkeby using ""geth --rinkeby"" command I am getting following error : 
Panic: runtime error: invalid memory address or nil pointer dereference  [signal 0xc0000005 code=0x0 addr=0x0 pc=0xb88a07] 
Please details find below : 
C:\Users\yogendra>geth --rinkeby
WARN [12-14|19:10:09] No etherbase set and no accounts found as default
INFO [12-14|19:10:09] Starting peer-to-peer node               instance=Geth/v1.
7.3-stable-4bb3c89d/windows-amd64/go1.9
INFO [12-14|19:10:09] Allocated cache and file handles         database=C:\\User
s\\yogendra\\AppData\\Roaming\\Ethereum\\rinkeby\\geth\\chaindata cache=128 hand
les=1024
INFO [12-14|19:10:09] Initialised chain configuration          config=""{ChainID:
 4 Homestead: 1 DAO: <nil> DAOSupport: true EIP150: 2 EIP155: 3 EIP158: 3 Byzant
ium: 1035301 Engine: clique}""
INFO [12-14|19:10:09] Initialising Ethereum protocol           versions=""[63 62]
"" network=4
INFO [12-14|19:10:09] Loaded most recent local header          number=0 hash=634
1fd…67e177 td=1
INFO [12-14|19:10:09] Loaded most recent local full block      number=0 hash=634
1fd…67e177 td=1
INFO [12-14|19:10:09] Loaded most recent local fast block      number=0 hash=634
1fd…67e177 td=1
INFO [12-14|19:10:09] Loaded local transaction journal         transactions=0 dr
opped=0
INFO [12-14|19:10:09] Regenerated local transaction journal    transactions=0 ac
counts=0
INFO [12-14|19:10:09] Starting P2P networking
INFO [12-14|19:10:11] UDP listener up                          self=enode://c719
de22207c8c2a0ce540017eae6a43d8c2b8d37dd1caaa2d0350d55ed9657d25e263ae94be7528466c
e029521eab8706bbac9571b8d98082b109601852ea01@0.0.0.0:30303
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xc0000005 code=0x0 addr=0x0 pc=0xb88a07]

goroutine 85 [running]:
github.com/ethereum/go-ethereum/eth/filters.(*EventSystem).eventLoop(0xc042e5c04
0)
        C:/gopath/src/github.com/ethereum/go-ethereum/eth/filters/filter_system.
go:417 +0x337
created by github.com/ethereum/go-ethereum/eth/filters.NewEventSystem
        C:/gopath/src/github.com/ethereum/go-ethereum/eth/filters/filter_system.
go:112 +0x10b

**Please guide me, how can I resolve this issue. your answer would be appreciated.** .
 @yogi-emorphis can you please post your docker-compose.yaml file?.
 @cdrage  Thanks for reply. I am not using docker, any other way for resolving ?

.
 @yogi-emorphis is this kompose related issue ?.
 
No , I am just trying to configure rinkeby..
 Probably this is wrong place to ask question regarding rinkeby..
 @surajnarwade May be you are right but I am facing same error. May be I will get any idea why are occurring this error. .
 @yogi-emorphis rinkeby uses go-etherium, I'd suggest opening up an issue with your error here: https://github.com/ethereum/go-ethereum.
 @cdrage  I think this should closed by #926 too..
 close by #926 .
 "
,,852,"Updated `--help` page for `kompose up`.
 This PR will add customhelp section in `kompose up --help` section,
which will show consistency in help section.
Issue reference: #842

for example,

```
$ kompose up --help
Deploy your Dockerized application to a container orchestrator. (default ""kubernetes"")

Usage:
  kompose up [flags]

OpenShift Flags:
      --build-branch             Specify repository branch to use for buildconfig (default is current branch name)
      --build-repo               Specify source repository for buildconfig (default is current branch's remote url
      --insecure-repository      Specify to use insecure docker repository while generating Openshift image stream object

Flags:
      --build string       Set the type of build (""local""|""build-config"" (OpenShift only)|""none"") (default ""local"")
  -h, --help               help for up
      --namespace string   Specify Namespace to deploy your application (default ""default"")
      --replicas int       Specify the number of replicas generated (default 1)
      --volumes string     Volumes to be generated (""persistentVolumeClaim""|""emptyDir"") (default ""persistentVolumeClaim"")

Global Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```.
 @cdrage review needed .
 LGTM.
 "
,,851,"Not creation of `-service.yaml` when `restart` is present.
 Hi, using `1.3.0` of `kompose` and this trivial `docker-compose.yaml`:

```
frontend:
  image: registry:5000/frontend:1.0.0
  ports:
    - ""12681:80""
    - ""12683:443""
  environment:
    API_URL: ""http://10.179.49.0:12603""
  restart: 'no'

redis:
  image: registry:5000/redis:3.0.7
  ports:
    - ""12679:6379""
```

```
[root@node1 k]# kompose convert
INFO Kubernetes file ""redis-service.yaml"" created 
INFO Kubernetes file ""frontend-pod.yaml"" created  
INFO Kubernetes file ""redis-deployment.yaml"" created 
```

There's no service for the frontend, which I thought was a bit odd. When I remove the `restart` line completely, I get a different set of files:

```
[root@node1 k]# kompose convert
INFO Kubernetes file ""frontend-service.yaml"" created 
INFO Kubernetes file ""redis-service.yaml"" created 
INFO Kubernetes file ""frontend-deployment.yaml"" created 
INFO Kubernetes file ""redis-deployment.yaml"" created 
```

Yes, two services and two deployments is what I'd expect. Is this a bug?

.
 @gdhgdhgdh , when you mention `restart: no`, kompose will generate pod.
for more reference: http://kompose.io/user-guide/#restart.
 Yeah that makes sense - the question was really that I would still expect a `kind: Service` to be created even if it's pointing to a one-off pod. Is that wide of the mark?.
 @gdhgdhgdh , `restart: no` will give same behaviour as `job`, so it makes no sense to create service, I think.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 @surajnarwade @cdrage  I thinks the logic should goes to:

1. with ports, create service by default
2. without ports, no service. With labels, create Headless Service

This should cause no confuse any more.

related #823 .
 /remove-lifecycle stale.
 @hangyan I agree with all those points. We should implement a label for a headless service rather than relying on ""hidden"" features such as `restart: no`. Labels such as specifying to use a Job instead...
 +1 @hangyan .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,850,"Add support for ""scratch space"" volumes.
 When running a worker-type container, you'd want it to have some temporary workspace where it can leave temp files, etc, so called ""scratch space"".

With `compose` and local environments, this would simply be another volume:

```yaml
# docker-compose.yaml
version: 2
services:
  worker:
    volumes:
      - tmp:/tmp
volumes:
  tmp: ~
```

But this would become a full blown PVC on production which is not something you want. Better alternative would be to label the volume (say, `kompose.volume.scratch = true` or something) and transform to an [`emptyDir`](https://kubernetes.io/docs/concepts/storage/volumes/#emptydir) volume:

```yaml
# dc.yaml
apiVersion: v1
kind: DeploymentConfig
spec:
    template:
        spec:
            containers:
                -
                    volumeMounts:
                      - mountPath: /tmp
                        name: tmp-scratch
            volumes:
              - emptyDir: {}
                name: tmp-scratch
```.
 @dkarlovi , you can mention something like this

```
kompose convert --volumes emptydir
```.
 @surajnarwade idea here is to allow the user to specify which volume is supposed to be a scratch space, which isn't, it's not binary..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
,,849,"Fix Redirecting Error in README.md.
 Setup and Quickstart file are giving 404 as they were renamed
to installation and getting-started repectively.
Renamed the same in README.md to fix redirecting.
Fixes #845.
 @cdrage Please review..
 "
,,848,"Redirects not working.
 Due to not adding a trailing `/` redirects were not working.

For example, going to kompose.io/docs/user-guide.md will appear as
plaintext html, adding a trailing / creates an index.html in the
directory and correctly redirects the user..
 "
,,847,"Fix Redirecting Error.
 This wil fix the redirecting issue to quickstart in integrations.md
and to kompose installation in maven-example.md
Fixes #844.
 @cdrage Please, review..
 LGTM.
 "
,,846,"Added support for build key in v3.
 Resolves #636 

This PR will add support for `build` in docker compose v3, as docker/cli#481 got merged now.
also this will update `sirupsen`, `docker/cli`, `docker/libcompose` in `glide`,
Also changed `Sirupsen` with `sirupsen` in all kompose packages as well as in
`docker/distribution` packages.
 @surajnarwade 
Please update commit description message (more detail, not just resolves X).

Tests would be good too!.
 Hey @surajnarwade I don't see why there is an issue with this. You are only updating Version 3 of Docker Compose which uses `docker/cli`, you shouldn't be touching / using `docker/libcompose`.

I also see that `docker/cli` is already using the most up-to-date logrus here: https://github.com/docker/cli/commit/e3b7700fb9ac7df392e4915978bfc714d9dacad8

What issues are you running into? Please investigate and let me know!.
 Also the error is just a simple renaming of `Sirupsen` in completion.go:

```
cmd/completion.go:9:2: cannot find package ""github.com/Sirupsen/logrus"" in any of:
	/home/travis/gopath/src/github.com/kubernetes/kompose/vendor/github.com/Sirupsen/logrus (vendor tree)
	/home/travis/.gimme/versions/go1.6.linux.amd64/src/github.com/Sirupsen/logrus (from $GOROOT)
	/home/travis/gopath/src/github.com/Sirupsen/logrus (from $GOPATH)
make: *** [test-unit-cover] Error 1
```.
 After the rename it seems to work:

```
github.com/kubernetes/kompose  master ✔                                                                                                                                                                                                                                  22h19m  
▶ git-pull-pr 846
Upstream:  kubernetes/kompose
Already on 'master'
error: branch 'pr_846' not found.
remote: Counting objects: 102, done.
remote: Compressing objects: 100% (22/22), done.
remote: Total 102 (delta 55), reused 83 (delta 55), pack-reused 19
Receiving objects: 100% (102/102), 70.32 KiB | 0 bytes/s, done.
Resolving deltas: 100% (55/55), completed with 49 local objects.
From github.com:kubernetes/kompose
 * [new ref]         refs/pull/846/head -> pr_846
Switched to branch 'pr_846'

github.com/kubernetes/kompose  pr_846 ✔                                                                                                                                                                                                                                      2d  
▶ vim

github.com/kubernetes/kompose  pr_846 ✗                                                                                                                                                                                                                                    2d ⚑  
▶ make bin
go build -ldflags=""-w -X github.com/kubernetes/kompose/cmd.GITCOMMIT=efb7552"" -o kompose main.go

github.com/kubernetes/kompose  pr_846 ✗                                                                                                                                                                                                                                    2d ⚑  
▶ 
```.
 @cdrage after renaming it works locally but not in CI
after investing I found out that, we have to update `openshift` from vendor, which may cause trouble.
 Hey @surajnarwade 

See my previous comment up-above. You don't need to update libcompose to make this work. Only docker/cli, as that's where my commit upstream was merged in for build support. No need to edit / mess around with libcompose vendoring.

Version 3 only deals with docker/cli, it doesn't touch docker/libcompose..
 To give an update of what's happening after talking to @surajnarwade 

To update docker/cli we had to update vendoring. To update vendoring with the logrus errors, we had to update libcompose. To update libcompose, we had to update OpenShift vendoring due to conflicts, now we have to update and somehow migrate from 1.4 of OpenShift to 3.2 (I believe) in order to get all of this to work. :+1: .
 @cdrage @kadel instead of updating openshift, I have replaced `Sirupsen` with `sirupsen` in `docker/distribution`.
 @surajnarwade Can you please provide details on what you did?

Was it a PR that updated docker/distribution?

Did you manually edit the vendoring files?

Have you updated Makefile to sed replace Sirupsen to sirupsen, or anything else for that matter?.
 @cdrage @kadel ,To give brief idea about this PR,

I have Updated `docker/cli` to get latest changes that @cdrage pushed for build v3 support

these changes comes with `sirupsen` case collsion problem, so updated `docker/libcompose` as well

after fixing `sirupsen` case collision, it again occured with package `docker/distribution` which is dependency of `openshift/origin`, since updating `openshift/origin` is too much tedious task.


To tackle this situation, I updated `imports` from `kompose` manually and  `docker/distribution` (from vendor) by adding line in Makefile and Now kompose seems to be working fine :)

I also added this thing to Makefile with `make vendor-update`.
 Awesome :+1: thanks for the detailed explanation!

One last thing, could you put the `make vendor-update` updates to Makefile into a separate commit so we can see what changes you've made? So in total, there should be three commits. One to the code, one to the Makefile and the other actually updating the vendoring files..
 @cdrage gotcha.
 @cdrage now you can easily review it :).
 @surajnarwade Your makefile commit is messy: https://github.com/kubernetes/kompose/pull/846/commits/c4044b56a56a1b6c34db88b35686555e0b8b5195

Seems like you included some vendor (libcompose) files and there are some code that you're modifying in `pkg`...

So to go into detail:
Commit 1: Updates to Kedge code (pkg, renaming sirupsen, etc.)
Commit 2: Updates to Makefile (and that's it!)
Commit 3: Any updates to vendoring file.

Remember when you do all this to also update the commit descriptions / titles!.
 @cdrage , Updated commits, review needed.
 @surajnarwade 

EDIT: Code / commits LGTM so far, awesome job! :+1: Just need to make CI pass now..
 @cdrage all green :).
 Code / implementation LGTM, works on my side perfectly.

After merging, can you please update the documentation (conversion.md document) as well as open an issue that we need to add a test for testing Kubernetes docker image building..
 > Above works when I changed it to my username.

Thanks @cdrage  :)

Added test for kubernetes as well
Ready to merge :tada:.
 Phew. Thanks A LOT for your contribution @surajnarwade  that was a lot of trouble-shooting. Merging in!.
 Thanks @cdrage .
 "
,,845,"Fix links in docs/README.md.
 `setup` is 404 as there is `getting-started` file added.
@piyush1594 .
 Seems very small, can you push a PR @surajnarwade ? It's just an update to: https://github.com/kubernetes/kompose/blob/master/docs/README.md.
 @cdrage I will do it today. It is just about updating quickstart to getting started and setup to installation..
 "
,,844,"Link is broken for maven example.
 `Quickstart` link in `kompose integation` section is broken (404)

@piyush1594 
.
 @surajnarwade Mind clarifying what you mean? Your description is a bit confusing. `kompose integration`? You mean docs/integration.md?.
 @cdrage The link is not redirecting. I need to add .md extension to filename in link section..
 "
,,843,"1.3.0 Release.
 "
,,842,"Update --help page for convert to be the same as up.
 We have separate sections for Kubernetes and OpenShift flags when specifying `kompose convert --help`.

The same should be for `kompose up`.

Ex:
```
Usage:
  kompose convert [file] [flags]

Kubernetes Flags:
      --daemon-set               Generate a Kubernetes daemonset object
  -d, --deployment               Generate a Kubernetes deployment object
  -c, --chart                    Create a Helm chart for converted objects
      --replication-controller   Generate a Kubernetes replication controller object

OpenShift Flags:
      --build-branch             Specify repository branch to use for buildconfig (default is current branch name)
      --build-repo               Specify source repository for buildconfig (default is current branch's remote url
      --deployment-config        Generate an OpenShift deployment config object
      --insecure-repository      Specify to use insecure docker repository while generating Openshift image stream object

Flags:
      --build string        Set the type of build (""local""|""build-config""(OpenShift only)|""none"") (default ""none"")
      --controller string   Set the output controller (""deployment""|""daemonSet""|""replicationController"")
  -h, --help                help for convert
  -j, --json                Generate resource files into JSON format
  -o, --out string          Specify a file name to save objects to
      --replicas int        Specify the number of repliaces in the generate resource spec (default 1)
      --stdout              Print converted objects to stdout
      --volumes string      Volumes to be generated (""persistentVolumeClaim""|""emptyDir"") (default ""persistentVolumeClaim"")

Global Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```.
 will take this up.
 @cdrage , we can close this as #852 is merged.
 "
,,841,"Update version number in introduction.md.
 "
,,840,"Update getting started guide docs.
 Updates the getting started docs to reflect the three different guides..
 "
,,839,"Add ""getting started"" to the menu.
 Adds the getting started guide to the side-menu.
 "
,,838,"Fix the cpu limits and requests in generated deployment file.
 Signed-off-by: Li Yi <denverdino@gmail.com>

The source docker-compose.yml with CPU limits and reservations is as following.

```
version: '3'
services:
  mysql:
    image: mysql:5.7
    environment:
      - MYSQL_ROOT_PASSWORD=password
    deploy:
      resources:
        limits:
          cpus: ""1""
        reservations:
          cpus: ""0.5""
```

The generated deployment file with kompose 1.2 has incorrect format for CPU resource

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert
    kompose.version: 1.2.0 (99f88ef)
  creationTimestamp: null
  labels:
    io.kompose.service: mysql
  name: mysql
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: mysql
    spec:
      containers:
      - env:
        - name: MYSQL_ROOT_PASSWORD
          value: password
        image: mysql:5.7
        name: mysql
        resources:
          limits:
            cpu: 1e3
          requests:
            cpu: ""500""
      restartPolicy: Always
status: {}
```

The proper format should be

```
...
        resources:
          limits:
            cpu: ""1""
          requests:
            cpu: 500m
```.
 @denverdino , thanks for the PR,  can you modify functional test accordingly, PR looks good to me.
 @surajnarwade Done, thx..
 @denverdino LGTM, let's wait for @cdrage's review.
 You're right, the quantities are wrong. Thanks for this fix @denverdino !.
 "
,,837,"Fixed kompose build failure.
 While `local` build, kompose was not recognizing `dockerfile` key
Hence it was breaking the build as mentioned in issue #832.
This PR will fix the issue..
 @cdrage review needed .
 @cdrage changed variable name, good to go.
 Hey @surajd can you do a quick review to see if this closes your issue? 

Ideally... one day we'll have some integration tests for build....
 sorry for the late reply, it didn't work for me:

```console
$ kompose version
1.3.0 (7dac78e)

$ docker version
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:42:30 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.09.0-ce
 API version:  1.32 (minimum version 1.12)
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:43:51 2017
 OS/Arch:      linux/amd64
 Experimental: false
```


trying to build using kompose
```console
$ kompose up -v
DEBU Docker Compose version: 2                    
DEBU Opening compose files: docker-compose.yml    
DEBU [0/1] [gen]: Adding                          
DEBU [0/1] [default]: EventType: 32               
DEBU Default network found                        
INFO Build key detected. Attempting to build and push image 'surajd/kedgeschema' 
DEBU Compose file dir: /home/fedora/go/src/github.com/kedgeproject/json-schema-generator 
INFO Building image 'surajd/kedgeschema' from directory 'scripts' 
DEBU Created temporary file /tmp/kompose-image-build-681917583 for Docker image tarballing 
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service gen: Unable to build image. For more output, use -v or --verbose when converting.: The command '/bin/sh -c cd /go/src/github.com/kedgeproject/kedge-jsonschema && go build -o kedge-jsonschema main.go parsego.go' returned a non-zero code: 1 
```

works with docker cli
```console
$ docker build -t surajd/kedgeschema -f ./scripts/Dockerfile .
Sending build context to Docker daemon  40.92MB
Step 1/11 : FROM golang:1.9.0 AS build-env
 ---> 1cdc81f11b10
Step 2/11 : ADD . /go/src/github.com/kedgeproject/kedge-jsonschema
 ---> 08dc2baeca36
Step 3/11 : RUN cd /go/src/github.com/kedgeproject/kedge-jsonschema && go build -o kedge-jsonschema main.go parsego.go
 ---> Running in 0c0a2eb954bc
 ---> 4159167cb457
Removing intermediate container 0c0a2eb954bc
Step 4/11 : FROM garethr/openapi2jsonschema
 ---> a889e74d0c7b
Step 5/11 : RUN apk add --update curl &&     rm -rf /var/cache/apk/*
 ---> Running in e0b9df79e429
fetch http://dl-cdn.alpinelinux.org/alpine/v3.4/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.4/community/x86_64/APKINDEX.tar.gz
(1/3) Installing libssh2 (1.7.0-r0)
(2/3) Installing libcurl (7.55.0-r0)
(3/3) Installing curl (7.55.0-r0)
Executing busybox-1.24.2-r13.trigger
OK: 32 MiB in 35 packages
 ---> e1c4f68be0f3
Removing intermediate container e0b9df79e429
Step 6/11 : RUN mkdir /lib64 && ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2
 ---> Running in a687d92837ba
 ---> c87a0b8a94ee
Removing intermediate container a687d92837ba
Step 7/11 : COPY --from=build-env /go/src/github.com/kedgeproject/kedge-jsonschema/kedge-jsonschema /usr/local/bin/
 ---> ebeb9c27eca1
Step 8/11 : COPY ./scripts/entrypoint.sh /usr/local/bin/
 ---> 879a1dbeeb42
Step 9/11 : WORKDIR /data
 ---> 01e4d1e6444e
Removing intermediate container e7f7c96fe212
Step 10/11 : ENTRYPOINT
 ---> Running in d822bde63994
 ---> 0ee419b4a177
Removing intermediate container d822bde63994
Step 11/11 : CMD /bin/sh /usr/local/bin/entrypoint.sh
 ---> Running in fbf29bf08841
 ---> 74e63cef9742
Removing intermediate container fbf29bf08841
Successfully built 74e63cef9742
Successfully tagged surajd/kedgeschema:latest
```
.
 @surajssd , problem with context and build has been solved with this PR, as you can see logs problem is with line in Dockerfile

```
The command '/bin/sh -c cd /go/src/github.com/kedgeproject/kedge-jsonschema && go build -o kedge-jsonschema main.go parsego.go
```.
 We *really* need to add tests for this, I believe we should add some integration tests with this too....
 @cdrage @surajssd since we need `docker login`, as of now we don't have integration tests for such cases
cc @ashetty1 .
 We don't need docker login... We can build these locally.

On Nov 8, 2017 03:32, ""Suraj Narwade"" <notifications@github.com> wrote:

> @cdrage <https://github.com/cdrage> @surajssd
> <https://github.com/surajssd> since we need docker login, as of now we
> don't have integration tests for such cases
> cc @ashetty1 <https://github.com/ashetty1>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/pull/837#issuecomment-342746503>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGH-oBeff12WgGZxPslTuNprtQ0MuFzUks5s0WcXgaJpZM4PvYa6>
> .
>
.
 @surajssd @cdrage it seems, error is coming from `fsouza/go-dockerclient` , I have filed an issue there which can be tracked here https://github.com/fsouza/go-dockerclient/issues/698.
 Thanks a lot @fsouza  for clearing out the confusion, I will update PR accordingly.
 @surajssd @cdrage can you please test the PR ?.
 I am using this file in https://github.com/kedgeproject/json-schema-generator

```yaml
$ cat docker-compose.yml 
version: ""2""
services:
  gen:
    build:
      context: .
      dockerfile: scripts/Dockerfile
    image: surajd/testschema
```

When I run kompose I get error:

```console
$ kompose up -v
DEBU Docker Compose version: 2                    
DEBU Opening compose files: docker-compose.yml    
DEBU [0/1] [gen]: Adding                          
DEBU [0/1] [default]: EventType: 32               
DEBU Default network found                        
INFO Build key detected. Attempting to build and push image 'surajd/testschema' 
DEBU Compose file dir: /home/hummer/go/src/github.com/kedgeproject/json-schema-generator 
INFO Building image 'surajd/testschema' from directory 'json-schema-generator' 
DEBU Created temporary file /tmp/kompose-image-build-720868890 for Docker image tarballing 
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service gen: Unable to build image.
For more output, use -v or --verbose when converting.: API error (500): {""message"":""Cannot locate specified Dockerfile: Dockerfile""}
```

I am not sure if it is taking the Dockerfile which is somewhere else and the context is somewhere else.

---

I think you might want to run this test to test if the code works..
 @surajssd , can you please check one more time, 

```
$ cat docker-compose.yml 
version: ""2""
services:
  gen:
    build:
      context: .
      dockerfile: scripts/Dockerfile
    image: docker.io/surajnarwade/kedgeschema
```

and output is:

```
$ kompose up -v
DEBU Docker Compose version: 2                    
DEBU Opening compose files: docker-compose.yml    
DEBU [0/1] [gen]: Adding                          
DEBU [0/1] [default]: EventType: 32               
DEBU Default network found                        
INFO Build key detected. Attempting to build and push image 'docker.io/surajnarwade/kedgeschema' 
DEBU Compose file dir: /home/snarwade/go/src/github.com/kedgeproject/json-schema-generator 
INFO Building image 'docker.io/surajnarwade/kedgeschema' from directory 'json-schema-generator' 
DEBU Created temporary file /tmp/kompose-image-build-521645935 for Docker image tarballing 
INFO Image 'docker.io/surajnarwade/kedgeschema' from directory 'json-schema-generator' built successfully 
DEBU Image docker.io/surajnarwade/kedgeschema build output:
Step 1/11 : FROM golang:1.9.0 AS build-env
 ---> 1cdc81f11b10
Step 2/11 : ADD . /go/src/github.com/kedgeproject/kedge-jsonschema
 ---> Using cache
 ---> 35f4234b278f
Step 3/11 : RUN cd /go/src/github.com/kedgeproject/kedge-jsonschema && go build -o kedge-jsonschema main.go parsego.go
 ---> Using cache
 ---> d7d43a0e297b
Step 4/11 : FROM garethr/openapi2jsonschema
 ---> a889e74d0c7b
Step 5/11 : RUN apk add --update curl &&     rm -rf /var/cache/apk/*
 ---> Using cache
 ---> 7710d0d40f49
Step 6/11 : RUN mkdir /lib64 && ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2
 ---> Using cache
 ---> a3e8a01c47d7
Step 7/11 : COPY --from=build-env /go/src/github.com/kedgeproject/kedge-jsonschema/kedge-jsonschema /usr/local/bin/
 ---> Using cache
 ---> c2f9b8443f30
Step 8/11 : COPY ./scripts/entrypoint.sh /usr/local/bin/
 ---> Using cache
 ---> 5b3610c2f411
Step 9/11 : WORKDIR /data
 ---> Using cache
 ---> f9e63f6aff5b
Step 10/11 : ENTRYPOINT
 ---> Using cache
 ---> 46aba1cefd60
Step 11/11 : CMD /bin/sh /usr/local/bin/entrypoint.sh
 ---> Using cache
 ---> 348c0ebcc764
Successfully built 348c0ebcc764
Successfully tagged surajnarwade/kedgeschema:latest
 
DEBU Pushing Docker image 'docker.io/surajnarwade/kedgeschema' 
INFO Pushing image 'surajnarwade/kedgeschema:latest' to registry 'docker.io' 
INFO Attempting authentication credentials 'https://index.docker.io/v1/ 
DEBU Image 'surajnarwade/kedgeschema:latest' push output:
The push refers to a repository [docker.io/surajnarwade/kedgeschema]
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Preparing
Waiting
Waiting
Waiting
Waiting
Waiting
Waiting
Waiting
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
Layer already exists
latest: digest: sha256:4fe015cfbc12ff21e2c5da135a124447fdf0e423e1c69da38e02c8535927b104 size: 2828
 
INFO Successfully pushed image 'surajnarwade/kedgeschema:latest' to registry 'docker.io' 
DEBU [gen] No ports defined. Headless service will be created. 
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: gen            
INFO Successfully created Deployment: gen         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```.
 LGTM :+1: .
 "
,,836,"Added Fabric8 Maven Plugin in Integration.
 Changes for #732 

- added fabric8-maven-plugin kompose integration links and basic description.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 hey @piyush1594 , you have to sign CLA first .
 @piyush1594 Ideally it would be nice to add a longer description (paragraph length) as well as quick tutorial on how to use this. Since ideally, this would be one of the ""top"" integrations for Kompose that's most widely used..
 @cdrage updated integrations.md and maven-example.md.
 @surajnarwade @cdrage Updates done..
 can you add a WIP (work in progress) into your title since you're still working on this @piyush1594 .
 you also need to merge your commits (one commit).
 @cdrage done changes..
 @cdrage Review needed..
 LGTM after minor comment fix..
 LGTM..
 "
,,835,"Update vendoring for logrus and gojsonschema changes.
                                                                                                                                                                                                                                                                                   
Some vendoring is blocking other PR's due to changes to logrus (Sirupsen                                                                                                                                                                                                          
vs sirupsen for lower-case) as well as a non-versioned gojsonschema in                                                                                                                                                                                                            
glide.yaml                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                  
This updates glide.yaml to reflect the upper-case as well as lower-case                                                                                                                                                                                                           
versions of logrus as well as adds a versionized gojsonschema in order                                                                                                                                                                                                            
to get rid of the following error:                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                  
```sh                                                                                                                                                                                                                                                                             
▶ make bin                                                                                                                                                                                                                                                                        
go build -ldflags=""-w -X github.com/kubernetes/kompose/cmd.GITCOMMIT=0e56b7d"" -o kompose main.go                                                                                                                                                                                  
# github.com/kubernetes/kompose/vendor/github.com/docker/cli/cli/compose/schema                                                                                                                                                                                                   
vendor/github.com/docker/cli/cli/compose/schema/schema.go:34: cannot use portsFormatChecker literal (type portsFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                                  
        portsFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                         
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
vendor/github.com/docker/cli/cli/compose/schema/schema.go:35: cannot use portsFormatChecker literal (type portsFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                                  
        portsFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                         
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
vendor/github.com/docker/cli/cli/compose/schema/schema.go:36: cannot use durationFormatChecker literal (type durationFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                            
        durationFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                      
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
# github.com/kubernetes/kompose/vendor/github.com/docker/libcompose/config                                                                                                                                                                                                        
vendor/github.com/docker/libcompose/config/schema_helpers.go:60: cannot use environmentFormatChecker literal (type environmentFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                   
        environmentFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                   
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
vendor/github.com/docker/libcompose/config/schema_helpers.go:61: cannot use portsFormatChecker literal (type portsFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                               
        portsFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                         
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
vendor/github.com/docker/libcompose/config/schema_helpers.go:62: cannot use portsFormatChecker literal (type portsFormatChecker) as type gojsonschema.FormatChecker in argument to gojsonschema.FormatCheckers.Add:                                                               
        portsFormatChecker does not implement gojsonschema.FormatChecker (wrong type for IsFormat method)                                                                                                                                                                         
                have IsFormat(string) bool                                                                                                                                                                                                                                        
                want IsFormat(interface {}) bool                                                                                                                                                                                                                                  
^CMakefile:29: recipe for target 'bin' failed                                                                                                                                                                                                                                     
make: *** [bin] Interrupt                                                                                                                                                                                                                                                         
```  .
 @cdrage , bit confused here but I am not able to see `sirupsen/logrus` in vendor directory (instead there `Sirupsen/logrus`).
 @surajnarwade There's conflicts with docker/cli updating to using `sirupsen/logrus` instead of `Sirupsen/logrus`.

Yes, there is no folder for it, Glide handles it. .
 LGTM.
 "
,,834,"Add Getting Started guide, adds Minishift tutorial.
 Updates the getting started guide as well as introduces an
""introduction"" page for Kompose.

Adds a Minishift guide as well as a general update to all documentation..
 @kadel @pradeepto please review.
 @pradeepto Both CDK/RHEL guide as well as Minishift (upstream) guide has now been added. Giving us a total of three getting started guides: minikube + kompose, minishift + kompose, rhel (cdk) + kompose..
 @surajnarwade done.
 @cdrage you rock when it's doc thing :+1: .
 "
,,833,"[doc] more tutorial for gcloud?.
 Hi,

it would be nice if there is a doc for kompose and kubectl with gcloud
this is my configuration, but i could not get external ip from gcloud container.
Any help on external ip?

```
gcloud auth login
gcloud auth application-default login
gcloud components install kubectl
```
setup google compute container on google cloud
click on connect to get instruction
```
...
kubectl proxy
kompose convert
kompose up
kompose replace ...yaml # to update
```

and never ever kompose down as it will delete off volumes

thank you
.
 okay i found the solution, after kompose up, i have to
```
kubectl delete service web
kubectl expose deployment web --type=""LoadBalancer"" 
```
assumed web is the service name

but some how it takes a long time to obtain ip.
 @u007 Hey James! thanks for leeting us know the problems with using gcloud. I am going to add a note in our tutorials / user guide for adding `kubectl expose deployment web --type=""LoadBalancer""`

.
 @cdrage nice, that will be awesome 👍 
btw, i my ip was pending because my google cloud is on free trial...

.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 "
,,832,"kompose build fails to read the context correctly.
 ## Problem

kompose fails to find the `Dockerfile` even if the `dockerfile` is set under `build` and `context` is also set.

## How to reproduce?

Please see the following directory structure    

```console
$ tree
.
├── docker-compose.yml
├── example
│   └── db.json
├── glide.lock
├── glide.yaml
├── LICENSE
├── main.go
├── Makefile
├── output.json
├── parsego.go
├── README.md
├── scripts
│   ├── Dockerfile
│   ├── entrypoint.sh
│   └── k8s-release
├── spec.go
├── swagger.json
└── vendor
    ├── github.com
    │   ├── davecgh
...
```

I am trying to do a build with `Dockerfile` being in `scripts` directory. But my build context is root of the project. Essentially I am running a build command as following:

```console
docker build -t surajd/kedgeschema -f ./scripts/Dockerfile .
```

Above works fine.

To make it easier I have created `docker-compose` file which looks like following:

```yaml
$ cat docker-compose.yml 
version: ""2""
services:
  gen:
    build:
      context: .
      dockerfile: scripts/Dockerfile
    image: surajd/kedgeschema
```

docker-compose works on this:

```console
$ docker-compose up
Building gen
Step 1/11 : FROM golang:1.9.0 AS build-env
...
```

But kompose fails as 

```console
$ kompose up
INFO Build key detected. Attempting to build and push image 'surajd/kedgeschema' 
INFO Building image 'surajd/kedgeschema' from directory 'json-schema-generator' 
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service gen: Unable to build image. For more output, use -v or --verbose when converting.: API error (500): {""message"":""Cannot locate specified Dockerfile: Dockerfile""}
```

## Versions

```console
$ kompose version
1.2.0 (8efe274)
```

## Other info

The project I am trying that docker-compose file is https://github.com/kedgeproject/json-schema-generator.
 In `dockerlib.BuildImageOptions` also set `Dockerfile` field as relative path to `context`.

I have tried something similar in https://github.com/kedgeproject/kedge/pull/295/files#diff-f9c1aac2b0fdb0b76e7a167cb362d95cR93.
 Thanks @surajssd for pointing this out, will send a fix very soon :).
 we can close this issue now :).
 "
,,831,"Add highlighting for menus + add slack/releases/github links.
 Adds highlighting depending on what page you are on, also adds links to
slack / releases / github.
 "
,,830,"Add Ubuntu font.
 "
,,829,"Update CSS.
 Updates the site to Ubuntu font, increases the width, increases the font
size as well..
 "
,,828,"Updated vendoring.
 Updated vendoring for getting changes from docker/cli
for build key in v3
(since https://github.com/docker/cli/pull/481 is merged now).
 Looks like you'll have to update a https://github.com/sirupsen/logrus importation too in this commit @surajnarwade 

See the error in Semaphore..
 LGTM..
 "
,,827,"Fixed `go vet`.
 Fixes #825 (since `go vet` was failing locally while doing `make test`).
 @surajnarwade Please update commit message to a more descriptive title (don't just like the issue, say what the issue is)..
 LGTM.
 "
,,826,"    Fixed `go vet` issue while doing `make test`.
  Fixes #825
.
 "
,,825,"`go vet` is failing locally.
 ```
$ make test
go get github.com/mattn/goveralls
go get github.com/modocache/gover
go get github.com/Masterminds/glide
go get github.com/sgotti/glide-vc
go get github.com/golang/lint/golint
go get github.com/mitchellh/gox
./script/check-vendor.sh
Checking for nested vendor dirs
OK
Checking if vendor was cleaned using glide-vc.
OK
./script/check-gofmt.sh
gofmt OK
go vet ./pkg/... ./cmd/... .
pkg/loader/compose/compose_test.go:59: arg expected for printf verb %s of wrong type: github.com/kubernetes/kompose/pkg/kobject.HealthCheck
exit status 1
Makefile:75: recipe for target 'vet' failed
make: *** [vet] Error 1
```.
 "
,,824,"Added `--build-repo` in `kompose up`.
 In order to maintain symmetry between kompose up and kompose convert,
adding `--build-repo`.
 Please add a CLI test.

Otherwise, LGTM..
 Fixes `--buil-repo` from issue #798.
 @cdrage , ready to merge :).
 @surajnarwade fix conflicts and then LGTM..
 @cdrage fixed conflicts.
 LGTM..
 "
,,823,"Do not generate empty services.
 If ports are not set `kompose` generates empty services. Example:
```
  cs-bitcoin-process:
    image: cybernode/cs-bitcoin-processor:release-0.5.3
    environment:
      CASSANDRA_CONNECTION: cs-elassandra
      KAFKA_CONNECTION: cs-kafka:9092
```
This generates:

    NAME                      CLUSTER-IP      EXTERNAL-IP      PORT(S)                       AGE
    svc/cs-bitcoin-process    None            <none>           55555/TCP                     8h
.
 @abitrolly , actually that is `headless` service,
For reference: https://kubernetes.io/docs/concepts/services-networking/service/#headless-services.
 Is there a way then to just make k8s run a Pod without any services? I expect an explicit `service.type` set if somebody needs a service, like

    kompose.service.type: headless.
 @abitrolly , `restart: no` will not create service.
 @surajnarwade thanks. Though I won't include it in our config, because there is little chance somebody will understand what is it for..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Explicit `headless: yes` is more logical. If somebody needs a headless service, then that person may need a choice not to restart it.

/remove-lifecycle stale.
 agreed @abitrolly .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale

https://hacktoberfest.digitalocean.com/ anyone?.
 "
,,822,"add support for `kompose update`.
 inspired from `minikube`,
To update to latest version, we should have something like,

```
kompose update
```.
 @surajnarwade 

Do you think we should also update our installation instructions so it's a one-liner? Another person requested this and I think it's much easier..

Example:
https://github.com/kubernetes/minikube/releases.
 @surajnarwade Minikube has no `minikube update` command...

```
▶ minikube --help
Minikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows.

Usage:
  minikube [command]

Available Commands:
  addons           Modify minikube's kubernetes addons
  completion       Outputs minikube shell completion for the given shell (bash)
  config           Modify minikube config
  dashboard        Opens/displays the kubernetes dashboard URL for your local cluster
  delete           Deletes a local kubernetes cluster
  docker-env       Sets up docker env variables; similar to '$(docker-machine env)'
  get-k8s-versions Gets the list of available kubernetes versions available for minikube
  ip               Retrieves the IP address of the running cluster
  logs             Gets the logs of the running localkube instance, used for debugging minikube, not user code
  mount            Mounts the specified directory into minikube
  profile          Profile sets the current minikube profile
  service          Gets the kubernetes URL(s) for the specified service in your local cluster
  ssh              Log into or run a command on a machine with SSH; similar to 'docker-machine ssh'
  ssh-key          Retrieve the ssh identity key path of the specified cluster
  start            Starts a local kubernetes cluster
  status           Gets the status of a local kubernetes cluster
  stop             Stops a running local kubernetes cluster
  update-context   Verify the IP address of the running cluster in kubeconfig.
  version          Print the version of minikube

Flags:
      --alsologtostderr                  log to standard error as well as files
  -b, --bootstrapper string              The name of the cluster bootstrapper that will set up the kubernetes cluster. (default ""localkube"")
      --log_backtrace_at traceLocation   when logging hits line file:N, emit a stack trace (default :0)
      --log_dir string                   If non-empty, write log files in this directory
      --loglevel int                     Log level (0 = DEBUG, 5 = FATAL) (default 1)
      --logtostderr                      log to standard error instead of files
  -p, --profile string                   The name of the minikube VM being used.  
        This can be modified to allow for multiple minikube instances to be run independently (default ""minikube"")
      --stderrthreshold severity         logs at or above this threshold go to stderr (default 2)
  -v, --v Level                          log level for V logs
      --vmodule moduleSpec               comma-separated list of pattern=N settings for file-filtered logging

Use ""minikube [command] --help"" for more information about a command.
```.
 @cdrage my bad, sorry about that, it's in `minishift` and `gofabric8` as well

for example, 

```
minishift update -h
Checks for the latest version of Minishift, prompts the user, and updates the binary if the user answers 'y'.

Usage:
  minishift update [flags]
```
or

```
gofabric8 upgrade -h
Upgrades the packages if there is a newer version available

Usage:
  gofabric8 upgrade [name] [flags]
```
.
 IMO, I don't believe our updates add major changes to how we convert objects, I'd vote no to adding `kompose update`. I could elaborate as to why, but in general, I don't see this feature added often to tools to warrant an inclusion of `update` to Kompose..
 @cdrage , I have seen people who are using very old `kompose` versions, so for them it might be useful.
 @surajnarwade Yes, but this is another command to be added to Kompose that wouldn't exactly be used much, does major changes to the underlying system (replaces binaries) and no other project within the Kubernetes ecosystem employs this `update` command. I see it useful for things such as `minikube` and `minishift` where major changes happen (updates to ISO files, virtualization, etc.) but not for Kompose. I'd advise for this feature to not be added. This command will also confuse users who use `kubectl update`.

Thoughts @kadel @containscafeine @surajssd ?

Cons:
 - I have effectively not seen any other tool use this functionality other than `minishift`, nor any other tool within the kubernetes ecosystem.
 - This command will confuse users who are used to the `kubectl update` command
 - Requires sudo privileges / it replaces binaries
 - Could introduce a host of security issues (man-in-the-middle attacks, URL spoofing for binaries)
 - We have not gathered any outside feedback, nor has this feature been requested by the community

I'm voting a hard no.
.
 I agree with @cdrage.
I don't like it either.  I'm a big fan of managing software using package managers. And this breaks it in a big way. It can't be used if you install Kedge from rpm or deb package (only with sudo, and then it totally breaks packaging and further updates via dnf/yum or apt)

Rather than implementing `kompose update` I would invest into automating packaging for various distributions and systems. So we don't have to do it manually.

We should have always update packages for all major systems (packages are **AUTOMATICALY** build for every new release) 
- MacOS  - [Homebrew](https://brew.sh/) ([package exists](http://formulae.brew.sh/formula/kompose) and it looks like updates are somehow automated )
- Windows  - [Chocolatey](https://chocolatey.org/)
- DEB systems (Ubuntu/Debian) - using  [PPA](https://launchpad.net/ubuntu/+ppas)
- RPM systems (Centos/Fedora - using [Copr](https://copr.fedorainfracloud.org/) 
- ArchLinux - [AUR](https://aur.archlinux.org) ([package exists](https://aur.archlinux.org/packages/kompose-bin/) but updates are not automated)

We should modify our docs, and guide users to install it from those packages. Downloading binary or doing `go get` should be only last resort for unsupported systems.

.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 "
,,821,"1.2.0 Release.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @kadel and @e-minguez, please review this..
 "
,,820,"Adding  --build-branch to `kompose up`.
 In order to maintain symmetry between `kompose up` and `kompose convert`,
adding `--build-branch`.
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @cdrage and @qujinping, please review this..
 LGTM.
 Please add a CLI test..
 Fixes `--build-branch` in issue #798.
 @cdrage , ready to merge :)
.
 "
,,819,"Adding documentation for tests.
 As part of issue #781 .
 we have to do `make bin` first right ?.
 LGTM!.
 "
,,818,"Simplify copy/paste installation for Linux.
 .
 @abitrolly, thank you for the pull request! We'll request some people to review your PR. @cdrage and @e-minguez, please review this..
 Hey @abitrolly 

We are following the convention as shown by https://kubernetes.io/docs/tasks/tools/install-kubectl/ where we separate the moving of files as well as chmod +x in order to emphasize what commands are needed (and to prevent people copying+pasting and messing something up on their system)..
 Make sense. I usually merge this into a single shell block, like this:
```
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl

# Make the kubectl binary executable.
chmod +x ./kubectl

# Move the binary in to your PATH.
sudo mv ./kubectl /usr/local/bin/kubectl
```.
 "
,,817,"Fixed `--volumes` validation.
 .
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @cdrage and @kadel, please review this..
 @cdrage , @kadel needs your review here :).
 ref https://github.com/kubernetes/kompose/issues/814.
 @cdrage done .
 @surajnarwade Please add description to commit..
 issue is being tracked here https://github.com/kubernetes/kompose/issues/814.
 @surajnarwade can you add a test? unit / cli test (make sure it fails if someone puts --volumes=foobar or something).
 "
,,816,"Fixed tmpfs with mode failure.
 Fixes #807
now kompose will ignore mode of tmpfs and will pass only mount path..
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @procrypt and @cdrage, please review this..
 issue is being tracked here https://github.com/kubernetes/kompose/issues/807.
 @surajnarwade can you add tests?

After that, LGTM..
 added functional test .
 LGTM! Thanks for adding the tests..
 "
,,815,"Fix reference to emptyDir in OpenShift test scripts.
 .
 @ashetty1, thank you for the pull request! We'll request some people to review your PR. @cdrage, please review this..
 LGTM.
 @ashetty1 Please change the title to something informative (remove `Fix PR 811`) and add a description to the commit! Thank you..
 @ashetty1 I see you updated the GitHub issue, you need to do `git commit --amend` and fix both the title and description of your commit..
 LGTM.
 "
,,814,"`--volumes` is not validated .
 If you run `kompose convert --volumes foobar` PVC is created and no error is raised.

This should error out as an invalid value for `--volumes`. Currently, only possible values are `PersistentVolumeClaim` and `emptyDir`.
 This should go into validation of flags, I will look into it.
 @kadel , since #817 is merged now, we can close this .
 "
,,813,"Added feature for `placement` key in v3.
 it will map `engine.labels.operatingsystem` to `beta.kubernetes.io/os` and
`node.hostname` to `kubernetes.io/hostname` and all other constraints will not be supported..
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @cdrage and @kadel, please review this..
 @surajnarwade Code looks good, but can you add some integration / cmd tests? Then LGTM from me :+1: .
 @cdrage , tests added :).
 One last thing, can you update `docs/conversion.md`? 

Otherwise, code LGTM. Once docs are updated let's merge..
 @cdrage updated `docs/conversion.md`.
 @surajnarwade Alright, code LGTM (thanks for adding another functional test).

Fix conflicts and then it should be good to go..
 @cdrage fixed conflicts.
 LGTM.
 "
,,812,"Update the styles.css for larger width.
 Changes to styles.css in order to increase the width..
 "
,,811,"emptvols -> volumes=yes.
 .
 @ashetty1, thank you for the pull request! We'll request some people to review your PR. @cdrage, please review this..
 LGTM.
 LGTM :).
 "
,,810,"Added `--controller` feature.
 Previously we used to mention controller type as `--deployment`,
`--replication-controller` or `--daemonset` as argument.
But now,
it will be like,

ex.

```
kompose convert --controller=daemonset
```.
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @procrypt and @cdrage, please review this..
 @surajnarwade is this still WIP?

I don't see the deprecation of the current commands (`--daemonset`), I also see removals of `IsDaemonSetFlag` which is not good since it's used for the `--daemonset` command....
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @surajssd and @cdrage, please review this..
 @surajnarwade awesome work, much better! :+1: I'll test this out when I have some time..
 issue is being tracked here https://github.com/kubernetes/kompose/issues/792.
 The code LGTM but tests need to be added (again, don't change any old ones / current ones, just add new tests) @surajnarwade .
 @cdrage , added tests.
 @cdrage review needed here :).
 @cdrage , fixed changes :) ready to merge.
 LGTM.
 "
,,809,"Cannot locate specified Dockerfile: Dockerfile.
 When I run `kompose up`, I get the following error:
```
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service business-api: Unable to build image. For more output, use -v or --verbose when converting.: API error (500): {""message"":""Cannot locate specified Dockerfile: Dockerfile""}
```

My folder structure is: 
```
repo 
  package
    business-api
        Dockerfile
```

My docker-compose.yaml is:
```yaml
version: '2'

services:
  business-api:
    restart: always
    build: ./package/business_api
    image: index.docker.io/company/business-api
    volumes:
      - ./:/usr/src/app:ro
      - ./data:/root/data:ro
    depends_on:
      - some-other-service
```
.
 Hmm, may be a bug with the pathing, you may have to manually specify by doing: `./package/business_api/Dockerfile` under build.

Try that with the `--verbose` output and let post the debug information here!.
 Added full path in build -> dockerfile:

```
    build:
      context: ./package/business_api
      dockerfile: ./package/business_api/Dockerfile
```

Output of `sudo kompose up -v 1000`:

```
DEBU Docker Compose version: 2
DEBU Opening compose files: docker-compose.yml
DEBU [0/0] [webapp_npm]: EventType: 31
DEBU [0/0] [webapp_build]: EventType: 31
DEBU [0/0] [webapp_config]: EventType: 31
DEBU [0/0] [webapp_node_modules]: EventType: 31
DEBU [0/1] [nginx]: Adding
DEBU [0/5] [webapp]: Adding
DEBU [0/5] [business-api]: Adding
DEBU [0/6] [default]: EventType: 32
DEBU [0/6] [default]: EventType: 32
DEBU [0/6] [default]: EventType: 32
DEBU [0/6] [default]: EventType: 32
DEBU [0/6] [default]: EventType: 32
DEBU Default network found
DEBU [0/6] [default]: EventType: 32
WARN Unsupported root level volumes key - ignoring
WARN Unsupported depends_on key - ignoring
INFO Build key detected. Attempting to build and push image 'index.docker.io/example/business-api'
DEBU Compose file dir: /home/user/project
INFO Building image 'index.docker.io/example/business-api' from directory 'business_api'
DEBU Created temporary file /tmp/kompose-image-build-853848623 for Docker image tarballing
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service business-api: Unable to build image. For more output, use -v or --verbose when converting.: API error (500): {""message"":""Cannot locate specified Dockerfile: Dockerfile""}
```

This is the same output that I get when build->dockerfile is not specified as shown in the original issue at the top..
 @shubhamchaudhary I'll investigate! Side-note: Why do you add `1000` to the `sudo kompose up -v` command?.
 @cdrage I thought it is `--verbose` parameterized (which it isn't now that I check --help). I added 1000 as the log level value in my head..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 "
,,808,"Remove redundant strings.ToLower().
 Removes the redundant strings.ToLower commands for GlobalProvider in
up.go, convert.go and down.go.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @surajssd and @kadel, please review this..
 works for me, LGTM :+1: .
 "
,,807,"tmpfs with mode fails.
 Hello, 

Trying to use kompose on [microservices-demo](https://github.com/microservices-demo/microservices-demo), I had to modify the generated files, because a mode is provided for the tmpfs. 
Here is a shortened version of it:

Using this compose file. 

```yml
version: ""2""

services:

  redis-master:
    image: gcr.io/google_containers/redis:e2e 
    ports:
      - ""6379""
    tmpfs:
      - /tmp:rw,noexec,nosuid
```

This file can be used correctly with docker compose. However, when running `kompose up`, the pod fails to be created: 
```
redis-master-1539052294-z8txm   0/1       rpc error: code = 2 desc = Error response from daemon: {""message"":""invalid bind mount spec \""/var/lib/kubelet/pods/c902b3c2-92d6-11e7-8f5f-0200ac100026/volumes/kubernetes.io~empty-dir/redis-master-tmpfs0:/tmp:rw,noexec,nosuid\"": invalid mode: rw,noexec,nosuid""}   0         47s

```

```bash 
kompose version
1.1.0 (36652f6)
```.
 @ThHareau Yup, that's something odd. I'll investigate and see what is causing it. Most likely rw,noexec,nosuid is being passed to Kubernetes but is incompatible. .
 @cdrage are you working on it ?
.
 @surajnarwade Kind of got busy with another project. Mind taking this up?.
 @cdrage, sure :+1:.
 @cdrage, as mode with tmpfs is not compatible, we should ignore it and pass only path for tmpfs ?
wdyt ?.
 @surajnarwade Yup, there's no modes for it, see: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir

So simply add a regex / strings.split to delete everything after `:` I guess! Then warn the user that the tmpfs modes will not work..
 @cdrage , did the same :).
 "
,,806,"Packaging Kompose for debian .
 Bug#874049: Acknowledgement (ITP: Kompose -- conversion tool for all things compose( namely Docker Compose) to container ochestrators (Kubernetes or Openshift)).
 @cdrage was looking at this one before IIRC !


@rahulkrishnanfs has filed it in Debian upstream
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=874049.
 Hey @rahulkrishnanfs I can help and become a co-maintainer. I've been wanting to become a Debian developer for a while..
 @cdrage thats great .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 Any updates @rahulkrishnanfs ?.
 "
,,805,"Script for generating unit tests.
 Issue #770 .
 @cdrage Please see if this works. Will proceed based on your inputs..
 This works, but perhaps lets make it interactive? Run `./script/make-test.sh` or something and it interacts with you and asks for the test directory?.
 @cdrage @surajnarwade review please .
 @ashetty1 , can you add it in Makefile and bit of documentation, I am confused how to test it.
 @surajnarwade Not sure if we should add it to Makefile. This is not a user-facing script. .
 IMO, let's add it to makefile, it doesn't hurt adding more stuff to it. @ashetty1 .
 > @surajnarwade Not sure if we should add it to Makefile. This is not a user-facing script.

It is not user-facing, but it is Kompose developer facing. This needs to be documented in [Development Guide](https://github.com/kubernetes/kompose/blob/master/docs/development.md).
 > IMO, let's add it to makefile, it doesn't hurt adding more stuff to it. @ashetty1
>  👍 1

+1 for adding this to Makefile, otherwise it will be hard to find those scripts, it is much more convenient to run this from make.
 @ashetty1 please merge commits into one :+1: .
 This LGTM. Let's merge and go from there..
 "
,,804,"1.1.0 Release.
 "
,,803,"`--deployment-config` flag is not necessary.
 even when we don't provide `--deployment-config` flag, kompose creates deploymentconfig, so it doesn't make any sense to have this flag..
 @surajnarwade it's used to disable --deployment-config being created.
 without flag
```
$ kompose convert --provider=openshift
INFO OpenShift file ""foo-service.yaml"" created    
INFO OpenShift file ""foo-deploymentconfig.yaml"" created 
INFO OpenShift file ""foo-imagestream.yaml"" created
```

and with flag,

```
 $ kompose convert --provider=openshift --deployment-config
INFO OpenShift file ""foo-service.yaml"" created    
INFO OpenShift file ""foo-deploymentconfig.yaml"" created 
INFO OpenShift file ""foo-imagestream.yaml"" created 
```

@cdrage ^^.
 @surajnarwade You're using it wrong, it's ` --deployment-config false` would work. It's true by default.
 ```
$ kompose convert --provider=openshift --deployment-config=false
INFO OpenShift file ""foo-service.yaml"" created    
INFO OpenShift file ""foo-deploymentconfig.yaml"" created 
INFO OpenShift file ""foo-imagestream.yaml"" created
```.
 Ah crap, it's a bug then. Let's fix this..
 @cdrage , what's the use case for disabling `deployment-config` ?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Yeah, this is deprecated. I'm going to close this. We've deprecated this for `--controller`.
 "
,,802,"Adding OpenShift tests for deploy keys.
 .
 LGTM, tests pass on Semaphore (with the exception of MariaDB CrashLoopBackOff...) and tests pass locally for me :+1: .
 "
,,801,"Kompose replicas option not working with v3 deploy?.
 It looks like the kompose replica option isn't working with v3 compose file including deploy label:

```
$ ./kompose version
1.0.0 (5f89e1a)

$ cat script/test/fixtures/v3/docker-compose-deploy-mode.yaml
version: ""3""

services:
  foo:
    deploy:
      mode: global
      replicas: 6
    image: redis

$ ./kompose up --provider=openshift --emptyvols --replicas 2 -f script/test/fixtures/v3/docker-compose-deploy-mode.yaml
WARN Global mode not yet supported, containers will only be replicated once throughout the cluster. DaemonSet support will be added in the future. 
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: foo            
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

$ oc get pods
NAME          READY     STATUS    RESTARTS   AGE
foo-1-jrqdc   1/1       Running   0          10m

```
.
 @ashetty1 

That is normal. Look at the WARN output:
```
WARN Global mode not yet supported, containers will only be replicated once throughout the cluster. DaemonSet support will be added in the future. 
```

mode: global has been set which limits each container to 1.

See: https://docs.docker.com/compose/compose-file/#mode.
 remove `mode: global` if you wish to use `replicas: 6`.
 @cdrage I get that, but does it overrule `kompose up --replicas 6` too?.
 @ashetty1 Yes..
 "
,,800,"Fixes output of help template.
 Fixes the issue of the help output not ouputting all commands due to the
wrong function being used within spf13/cobra.

Closes https://github.com/spf13/cobra/issues/512
Closes https://github.com/kubernetes/kompose/issues/744.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @procrypt and @kadel, please review this..
 "
,,799,"Add env_file + ConfigMaps feature to Kompose.
 When using env_file with Docker Compose, a ConfigMap will be generated.

For example:

```sh
▶ ./kompose convert -f
script/test/fixtures/configmaps/docker-compose.yml
INFO Kubernetes file ""redis-service.yaml"" created
INFO Kubernetes file ""redis-deployment.yaml"" created
INFO Kubernetes file ""foo-env-configmap.yaml"" created
INFO Kubernetes file ""bar-env-configmap.yaml"" created
```

File:

```yaml
version: '3'

services:
  redis:
    image: 'bitnami/redis:latest'
    environment:
      - ALLOW_EMPTY_PASSWORD=no
    # Env file will override environment / warn!
    env_file:
      - ""foo.env""
      - bar.env
    labels:
      kompose.service.type: nodeport
    ports:
      - '6379:6379'
```

To:

```yaml
apiVersion: v1
data:
  ALLOW_EMPTY_PASSWORD: ""yes""
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: foo-env
```

```yaml
...
      - env:
        - name: ALLOW_EMPTY_PASSWORD
          valueFrom:
            configMapKeyRef:
              key: ALLOW_EMPTY_PASSWORD
              name: foo-env
```.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @containscafeine and @procrypt, please review this..
 TODO: 
- [x] Add tests
- [x] Remove conflicts (kobject.go).
 Ready for review @ashetty1 @containscafeine @kadel @surajnarwade @surajssd .
 version 2 docker -compose file,

```
version: '3'
  
services:
  redis:
    image: 'bitnami/redis:latest'
    environment:
      - ALLOW_EMPTY_PASSWORD=no
    # Env file will override environment / warn!
    env_file:
      - ./bar.env
    labels:
      kompose.service.type: nodeport
    ports:
      - '6379:6379'
```
doesn't create configmaps,

```
$ kompose convert 
INFO Kubernetes file ""redis-service.yaml"" created 
INFO Kubernetes file ""redis-deployment.yaml"" created 
```.
 Your example shows Version 3 @surajnarwade 

Yeah, at the moment it doesn't support Version 2. I will have to add that. Baby steps! :+1: 

Can you do a review on the basis Version 3?.
 @cdrage , my bad about version

:+1:  for baby step.
 @containscafeine @kadel @surajnarwade @surajssd ready for review :+1: 

edit: next sprint I will add v2 support, i have updated the conversion.md matrix accordingly..
 Reason why this is not in v2 is because of this: https://github.com/docker/libcompose/issues/488.
 @cdrage still getting the error in https://github.com/kubernetes/kompose/pull/799#pullrequestreview-59446489 :(.
 @containscafeine should work now, i've created a new function in order to format the new env name's correctly, feel free to do another review!

```
github.com/kubernetes/kompose  add-configmap ✗                                                                                                                                                                                                                          19m ⚑ ◒  
▶ ./kompose up
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Deployment: redis       
INFO Successfully created Config Map: bar-env     

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.

github.com/kubernetes/kompose  add-configmap ✗                                                                                                                                                                                                                          19m ⚑ ◒  
▶ kubectl get cm
NAME      DATA      AGE
bar-env   2         5s
```.
 ignoring vendoring updates, this PR needs review

edit: vendoring updates blocked on https://github.com/kubernetes/kompose/pull/835 due to running into errors with logrus + gojsonschema

@kadel @containscafeine @surajnarwade @surajssd please review.
 works for me :+1: .
 "
,,798,"Up and convert commands are not equal in features.
 For example, we are able to deploy --daemon-set using `convert`, but not with `up`.

We have *some* things such as `--build` which is consistent in `kompose up`, but other aspects such as controllers, etc do not function correctly.

We should have the SAME experience between `up` and `convert`.

It goes against UX/UI having inconsistencies between the commands. One should convert, one should bring those converted up.

List of parameters NOT in `up`:
- [ ] --daemon-set
- [ ] --deployment
- [ ] --chart (I don't think this should be applicable)
- [ ] --replication-controller
- [x] --build-branch
- [x] --build-repo
- [ ] --deployment-config
- [x] --insecure-repository

A couple of these parameters will be deprecated in favour of `--controller` however. .
 Picking `--build-branch` first.
 sending PR for `--build-repo`.
 `--build-repo` is being tracked in PR https://github.com/kubernetes/kompose/pull/824
`--build-branch` is being tracked in PR https://github.com/kubernetes/kompose/pull/820.
 if we are adding `--controller`  and controller flags like `--daemon-set`, `--replication-controller`, we have to implement in `kompose down` as well
@cdrage thoughts ?.
 "
,,797,"Fix kompose docker container wrong href.
 The link was pointing to komposeui instead of kompose-docker.
 @JadCham, thank you for the pull request! We'll request some people to review your PR. @cdrage, please review this..
 @JadCham My mistake! Thanks :+1: .
 "
,,796,"Update to lowercase in conversion.md.
 Makes the table a little less clustered with lowercase abbreviations..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @asifdxtreme, please review this..
 "
,,795,"Added functional test for docker compose files in Example directory.
 Fixes #793.
 @surajnarwade, thank you for the pull request! We'll request some people to review your PR. @cdrage and @surajssd, please review this..
 Tests pass. LGTM..
 "
,,794,"changing the organisation from kubernetes-incubator to kubernetes.
 @cdrage, I have updated the Jenkinsfile.
 LGTM.
 "
,,793,"Functional test for examples Directory.
 We should add functional test for docker-compose files present in examples Directory.
 As discussed in very previous meeting, I will take this up and will add functional test for the same.
 "
,,792,"Add --controller.
 Add a --controller flag instead of using parameters such as `--daemon-set` `--deployment`, etc.

This allows output based on simply doing `--controller=DaemonSet`.
 I will take this up.
 @surajnarwade Let's focus on some of the milestones :) https://github.com/kubernetes/kompose/issues?q=is%3Aopen+is%3Aissue+milestone%3A%221.1.0+release%22.
 "
,,791,"Update favicons delete useless files.
 Updates the favicon to work on all pages, adds an android chrome
favicon, removes the deleted / useless files from _site.
 Well tests fail! JK, SemaphoreCI isn't blacklisting gh-pages branch.

:+1: Mergin'.
 "
,,790,"Fabric8 CI not working.
 Ping @rupalibehera seems that http://jenkins.cd.k8s.fabric8.io/job/kubernetes-incubator/ doesn't show.

Could it be since we move the org to `kubernetes` from `kubernetes-incubator`?.
 Yes it is because of the change, the new org should be added in Fabric8
Jenkins.
We can ask James S or James R for it, as they have permission.

On 23-Aug-2017 9:40 PM, ""Charlie Drage"" <notifications@github.com> wrote:

> Ping @rupalibehera <https://github.com/rupalibehera> seems that
> http://jenkins.cd.k8s.fabric8.io/job/kubernetes-incubator/ doesn't show.
>
> Could it be since we move the org to kubernetes from kubernetes-incubator?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/790>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEFwMSHorYVW6_sWyHJ32E1ugJh2mEmRks5sbE8CgaJpZM4PAP0c>
> .
>
.
 Okay, can you update the Jenkinsfile as well? @rupalibehera :+1: .
 new org in fabric8-ci is not added yet, is that manual process ?.
 Yes @surajnarwade it is a manual process of adding the org .
 @surajnarwade and @cdrage, here we go http://jenkins.cd.k8s.fabric8.io/job/kubernetes/job/kompose/job/master/1/console.
 Thanks @rupalibehera , we can close this now :).
 If you look at http://jenkins.cd.k8s.fabric8.io/job/kubernetes/job/kompose/job/master/1/console @surajnarwade it still shows that it fails.

Is it due to Fabric8-CI still not having permission with Kompose (2 factor auth?) @rupalibehera ?.
 No it is a different issue. all pipelines are facing this issue right now

On Wed, Aug 30, 2017 at 7:16 PM, Charlie Drage <notifications@github.com>
wrote:

> If you look at http://jenkins.cd.k8s.fabric8.
> io/job/kubernetes/job/kompose/job/master/1/console @surajnarwade
> <https://github.com/surajnarwade> it still shows that it fails.
>
> Is it due to Fabric8-CI still not having permission with Kompose (2 factor
> auth?) @rupalibehera <https://github.com/rupalibehera> ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes/kompose/issues/790#issuecomment-325995052>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEFwMWJEhkolQ1fIkZBuBY7PT9OKYmzJks5sdWepgaJpZM4PAP0c>
> .
>



-- 
Thanks,
Rupali Behera
.
 @rupalibehera okidoki, any open issue / pr that's out there we can track / help out on?.
 Hey @rupalibehera is this fixed?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 We're using SemaphoreCI / TravisCI and it's working :100: so far, let's close this for now..
 "
,,789,"Update Kubernetes cluster tests with port testing.
 Currently we deploy Kubernetes artifacts and undeploy them using the `make test-k8s` command.

However, we don't check to see if the ports have come up nor checking to see if the service / pods / containers are actually running. 

Similar to the work @ashetty1 did to OpenShift, let's implement port testing to the Kubernetes cluster tests..
 Using efforts from https://github.com/kedgeproject/kedge/blob/master/tests/e2e/e2e_test.go we can covert / port this code to effectively test both OpenShift and Kubernetes tests..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/789#issuecomment-429061314):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,788,"Rework ""unsupported keys"" prompt.
 Rework out ""unsupported keys"" function for both v3.go and v1v2.go files. Having both better outputs as well as warnings..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,787,"Add --volumes parameter, deprecate emptyvols.
 This adds the --volumes paramater with a ""generate"" and ""empty""

By default, ""generate"" will be used as a place-holder for ""true"".
Although not used in the code, we will eventually add ""none""

This uses CLI paramater naming processes (no emptyVols as that is Go /
Kubernetes specific) and thus we use dashes..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @procrypt and @kadel, please review this..
 @cdrage I tried running this with etherpad docker-compose file, and it looks like `--volumes empty` option creates a pvc:

```
$ ./kompose up --provider=openshift  --volumes empty  -f script/test/fixtures/etherpad/docker-compose.yml 
WARN Unsupported depends_on key - ignoring        
INFO We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: etherpad       
INFO Successfully created Service: mariadb        
INFO Successfully created DeploymentConfig: etherpad 
INFO Successfully created ImageStream: etherpad   
INFO Successfully created DeploymentConfig: mariadb 
INFO Successfully created ImageStream: mariadb    
INFO Successfully created PersistentVolumeClaim: mariadb-claim0 of size 100Mi. If your cluster has dynamic storage provisioning, you don't have to do anything. Otherwise you have to create PersistentVolume to make PVC work 

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.

```

Let me know if I am doing anything wrong here..
 @ashetty1 Odd! Thanks for noticing that, looks like I missed something in the `openshift.go` file..
 @ashetty1 It works on my machine using `convert`...
```
▶ ./kompose convert --provider=openshift  --volumes empty  -f script/test/fixtures/etherpad/docker-compose.yml 
WARN Unsupported depends_on key - ignoring        
INFO OpenShift file ""etherpad-service.yaml"" created 
INFO OpenShift file ""mariadb-service.yaml"" created 
INFO OpenShift file ""etherpad-deploymentconfig.yaml"" created 
INFO OpenShift file ""etherpad-imagestream.yaml"" created 
INFO OpenShift file ""mariadb-deploymentconfig.yaml"" created 
INFO OpenShift file ""mariadb-imagestream.yaml"" created 
```

But not `up`.

Thanks for testing it! I'll go ahead and fix it..
 @ashetty1 Okay, should be fixed now. I forgot to add the param to `up.go`. Please try again for me!.
 Something's wrong here. @cdrage, can you do a fresh checkout and try?

```
$ ./kompose version
panic: up flag redefined: volumes

goroutine 1 [running]:
panic(0x19a4140, 0xc42049d590)
        /usr/lib/golang/src/runtime/panic.go:500 +0x1a1
github.com/kubernetes/kompose/vendor/github.com/spf13/pflag.(*FlagSet).AddFlag(0xc42034c3c0, 0xc42026cb40)
        /usr/lib/golang/src/github.com/kubernetes/kompose/vendor/github.com/spf13/pflag/flag.go:797 +0x9ea
github.com/kubernetes/kompose/vendor/github.com/spf13/pflag.(*FlagSet).VarPF(0xc42034c3c0, 0x29d8020, 0x2a2ba70, 0x1c9a1df, 0x7, 0x0, 0x0, 0x1cce0b1, 0x2c, 0xc42026caa0)
        /usr/lib/golang/src/github.com/kubernetes/kompose/vendor/github.com/spf13/pflag/flag.go:780 +0x141
github.com/kubernetes/kompose/vendor/github.com/spf13/pflag.(*FlagSet).VarP(0xc42034c3c0, 0x29d8020, 0x2a2ba70, 0x1c9a1df, 0x7, 0x0, 0x0, 0x1cce0b1, 0x2c)
        /usr/lib/golang/src/github.com/kubernetes/kompose/vendor/github.com/spf13/pflag/flag.go:786 +0x8e
github.com/kubernetes/kompose/vendor/github.com/spf13/pflag.(*FlagSet).StringVar(0xc42034c3c0, 0x2a2ba70, 0x1c9a1df, 0x7, 0x1c9af6b, 0x8, 0x1cce0b1, 0x2c)
        /usr/lib/golang/src/github.com/kubernetes/kompose/vendor/github.com/spf13/pflag/string.go:37 +0xa3
github.com/kubernetes/kompose/cmd.init.5()
        /usr/lib/golang/src/github.com/kubernetes/kompose/cmd/up.go:76 +0x1a9
github.com/kubernetes/kompose/cmd.init()
        /usr/lib/golang/src/github.com/kubernetes/kompose/cmd/version.go:46 +0xb5
main.init()
        /usr/lib/golang/src/github.com/kubernetes/kompose/main.go:24 +0x2e
```.
 @ashetty1 Ah, you're too fast! It didn't git push -f in time. Try now:

```
▶ ./kompose up --provider=openshift  --volumes empty  -f script/test/fixtures/etherpad/docker-compose.yml 
WARN Unsupported depends_on key - ignoring        
INFO We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: etherpad       
INFO Successfully created Service: mariadb        
INFO Successfully created DeploymentConfig: etherpad 
INFO Successfully created ImageStream: etherpad   
INFO Successfully created DeploymentConfig: mariadb 
INFO Successfully created ImageStream: mariadb    

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.
```
.
 Works now :).
 @ashetty1 Awesome! Wanna do a quick review? :+1: .
 @ashetty1 I'll add some unit tests as well, could you do a code review for me?.
 @ashetty1 Unit test has been added!.
 > This adds the --volumes paramater with a ""generate"" and ""empty""
> 
> By default, ""generate"" will be used as a place-holder for ""true"".


why generate?

what does `generate` do?.
 @kadel Because if I set it to ""none"" and set that as default, it would seem as though no volumes are used / generated. Hence why I put ""generate"" and set that as a the default. Does that make sense?
.
 > @kadel Because if I set it to ""none"" and set that as default, it would seem as though no volumes are used / generated. Hence why I put ""generate"" and set that as a the default. Does that make sense?

I don't think that its good name :-(
It is not clear what it does :-(

I think that the best would be to use actual Kubernetes volume type names (https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes).  It would be much cleaner .

The default should be `persistentVolumeClaim` - I know it is long :-( but it will be the default value so users don't have to write it.

Instead of empty I would put there the whole `emptyDir` and once implemented we will add `hostPath` 

what do you think?



.
 @kadel To be honest I don't like using Kubernetes naming conventions in CLI tools. Not even `kubectl` uses that naming convention within their CLI. It's all lower-case with hyphens. 

Having the long names would make `kompose convert --help` output even longer. 

What about: `pvc | none | empty` for the options with `pvc` set as the default?

edit: use `pvc | empty-dir | host-path`.
 > @kadel To be honest I don't like using Kubernetes naming conventions in CLI tools. Not even kubectl uses that naming convention within their CLI. It's all lower-case with hyphens.

I think this rule is only for flag name not for values.

> What about: pvc | none | empty for the options with pvc set as the default?

Problem with this is that it is still not clear what it does :-(

If we do `emptyDir`, `persistentVolumeClaim`, and `ignore` that it says everything. I don't think that few words more is a problem.

`emptyDir` is also easier to find in documentation that just `empty` same for `pvc` vs `persistentVolumeClaim` .
 @kadel Okay, that *would* make it easier.

For CLI params keep with the conventional way, but with values stick to Kubernetes.

For example, this this how they do --type in `kubectl`:

```sh
      --type='': Type for this service: ClusterIP, NodePort, or LoadBalancer. Default is 'ClusterIP'
```

I'll update this in this PR.

.
 @cdrage or should the value be just boolean? False/no would mean emptyvols; yes by default. WDYT.
 @ashetty1 A bit confused. --emptyvols is false by default, passing in --emptyvols by itself makes it true.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @containscafeine and @procrypt, please review this..
 @ashetty1 @kadel I have update the PR to reflect the changes that @kadel suggested. I will add `ignore` later, but at the moment there have been no feature requests nor does it make sense to currently ignore volumes being generated / added..
 @ashetty1 @kadel @surajnarwade @surajssd @containscafeine up for review.
 We can't forget to put mentions about this to release notes when we do next release.
 @kadel Yup, will do! :+1: .
 "
,,786,"Fix minor help output.
 Fixes the minor help output for --build (removes the space).
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @procrypt and @kadel, please review this..
 "
,,785,"Add Bintray documentation to README and installation doc.
 Adds information on nightly builds to the README and installation
document..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @e-minguez, please review this..
 @kadel I used the links directly from bintray but they were wrong.. thanks for the review! Updated the PR..
 If I goto this link `https://dl.bintray.com/kedgeproject/kedge/latest/`,
I can see,

* kedge-darwin-amd64
* kedge-linux-amd64
* kedge-linux-arm
* kedge-windows-amd64.exe

`kompose` is not there.
 you can find all the correct links here: https://dl.bintray.com/kompose/kompose/latest/

Sorry about confusion with Kedge :-( .
 I think this it the longest review for a doc every from mistypes, haha. Both @kadel and I had brainfarts.

Updated (again!).

@surajnarwade .
 "
,,784,"Fix minor typo in comment.
 Fix minor typo in comment.
 @Rajadeepan, thank you for the pull request! We'll request some people to review your PR. @cdrage and @surajssd, please review this..
 LGTM! :+1: .
 "
,,783,"add correct secrets for bintray.
 this should fix `Bintray response: 401 Unauthorized. This resource requires authentication` error while uploading binaries to bintray


I'll add links to readme in another PR, once we are sure that this works..
 @kadel, thank you for the pull request! We'll request some people to review your PR. @cdrage and @surajnarwade, please review this..
 LGTM.
 "
,,782,"build and upload master builds to bintray.
 .
 "
,,781,"Add testing documentation.
 As of now, we don't have testing documetation (which is needed for any new contributors).
 @cdrage @surajnarwade I am going write a document on how to write tests for OpenShift / k8s framework that we have. Let me know if you have any inputs..
 @ashetty1, one of the pointer will be how to test code using commands like `make test` or `make test-cmd` and what they do.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Priorities:

 - [ ] Better documentation on how to write tests
 - [ ] Better documentation on how to actually RUN these tests..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/781#issuecomment-429061320):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,780,"Update the dev guide with CI details.
 Updates the development.md doc with details on what CI's we use..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @kadel and @surajssd, please review this..
 @cdrage , can you hyperlink each CI name with respective links ?.
 @surajnarwade updated!.
 "
,,779,"Update conversion matrix with windows notes.
 Moves one of the notes as well as updates credentials_spec.
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @asifdxtreme, please review this..
 "
,,778,"Change directory for cluster tests.
 Fixes the directory for running cluster tests (test_k8s rather than
test_ci).
 "
,,777,"Remove dab examples.
 Removes .dab examples from the example dir.
 lgtm, but semaphore CI is failing.
 @surajnarwade had to rebase, should be good now..
 "
,,776,"Improve user guide.
 Discussion for improving the user-guide..
 ## Findings

I perused the docs, primarily the User Guide (UG) part and the Installation Guide (IG) part. My expectation was that the IG would tell me what I need to install and the UG would tell me what I can do with Kompose, possibly walk me through a common use case for the tool, etc. 

I remained confused for a while because while the IG is as expected, the UG seemed like a reference document since it lists all the commands available for Kubernetes and OpenShift but not much about what I'm doing or why.

I unexpectedly found the information I was looking for in the Introduction section. What I expected to find here was an overview of what Kompose is and what one would use it for. Instead, it has a concise and clear (and I assume, most common) use case for the tool.

## Workflow

After reviewing all the information, I came up with the following basic workflow for a common use case:

1. Configure/customize your docker-compose.yml file:
   1. Use Kompose-specific labels to your yml file to define the service's behavior when converted, specifically __kompose.service.type__ and __kompose.service.expose__.
   1. To create pods without controllers, use __restart__ in the yml file to define this. Valid options include __""""__, __always__, __on-failure__, and __no__.
1. Deploy your application in one of two ways:
   1. Run __kompose up__ (with options for Kubernetes or OpenShift) in the same directory as the yaml file. The UI has a __build__ key that does the same thing.
   1. Run __kompose convert__ and then __kubectl create -f__ to convert V1, V2, and V3 Docker Compose filed into Kubernetes or OpenShift objects and then deploy them). There are also a variety of additional parameters (-j, -c, --daemon-set, --replication-controller) for generating JSON files, Helm charts, and Deployment objects.
1. View the deployed service in one of two ways:
   1. If you are already using minikube for development, run __minikube service frontend__.
   1. If you are not using minikube, look up your service's IP address using __kubectl describe svc frontend__ and then ""curl <IP>"".
1. Remove the deployment and reclaim resources using __kompose down__.

Does this seem about right to you?

## Proposed Changes

I would recommend a restructure to make the content flow in a more intuitive way for users, as well as a general edit to fix up some phrasing that is either unclear, informal, or at times a bit convoluted. 

For the restructure, I would recommend:

__General:__
* Confirming a primary workflow that is common to most users, as above, and then fleshing out the steps.
* Outline the general workflow and explain what each step does, then flesh out the details of each step in subsequent sections. These sections provide details and alternative paths for each step.

__Landing Page:__
* Change the landing page (http://kompose.io/) from the introduction to just a quick explanation of what the tool is and what you would use it for. As it stands, the information there is useful, certainly, but a bit overwhelming since we don't know which part of the menu (left side of page) we are at yet or what the information being presented is. 
* Add a very high level outline of the identified workflow here so that the user is eased into what they will be doing, or click through directly to a step.

__User Guide/Getting Started Guide:__
* The User Guide can probably remain a more reference based document, much like it is now.
* Add a Getting Started guide or something similarly named so that new users know exactly where to go to start and get a walkthrough.

.
 @cdrage These are my initial thoughts. Please let me know what you think and we can discuss it further. .
 @mishaone Thank you so much! I will go through this and make some updates / notes in regards to the site.

Have you looked at http://kedgeproject.org ? We've included an ""introduction"" page to the index, is this similar to your suggestion of having the landing page updated to reflect an explanation of the tool as well as what people would use it for?.
 Hi @cdrage,

Happy to help! The Kedge Project site looks great. That's precisely the sort of thing I meant. 

Would you like me to create issues to track these items or do you prefer to track them yourself somewhere?.
 @mishaone I'll split off the issues into separate tracking cards / issues. Thanks again for the feedback!.
 TODOS:

General:

- [x] Confirming a primary workflow that is common to most users, as above, and then fleshing out the steps.
- [x] Outline the general workflow and explain what each step does, then flesh out the details of each step in subsequent sections. These sections provide details and alternative paths for each step.

Landing Page:

- [x] Change the landing page (http://kompose.io/) from the introduction to just a quick explanation of what the tool is and what you would use it for. As it stands, the information there is useful, certainly, but a bit overwhelming since we don't know which part of the menu (left side of page) we are at yet or what the information being presented is.
- [x] Add a very high level outline of the identified workflow here so that the user is eased into what they will be doing, or click through directly to a step.

User Guide/Getting Started Guide:

- [x] The User Guide can probably remain a more reference based document, much like it is now.
- [x] Add a Getting Started guide or something similarly named so that new users know exactly where to go to start and get a walkthrough.

OTHER / ADDITIONALLY ADDED:

- [x] Highlighting added https://github.com/kubernetes/kompose/pull/831.
 Most, if not, all of the tasks above have been completed. Thanks again for @mishaone for the feedback! :+1: .
 "
,,775,"Adds a more ""full"" conversion document.
 This majorly updates the conversion document in order to have version
compatibile checks with V1, V2 and V3 of Docker Compose and Kompose
support..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @asifdxtreme, please review this..
 "
,,774,"Fix footer horizontal scrolling.
 "
,,773,"Fix css for horizontal scrolling.
 Closes #765 .
 "
,,772,"Remove useless Kubernetes artifact keys.
 For example, `""importPolicy"": {}` is added to each OpenShift output.

Within Kubernetes there are also other useless keys that are either `null` or `{}`.

Let's remove them..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,771,"Add deploy: mode: global support.
 Adds support for deploy: mode.

For example:

```yaml
version: ""3""

services:
  foo:
    deploy:
      resources:
        mode: global
        replicas: 6
    image: redis
```

Will only generate replicas: 1 in Kubernetes pods as ""global"" limits
replicas to only one..
 @cdrage, thank you for the pull request! We'll request some people to review your PR. @surajnarwade and @procrypt, please review this..
 documentation of [mode](https://docs.docker.com/compose/compose-file/#mode) says `global` spin up exactly one container per swarm **node**, can we achieve same with kubernetes ?.
 @surajnarwade nope, unless it's a daemonset. For now it's just `replicas: 1`. I really want to add DaemonSet however.

But you *are* right..
 Thanks @kadel I've gone ahead and implemented the changes..
 Again, another mistake and tests failed. But fixed with @kadel 's suggestions.

Ready for another review!.
 @kadel Updated with the new warning message.
 "
,,770,"Update to annotations / cli tests + development document.
 So there's two issues I'm encountering with annotations:

1. If there is no `kompose`, it does not error out. For example, if Kompose is not within $GOPATH or /usr/local/bin, then the annotation is blank for VERSION.
2. Tests need to be updated.. Using sed seems like a hack at the moment and it should be refactored (in the future)

Ping @surajnarwade .
 Another suggestion as well is after fixing issue **1** we implement a small script that passes in a file name and automatically adds the ""test"" to `tests.sh` as it's fairly difficult / troublesome to manually create all the test outputs as well as modify it so `%VERSION%` and `%CMD% is there for the annotations..
 @cdrage that script is already on my list :).
 @surajnarwade can you work on option 1. as well?.
 Taking this up.
 documentation issue: https://github.com/kubernetes/kompose/issues/781.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
,,769,"Change bot message.
 .
 @asifdxtreme, thank you for the pull request! We'll ping some people to review your PR. @cdrage, please review this..
 Thanks! .
 "
,,768,"Fix minor typo.
 .
 @asifdxtreme, thank you for the pull request! We'll ping some people to review your PR. @cdrage, please review this..
 Thanks!.
 "
,,767,"Add compatibility matrix.
 Adds a matrix that signifies what versions of Kubernetes we support..
 I'm going to update this at a later date with `Deployment` artifacts and such..
 "
,,766,"[WIP] Update to use ./kompose instead of $GOPATH kompose binary.
 The issue is that when running `make test-cmd` you'll have to cp kompose
to the /usr/local/bin directory or the $GOPATH directory.

Since `make test` is being used consistently in the same git diretory,
it makes sense to use the local-built binary..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @procrypt, please review this..
 Blocked on #770 since `kompose version` does not fail if no kompose is located..
 Closing for now..
 "
,,765,"overlapped content on the conversion matrix documentation page.
 In the [Conversion Matrix](http://kompose.io/conversion/) page, when you scroll horizontally on the table, the content will overlap with the menu.

<img width=""777"" alt=""screen shot 2017-08-15 at 4 35 51 pm"" src=""https://user-images.githubusercontent.com/1469579/29341231-d8928342-81d7-11e7-8681-3f11c0fa2900.png"">
.
 @rickypai , it maybe your browser issue. works well for me on chrome and firefox.
 @rickypai I don't see an issue either :( mind telling us what browser you're using?.
 I tired it on multiple bowsers: chrome, chrome canary, safari, brave, all the same result.

you need to scroll the content horizontally to see the overlap.
 @rickypai Ohhhhh, I see how. I was able to re-produce this. I'll push a fix out soon..
 @rickypai Should be fixed now with #773 and #774 let me know if it's not :+1: .
 "
,,764,"Update Community Code of Conduct.
 Update Community Code of Conduct from kubernetes/kubernetes-template-project.
 LGTM! :+1: .
 "
,,763,"Fix for OpenShift cluster tests.
 Tests are pass/failing 50% of the time due to the fact that Kompose down
is too fast for the next step to continue.

Hopefully this fixes it..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @ashetty1, please review this..
 Still failing :( Any ideas @ashetty1 ?

```
Running kompose up ...
B
WARN Unsupported depends_on key - ignoring        
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: etherpad       
INFO Successfully created Service: mariadb        
INFO Successfully created DeploymentConfig: etherpad 
INFO Successfully created ImageStream: etherpad   
INFO Successfully created DeploymentConfig: mariadb 
INFO Successfully created ImageStream: mariadb    

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.

Waiting for the pods to come up ...
B
FAIL: kompose up has failed to bring the pods up
BNAME               READY     STATUS             RESTARTS   AGE
etherpad-1-tlpxn   0/1       CrashLoopBackOff   4          5m
mariadb-1-cfmt5    0/1       CrashLoopBackOff   5          5m
```.
 @cdrage Unable to reproduce the crashloopbackoff error :/ .
 @ashetty1 Yeah... It's really hard to reproduce... I'm going to update the PR with your suggestion `convert::oc_cleanup` as well as push the PR and see if it fixes the tests..
 @ashetty1 Thanks for approving but I dont think this fixed it :-1: I'm going to close this for now.

I've freed some RAM on the SemaphoreCI tests, let's see if that fixes anything..
 "
,,762,"Go down to one ACK.
 Move down to one ACK rather than two for code changes. One or none for
doc changes..
 ping @kadel @containscafeine @surajnarwade @surajssd .
 "
,,761,"Rename test-ci to test-k8s.
 Renames test-ci to test-k8s to coincide with our `make test-openshift`
command..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @kadel and @ashetty1, please review this..
 Obviously Semaphore is failing since we have to edit the commands to `make test-k8s` :+1: .
 "
,,760,"Fix typo in Events Code of Conduct.
 .
 @mbssaiakhil , thanks for the contribution :).
 Thanks! :+1: .
 "
,,759,"Adds healthcheck.
 This PR adds support for HealthCheck, being able to supply, for example:

```yaml
version: ""3""

services:
  redis:
    image: redis
    healthcheck:
      test: echo ""hello world""
      interval: 10s
      timeout: 1s
      retries: 5
```

Which is then converted to:

```yaml
spec:
  containers:
  - image: redis
    livenessProbe:
      exec:
        command:
        - echo ""hello world""
      failureThreshold: 5
      periodSeconds: 10
      timeoutSeconds: 1
    name: redis
    resources: {}
  restartPolicy: Always
```

At the moment, this only supports livenessProbe, with support for readinessProbe in the future..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @kadel, please review this..
 Note: Tests are still being added, but this is up for review :+1: .
 @surajssd @containscafeine @kadel @surajnarwade Can I get a review?

EDIT: Tests have now been added..
 So essentially @containscafeine Health Check restarts the Docker container when it fails, LivenessProbe is the same within Kubernetes. Makes sense to only have LivenessProbe and add the ability to use Readiness when we add an external label :+1: .
 @containscafeine Added your suggestion regarding `Disable`!.
 Awesome!! @containscafeine I have rebased :+1: .
 "
,,758,"Revert "" Added support for `group_add` key"".
 Reverts kubernetes/kompose#739.
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @procrypt, please review this..
 "
,,757,"Update cluster tests, use local Kompose binary.
 Uses the local kompose binary that was built, not the one stored in the
GOPATH bin folder.

For example, using `./kompose` instead of `kompose`

Disables `make bin` generation for Kubernetes tests..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @ashetty1, please review this..
 Hey @ashetty1 I'm going to merge this for now in order to make any new PR's pass for the cluster tests, let me know if this conflicts with anything. .
 "
,,756,"[testing ci] testing ci builds.
 testing to see if new builds successfully trigger all CI integrations
(semaphore, cla, travis, etc.).
 Note to self: OpenShift tests are a bit finnicky at the moment due to low-memory on the VM. People may need to retry / rebuild some test cases..
 "
,,755,"Re-add tests for buildconfig to OpenShift cluster.
 With this PR we remove them:
https://github.com/kubernetes/kompose/pull/754/files

Let's re-add BuildConfig tests for OpenShift..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,754,"Temporarily remove buildconfig tests for OpenShift.
 Temporarily remove these until we get buildconfig tests working..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @ashetty1, please review this..
 Hey @ashetty1 I've opened #755 to re-add these in the future. Let's open up another PR to fix these tests in the future.

I'm going to merge this (for now)..
 "
,,753,"unit test for annotation.
 after merging #733 , we will need to figure out a way to add unit test for annotations,

Removed unit test code snippet,

```
if !equalStringMaps(config.Annotations, meta.Annotations) {
		return fmt.Errorf(""Found different annotations: %#v vs. %#v"", config.Annotations, meta.Annotations)
	}
```.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
  /remove-lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,752,"Build errors with current OpenShift cluster tests.
 See: https://semaphoreci.com/cdrage/kompose-2/branches/master/builds/25

Seems that adding the `xip.io` change caused an issue..
 @cdrage , `xip.io` is changed to `nip.io`.
 Hey @surajnarwade and @ashetty1 
Still getting issues with CrashLoopBackOff :(
```sh
Pulled 3/4 layers, 85% complete
Pulled 4/4 layers, 100% complete
Extracting
Image pull complete
OpenShift server started.

The server is accessible via web console at:
    https://127.0.0.1:8443

You are logged in as:
    User:     developer
    Password: <any value>

To login as administrator:

Testing buildconfig dockerfile construct in kompose
(BRunning kompose up ...
(B
INFO Buildconfig using git@github.com:kubernetes/kompose.git::master as source. 
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
INFO Successfully created Service: foo            

(B
Waiting for the pods to come up ...

    oc login -u system:admin


FAIL: kompose up has failed to bring the pods up
(BNAME          READY     STATUS    RESTARTS   AGE
foo-1-build   0/1       Error     0          4m

Testing buildconfig on kompose
(BRunning kompose up ...
(B


INFO Buildconfig using git@github.com:kubernetes/kompose.git::master as source. 
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 

INFO Successfully created DeploymentConfig: foo   INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: foo            
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

Waiting for the pods to come up ...
(B
FAIL: kompose up has failed to bring the pods up
(BNAME          READY     STATUS    RESTARTS   AGE
foo-1-build   0/1       Error     0          4m

Running tests with entrypoint/command option
(BRunning kompose up ...
(B


INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: base1          
INFO Successfully created Service: base2          
INFO Successfully created DeploymentConfig: base1 
INFO Successfully created ImageStream: base1      
INFO Successfully created DeploymentConfig: base2 
INFO Successfully created ImageStream: base2      

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.

Waiting for the pods to come up ...
(B
No resources found.
NAME            READY     STATUS    RESTARTS   AGE
base1-1-2dsxl   1/1       Running   0          8s
base2-1-r6094   1/1       Running   0          8s
(B
PASS: All pods are Running now. kompose up is successful.
Running kompose down ...
(B
INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: base1          
INFO Successfully deleted Service: base2          
INFO Successfully deleted DeploymentConfig: base1 
INFO Successfully deleted ImageStream: base1      
INFO Successfully deleted DeploymentConfig: base2 
INFO Successfully deleted ImageStream: base2      

(B
Waiting for the pods to go down ...
PASS: All pods are down now. kompose down successful.
(BNAME            READY     STATUS        RESTARTS   AGE
base1-1-2dsxl   1/1       Terminating   0          13s
base2-1-r6094   1/1       Terminating   0          13s

Testing kompose up/down with etherpad docker-compose file
(B

Running kompose up ...
(B
WARN Unsupported depends_on key - ignoring        
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: etherpad       
INFO Successfully created Service: mariadb        
INFO Successfully created DeploymentConfig: etherpad 
INFO Successfully created ImageStream: etherpad   
INFO Successfully created DeploymentConfig: mariadb 
Waiting for the pods to come up ...

INFO Successfully created ImageStream: mariadb    

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.
(B
FAIL: kompose up has failed to bring the pods up
(BNAME               READY     STATUS             RESTARTS   AGE
etherpad-1-djzv7   0/1       CrashLoopBackOff   4          5m
mariadb-1-deploy   1/1       Running            0          5m
mariadb-1-rbq4f    0/1  5m
       CrashLoopBackOff   5        
Running tests for replica option
(B
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Service: web            
INFO Successfully created DeploymentConfig: redis 
INFO Successfully created ImageStream: redis      
INFO Successfully created DeploymentConfig: web   
INFO Successfully created ImageStream: web        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.

Waiting for the pods to come up ...
(BAGE
redis-1-2bb9s   1/1       Running   0          28s
redis-1-lrcfq   1/1       Running   
NAME            READY     STATUS    RESTARTS      0          28s
web-1-th78nweb-1-f517v     1/1       Running0          28s
PASS: All pods are Running now. kompose up is successful.
(B
     1/1       Running   0          28s
Running kompose down ...
(B
INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: redis          
INFO Successfully deleted Service: web            
INFO Successfully deleted DeploymentConfig: redis 
INFO Successfully deleted ImageStream: redis      
INFO Successfully deleted DeploymentConfig: web   
INFO Successfully deleted ImageStream: web        

Waiting for the pods to go down ...
(B
PASS: All pods are down now. kompose down successful.
(BNAME            READY     STATUS
redis-1-2bb9s        RESTARTS   AGE   1/1       Terminating   0          redis-1-lrcfq   33s
  33s0        1/1       Terminating   0          33s
web-1-f517v     1/1       Terminating   0          33s
web-1-th78n     1/1       Terminating   



Testing  restart: 'always'
(BRunning kompose up ...
(B
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: pival          
INFO Successfully created DeploymentConfig: pival 
INFO Successfully created ImageStream: pival      

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
PASS: restart option set to 'always' is working as expected

AGE
pival-1-hbq20   1/1       Running   1          37s
(BNAME            READY     STATUS    RESTARTS   Running kompose down ...
(B
INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: pival          
INFO Successfully deleted DeploymentConfig: pival 
INFO Successfully deleted ImageStream: pival      

Waiting for the pods to go down ...
(B
PASS: All pods are down now. kompose down successful.
(BNo resources found.



Running kompose up ...
(BTesting kompose-specific label:kompose.service.expose=hostname 
(B
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Service: web            
INFO Successfully created DeploymentConfig: redis 
INFO Successfully created ImageStream: redis      
INFO Successfully created DeploymentConfig: web   
INFO Successfully created ImageStream: web        
(B

INFO Successfully created Route: web              

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.
Waiting for the pods to come up ...
No resources found.
0          5s
web-1-25c4w     1/1       Running   0          5s
NAME            READY     STATUS    RESTARTS   AGE
redis-1-d98xh   1/1       Running   PASS: All pods are Running now. kompose up is successful.
(B
(BPASS: Route *.batman.example.com has been exposed
NAME      HOST/PORT            PATH      SERVICES   PORT      TERMINATION   web        
Running kompose down ...
(B
WILDCARD
web       INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: redis          
batman.example.com             5000                    None
INFO Successfully deleted Service: web            
INFO Successfully deleted DeploymentConfig: redis 
INFO Successfully deleted ImageStream: redis      
INFO Successfully deleted DeploymentConfig: web   
INFO Successfully deleted ImageStream: web        
INFO Successfully deleted Route: web              

Waiting for the pods to go down ...
(B
PASS: All pods are down now. kompose down successful.
(BNAME            READY     STATUS        RESTARTS   AGE
redis-1-d98xh   1/1       Terminating   0          11s
web-1-25c4w     1/1       Terminating   0          11s

Running tests for kompose-specific labels: 'kompose.service.expose:True'
(B

Running kompose up ...
(B
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Service: web            
INFO Successfully created DeploymentConfig: redis 
INFO Successfully created ImageStream: redis      
INFO Successfully created DeploymentConfig: web   
INFO Successfully created ImageStream: web        
INFO Successfully created Route: web              

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.

Waiting for the pods to come up ...
(B
NAME            READY     STATUS        RESTARTS   AGE
redis-1-d98xh   1/1       Terminating   0          18s
redis-1-mqtl7   1/1       Running       0          5s
web-1-25c4w     1/1       Terminating   0          18s
web-1-3w7zr     1/1       Running       0PASS: All pods are Running now. kompose up is successful.
          5s
(BPASS: Route *.nip.io has been exposed
(B
NAME      HOST/PORT                        PATH      SERVICES   PORT      TERMINATION   WILDCARD
web       web-myproject.127.0.0.1.nip.io             web        5000                    None

Running kompose down ...
(B
INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: redis          
INFO Successfully deleted Service: web            
INFO Successfully deleted DeploymentConfig: redis 
INFO Successfully deleted ImageStream: redis      
INFO Successfully deleted DeploymentConfig: web   
INFO Successfully deleted ImageStream: web        
INFO Successfully deleted Route: web              

(B
Waiting for the pods to go down ...
PASS: All pods are down now. kompose down successful.
(B0          NAME            READY     STATUS        RESTARTS   AGE
redis-1-mqtl7   0/1       Terminating   0          38s
web-1-3w7zr     0/1       Terminating   38s
make: *** [test-openshift] Error 1
```

That's after your PR has been merged...
 For the first one, here are the logs:
```
github.com/kubernetes/kompose  get-rid-of-bundle-tag ✔                                                                                                                                                                                                                   23h30m  
▶ oc logs foo-1-build
Cloning ""git@github.com:cdrage/kompose.git"" ...
error: build error: Host key verification failed.
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
```.
 @cdrage this looks like an git authentication error because the repo is a ssh-git clone. I tried with an https clone, and it works:

```
$ kompose up --provider=openshift --emptyvols -f script/test_in_openshift/compose-files/buildconfig/docker-compose.yml --build build-config
INFO Buildconfig using https://github.com/ashetty1/kompose.git::build_tests as source. 
INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: foo            
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

$ oc logs -f foo-1-build
Cloning ""https://github.com/ashetty1/kompose.git"" ...
	Commit:	af6f5a75ce868ff9a81165e447552b35ed76a2ec (tmp)
	Author:	Anush Shetty <ashetty@redhat.com>
	Date:	Thu Aug 10 14:52:36 2017 +0530
Step 1 : FROM busybox:1.26.2
 ---> 01a9b6c990de
Step 2 : RUN touch /test
 ---> Using cache
 ---> 63c6be9cc512
Step 3 : ENV ""OPENSHIFT_BUILD_NAME"" ""foo-1"" ""OPENSHIFT_BUILD_NAMESPACE"" ""myproject"" ""OPENSHIFT_BUILD_SOURCE"" ""https://github.com/ashetty1/kompose.git"" ""OPENSHIFT_BUILD_REFERENCE"" ""build_tests"" ""OPENSHIFT_BUILD_COMMIT"" ""af6f5a75ce868ff9a81165e447552b35ed76a2ec""
 ---> Running in d0a8f052d275
 ---> 69521d7a93dd
Removing intermediate container d0a8f052d275
Step 4 : LABEL ""io.openshift.build.commit.date"" ""Thu Aug 10 14:52:36 2017 +0530"" ""io.openshift.build.commit.id"" ""af6f5a75ce868ff9a81165e447552b35ed76a2ec"" ""io.openshift.build.commit.ref"" ""build_tests"" ""io.openshift.build.commit.message"" ""tmp"" ""io.openshift.build.source-location"" ""https://github.com/ashetty1/kompose.git"" ""io.openshift.build.source-context-dir"" ""script/test_in_openshift/compose-files/buildconfig/build"" ""io.openshift.build.commit.author"" ""Anush Shetty \u003cashetty@redhat.com\u003e""
 ---> Running in df5a6241bee5
 ---> 3c6310ebdfff
Removing intermediate container df5a6241bee5
Successfully built 3c6310ebdfff

Pushing image 172.30.1.1:5000/myproject/foo:latest ...
Pushed 0/5 layers, 21% complete
Pushed 1/5 layers, 100% complete
Pushed 2/5 layers, 100% complete
Pushed 3/5 layers, 100% complete
Pushed 4/5 layers, 100% complete
Pushed 5/5 layers, 100% complete
Push successful


$ oc get pods 
NAME          READY     STATUS      RESTARTS   AGE
foo-1-build   0/1       Completed   0          54s
foo-1-zbc3t   1/1       Running     0          17s

```.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 I believe this has been fixed. Please re-open if not! I don't encounter these issues anymore..
 "
,,751,"Gets rid of bundle tag.
 Closes https://github.com/kubernetes/kompose/issues/750

Since we no longer support DAB / Bundle (for now), let's remove the
uneeded bundle tag..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @procrypt, please review this..
 "
,,750,"get rid of the bundle tag in kobject.
 We have removed support for docker `bundle` so I think we can get rid of the tags in `kobject` file [here](https://github.com/kubernetes/kompose/blob/af26b797a22ac67c6789212fa050477c33bbec87/pkg/kobject/kobject.go#L65)..
 @surajssd thanks, PR added: #751 .
 "
,,749,"Update docs to reflect conversion changes.
 Updates the doc due to the recent changes to deploy keys as well as
othre mappings..
 "
,,748,"Update development.md with relevant details regarding CI.
 Update the development.md documentation in regards to what CI does what (Travis, SemaphoreCI, Fabric8, etc.).
 PR #780 .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,747,"Exit 1 not Exit 0.
 Wrong exit value.
 "
,,746,"Create docker client from environment variables.
 *Why:*

Currently `kompose` works only with the hard-coded Unix socket endpoint, which makes it difficult to use with macOS and other non-Linux environments.

*What:*

Detect if the `DOCKER_HOST` is set and create a docker client from the environment variables DOCKER_HOST, DOCKER_TLS_VERIFY, and DOCKER_CERT_PATH..
 @rathko, thank you for the pull request! We'll ping some people to review your PR. @cdrage and @surajnarwade, please review this..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Hey @rathko 

Thanks for the contribution!

A few things:

- Gotta sign the CLA (pain in the ass I know)

- Do you mind re-basing? I *just* enabled cluster building for Kubernetes hence the reason why SemaphoreCI just failed

- Tests fail, mind doing a `gofmt` on the code? Gotta fix some of that indentation..
 @cdrage Thanks, it's rebased, `gofmt`ed and CLA is signed. Cheers.
 SemaphoreCI is being funky, but tests pass and code LGTM :+1: .
 @rathko , Thanks for contribution :) 
LGTM for code :+1: .
 "
,,745,"Improve chart support / Helm testing.
 We should improve chart / helm support, check that it works as well as add it to an end-to-end test..
 Can kompose convert docker compose to a chart ?
@cdrage .
 @xianlubird Yup, using the option `-c` when using convert. Unfortunately I believe it's broken right now..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 "
,,744,"When specifying a wrong parameter, --help is not complete.
 For example:
```
▶ kompose convert --daemonset
Error: unknown flag: --daemonset
Usage:
  kompose convert [file] [flags]

Flags:
      --build string   Set the type of build (""local""|""build-config"" (OpenShift only)|""none"") (default ""none"")
      --emptyvols      Use Empty Volumes. Do not generate PVCs
  -h, --help           help for convert
  -j, --json           Generate resource files into JSON format
  -o, --out string     Specify a file name to save objects to
      --replicas int   Specify the number of repliaces in the generate resource spec (default 1)
      --stdout         Print converted objects to stdout

Global Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output

unknown flag: --daemonset
```

Does not show the Kubernetes or OpenShift flags:
```
github.com/kubernetes/kompose  add-healthcheck ✔                                                                                                                                                                                                                            1d  ⍉
▶ ./kompose convert --help     
Usage:
  kompose convert [file] [flags]

Kubernetes Flags:
      --daemon-set               Generate a Kubernetes daemonset object
  -d, --deployment               Generate a Kubernetes deployment object
  -c, --chart                    Create a Helm chart for converted objects
      --replication-controller   Generate a Kubernetes replication controller object

OpenShift Flags:
      --build-branch             Specify repository branch to use for buildconfig (default is current branch name)
      --build-repo               Specify source repository for buildconfig (default is current branch's remote url
      --deployment-config        Generate an OpenShift deployment config object
      --insecure-repository      Specify to use insecure docker repository while generating Openshift image stream object

Flags:
      --build string   Set the type of build (""local""|""build-config"" (OpenShift only)|""none"") (default ""none"")
      --emptyvols      Use Empty Volumes. Do not generate PVCs
  -h, --help           help for convert
  -j, --json           Generate resource files into JSON format
  -o, --out string     Specify a file name to save objects to
      --replicas int   Specify the number of repliaces in the generate resource spec (default 1)
      --stdout         Print converted objects to stdout

Global Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```
.
 Opened up issue upstream: https://github.com/spf13/cobra/issues/512.
 "
,,743,"Add Goreport badge.
 .
 @asifdxtreme , LGTM :+1: , it will be awesome if you send corrections for goreport resullts.
 @cdrage Thanks for the review, I have updated the changes as per the suggestion.
 @surajnarwade Thanks for the suggestion, I will send the correction for goreport in later PR's..
 @cdrage the PR is updated as per your suggestions, can you please help me to merge this PR.
 @cdrage Thanks for the suggestion, I have done the changes as requested.
 I appreciated it! thanks man..
 "
,,742,"Add author to Kompose UI.
 .
 @JadCham, thank you for the pull request! We'll ping some people to review your PR. @cdrage, please review this..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 @JadCham , please sign CLA and update PR.
 LGTM! :+1: Thanks @JadCham .
 "
,,741,"Update installation instructions.
 Updates the install instructions on the README and installation.md guide.
 LGTM :).
 "
,,740,"Update integrations links.
 Jekyll doesn't support automatically linking, so we have to manually add
the links here..
 "
,,739," Added support for `group_add` key.
 .
 @surajnarwade, thank you for the pull request! We'll ping some people to review your PR. @surajssd and @containscafeine, please review this..
 I have updated PR with suggested changes, @cdrage @surajssd needs review on it.
 Please add a description to your commit as well as update this original PR description..
 @cdrage updated with suggested changes.
 Awesome! This is great. Changes are good. Thanks @surajnarwade for the hard work..
 "
,,738,"Add CPU limit, CPU Reservation and Memory Reservation.
 This adds support for CPU limit, CPU reservation as well as memory
reservation.

Specifically, when using the `deploy` key in Docker Compose..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @kadel, please review this..
 LGTM.
 "
,,737,"Adds integrations doc.
 Adds integrations doc to website.
 #736 must be merged in first.
 "
,,736,"Add integration doc.
 Adds an integration document that lists third-party organizations /
users that use Kompose in some-way or another..
 "
,,735,"Add Windows instructions to installation.md.
 LGTM :+1: 
.
 "
,,734,"add option --hostpaths.
 add option --hostpaths, #109 .
 Hey @xiaoping378 we're having the discussion here: https://github.com/kubernetes/kompose/issues/109 but we will go ahead and refactor --emptyvols to use --volumes :+1: when we do that you can update the above code to use the new parameter..
 @xiaoping378 , can you please rebase your PR.
 Hey @xiaoping378 to comment on what @surajnarwade said, we added the CLI parameter --volumes. You will have to update your PR in order to add hostPath to `--volumes`..
 Any update?
.
 sorry, has no time to do this now..
 any updates.
 "
,,733,"Added `saving command` to annotation feature.
 This will save kompose command and version to annoatations, which were used to generate artifacts.
Fixes #639.
 @surajnarwade, thank you for the pull request! We'll ping some people to review your PR. @procrypt and @cdrage, please review this..
 Couple of files have been added by accident and need to be deleted:
```
build/a
*.coverprofile
```.
 Can you please also separate the commits so we can review this easier (one for code change, other for test changes).
 Let's wait until @kadel get's back for him to review this. But other than uncommenting those tests / separating them, LGTM. .
 @kadel , needs your review here.
 @surajnarwade also add `fixes ` to your first comment in this PR, so that the issue tracking this PR will be closed as soon as this is merged.
 @surajssd @cdrage , ready to merge :).
 @surajnarwade this one https://github.com/kubernetes/kompose/pull/733#issuecomment-320967817.
 DO NOT MERGE YET.

@surajnarwade Please update the commit message with a description of what has been implemented, including an example.

It is still blank..
 @cdrage updated commit message.
 Thank you @surajnarwade ! Mergin :).
 "
,,732,"Add documentation on Kompose integrations.
 Kompose has been integrated into Fabric8 (see: https://github.com/fabric8io/fabric8-maven-plugin/pull/988) we should effectively document cases where Kompose has been used in other integrations. Whether it's a GUI site or plugin..
 Same applies for integration with DevSuite installer. https://developers.redhat.com/products/devsuite/overview/.
 Are we expecting new doc or add it under particular section in existing doc e.g. user guide?.
 @hrishin , maybe under `Introduction` section itself.
 @surajnarwade @hrishin I'd say separate. Such as ""third-party"". Adding to Introduction may clutter a few things..
 Hey @hrishin do you know where I can find documentation on the Kompose maven plugin? I was unable to find anything on Google or a quick search @ Red Hat..
 Hey @cdrage 
Here you go for f8mp and kompose integration documentation https://maven.fabric8.io and look for following sections having `Docker Compose` keywords.

1.  Introduction
2. [Configuration](https://maven.fabric8.io/#configuration)
3. [Docker Compose](https://maven.fabric8.io/#docker-compose)

Please let me know if its sufficient..
 Perhaps https://www.katacoda.com/courses/kubernetes/deploy-docker-compose-using-kompose this can be added as well..
 @pradeepto Personally, I wouldn't like https://www.katacoda.com/courses/kubernetes/deploy-docker-compose-using-kompose added as it forces users to sign-up and give away their information in order to use the tutorial. If there's an alternative site, that would be better..
 Hi @cdrage,
How should be the documentation for Kompose Fabric8-maven Plugin Integration ?
Just add the links in integration or we should create a explicit document for it..
 ![sample](https://user-images.githubusercontent.com/19270240/31124367-c91419f2-a861-11e7-8773-e4fbee1aca2f.png)
@cdrage @surajnarwade Right Now, i have done this. Is this fine ?.
 @piyush1594 ideally create an elaborate example where you can clearly use Kompose. Further increasing the size of integration.md document.

Can you link me those examples?

We may need a better description too for the Fabric8 Maven plugin.

Instead of a screenshot, it would be better to open up a PR for this..
 Hi @cdrage,

Submitted the PR. Lets discuss the exact changes required for plugin documentation..
 since #836 is merged, we can close this issue.
 "
,,731,"Adds Kubernetes cluster tests.
 This adds cluster tests for ""kompose up"" and ""kompose down"" for
Kubernetes. At the moment this checks that they are deployable to a
single-node Kubernetes cluster.

More proficient tests such as testing if the pods are actually up will
be added in the future.

You can test this by running: `make test-ci` on your local-machine.

Furthermore, we'll eventually have this enabled on Fabric8 / CentOS CI /
Semaphore (whatever comes first) so we can have a full end-to-end
testing environment..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @kadel and @ashetty1, please review this..
 @surajnarwade @surajssd @ashetty1 @kadel 

Please review.
 @cdrage when I run examples/docker-gitlab.yaml, it throws up volume mount related warnings; the pods are not brought up successfully. How about we add --emptyvols  for `kompose up` command?

Also, you aren't checking if the pods are actually running post `kompose up`. Is that how you want it to be? .
 @ashetty1 That kind of sucks that our current gitlab example doesn't work... I don't like how we have to pass in `--emptyvols`.. I think we should update our examples.

Yup, we are currently not checking if each pod are actually running post `kompose up`. I'll be adding that implementaiton later. Right now, it's getting `make test-ci` into Semaphore / some sort of CI.

Can you LGTM? .
 "
,,730,"Add support for cpus (Version 3 Resources Key).
 Now that Docker Compose Version 3 has been released, we're able to map `limits` and `reservations` regarding CPU to Kubernetes.

See: https://docs.docker.com/compose/compose-file/#resources

In particular:

```yaml
version: '3'
services:
  redis:
    image: redis:alpine
    deploy:
      resources:
        limits:
          cpus: '0.001'
          memory: 50M
        reservations:
          cpus: '0.0001'
          memory: 20M
```

Which will map directly to Kubernetes: https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-ram-container/.
 This has been merged in via https://github.com/kubernetes/kompose/pull/738.
 "
,,729,"Add gitlawr to mention bot blacklist.
 Let's try to keep it to active contributors / maintainers so people
aren't needlessly pinged :).
 "
,,728,"Updates the conversion document to reflect changes.
 This updates the conversion document to outline that we do not support
minor versions since libcompose does not support 2.1 or 2.2 as well as
constant changes to docker/cli stack code regarding 3.1 and above.

I also update the conversion document to better reflect our support on
version 3 as well as update current values..
 "
,,727,"Add tests for deploy key specifically.
 Due to:
https://github.com/kubernetes/kompose/commit/9dcb2bfba6639c045022d732d49867689ebb1de9
tests for ""replicas"" was disabled due to generating ""pod-only""
kubernetes artifacts as per ""restart_policy"" being added.

This PR adds ""deploy"" tests so we can effectively test `replicas`.
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @procrypt and @surajnarwade, please review this..
 I'm going to wait until #738 is merged in before merging this one in since this will create a conflict..
 #738 is merged in. Let's wait for these tests to pass and then merge this in..
 "
,,726,"Adding compatibility matrix for different Kubernetes versions.
 Add something similar to: https://github.com/kubernetes-incubator/client-python where we have the compatibility matrix on different versions of Kubernetes and/or OpenShift..
 PR here: #767 .
 Going to post-pone this for now. We will have to essentially investigate and figure out the MINIMUM version that Kompose supports for conversion. Have a table that represents what version you need of Kubernetes to use the Kompose feature (for example, DaemonSet generation)..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/726#issuecomment-429061322):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,725,"Deprecate Docker Compose Version 2.1, 2.2, and 3.3. Only support 1,2,3,4 (future)..
 See:
https://docs.docker.com/compose/compose-file/compose-versioning/#versioning

I propose that we deprecate any minor versions and only support major versions. 

Problem case is that version 2.1 and 2.2 isn't support by https://github.com/docker/libcompose and we would have to contribute up-stream.

Docker is pushing for Version 3 and is supported by their http://github.com/docker/cli tool, however, 3.1, 3.2 and 3.3 are moving too quick (3.1 and 3.2 aren't even mentioned on https://docs.docker.com/compose/compose-file/compose-versioning/#version-3 anymore).

I suggest we only support major versions (1,2,3) and eventually 4 (in the farrrr future)..
 ping @kadel @surajnarwade @surajssd @containscafeine for discussion..
 I think we don't support any minor version in kompose as of now, 
but +1 for deprecating minor versions in future..
 I have updated http://kompose.io/conversion/ to outline that we only support major versions.

Can we close this?

@kadel @surajnarwade @surajssd @containscafeine .
 yeah, we can close this.
 Sorry to resurrect a closed issue but what syntax for 2/3 is supported? There's quite a bit of difference between 2, 2.1, 2.4, etc. I have a 2.4 compose with healthcheck for example, how do I map that?.
 @mterron We support all versions now. If you have troubles, you can always upgrade to version 3 and deploy that. Healthcheck works on there! http://kompose.io/conversion/.
 "
,,724,"Update release script with properly formatted table.
 Updates the script to properly format the table (had a bit of a
shortcoming doing that) as well as remove the leftover file
install_guide.txt as it's generated for release notes..
 "
,,723,"1.0.0 Release.
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @surajnarwade and @kadel, please review this..
 "
,,722,"Update the release script.
 Updates the release script with SHA256 sums, installation guide as well
as a switch to kubernetes from kubernetes-incubator..
 "
,,721,"Error running kompose on counter v3 example file.
 When running ```kompose convert``` on the newly added `docker-compose-counter-v3.yaml` example file, I got the following error.

```
$ kompose -f docker-compose-counter-v3.yaml convert
ERRO Could not parse config for project examples : yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService
FATA composeObject.Parse() failed, Failed to load compose file: yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService
```
.
 @lucj which version of kompose are you using? did you build from master? .
 @lucj , @JadCham , I think you are using it with version `0.7`,  I have added this example with kompose( built using master)..
 @surajnarwade you'r right, I'm using 0.7.0 (c25b7e8).
 @lucj 1.0.0 is coming out today, so you'll be able to download the latest binary and have it work against `docker-compose-counter-v3.yaml`..
 👍 
In the same time I've built from source and have it working on my compose file version 3.

BTW, on a custom docker-compose, it generates only Pod and PersistentVolumeClaim but no Deployment nor Services. Is there a special key so a Deployment is created (default number of replicas ?).

.
 @lucj It *should* be creating deployments and services. Is your docker-compose file open  for us to test it out?.
 No problem, here is an extract of the compose file I'm using. I'm sure I'm missing something, still very new to k8s though.

```
version: '3'
services:
  api:
    image: lucj/api:develop
    deploy:
      restart_policy:
        condition: on-failure

  authn:
    image: 'lucj/authn:develop'
    deploy:
      restart_policy:
        condition: on-failure

  db:
    image: 'mongo:3.4'
    volumes:
      - mongo-data:/data/db
    deploy:
      restart_policy:
        condition: on-failure

  kv:
    image: 'redis:3.0.7-alpine'
    volumes:
      - redis-data:/data
    deploy:
      restart_policy:
        condition: on-failure

  mq:
    image: 'rabbitmq:3.6'
    volumes:
      - rabbit-data:/var/lib/rabbitmq
    deploy:
      restart_policy:
        condition: on-failure

  proxy:
    image: 'lucj/proxy:develop'
    ports:
      - '8000:8000'
      - '8002:8002'
    deploy:
      restart_policy:
        condition: on-failure

  web:
    image: 'lucj/web:develop'
    deploy:
      restart_policy:
        condition: on-failure

  wss:
    image: 'lucj/wss:develop'
    deploy:
      restart_policy:
        condition: on-failure

volumes:
  mongo-data:
  redis-data:
  rabbit-data:
```.
 @lucj `restart_policy:` is the reason why.. See http://kompose.io/user-guide/#restart

We need to document this better / output to log as the pods are created manually. 

Same goes with `volumes`, we don't support any top-level volume keys (yet)..
 Thanks a lot, that make sense.
No pb for the top volume key, I do not really need them for testing :).
 @lucj , can we close this issue now ?.
 @surajnarwade Yes, no problem. Thanks for your help..
 "
,,720,"Adds clarification on commands.
 Re-adds '$' to commands.
 "
,,719,"Change imports  for kompose packages to 'k8s.io/kompose"".
 To reflect move to Kubernetes  org we should use `k8s.io/kompose` instead of `github.com/kubernetes-incubator/kompose`.
 ah, I was looking to some old version, now I can see that we are already using `github.com/kubernetes/kompose`.
 @kadel Should we close?.
 "
,,718,"Distinguish / re-add ` $` to docs.
 As per #692 @surajssd 's comments, let's re-add `$` whenever we show a command whether in the README, docs or website..
 Fixed in https://github.com/kubernetes/kompose/pull/720.
 "
,,717,"adding timestamp in k8s artifacts.
 I was validating results from kompose using [kubeval](https://github.com/garethr/kubeval), I got following output: 

```
$ kubeval frontend-deployment.yaml 
The document frontend-deployment.yaml contains an invalid Deployment
--> spec.template.metadata.creationTimestamp: Invalid type. Expected: string, given: null
--> metadata.creationTimestamp: Invalid type. Expected: string, given: null
```

Should we add timestamp in spec ?
any thoughts, @kadel @surajssd @cdrage .
 I don't think it should be set, and null should be valid for `createationTimestamp`

It looks like bug in `kubeval`

If you look at the [reference documentatoin](https://kubernetes.io/docs/api-reference/v1.7/#objectmeta-v1-meta) it says
""**CreationTimestamp is a timestamp representing the server time when this object was created**. It is not guaranteed to be set in happens-before order across separate operations. Clients may not set this value. It is represented in RFC3339 form and is in UTC. **Populated by the system.** ""



.
 @kadel , gotcha, thanks for clarifying.
 @surajnarwade do you mind reporting it in `kubeval` ?.
 Hey, author of `kubeval` here.

According to the Kubernetes spec (https://github.com/garethr/kubernetes-json-schema/blob/master/master-standalone/deployment.json#L3511-L3514) the error is correct. Unfortunately Kubernetes doesn't exactly use this spec internally, so `kubeval` is finding upstream bugs in how the types are output to JSON Schema in the OpenAPI spec in a few places.

I've opened https://github.com/garethr/kubeval/issues/16 to track.

@surajnarwade note that kubeval will shortly be available as a Go library as well, so it might be interesting to build the validation in as an optional step into Kompose?.
 @garethr that will be awesome.
 @garethr thanks, having a golang binary will help both kompose and [kedge](https://github.com/kedgeproject/kedge/) !

cc: @containscafeine @kadel .
 Usage as a go library is now in master with a little documentation. https://github.com/garethr/kubeval#library

I'd love any feedback on that interface, or other things folks would like to see..
 @surajnarwade just to let you know I've updated the schemas and the service definition should now work as expected. All the details in https://github.com/garethr/kubeval/issues/16 for anyone following along..
 @garethr awesome, It's working as expected, Thanks :).
 "
,,716,"Update doc script.
 Redirection works for http://kompose.io/docs/conversion/ but not for
http://kompose.io/docs/conversion.md which is what I originally
intended.

This PR updates the script to redirect all `.md` doc links..
 LGTM :).
 "
,,715,"Ignore pinging dusty on PR's.
 Adds Dusty to the user blacklist so he doesn't get pinged..
 "
,,714,"Moving version from variable to text file.
 Resolves #712 , As it is needed for fabric8-maven-plugin.
 @surajnarwade, thank you for the pull request! We'll ping some people to review your PR. @cdrage and @kadel, please review this..
 cc: @surajssd for review.
 @surajnarwade 

I really don't like this and this over-complicates things. 

What happens if someone's developing in a different path?

What happens if someone doesn't have the source code?

What if GOPATH isn't set (they're just using Kompose on a production machine?)


You're also not checking to see if this errors out:

```
version, _ := ioutil.ReadFile(path)
```


Let's not modify version.go and only add VERSION to `/build`, we can modify the `release.sh` script to make the variable substitution of `build/VERSION`. But let's keep `version.go` as it is since this PR over-complicates gathering the version information when it could simply be a const variable..
 @cdrage got it, made changes accordingly.
 LGTM.
 "
,,713,"error with autogenerated cluster name.
 ![image](https://user-images.githubusercontent.com/15216503/28242224-b0a035a4-69c3-11e7-840d-1ef6b1bd2501.png)
![image](https://user-images.githubusercontent.com/15216503/28242227-c7700ae8-69c3-11e7-93df-6dc5b34b3aa1.png)

.
 @nikhilrayaprolu , can you paste your docker-compose file here ?.
 @nikhilrayaprolu your env name is wrong, you cannot define env that has `.` dot in it. You can only have capital and small characters, dashes and underscores and numbers.

Also see the regex in the error:

```
a valid C identifier must start with alphabetic character or '_', followed by a string
of alphanumeric characters or '_' (e.g. 'my_name',  or 'MY_NAME',  or 'MyName',
regex used for validation is '[A-Za-z_][A-Za-z0-9_]*')
```

So change the name of env `cluster.name` to something else, similarly for all other envs.

I don't think kompose can do anything with this other than adding checks on our side. This comes from kubernetes..
 @nikhilrayaprolu , is your problem resolved, can we close this issue ?.
 @surajnarwade @surajssd 
here is my docker-compose.yml
```

version: '2'
services:
  yacy_mcp:
    build: .
    links:
      - elasticsearch
    ports:
      - 8100:8100

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.5.0
    container_name: elasticsearch
    environment:
      - cluster.name=yacygrid
      - bootstrap.memory_lock=true
      - ""ES_JAVA_OPTS=-Xms512m -Xmx512m""
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    mem_limit: 1g
    volumes:
      - esdata1:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    expose:
      - ""9300""
      - ""9200""

    
volumes:
  esdata1:
    driver: local

```.
 that is standard syntax by elastic regarding env variables
https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html.
 @nikhilrayaprolu you can get some inspiration from elastic [example in k8s repo](https://github.com/kubernetes/kubernetes/blob/master/examples/elasticsearch/es-rc.yaml) or [helm chart for elastic](https://github.com/kubernetes/charts/tree/master/incubator/elasticsearch).

Also issue is [filed with elastic upstream](https://github.com/elastic/elasticsearch-docker/issues/33) and [PR](https://github.com/elastic/elasticsearch-docker/pull/88) to improve their docker-images to enable it to run on k8s..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,712,"Kompose  latest release version info from version file.
 For fabrica8 maven plugin integration, we need a file which can give latest release version from Http URL.

Now this can be done by consuming github release API  but it will overkill the simplicity.
For the sake of consistency and aligning existing implementations we need the version file under kompose repository.
e.g. gofabric8 https://github.com/fabric8io/gofabric8/blob/master/version/VERSION

It would e great if kompose project can provide similar version file.
 @hrishin fine by me! should we stick this in the `/build` directory? what do you think?.
 @cdrage sure, looks good :)
Thanks @cdrage  @surajnarwade .
 @hrishin Feel free to push a PR if you wish!.
 @cdrage @hrishin , I already got some inspiration for this from fabric8, /me taking this..
 "
,,711,"Make mention bot less aggresive.
 2 or less reviewers as well as up to 5 max files searched..
 "
,,710,"Updated code with go lint result.
 Updated code with suggestion given by `go lint`.
 @surajnarwade, thank you for the pull request! We'll ping some people to review your PR. @cdrage, @procrypt and @gitlawr, please review this..
 LGTM.
 /lgtm.
 "
,,709,"fix some typos to make goreport happy.
 .
 @fate-grand-order, thank you for the pull request! We'll ping some people to review your PR. @kadel, @dustymabe and @procrypt, please review this..
 thanks for the PR @fate-grand-order, changes LGTM :).
 @fate-grand-order LGTM!.
 "
,,708,"Conversion Reference -> Conversion Matrix.
 Initialize a documentation build (running the script on travis) as well
as change from Conversion Reference to Conversion Matrix..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @gitlawr, please review this..
 Need to initiate a doc build (travis only) in order to effectively build this since incorporating recent changes, see: https://github.com/kubernetes/kompose/commits/gh-pages.
 "
,,707,"Added docker compose v3 example for counter.
 .
 @cdrage review needed :)
.
 @cdrage updated with replica, I need this example for blog thing :).
 LGTM.
 "
,,706,"Added Fedora 26.
 http://fedora.melbourneitmirror.net/fedora/linux/releases/26/Everything/x86_64/os/Packages/k/kompose-0.7.0-0.1.fc26.x86_64.rpm.
 @e-minguez, thank you for the pull request! We'll ping some people to review your PR. @cdrage, please review this..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Just signed the CLA.
 /lgtm.
 Thanks!.
 "
,,705,"Update _config with new repo.
 Updates the _config with the kubernetes repo instead of
kubernetes-incubator..
 /lgtm.
 "
,,704,"kubernetes-incubator -> kubernetes.
 Today, we graduate from the incubator, thus all links are updates from
kubernetes-incubator to kubernetes.
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @kadel, @surajssd and @rtnpro, please review this..
 "
,,703,"Refactoring code as per gosimple check.
 This PR refactors some code bits as per `gosimple` tool check..
 @surajnarwade, thank you for the pull request! We'll ping some people to review your PR. @containscafeine, @gitlawr and @surajssd, please review this..
 LGTM!.
 "
,,702,"remove unused parameter from ValidateComposeFile().
 In pkg/app/app.go, the function ValidateComposeFile() has an
unused parameter ""cmd *cobra.Command"".

This commit removes that parameter from the function and the
callers of the function..
 @containscafeine, thank you for the pull request! We'll ping some people to review your PR. @procrypt, @cdrage and @surajssd, please review this..
 LGTM.
 LGTM.
 "
,,701,"Update mention bot configuration to avoid mentioning people twice.
 This updates the config to avoid mentioning people twice as well as
assinging people appropriately..
 "
,,700,"Update mention bot config.
 Removes some of the values which are already set to their default values
on mention bot..
 Unable to parse mention-bot custom configuration file due to a syntax error.
Please check the potential root causes below:

1. Having comments
2. Invalid JSON type
3. Having extra "","" in the last JSON attribute

Error message:
```
Error: Parse error on line 2:
... ""maxReviewers"": 3, // 3 is enough  ""nu
-----------------------^
Expecting 'STRING', got 'undefined'
```.
 Going to merge this to fix the bot (wasn't correctly finding reviews due to it being labeled by the CLA bot before declared ""open"").
 "
,,699,"[dont close] Test mention bot functionality.
 Testing mention bot, please ignore..
 @cdrage, thank you for the pull request! We'll ping some people to review your PR. @kadel and @surajnarwade, please review this..
 Perfect! it works. Closing..
 "
,,698,"Add StatefulSet.
 We've gone DaemonSet, let's add StatefulSet now.

https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 It is really useful.

May I know what is the status now?.
 "
,,697,"Fixed minor issue in kubernetes_test.go.
 Fixed identical expression in kubernetes_test.go.
 "
,,696,"remove dependency on docker daemon for building container images.
 As a part of removing the dependency on docker and docker daemon, I propose we use buildah for building OCI compliant images.
And as a part of this work we will also need a mechanism that helps to push the images so we can use skopeo for that.

This will make sure we can build image anywhere regardless of the docker daemon, we don't need to exec since exec is bad. We can package all this in one single binary.

Project Buildah: https://github.com/projectatomic/buildah
Skopeo project: https://github.com/projectatomic/skopeo

.
 @surajssd Once they both exit alpha / work-in-progress it will make sense to add. 

Doesn't make sense to add this to the binary however... If you're using Kompose it's assumed you have Docker installed considering you're converting. The use case as well for building / pushing too is for those whom use Docker within Kubernetes deployments. So makes sense to use a stable API (the Docker API) for builds and pushes..
 Actually, Kompose never required Docker to be installed before it had the build story. Integrating with `buildah` is important because it builds OCI compliant images and this integration is definitely important to have.

Having said that, I agree that `buildah` is alpha but it is feature complete. It is very important and good to start thinking about integrating it because being an early adopter helps us with influencing the project if need be. I don't think we should remove Docker dependency though. We should implement `buildah` as a limited support..
 I don't know about this. Kompose is a converter for **docker compose** files. Expectation is that you are using dokcer-compose  alongside with Kompose. I don't know if it is make sense to use smething else for building container than docker..
 Good point, but then docker compose is for docker, we use Kompose to move to Kubernetes.

This doesn't need to be a priority issue but if images built using `buildah` can run on Kubernetes, we should support that..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 "
,,695,"Add mention bot.
 In order to deploy https://github.com/facebook/mention-bot it's good to
have a .mention-bot file in the root directory.

This PR adds that said file as well as creates a user blacklist so
maintainer alumni aren't needlessly pinged..
 "
,,694,"Fix redirection site issues.
 Fixes the issues in regards to rediction.

For example, supplying `/docs/conversion` within the user guide the link
will appear as a 404.

Adding this allows redirection from `/docs/conversion` to `/conversion`..
 Doing a lazy merge as I'm doing some site changes / updates..
 "
,,693,"Adds redirection plugin for website.
 Fixes redirection issues when adding links such as `/docs/` to the
documentation.
 "
,,692,"Update quickstart.
 Remove ▶ from CLI commands as well as remove .dab reference..
 Doing a lazy merge (no reviews) in order to incorporate site changes..
 Why remove the `▶` or `$` this helps distinguish between the command and it's output?

If you have multiple commands which are shown without any output, there it makes sense to not have `$` because the user can copy the block and paste it in terminal.

But when we are showing output i think we should have command starting with `$` ..
 @surajssd After discussion, I'm going to re-add the `$`. You're right. It's confusing and I don't like it either :-1: after viewing it almost-daily when modifying the docs and all..
 "
,,691,"Docker build in kompose convert.
 `kompose convert` provides nice utility for converting docker-compose resources to kubenetes resources. However while leveraging on it if compose file has `build:` tag, so converting those resources to kubernates resources wont help much in our case as another system expects docker image do exists in respective registry prior bringing kubenetes deployment up and running.
It would be great if we can add optional flag in `kompose convert -b`so on presence of it `kompose ` can build docker images, push it to respective registry and the execute conversation process as a whole.

As of now I can see this functionality is available in `kompose up` command but we don't want to spin up the pods/containers.
.
 @hrishin , try this `kompose convert --build=local`, I forgot to mention it earlier, sorry about that.
 Hi @hrishin !

Feel free to view the discussion here: https://github.com/kubernetes-incubator/kompose/pull/521 on why build/push wasn't added to convert :+1: .
 @cdrage , but I can see `--build` flag as well when I do `kompose convert -h`.
 @surajnarwade Woops, let me clarify, As to why build/push wasn't enabled by default when added to convert :+1: .
 @cdrage  @surajnarwade 
Thanks!

So are we going to release this feature in next release?.
 @hrishin Yup! We *just* graduated (hence why we're in Kubernetes land now) and haven't made the announcement yet, but we will be coinciding the graduation blog post with a 1.0.0 release!.
 @cdrage @hrishin i think we can close this issue.
 @surajnarwade Once 1.0.0 is out the issue is solved and we can close this..
 @hrishin can you verify with the latest release that your issue is solved?.
 Yes its resolved now, thanks! :+1: .
 "
,,690,"Change menu to left side.
 This commit changes the menu to the left side rather than on top,
syncing with cdrage/minimal branch / style..
 Mergin' after my screwups with the gh-pages branch..
 "
,,689,"Conversion -> Conversion Matrix.
 "
,,688,"Merge pull request #686 from cdrage/add-dev-doc.
 Adds development doc + conversion -> conversion matrix.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 "
,,687,"Update menu.yml with installation.
 Merge after: https://github.com/kubernetes-incubator/kompose/pull/685.
 "
,,686,"Adds development doc + conversion -> conversion matrix.
 Makes development doc available on the site and change name of the
conversion menu name..
 "
,,685,"Setup -> Installation + title updates.
 Updates the docs to reflect that it's not a ""setup"" documention but
rather an installation document.

I've also updated the header of architecture.md to reflect the filename..
 LGTM :+1: .
 "
,,684,"Change menu to left side.
 This commit changes the menu to the left side rather than on top,
syncing with cdrage/minimal branch / style..
 This syncs to the changes I made upstream at https://github.com/cdrage/minimal

It will now look like this:

![image](http://i.imgur.com/lTCkvMV.png).
 this looks cool, LGTM :+1: .
 "
,,683,"One Script to Run Them All.
 Running each individual K8s YAML file is dramatic change for anyone who is used to Docker Swarm, who tends to only run a single 'docker-compose.yaml' file for deployment. 

It'd be nice for kompose to produce a single, executable script that runs all the K8s YAML files it produced. This thus improves the workflow of a former Docker Swarm user in addition to easing their transition to Kubernetes.

There could be an option to opt in or opt out of this feature.

If not, then it'd be nice if all the produced K8s YAML file are organized into a single folder..
 @phatlast96  When you convert you can use kompose convert -o output.yaml and the output will be aggregated in one single file. I think this is very close to docker-compose..
 What @JadCham said :)

If you do `-o` everything should work correctly in one file..
 Thanks! I did not know that!.
 "
,,682,"Remove empty if branch.
 .
 @surajnarwade LGTM after you add a descriptive message for both the PR and commit..
 @cdrage updated commit message.
 "
,,681,"Remove meeting from README + update.
 We talk enough in the Slack channel and find that impromptu meetings to
be more efficient :+1: rather than a monthly meeting..
 "
,,680,"Updated user-guide.
 Fixes issue #678. As we no longer supports setting provider by environment
variable, this PR will remove documentation for the same..
 @cdrage review please :).
 "
,,679,"ci test pr do not merge.
 do not merge.
 "
,,678,"setting environment variable PROVIDER no longer works.
 Kompose user guide states as:

```
... By setting environment variable PROVIDER you can permanently switch to OpenShift provider without need to always specify --provider openshift option. 
```

but it doesn't work.

```
$ export PROVIDER=openshift
$ echo $PROVIDER
openshift
$ kompose convert 
INFO Kubernetes file ""frontend-service.yaml"" created 
INFO Kubernetes file ""redis-master-service.yaml"" created 
INFO Kubernetes file ""redis-slave-service.yaml"" created 
INFO Kubernetes file ""frontend-deployment.yaml"" created 
INFO Kubernetes file ""redis-master-deployment.yaml"" created 
INFO Kubernetes file ""redis-slave-deployment.yaml"" created 
```.
 Should we even support this?.
 @cdrage probably not, but we should remove it from user-guide as well..
 "
,,677,"2016 -> 2017 for licensing.
 New year, update to the license..
 ping @pradeepto (legal?) @surajssd @surajnarwade for a quick review :) .
 LGTM :+1: .
 "
,,676,"Add OpenShift specific examples for conversion.
 Let's add some OpenShift-specific examples to the `/examples` folder as many of the example files use root-user images (ex. official docker hub nginx image, apache2, etc.).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale
.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/676#issuecomment-427615549):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,675,"Clean up and add current example files to integration tests..
 Two things:

- Test each example to see if they work and convert correctly
- Add integration tests for each one, test against a real Kubernetes cluster.
 I am taking this up.
 As of now, I have tested each  example from our example directory and all are working on minikube..
 @surajnarwade 

It would be nice to eventually have this in our integration tests too..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/675#issuecomment-427606779):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,674,"Fixes kompose.service.type label issue.
 Minor Fix, resolves #673.
 @cdrage @surajssd review needed.
 LGTM.

I actually encountered this issue before a demo yesterday. I think this is high-priority since our main examples use it (see http://kompose.io). :-1: 

Any way to add tests too so this does not happen again @surajnarwade ?
.
 @cdrage , tests are already there, i dont think we can add any more tests.
 "
,,673,"kompose.service.type issues.
 For some odd reason, our example no longer works:
```
version: ""2""                                                                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                                  
services:                                                                                                                                                                                                                                                                         
                                                                                                                                                                                                                                                                                  
  redis-master:                                                                                                                                                                                                                                                                   
    image: gcr.io/google_containers/redis:e2e                                                                                                                                                                                                                                     
    ports:                                                                                                                                                                                                                                                                        
      - ""6379""                                                                                                                                                                                                                                                                    
                                                                                                                                                                                                                                                                                  
  redis-slave:                                                                                                                                                                                                                                                                    
    image: gcr.io/google_samples/gb-redisslave:v1                                                                                                                                                                                                                                 
    ports:                                                                                                                                                                                                                                                                        
      - ""6379""                                                                                                                                                                                                                                                                    
    environment:                                                                                                                                                                                                                                                                  
      - GET_HOSTS_FROM=dns                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                  
  frontend:                                                                                                                                                                                                                                                                       
    image: gcr.io/google-samples/gb-frontend:v4                                                                                                                                                                                                                                   
    ports:                                                                                                                                                                                                                                                                        
      - ""80:80""                                                                                                                                                                                                                                                                   
    environment:                                                                                                                                                                                                                                                                  
      - GET_HOSTS_FROM=dns                                                                                                                                                                                                                                                        
    labels:                                                                                                                                                                                                                                                                       
      kompose.service.type: LoadBalancer  
```

```
▶ kompose convert -v
DEBU Checking validation of provider %skubernetes 
DEBU 'docker-compose.yml' not found: stat docker-compose.yml: no such file or directory 
DEBU Docker Compose version: 2                    
DEBU Opening compose files: docker-compose.yaml   
DEBU [0/1] [frontend]: Adding                     
DEBU [0/1] [redis-master]: Adding                 
DEBU [0/3] [redis-slave]: Adding                  
DEBU [0/3] [default]: EventType: 32               
DEBU [0/3] [default]: EventType: 32               
DEBU [0/3] [default]: EventType: 32               
DEBU Default network found                        
FATA kompose.service.type can't be set if service doesn't expose any ports.: LoadBalancer defined in service frontend with no ports present. Issues may occur when bringing up artifacts. 
```.
 @kadel @surajnarwade @surajssd 

Should we release 0.7.1? This is a huge bug in regards to the main demo. At the moment, our main example does not work due to this issue. Patching PR #674 into a separate cherry-picked release..
 @cdrage yeah 
.
 @cdrage yeah :+1: .
 @kadel @surajnarwade @surajssd 

So I was double-checking everything, it seems that we __dont__ need to do a release as long as #674 is merged in.

When I was testing the binary, I was testing 0.7.0 as well as the latest master (had it in two different bin directories), hence the reason why I was getting this error half the time.

Funny enough, #674 was actually a separate bug..
 "
,,672,"Remove DAB from docs.
 Removes references to --bundle or DAB from the Kompose documentation..
 :+1 lgtm.
 :+1:   lgtm.
 "
,,671,"Add example integration tests.
 We should test our examples using integration tests ran on Travis / CentOS CI via this method: https://github.com/kubernetes/community/blob/master/contributors/devel/local-cluster/local.md (despite it being deprecated, it still works well)..
 Closing in favour of https://github.com/kubernetes/kompose/issues/675.
 "
,,670,"Add v3 example.
 Same example as docker-compose.yaml but with 3 in the version name.

Needed for 1.0.0 blog post!.
 This is really bad example :-(
We shouldn't use it at all.

In most clusters it doesn't work without hacking it :-( 
.
 Sorry, I'm completely wrong here. This one is OK .
 "
,,669,"Adding Jenkinsfile for PR pipeline on Fabric8CD infrastructure.
 Initial commit adding Jenkinsfile for pr pipeline on fabric8CD(http://jenkins.cd.k8s.fabric8.io/job/kubernetes-incubator/)

This PR includes a Jenkinsfile which just does `make test` for now which will run the tests on every PR and on merge with master.
It uses golang version 1.8.1

The below things are not covered which are there in .travis.yml:
1. It does not test with the Matrix of various versions of go lang.
2. It does not do the coverage 
3. It does not sync the docs.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.
- If you have done the above and are still having issues with the CLA being reported as unsigned, please email the CNCF helpdesk: helpdesk@rt.linuxfoundation.org

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 I have signed the CLA.
 @rupalibehera you commit is created with your redhat email. It looks like you don't have that email associated with you github account. You might have to add redhat email to your github account or use the same email that you are using on github for that commit..
 Thanks @kadel I just added my redhat email-id to github account, hopefully it works..
 CLA has been passed.

@rupalibehera Any way we could test this / authorize this / see what happens? Have you tested this against your Kompose fork?

Let us know!

This saves us having to merge this in, then merge something else, unmerge, etc just to get it test to see if it works.

Code LGTM!
.
 @cdrage , I have tested this against my kompose fork.
Here is the sample successful run : http://pastebin.test.redhat.com/497821
I can tag the experts to review this.
@rawlingsj it would be really great if you can review this PR once :).
 "
,,668,"Remove 'cdrage' username from example.
 Removes username in favour of a foobar username.
 "
,,667,"Change title to build and push images.
 Changes the header in the user-guide.md in regards to building and
pushing docker images.
 "
,,666,"added support for `restart-policy` keys in v3.
 Resolves `restart_policy` from issue #644.
 @cdrage , there was typo ( `on_failure` >> `on-failure`) in example due to which output was varying, can you please review now..
 @cdrage , `on_failure` case added, final review please and ready for merge :)
.
 @kadel @surajssd  needed one more +1 here :)
.
 @cdrage , removed `on_failure`, we are good to go.
 @surajnarwade thanks for helping me in terms of the confusion! this LGTM.
 @surajssd , needs +1 to get it merged.
 "
,,665,"Fix OpenShift tests for build and push.
 [Work in Progress]
This patch fixes the broken buildconfig functional tests and also will add more tests for the new build and push feature..
 @cdrage @surajnarwade review please .
 @surajssd  Can you do a quick review / look-over and then merge?.
 @ashetty1 , small change
change route from `xip.io` to `nip.io` 
otherwise, LGTM :+1: 
here, https://github.com/ashetty1/kompose/blob/de5cdfa6a219a70d51c5e0bfb698ef4fe1832a5d/script/test_in_openshift/lib.sh#L177.
 Ahhh, this is why the build is failing! See: https://github.com/kubernetes/kompose/issues/752

Please fix the small issue @ashetty1 and then we can merge this in :) thanks!.
 Thanks @ashetty1 ! Let's see if this new build passes :+1: .
 "
,,664,"Added support for `replicas` keys in v3.
 resolves #644 `replicas` key.
 if `replica` is not mentioned in  docker-compose file, it will look for `--replicas`.
 @cdrage @kadel @procrypt, needs review :).
 @cdrage review please as tests are added .
 @cdrage added changes as per your suggestions, please review :).
 @kadel @surajssd  needed one more +1 here :)
.
 "
,,663,"Update vendoring for Cobra CLI fix.
 Updates the vendoring in order to implement the fix for MarkDeprecated
output in the CLI

See: https://github.com/spf13/cobra/pull/466

Closes https://github.com/kubernetes-incubator/kompose/issues/652.
 Ping @surajnarwade @kadel @procrypt .
 LGTM.
 LGTM @cdrage :+1: .
 "
,,662,"Removing unused function taggedimage.
 .
 LGTM.
 @surajssd , one more lgtm needed :).
 cool LGTM.
 "
,,661,"Fix make test.
 Fixed #659.
 Closing in favour of #660 .
 "
,,660,"Fix vet issues with build/push code.
 This fixes the vet issues when running `make vet` due to unkeyed fields..
 Going to quickly merge this in since this is causing issues with those running local tests. Revert if this is incorrect!.
 "
,,659,"make test failing again.
 When I run `make test`, it's failing again
```bash
$ make test
go get github.com/mattn/goveralls
go get github.com/modocache/gover
go get github.com/Masterminds/glide
go get github.com/sgotti/glide-vc
go get github.com/golang/lint/golint
./script/check-vendor.sh
Checking for nested vendor dirs
OK
Checking if vendor was cleaned using glide-vc.
OK
./script/check-gofmt.sh
gofmt OK
go vet ./pkg/... ./cmd/... .
pkg/transformer/utils.go:216: github.com/kubernetes-incubator/kompose/pkg/utils/docker.Build composite literal uses unkeyed fields
pkg/transformer/utils.go:243: github.com/kubernetes-incubator/kompose/pkg/utils/docker.Push composite literal uses unkeyed fields
exit status 1
Makefile:75: recipe for target 'vet' failed
make: *** [vet] Error 1
```
.
 #660 fixes this :).
 Fixed!.
 "
,,658,"fix env substitution for docker compose v3.
 fixes #650 .
 @kadel awesome! Is it worth to include some tests for it, like the once from the issue maybe?.
 > @kadel awesome! Is it worth to include some tests for it, like the once from the issue maybe?

definitely, I'll add it :wink: .
 @kadel , works for me :).
 fixed as per comments.
 LGTM..
 @kadel does this also add replacements for ${FOO:-bar}? Haven't seen this in your tests.
Thanks again!.
 "
,,657,"Enable kompose to generate configs per docker-compose service.
 Right now we create configs of entire docker-compose file.

Consider the following docker-compose file with only one service:

```yaml
services:
  one:
  ...
```

Now a user is using this for sometime, but after sometime she adds one more service and docker-compose file looks like this:

```yaml
services:
  one:
  ...
  two:
  ...
```

Now what user wants is that only artifacts of service `two` to be created. How can we enable that to happen? I propose that we add a flag named `service` which creates config only for particular docker-compose service.

```bash
kompose convert --service two
kompose up --service two
```.
 I will take this up.
 @surajnarwade Please don't take this up yet, we need to discuss the scope of this functionality before any sort of implementation.

@surajssd This doesn't really make sense. If someone we're to add another service, it's as simple as adding the service to `docker-compose.yaml` converting, and then using `kubectl apply`, no? Kubernetes would automatically figure out what needs to be added and/or updated.
.
 @cdrage okay :).
 @cdrage yeah people can use `kubectl apply` but this was more on the lines of UX, not everyone knows about the `kubectl apply` recipe of using kompose, if we are not adding this feature please consider documenting it..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 "
,,656,"kompose build fails: unable to create tarball.
 kompose build fails: unable to create tarball

my kompose version
```
$ kompose version
0.7.0 (ee79612)
```

when doing local builds on repo https://github.com/pranavgore09/classico/tree/nodejs-service

```bash
✔ ~/git/classico [:9f03f9e|✚ 1] 
12:08 $ git branch 
* (HEAD detached at origin/nodejs-service)
  master
```

I have made changes to the docker-compose file to have my docker hub repo name, docker-compose file looks like this:

```yaml
✔ ~/git/classico [:9f03f9e|✚ 1] 
12:03 $ cat docker-compose.yaml 
version: '2'
services:
  backend:
    image: docker.io/surajd/backend
    build:
      context: ./backend
  gateway:
    image: docker.io/surajd/pranav/gateway
    build:
      context: ./gateway
    ports:
      - ""1111:1111""
  daily:
    image: docker.io/surajd/daily-backend
    build:
      context: ./daily-backend
```

running the kompose build command

```bash
✔ ~/git/classico [:9f03f9e|✚ 1] 
12:04 $ kompose up --provider openshift 
INFO Building image 'docker.io/surajd/backend' from directory 'backend' 
INFO Image 'docker.io/surajd/backend' from directory 'backend' built successfully 
INFO Pushing image 'surajd/backend:latest' to registry 'docker.io' 
INFO Multiple authentication credentials detected. Will try each configuration. 
INFO Attempting authentication credentials 'https://index.docker.io/v1/ 
INFO Successfully pushed image 'surajd/backend:latest' to registry 'docker.io' 
INFO Building image 'docker.io/surajd/daily-backend' from directory 'daily-backend' 
FATA Unable to build Docker container for service daily: Unable to create a tarball: archive/tar: write too long 
```

Since the build is big, so i cannot know what is happening in background whether it is stuck or going on..
 It looks like this problem is caused by symlinks in the build directory. They are not handled properly .
 @kadel just a note this works if we use buildconfigs to do builds.
 yes, That makes sense as buildconfig is not creating tar. 

The problem is with creating tar that gets sent to docker daemon, it doesn't handle symlinks properly.
 one of the possible solutions is described here https://stackoverflow.com/questions/38454850/getting-write-too-long-error-when-trying-to-create-tar-gz-file-from-file-and-d.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Hi guys I'm having the same issue as well. Here is my docker-compose.yml:

```
version: '2'

services:

    mongo:
        image: mongo:latest
        restart: always
        environment:
         - MONGO_INITDB_ROOT_USERNAME=user
         - MONGO_INITDB_ROOT_PASSWORD=password
        ports:
         - ""27017:27017""

    notifier:
        restart: always
        build:
          context: ./Notifier
        image: staterecordsnotifications_notifier
        volumes:
          - ./Notifier:/opt/app
        ports:
          - ""3001:3001""
        links:
          - mongo
```

and it returns 
INFO Build key detected. Attempting to build and push image 'staterecordsnotifications_notifier'
INFO Building image 'staterecordsnotifications_notifier' from directory 'Notifier'
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service notifier: Unable to create a tarball: archive/tar: write too long.
 I too am having the same issue. I do not have any symlinks, either..
 Same here..
 No symlinks in my project, but still getting the same error. Anyone find another solution?
/remove-lifecycle rotten.
 Did any of you guys find a solution to this problem?.
 I was trying to do it in a `nuxt` project (javascript project) and got the same error

but after removing the `node_modules` and the `.nuxt` built directories, this worked like a charm 

(on Mac OS X 10.11.6).
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @Oliboy50 Move where? Why would you move your node_modules dir.
 @alxvallejo I said ""remove"" not ""move"", I just had to `rm -rf node_modules` and rebuild the docker image to let docker rebuild the node_modules itself

my issue seemed to be symlinks indeed.
 Can anyone tell me WHY this is _still_ an issue? I am getting the following, slightly-more-helpful-but-not-really kind of error:
```kompose up
WARN Volume mount on the host ""...ux/data"" isn't supported - ignoring path on the host
INFO Build key detected. Attempting to build and push image 'web:latest'
INFO Building image 'web:latest' from directory 'ux'
FATA Error while deploying application: k.Transform failed: Unable to build Docker image for service web: Unable to create a tarball: archive/tar: write too long
```
How long is this expected to wait, and how can I change it?.
 as @Oliboy50 has said.. remove your node_modules and build dirs and the tar will build.

In my case I had to ``` rm -rf node_modules && rm -rf dist```
.
 I don't even use node (i'm using django rest framework) and have the same error..
 "
,,655,"Changing printf verb in compose_test.go.
 Fixes #654 
cc: @surajssd @cdrage @kadel @surajnarwade .
 LGTM.
 LGTM.
 Hey @cdrage can we merge it since it's blocker to #640.
 @procrypt I just tested this locally and it doesn't fix `vet`.. Odd:
```
▶ make vet
go vet ./cmd/... ./pkg/... .
pkg/loader/compose/compose_test.go:67: arg expected for printf verb %s of wrong type: github.com/kubernetes-incubator/kompose/pkg/kobject.Ports
exit status 1
pkg/transformer/utils.go:216: github.com/kubernetes-incubator/kompose/pkg/utils/docker.Build composite literal uses unkeyed fields
pkg/transformer/utils.go:243: github.com/kubernetes-incubator/kompose/pkg/utils/docker.Push composite literal uses unkeyed fields
exit status 1
Makefile:75: recipe for target 'vet' failed
make: *** [vet] Error 1
```.
 Well, I mean, it solves the first one! Merging..
 @cdrage Thanks :).
 "
,,654,"make test is failing.
 When I run make test I'm getting this error
```bash
$ make test
go get github.com/mattn/goveralls
go get github.com/modocache/gover
go get github.com/Masterminds/glide
go get github.com/sgotti/glide-vc
go get github.com/golang/lint/golint
./script/check-vendor.sh
Checking for nested vendor dirs
OK
Checking if vendor was cleaned using glide-vc.
OK
./script/check-gofmt.sh
gofmt OK
go vet ./pkg/... ./cmd/... .
pkg/loader/compose/compose_test.go:67: arg expected for printf verb %s of wrong type: github.com/kubernetes-incubator/kompose/pkg/kobject.Ports
exit status 1
Makefile:75: recipe for target 'vet' failed
make: *** [vet] Error 1
```
.
 "
,,653,"Disable dab.
 See issue: https://github.com/kubernetes-incubator/kompose/issues/390

Remove DAB as it is hard to maintain / not much usage / DAB is still
experimental in Docker and there hasn't been much movement:
https://github.com/moby/moby/issues/26876

MarkDeprecated does not work at the moment due to issue:
https://github.com/kubernetes-incubator/kompose/issues/652

However, that is not a blocker as we `fatalF` within `ValidateFlags`.
 ![dabbing](http://img.over-blog-kiwi.com/2/05/77/12/obpicfFcfKx.png)

ping @sebgoa @kadel  .
 so +1 , except that as you mention MarkDeprecated does not work..
 @sebgoa Yes, an issue with Cobra, which already has a fix, see: https://github.com/spf13/cobra/pull/466 will just have to wait until it's merged upstream. But since we error out anyways if `--bundle` is passed, this will still work. We'll just have to update vendoring once https://github.com/spf13/cobra/pull/466 is merged :+1: .
 I've also updated the commit title / information. 

We're **disabling** DAB not removing it, as the code for conversion is still there for future use!.
 Okay. Tests pass now. @kadel @surajssd want to do a quick review?.
 works for me :).
 @cdrage LGTM  and +1 for disabling DAB :dancer: .
 @cdrage Do we need to write the `functional tests` for dab in `golang` since we are disabling it..
 > @cdrage Do we need to write the functional tests for dab in golang since we are disabling it.

No, we definitely shouldn't but I will let @cdrage and others take the final call..
 @procrypt @surajnarwade Remeber to go through the review process and hit ""approve"" :+1: But since I got two confirmations, let's go ahead and merge this!.
 "
,,652,"Deprecation warnings are not showing.
 See: https://github.com/spf13/cobra/issues/463

Marking flags as `MarkDeprecated` does not show the proper warning..
 "
,,651,"move git and related functions from openshift.go into a separate file.
 Fixes #640 and we can use the same functions in #518 
cc: @kadel @surajssd .
 https://github.com/kubernetes-incubator/kompose/pull/655 will unblock this PR.
 @surajnarwade Yes it will unblock this PR..
 @procrypt @surajnarwade 

Actually... there's a lot of things weird going on in this PR, weird indenting, changing of code to buildconfig. This all should just be a quick move and function name change, shouldn't it?.
 @procrypt run gofmt.
 @procrypt @cdrage , I think as `git` related functions are only required by openshift, `git.go` should be in `pkg/transformer/openshift/git.go`,
thoughts ?
.
 @surajnarwade makes sense to put in different folder even though only OpenShift uses it.. we may use it for Kubernetes in the future?.
 @surajnarwade we will be using it for Functional Tests also..
 LGTM.
 Ping @kadel Please review..
 Should those functions be used in openshift code for buildconfig stuff etc...?.
 @kadel , yeah buildconfig stuff.
 @procrypt Mind fixing the conflicting file and then we can do another review / possible merge?.
 @cdrage @kadel , I have updated @procrypt PR, good to go now :).
 @cdrage @surajssd @kadel needs your review here.
 This LGTM..
 @surajssd ?.
 "
,,650,"v3 env substitution is not working.
 Hi,

I have a few problems with the latest kompose version and the substitutions of env vars.

```
bag@bag ~/temp/foo % go get -u github.com/kubernetes-incubator/kompose                                                  
bag@bag ~/temp/foo % kompose version
0.7.0 (08658d3)
```

This small test file:
```
version: ""3""
services:
  web:
    image: quay.io/bgruening/galaxy-web:${IMAGE_VER:-latest}
    environment:
        - GALAXY_RUNNERS_ENABLE_K8=${GALAXY_RUNNERS_ENABLE_K8}
```

result in this k8s file:
```
bag@bag ~/temp/foo % IMAGE_VER=foo GALAXY_RUNNERS_ENABLE_K8=""asdf"" kompose convert -f k8.yaml && cat web-deployment.yaml
INFO Kubernetes file ""web-service.yaml"" created   
INFO Kubernetes file ""web-deployment.yaml"" created 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: web
  name: web
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: web
    spec:
      containers:
      - env:
        - name: GALAXY_RUNNERS_ENABLE_K8
        image: quay.io/bgruening/galaxy-web:latest
        name: web
        resources: {}
      restartPolicy: Always
status: {}

```

I tried to create an .env file
```
GALAXY_RUNNERS_ENABLE_K8=True
IMAGE_VER=8.9
```

and also exported it with no success.

`- GALAXY_RUNNERS_ENABLE_K8=${GALAXY_RUNNERS_ENABLE_K8:-default}` in the docker-compose.yml file will substitute it with `default` but not with the values available during runtime.
` - GALAXY_RUNNERS_ENABLE_K8=$GALAXY_RUNNERS_ENABLE_K8` does not work at all.

Thanks a lot for any help!
.
 ping @cdrage as you have rocked the v3 world lately :).
 Hey @bgruening I'm going to have a look into this and see what's up! Other than the env variables, I'm assuming everything has converted correctly for docker-galaxy-stable?.
 @cdrage galaxy-docker-stable is a very complicated beast and we have some more problems.

For example this one: https://github.com/bgruening/docker-galaxy-stable/pull/347/commits/2c56ffa38d79078d578cca031155b40a1ee57a53

An other thing is that I want to get this under CI testing. So I use `./hack/local-up-cluster.sh` to start a k8s test env and in this it seems I need to have PV.yaml files which are not generated.

Coming back to the env problem this is the hack I'm currently using, maybe this helps in some way. It works reliable as bash is probably the best way to replace bash envs :)

```
#!/bin/bash
cat > $2 << EOF
`cat $1`
EOF
```

Thanks @cdrage for working on this!


.
 hope I haven't stepped on your toe @cdrage :innocent:   I just wanted to look what is happening there, and saw a solution - #658 :wink: .
 "
,,649,"Updating Vendor.
 resolves #620 as libcompose PR https://github.com/docker/libcompose/pull/476
got merged..
 LGTM.
 "
,,648,"Update documentation to reflect build/push and v3 changes.
     Update documentation to reflect build/push and v3 changes
    
    Adds a user guide on how to use the build/push functionality of Docker
    images to the user guide.
    
    Adds v3 documentation as well as cleans up the user guide as well.
    
    I also do minor changes such as removing `$ ` in the CLI examples, as
    it's easier to copy and paste without the `$ ` there (when double
    clicking).
    
    I've also changed the `console` yaml indicitors to `sh` since it doesn't
    matter / it's aliased, see:
    https://github.com/github/linguist/blob/master/lib/linguist/languages.yml
.
 ping @kadel @surajssd .
 Updated it with your changes @surajssd ready for another doc review @kadel @surajssd or @surajnarwade .
 @cdrage , only one comment, otherwise LGTM :).
 @kadel @surajssd Updated the PR with your changes (adding the `$` and other comments).
 LGTM :).
 "
,,647,"Docker Build/Push documentation.
 With the changes to how we build and push containers when users use the `build` key, we should note in our documentation both the functionality as well as *how* to use it..
 "
,,646,"v3 Documentation.
 We should add some more documentation in regards to v3 as well as a bit on v1/v2 somewhere in the user-guide or elsewhere..
 "
,,645,"Update ROADMAP.
 This updates the ROADMAP.md with a clear outline of the future release
of Kompose as well as the current updates / changes on each-release..
 ping @pradeepto @kadel @surajssd .
 "
,,644,"Tracking card for new `deploy` keys in v3.
 We have to cover the new keys in deploy for v3 of Docker Compose, at the moment, we only have mem_limit complete.

New keys:

- [x] mode
- [x] replicas
- [x] placement
- [ ] update_config
- [x] resources
- [x] restart_policy
- [x] labels
- [x] cpus (under 'resources')
- [X] memory (under 'resources')

.
 I will take `replicas` key.
 @surajnarwade I already started work on it, sorry :( I'm setting up a separate function so that we can parse these keys easier..
 @cdrage okay no worries.
 @cdrage also, Ports in long syntax?.
 @ashetty1 Open up another issue for that. But it's v3.2 and it's not even integrated into moby/moby yet..
 Hey @surajnarwade wanna take this up and see how we can implement the `deploy` side of things? I was starting work on this but got side-tracked by the 1.0.0 release.
 @cdrage, sure, can you point me towards where you start.
 @surajnarwade https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L159 would be a good start. Luckily we're able to easily access the deploy keys via v3.go :smile: .
 I will take `restart-policy` as well.
 this was closed by #664 this by mistake, if this is a tracking card @surajnarwade please don't add the fixes thing in your PR because this will get closed on the next PR that says that again.
 @cdrage @surajssd , I think `mode` is swarm specific command, it will be better if we can add it to unsupported keys.
 Three more to-go.

@surajnarwade 

I have added mode here: https://github.com/kubernetes/kompose/pull/771 you said it couldn't be done, but I did it! :+1: .
 @cdrage , that's good.
I have investigated on `placement` key, I found only two mappings,
* `engine.labels.operatingsystem` is equivalent to `beta.kubernetes.io/os`
* `node.hostname` is equivalent to `kubernetes.io/hostname`

Does this makes sense ?
I havn't found any other mappings..
 @surajnarwade that makes sense. everything else we can warn / info out..
 Placement has been completed. 1 more to-go..
 @cdrage  since `update_config` has no direct mapping in kubernetes, Let's close this issue.
 @surajnarwade Before that, we will have to update the conversion matrix documentation..
 @cdrage since conversion matrix is also updated now, Let's close the issue :).
 "
,,643,"Support  restart_policy in v3 docker compose.
 We need to support the restart_policy key in v3 docker compose file.
.
 Hi @ashetty1 I decided to create a tracking card for all of this here: #644 .
 "
,,642,"OpenShift tests for docker compose v3.
 Adding OpenShift tests for docker compose v3 support on Kompose

Ref: #600 .
 LGTM. Unfortunately because of my distro I can't test this. Could someone else do a quick test?.
 I found following results:

```
Running tests for docker compose v3


Running kompose up ...

INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Service: web            
INFO Successfully created DeploymentConfig: redis 
INFO Successfully created ImageStream: redis      
INFO Successfully created DeploymentConfig: web   
INFO Successfully created ImageStream: web        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

Waiting for the pods to come up ...

FAIL: kompose up has failed to bring the pods up
the server doesn't have a resource type ""deploy""

Testing  restart: 'always' in v3 docker-compose file


Running kompose up ...

INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: pival          
INFO Successfully created DeploymentConfig: pival 
INFO Successfully created ImageStream: pival      

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
PASS: restart option set to 'always' is working as expected
NAME            READY     STATUS    RESTARTS   AGE
pival-1-ropod   1/1       Running   1          9s

Running kompose down ...

INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: pival          
INFO Successfully deleted DeploymentConfig: pival 
INFO Successfully deleted ImageStream: pival      

Waiting for the pods to go down ...

PASS: All pods are down now. kompose down successful.
NAME            READY     STATUS        RESTARTS   AGE
pival-1-ropod   1/1       Terminating   1          13s
the server doesn't have a resource type ""deploy""
Makefile:62: recipe for target 'test-openshift' failed
make: *** [test-openshift] Error 1
```.
 @surajnarwade Buildconfig tests are failing due to #521 changes; the tests added here are working. .
 @ashetty1 what changes? I don't believe we've updated anything related to buildconfig since then.

@surajnarwade can you try again?.
 @cdrage the change in examples/buildconfig/docker-compose.yml.
 @cdrage okay.
 @cdrage Could you take a look at this too. It is WIP because I am planning to add more tests as new features come in. But if you think it could be merged, I am cool with that too. .
 @ashetty1 , I just tried this PR, I think  `kompose down` is needed, as it says  `FATA Error while deploying application: services ""redis"" already exists 
` 
and results:

```
Running tests for environment variable for docker compose v3


Running kompose up ...

INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
FATA Error while deploying application: services ""redis"" already exists 
FAIL: kompose up has failed
the server doesn't have a resource type ""deploy""

Running tests for docker compose v3


Running kompose up ...

INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
FATA Error while deploying application: services ""redis"" already exists 
FAIL: kompose up has failed
the server doesn't have a resource type ""deploy""
```.
 @surajnarwade weird. Works for me. Can you just try:

./script/test_in_openshift/run.sh script/test_in_openshift/tests/v3-redis.sh.
 change route to `nip.io` as, 

```
FAIL: Route *.xip.io has not been exposed
```
.
 What's the status of this @ashetty1 ? Perhaps you can rebase against master? :+1: .
 @cdrage Apologies. Give me a day. Will follow up on this..
 @cdrage @surajnarwade kindly give it a spin. Have rebased and squashed the commits..
 Works with the exception of Docker Compose v3 environment variables test not coming up:
```sh
Running tests for environment variable for docker compose v3


Running kompose up ...

INFO We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: redis          
INFO Successfully created Service: web            
INFO Successfully created DeploymentConfig: redis 
INFO Successfully created ImageStream: redis      
INFO Successfully created DeploymentConfig: web   
INFO Successfully created ImageStream: web        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
No resources found.

Waiting for the pods to come up ...

No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
No resources found.
```.
 @cdrage can you try once more and push this? .
 @ashetty1 works now! Mergin'.
 "
,,641,"Add openshift tests for docker compose v3.
 Add OpenShift tests for validating docker composer v3 support in Kompose

Ref: #600 .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,640,"Move git functions in openshift.go into a separate package.
 We have some git functions like `GetGitCurrentRemoteURL()` and  `GetGitCurrentBranch()` in `opneshift.go`, it would be great if we move them to a separate package.

cc: @kadel.
 @kadel Working on this..
 @procrypt @kadel completing this :)
.
 "
,,639,"Save the cmd used to create config.
 When we generate config it is really hard to know what command was used to generate that config. And has caused issues in past. As much as important it is to have the docker-compose file to generate the artifacts the command line flags used to generate config are also important, so we should have some way to know what flags were used to generate specific config.

So I propose saving the command given to convert along with flags in annotations of generated configs

like if I use:

```
kompose convert --emptyvols
```

This should show up in the converted annotations like 

```yaml
...
annotations:
  ""kompose.cmd"": ""kompose convert --emptyvols""
  ""kompose.version"": ""0.6.0 (45a0daw)""
...
```

This will help us mitigate issues like https://github.com/kubernetes-incubator/kompose/issues/632.
 This is a good idea.
But maybe instead of full command, it might be better to add something that can be easily parsed.
Or add another extra annotation that will be easy to parse. 

```yaml
...
annotations:
  ""kompose.cmd"": ""kompose convert --emptyvols""
  ""kompose.version"": ""0.6.0 (45a0daw)""
  ""kompose.data"": ""{version: 0.6.0, command: 'convert', emptyvols: 'true'} ""
....
```
.
 @kadel yeah even that SGTM!.
 This sounds great! Would really help in term's of troubleshooting conversions..
 I am taking this up..
 Since this will be major change in all unit test case and functional test files, 
I have something output as of now,

```
metadata:
    annotations:
      kompose.cmd: kompose convert --stdout
      kompose.version: |
        1.0.0 (HEAD)
```

Any suggestions before sending PR? @surajssd  @kadel @cdrage .
 This will be the pain for functional tests, as it may be
`kompose convert -f /home/snarwade.....`  for me,

```
metadata:
    annotations:
      kompose.cmd: kompose convert -f /home/snarwade --stdout
      kompose.version: |
        1.0.0 (HEAD)
```

but for travis, `kompose convert -f /home/travis...`
it will be,

```
metadata:
    annotations:
      kompose.cmd: kompose convert -f /home/travis --stdout
      kompose.version: |
        1.0.0 (HEAD)
```.
 @surajnarwade Remove the pipe `|` from version and it's a :+1: from me..
 @cdrage , what I mean is we have to write template for each and every functional test as `kompose.cmd` will be different for local and travis, is that okay ?.
 @surajnarwade Yup. Since you're adding annotations by default, you'll have to change every test. It's a pain-in-the-butt to do, but it's a must.

I think that's okay, right @kadel @surajssd ?.
 "
,,638,"Failing test will show diff.
 If test in `make test-cmd` is failing, now it will show diff so that
it will be easy to debug.

for example,

```
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose -f /home/snarwade/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/service-name-change/docker-compose.yml convert --stdout -j' expected_output: '/home/snarwade/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/service-name-change/output-k8s.json' expected_warning: 'Unsupported root level volumes key - ignoring'
WARN Unsupported root level volumes key - ignoring
WARN Unsupported depends_on key - ignoring
103c103
<                     ""value"": ""bitnami_wordpres""
---
>                     ""value"": ""bitnami_wordpress""
FAIL: converted output does not match
```.
 resolves #604 .
 Awesome! This LGTM..
 @surajssd @kadel review please :).
 "
,,637,"Add documentation list.
 Adds an ""index"" with a list of all documentation on the README.md.
 "
,,636,"Add `build` key support for v3 of Docker Compose.
 This will have to be fixed upstream as the code here in `docker/cli` ignores build at the moment: https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L9

This is a tracking issue as #600 has yet to be merged..
 @cdrage #600 is merged!.
 @surajssd Yes, but this issue is for post-# #600 merge. V3 Build support does not work due to: https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L9 (see ignored section), thus we don't map it in Kompose..
 @surajssd @cdrage , as `build` is still unsupported in https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L9 , shall we use it from v1v2.go for v3.go ?
does it make sense ? if yes I am up for this :).
 @surajnarwade
Yes, we are indeed going to be re-using the code from `v1v2.go` in `v3.go` but that's the easy part, the problem is parsing v3 correctly so we can actually retrieve the information.

This would have to be fixed upstream unfortunately, or we can find a work-around to retrieve the keys. .
 When the time comes, we will move the `build` conversion code to a separate file (`compose.go` maybe where the other functions are? So both v1v2.go and v3.go can use it.

If you can find a way to retrieve the build key that'd be great! :+1: :100: :+1: (we don't need to figure out the `build` key conversion, we already figured that part out :smile: ).
 thanks , @cdrage I will give it a try :).
 I think we should set this as high-priority so we can add `build` support for Compose V3 as that is the *only* thing that is missing between v1v2 and v3.. Unfortunately it's due to the key being missing  from https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L9 so we can use it to parse Docker Compose..
 PR pushed here: https://github.com/docker/cli/pull/481.
 Looks like it doesn't support just a string for build.

* 'Build' expected a map, got 'string' 
.
 @coli , yeah :( 
need to fix that in docker/cli.
 @coli , that problem will resolve after https://github.com/docker/libcompose/pull/498 gets merged and again vendoring for `libcompose` and `docker/cli`.
 @surajnarwade No idea why you're referencing docker/libcompose. Docker Compose V3 support within Kompose is using docker/cli

Your PR is here: https://github.com/kubernetes/kompose/pull/846 for Version 3 implementation. 

@coli are you using Version 2 or Version 3 in your Docker Compose YAML file?

If you're using Version 2, this is a separate issue as Version 3 is yet to be supported..
 @cdrage , @coli  is getting issue for v3, to solve this, I need to update `Docker CLI` vendor and then `libcompose` to solve `logrus` issues as well  as `build context` issue.
 I'm on v3..
 Okay, so your statement about libcompose was unrelated.. The problem will *not* be resolved after https://github.com/docker/libcompose/pull/498 is merged in. It will be resolved after #846 .
 @cdrage to merge #846 , I need to update vendor for `docker/cli` upon which kompose is breaking due to `logrus` stuff.
 How do you fix `'Build' expected a map, got 'string'` for v3 when running `kompose convert` ? I'm on a Windows platform..
 @tsauvajon I've had this same problem, it looks like kompose doesn't respect the optional string parameter. You can work around it by changing the config to a map like so
```yaml
  build:
    context: ./build_path
```.
 @rkachowski oh okay I had not understood the error message thanks a lot! .
 "
,,635,"Change output examples in docs to new format.
 Changes the format from INFO to INFO <PROVIDER> in output examples..
 "
,,634,"Update widgets (add godoc) as well as README.
 Update the widgets (as well as add godoc), and update the README, making
the `kompose completion` section more concise..
 ping @kadel .
 "
,,633,"ports error on converting.
 Hi.

I am trying to convert this docker-compose file:

[https://raw.githubusercontent.com/wazuh/wazuh-docker/master/docker-compose.yml]()

With this output:

```bash
ERRO Could not parse config for project kompose : Service 'wazuh' configuration key 0 value Does not match format 'ports'
Service 'wazuh' configuration key 2 value Does not match format 'ports'
FATA composeObject.Parse() failed, Failed to load compose file: Service 'wazuh' configuration key 0 value Does not match format 'ports'
Service 'wazuh' configuration key 2 value Does not match format 'ports'
```
Docker-compose file is valid, what is wrong?

Thanks!
.
 @changux 

Try: 
```
      - ""514:514/udp""
```

instead of

```
      - ""514/udp:514/udp""
```

and see what happens.
.
 hmm, interesting. It looks like ""514/udp:514/udp"" is supported by docker-compose tool, but not by libcompose.

It's strange as I don't see why it would ever make sense to set different protocol for container and host port..
 Thanks. After follow your suggestions, convert process finished successfully.

Regards!.
 "
,,632,"Delete BuildConfig on `kompose down`.
 After #521 is merged in, we'll have to figure out a way to determine if BuildConfig has been used and delete it accordingly when doing `kompose down`.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,631,"Fix EnvSort struct.
 Fixes #627 and unblocks #518  

cc: @surajssd @cdrage .
 Tests(unit tests, functional tests).
 Ping @kadel please review..
 LGTM / I approve these changes. Other than the nitpick from @kadel 's comment. I agree with adding a few comments..
 Thanks @kadel ;).
 "
,,630,"Remove jekyll format from top of quickstart.
 Left this in while adding docs/quickstart.md by accident.
 "
,,629,"Fix adding Jekyll format to the top.
 Problem with `/permalink/`. This adds a few bash lines that updates
index.md without the permalink..
 Unfortunately I'm going to have to merge this in, in order to troubleshoot what's up with GitHub (pages are failing with unknown error). If this doesn't work i'll revert it manually..
 "
,,628,"Update documentation to reflect quickstart.
 Adds quickstart.md from the kompose.io site as well as incorporates
changes so that you can update the index page of Kompose.io via
quickstart.md.
 "
,,627,"Fix EnvSort so that env variables are populated properly.
 Environment variables in `docker-compose` file are populated in random order resulting in failure of the `functional test` in `golang`.

I have used multiple `docker-compose` files to test this out from 
[fixtures](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/multiple-compose-files) folder.
`docker-compose` file used [1](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/multiple-compose-files/docker-k8s.yml) and [2](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/multiple-compose-files/docker-os.yml)

```bash
$ kompose convert --provider=openshift -f docker-k8s.yml -f docker-os.yml --stdout -j > a.json
$ kompose convert --provider=openshift -f docker-k8s.yml -f docker-os.yml --stdout -j > b.json
```
```
$ diff a.json b.json
```
```vim
126a127,130
>                     ""name"": ""DB_DBID"",
>                     ""value"": ""openshift""
>                   },
>                   {
140,143d143
<                     ""value"": ""openshift""
<                   },
<                   {
<                     ""name"": ""DB_DBID"",
```
Sorting this [struct](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/kobject/kobject.go#L96)
```go
type EnvVar struct {
	Name  string
	Value string
}
```
 would fix this issue.
This issue is a blocker for #518.
 I'm working on this..
 "
,,626,"Handling Volume at early stage.
 It will resolve #544 as well as refactor volume handling part..
 this PR is still in WIP, so I will add tests later.
@cdrage @kadel @surajssd suggestions needed.
 @surajnarwade DaemonSet's aren't working. See: https://travis-ci.org/kubernetes-incubator/kompose/jobs/237507721#L398

Please get current tests to pass as well :smile: before we add new tests!.
 @surajnarwade please rebase .
 @surajssd @cdrage  done with rebase and tests are green now, needs your review please :).
 @cdrage , in order to answer your question regarding copying functionality from `docker/cli`, it can be used moreover for root level `volumes` key but not the thing that I am working on..
 @surajnarwade I believe that you can use similar type.

See how we ""copy"" from libcompose in kobject.go in terms of ServiceConfig. This should be the same in terms of Volumes. It makes sense to try to keep the underlying code similar to upstream code.

What do you think @kadel ? Also regarding the many variables (see https://github.com/kubernetes-incubator/kompose/pull/626#discussion-diff-122452810R120)

.
 @surajssd review please :).
 @kadel @cdrage , I have updated the PR with comments as suggested, needs review :).
 Also add the test case in functional tests that you are using for testing locally it has some good corner case checks, also maybe name them something better!.
 @surajssd , I have updated volume_from example which covers all corner cases probably..
 @kadel , needs your review :).
 @cdrage , added new example.
 Let's get @kadel 's quick approval then merge..
 LGTM!.
 > It will resolve #544 as well as refactor volume handling part.

this is not resolving #544 is it?
Isn't this meant to be just ground work for resolving #544 in the future?.
 @kadel , it will completely resolve #544 .
 > @kadel , it will completely resolve #544

I've tested that and result is still the same :-( .
 @kadel , problem is occuring due to permissions of volumes in the example mentioned in the issue..
 > @kadel , problem is occuring due to permissions of volumes in the example mentioned in the issue.

yeh, but it should work even with permissions. 
If volumes are the same, only permissions differ that kompose has to set `readOnly` for `ro` volumes. Right now it puts duplicate volume there.

.
 @kadel , now it works.
 @surajnarwade  getting closer ;-)

But permissions are still not correct:-(

letsencrypt Deployment has `/etc/nginx/certs` mounted as readOnly, even  if docker-compose says `rw`

```yaml
          - mountPath: /etc/nginx/certs
            name: proxy-claim2
            readOnly: true
```





.
 @kadel Odd that this is not caught in a failing test, did @surajnarwade override it or is there actually no tests written for checking if the readOnly value has been enabled?.
 > @kadel Odd that this is not caught in a failing test, did @surajnarwade override it or is there actually no tests written for checking if the readOnly value has been enabled?

It looks like there is no test case checking that :-(

There should be a test testing this case: One volume mounted to two different containers, in one container as ro, in other as rw


.
 I've created simple test file:


```yaml
version: ""2""

services:
  foo:
    image: quay.io/tomkral/sleeper
    volumes:
     - ./data:/opt/data:ro
    
  bar:
    image: quay.io/tomkral/sleeper
    volumes_from: 
     - foo
    volumes:
     - ./data:/opt/data:rw
```

using this I've found weird bug
If I use this docker-compose file I Deploymnet for bar service doesn't have any volumeMounts.

Once I add second volume for bar service:
```
    volumes:
     - ./data:/opt/data:rw
     - /tmp
```
generated Deployment suddenly has both volumeMounts 














.
 I think that for this docker-compose 
```yaml
version: ""2""

services:
  foo:
    image: quay.io/tomkral/sleeper
    volumes:
     - ./data:/opt/data:ro
    
  bar:
    image: quay.io/tomkral/sleeper
    volumes_from: 
     - foo
    volumes:
     - ./data:/opt/data:rw
```

correct output should be

```yaml
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: bar
    name: bar
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: bar
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: foo
  status:
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: bar
    name: bar
  spec:
    replicas: 1
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: bar
      spec:
        containers:
        - image: quay.io/tomkral/sleeper
          name: bar
          resources: {}
          volumeMounts:
          - mountPath: /opt/data
            name: foo-claim0
        restartPolicy: Always
        volumes:
        - name: foo-claim0
          persistentVolumeClaim:
            claimName: foo-claim0
  status: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec:
    replicas: 1
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: foo
      spec:
        containers:
        - image: quay.io/tomkral/sleeper
          name: foo
          resources: {}
          volumeMounts:
          - mountPath: /opt/data
            name: foo-claim0
            readOnly: true
        restartPolicy: Always
        volumes:
        - name: foo-claim0
          persistentVolumeClaim:
            claimName: foo-claim0
            readOnly: true
  status: {}
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo-claim0
    name: foo-claim0
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
kind: List
metadata: {}

```




To sum this up with the current state of this PR I see two issues.
 1) `readOnly` flag is set for `volumeMount` that has explicitly specified `rw` in docker-compose
 2) missing volume if there is only one `volume` with `volume_from` defined


.
 It looks like all the problems were solved in the last update of this PR. :tada: 

Grat work @surajnarwade ! :+1: .
 "
,,625,"emptyvols option doesn't work for kompose convert/up.
 `kompose convert` and `kompose up` fails with emptyvols option:

```
$ kompose version
0.7.0 (c25b7e8)
```

```
$ kompose --provider=openshift --emptyvols -f examples/docker-compose.yaml convert -h
Error: unknown command ""examples/docker-compose.yaml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""examples/docker-compose.yaml"" for ""kompose""
```
 Without emptyvols option: 
```
$ kompose --provider=openshift -f examples/docker-compose.yaml convert
INFO file ""frontend-service.yaml"" created         
INFO file ""redis-master-service.yaml"" created     
INFO file ""redis-slave-service.yaml"" created      
INFO file ""frontend-deploymentconfig.yaml"" created 
INFO file ""frontend-imagestream.yaml"" created     
INFO file ""redis-master-deploymentconfig.yaml"" created 
INFO file ""redis-master-imagestream.yaml"" created 
INFO file ""redis-slave-deploymentconfig.yaml"" created 
INFO file ""redis-slave-imagestream.yaml"" created 
```

Same issue is seen with `kompose up`, and has been documented here #614 .
 Taking a look at this :+1: .
 @ashetty1 , this is weird but if I run, I got error,

```
$ kompose --provider=openshift --emptyvols -f kompose/examples/docker-compose.yaml convert
Error: unknown command ""kompose/examples/docker-compose.yaml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""kompose/examples/docker-compose.yaml"" for ""kompose""

```

but if I run it as,

```
$ kompose --provider=openshift  -f kompose/examples/docker-compose.yaml convert --emptyvols 
INFO file ""frontend-service.yaml"" created         
INFO file ""redis-master-service.yaml"" created     
INFO file ""redis-slave-service.yaml"" created      
INFO file ""frontend-deploymentconfig.yaml"" created 
INFO file ""frontend-imagestream.yaml"" created     
INFO file ""redis-master-deploymentconfig.yaml"" created 
INFO file ""redis-master-imagestream.yaml"" created 
INFO file ""redis-slave-deploymentconfig.yaml"" created 
INFO file ""redis-slave-imagestream.yaml"" created 
```

it worked :).
 @surajnarwade yes. I saw the same behaviour too. If --emptyvols is passed after up/down, it works. Weird indeed..
 @kadel , is it intentional ?.
 yes, that is intentional. 
`--emptyvol` is not a global flag, so it has to be specified after subcommand. .
 Closing this..
 "
,,624,"duplicate info from multiple compose files not being overridden.
 duplicate info from multiple compose files not being overridden

I am using two docker-compose files:
```bash
$ ll
total 8
-rw-rw-r--. 1 foo foo 77 May 29 12:16 docker-compose1.yml
-rw-rw-r--. 1 foo foo 77 May 29 12:16 docker-compose2.yml

$ cat docker-compose1.yml 
version: ""2""

services:
  web:
    image: centos/httpd
    ports:
    - ""80""

$ diff docker-compose1.yml docker-compose2.yml 
```

Both docker-compose files are same.

Now when deploying it to the cluster using kompose the conversion does not look at the duplicate data. But merges the values.

When deploying to the cluster directly:

```bash
$ kompose up -f docker-compose1.yml -f docker-compose2.yml --provider openshift
INFO We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""web"" namespace     
FATA Error while deploying application: Service ""web"" is invalid: spec.ports[1].name: Duplicate value: ""80"" 
```

When doing the conversion, see the repetition of ports in the `service` and in the `DeploymentConfig`

```yaml
$ kompose convert --stdout -f docker-compose1.yml -f docker-compose2.yml --provider openshift
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: web
    name: web
  spec:
    ports:
    - name: ""80""
      port: 80
      targetPort: 80
    - name: ""80""
      port: 80
      targetPort: 80
    selector:
      io.kompose.service: web
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: web
    name: web
  spec:
    replicas: 1
    selector:
      io.kompose.service: web
    strategy:
      resources: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
      spec:
        containers:
        - image: ' '
          name: web
          ports:
          - containerPort: 80
          - containerPort: 80
          resources: {}
        restartPolicy: Always

...
```

Also the config in [script/test/fixtures/multiple-compose-files/output-openshift.json](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/multiple-compose-files/output-openshift.json) is not deployable.

.
 Not sure if this is coming from upstream, libcompose..
 docker-compose seems to be working fine with it:

```bash
$ docker-compose -f docker-compose1.yml -f docker-compose2.yml up
Creating network ""multiple_default"" with the default driver
Pulling web (centos/httpd:latest)...
Trying to pull repository docker.io/centos/httpd ... 
sha256:d76aaac3b483cc7cb51ec16a48a717b9cbbb55df759613f6fcb94ac674e33b28: Pulling from docker.io/centos/httpd
785fe1d06b2d: Already exists
11ab8f4c345d: Pull complete
68efd29fbc4a: Pull complete
516852272af9: Pull complete
Digest: sha256:d76aaac3b483cc7cb51ec16a48a717b9cbbb55df759613f6fcb94ac674e33b28
Status: Downloaded newer image for docker.io/centos/httpd:latest
Creating multiple_web_1
Attaching to multiple_web_1
web_1  | AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.21.0.2. Set the 'ServerName' directive globally to suppress this message
...
```

additional info:

```bash
$ docker-compose version
docker-compose version 1.9.0, build 2585387
docker-py version: 1.10.6
CPython version: 2.7.13
OpenSSL version: OpenSSL 1.0.2k-fips  26 Jan 2017
```.
 I think fixing this will unblock https://github.com/kubernetes-incubator/kompose/pull/596 since this is causing the duplicate env to be populated ref: https://github.com/kubernetes-incubator/kompose/pull/596#discussion_r116923543.
 Reported in upstream https://github.com/docker/libcompose/issues/473.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 This is a libcompose issue, seems have to wait upstream solve.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 @fejta-bot: Closing this issue.

<details>

In response to [this](https://github.com/kubernetes/kompose/issues/624#issuecomment-425854394):

>Rotten issues close after 30d of inactivity.
>Reopen the issue with `/reopen`.
>Mark the issue as fresh with `/remove-lifecycle rotten`.
>
>Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
>/close


Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>.
 "
,,623,"Move logo to the bottom.
 Moves the logo to the bottom of the sidebar rather than the top..
 Looks better IMO. Doesn't indent the title / not have a full-logo..
 :+1: , Nice looking now :).
 "
,,622,"Update README with only docker compose example.
 At the moment, `dabs` don't seem to work as well as the fact that there
hasn't been much development since the experimental announcement of the
DAB format.

Removing it from the README makes the example clearer as well as more
direct / informative..
 ping @sebgoa .
 At the moment, the example and --dab functionality does not work..
 lgtm

It has been long enough without movement on the dab front..
 Since this is doc review / updating, it only requires one LGTM!

Mergin'.
 "
,,621,"Update ROADMAP.
 This updates the ROADMAP.md with a clear outline of the future release
of Kompose as well as the current updates / changes on each-release..
 "
,,620,"configuration key 'build' contains an invalid type, it should be a string..
 - I have docker-compose file whixh extends other compose files and setup my apps. It is working fine.
- But When I tried same file with `kompose` I am getting invalid type error : 

```
ERRO Failed to parse service micro_service_api: Service 'v_test' configuration key 'build' contains an invalid type, it should be a string. 
```

- here are my Compose files : 
   - Main : 

```
version: '2'

services:
  test_micro_service_api:
    extends :
      file : ../v-test/docker-compose-test.yml
      service : v_test
```

   - child : 

```
version: ""2""

services:
  v_test:
    build:
      context: .
      dockerfile: ./Dockerfile
    env_file:
     - ../locale/env/test_service
    environment:
     DEBUG: 'true'
    command: bash -c ""python ./manage.py migrate && python ./manage.py runserver 0.0.0.0:8018""
    volumes:
     - .:/v-test
    ports:
     - ""8018:8018""
```.
 @verisadmin what is the version of kompose you are using?.
 @surajssd  
`0.7.0 (c25b7e8)`
.
 this looks like bug in libcompose :-( 
It seems like for some reason extends and with builds are not handled properly :(.
 I will take this up.
 I have filed issue in libcompose which can be tracked here: https://github.com/docker/libcompose/issues/475.
 "
,,619,"0.7.0 Release.
 "
,,618,"Update version number in setup.md file in release script.
 This change updates setup.md to include the new version number when
doing a release..
 Mergin' before today's release! Just a simple update to release.sh.
 "
,,617,"add support for ""pid"" key.
 solve #610
convert service.pid to Pod.Spec.HostPid
set Pod.Spec.HostPid to true if service.pid =""host""
update conversion.md on support for the key.
 Awesome. Thanks for updating. LGTM! @kadel @surajssd wanna give a quick review?.
 LGTM :).
 When the `pid: ""host""` is set inside the docker-compose file, I could see all the processes on the host, but when the flag on pod is set to `hostPID: true`, I don't see all the processes on the host but only inside the pod.

Please pardon me on this, I should I done this test even before this reached the PR state and we decided we gonna implement this!

I am using this docker-compose file:

```yaml
$ cat docker-compose.yml 
version: ""2""

services:
  web:
    image: centos/httpd
    ports:
    - ""80""
    pid: ""host""
```

when I run it with docker-compose and exec into the container:

```bash
$ eval $(minikube docker-env)
$ docker-compose up
Creating network ""multiple_default"" with the default driver
Creating multiple_web_1
Attaching to multiple_web_1
...
```

inside minikube vm:

```bash
$ docker ps | grep httpd
4e78c8566748        centos/httpd                               ""/run-httpd.sh""          22 seconds ago       Up 22 seconds       0.0.0.0:32768->80/tcp   multiple_web_1

$ docker exec -it multiple_web_1 ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  2.5  0.2 120416  5784 ?        Ss   08:13   0:11 /sbin/init
root         2  0.0  0.0      0     0 ?        S    08:13   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    08:13   0:00 [ksoftirqd/0]
root         4  0.0  0.0      0     0 ?        S    08:13   0:00 [kworker/0:0]
root         5  0.0  0.0      0     0 ?        S<   08:13   0:00 [kworker/0:0H]
root         7  0.0  0.0      0     0 ?        S    08:13   0:00 [rcu_sched]
root         8  0.0  0.0      0     0 ?        S    08:13   0:00 [rcu_bh]
root         9  0.0  0.0      0     0 ?        S    08:13   0:00 [migration/0]
root        10  0.0  0.0      0     0 ?        S<   08:13   0:00 [lru-add-drain]
root        11  0.0  0.0      0     0 ?        S    08:13   0:00 [cpuhp/0]
root        12  0.0  0.0      0     0 ?        S    08:13   0:00 [cpuhp/1]
root        13  0.0  0.0      0     0 ?        S    08:13   0:00 [migration/1]
root        14  0.0  0.0      0     0 ?        S    08:13   0:00 [ksoftirqd/1]
root        16  0.0  0.0      0     0 ?        S<   08:13   0:00 [kworker/1:0H]
...
```

while inside minikube vm:

```bash
$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  3.6  0.2 120416  5784 ?        Ss   08:13   0:10 /sbin/init
root         2  0.0  0.0      0     0 ?        S    08:13   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    08:13   0:00 [ksoftirqd/0]
root         4  0.0  0.0      0     0 ?        S    08:13   0:00 [kworker/0:0]
root         5  0.0  0.0      0     0 ?        S<   08:13   0:00 [kworker/0:0H]
root         6  0.0  0.0      0     0 ?        S    08:13   0:00 [kworker/u4:0]
root         7  0.0  0.0      0     0 ?        S    08:13   0:00 [rcu_sched]
root         8  0.0  0.0      0     0 ?        S    08:13   0:00 [rcu_bh]
root         9  0.0  0.0      0     0 ?        S    08:13   0:00 [migration/0]
root        10  0.0  0.0      0     0 ?        S<   08:13   0:00 [lru-add-drain]
root        11  0.0  0.0      0     0 ?        S    08:13   0:00 [cpuhp/0]
root        12  0.0  0.0      0     0 ?        S    08:13   0:00 [cpuhp/1]
root        13  0.0  0.0      0     0 ?        S    08:13   0:00 [migration/1]
root        14  0.0  0.0      0     0 ?        S    08:13   0:00 [ksoftirqd/1]
root        15  0.0  0.0      0     0 ?        S    08:13   0:00 [kworker/1:0]
...
```


Now when run with kompose on the cluster running on the vm.

```bash
$ kompose up
...
$ kubectl get pods
NAME                   READY     STATUS    RESTARTS   AGE
web-2967932665-g4kbm   1/1       Running   0          2m

$ kubectl exec -it web-2967932665-g4kbm ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.1  11636  2388 ?        Ss   08:30   0:00 /bin/sh /usr/sb
root         8  0.0  0.3 221928  7468 ?        S    08:30   0:00 /usr/sbin/httpd
apache       9  0.0  0.2 221928  5968 ?        S    08:30   0:00 /usr/sbin/httpd
apache      10  0.0  0.2 221928  5968 ?        S    08:30   0:00 /usr/sbin/httpd
apache      11  0.0  0.2 221928  5968 ?        S    08:30   0:00 /usr/sbin/httpd
apache      12  0.0  0.2 221928  5968 ?        S    08:30   0:00 /usr/sbin/httpd
apache      13  0.0  0.2 221928  5968 ?        S    08:30   0:00 /usr/sbin/httpd
root        18  0.0  0.1  47448  3344 ?        Rs+  08:32   0:00 ps aux


$ kubectl get pod web-2967932665-g4kbm -o yaml | grep -i hostpid
  hostPID: true
```

While according to this PR this should have shown the processes on the host..
 I don't think these keys from docker-compose and kubernetes map to each other!.
 @cdrage @surajnarwade @gitlawr I think before we start implementing any key we should see if they have similar behavior in both the worlds and then only map it! At least from now on!.
 I think this is the best possible 1-1 conversion, perhaps we should simply add a note/warning to it when the key is used?

Yes, the concept of pods vs docker compose's containers is much different. But the k8s docs say: ""Use the host's pid namespace"" in terms of using hostPID. 

.
 @cdrage what is the point of adding something that behaves differently in two environment? IMHO we should only map keys which are similar in behavior..
 @surajssd 

Perhaps it behaves differently, but the concepts are the same. Kubernetes views ""Pods"" as the host, while Docker-Compose views the entire system (in k8s terms, ""Node""). Containers in the same Pod will be accessible, but not the entire Node..
 @surajssd 
what is your k8s version and docker version? I wonder if it is related to some issues with Kubernetes
https://github.com/kubernetes/kubernetes/issues/44041
Regarding to the concept of both keys I think the mapping is reasonable.

Following are my steps to reproduce, I am runing a 1.5 k8s on AWS.
```
$ kubectl version
Client Version: version.Info{Major:""1"", Minor:""5"", GitVersion:""v1.5.3"", GitCommit:""029c3a408176b55c30846f0faedf56aae5992e9b"", GitTreeState:""clean"", BuildDate:""2017-02-15T06:40:50Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""5"", GitVersion:""v1.5.6"", GitCommit:""114f8911f9597be669a747ab72787e0bd74c9359"", GitTreeState:""clean"", BuildDate:""2017-03-28T13:36:31Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/amd64""}
```
The compose file to use:
```
$ cat docker-compose.yaml 
version: ""2""

services:
  web:
    image: centos/httpd
    ports:
    - ""80""
    pid: ""host""
```
Deploy to k8s:
```
$ kompose up
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: web            
INFO Successfully created Deployment: web         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```
```
$ kubectl get po -o wide
NAME                   READY     STATUS    RESTARTS   AGE       IP            NODE
web-3376332856-6x0s1   1/1       Running   0          2m        10.244.2.41   ip-172-31-63-82.ec2.internal
$ kubectl exec -it web-3376332856-6x0s1 ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.2  38020  6104 ?        Ss   02:00   0:02 /sbin/init
root         2  0.0  0.0      0     0 ?        S    02:00   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    02:00   0:00 [ksoftirqd/0]
root         5  0.0  0.0      0     0 ?        S<   02:00   0:00 [kworker/0:0H]
root         6  0.0  0.0      0     0 ?        S    02:00   0:00 [kworker/u30:0]
root         7  0.0  0.0      0     0 ?        S    02:00   0:00 [rcu_sched]
root         8  0.0  0.0      0     0 ?        S    02:00   0:00 [rcu_bh]
root         9  0.0  0.0      0     0 ?        S    02:00   0:00 [migration/0]
root        10  0.0  0.0      0     0 ?        S    02:00   0:00 [watchdog/0]
```
And inside the node on which the pod runs:
```
ubuntu@ip-172-31-63-82:~$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.2  38020  6104 ?        Ss   02:00   0:02 /sbin/init
root         2  0.0  0.0      0     0 ?        S    02:00   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    02:00   0:00 [ksoftirqd/0]
root         5  0.0  0.0      0     0 ?        S<   02:00   0:00 [kworker/0:0H]
root         6  0.0  0.0      0     0 ?        S    02:00   0:00 [kworker/u30:0]
root         7  0.0  0.0      0     0 ?        S    02:00   0:00 [rcu_sched]
root         8  0.0  0.0      0     0 ?        S    02:00   0:00 [rcu_bh]
root         9  0.0  0.0      0     0 ?        S    02:00   0:00 [migration/0]
root        10  0.0  0.0      0     0 ?        S    02:00   0:00 [watchdog/0]
```
Verify pidMod of the container that k8s created:
```
root@ip-172-31-63-82:/home/ubuntu# docker ps |grep web
ba562a75a72a        centos/httpd                                          ""/run-httpd.sh""          4 minutes ago       Up 4 minutes                            k8s_web.dc333111_web-3376332856-6x0s1_default_939512e9-45ac-11e7-bd4c-129b80d9a4d4_ef68db5f
26a72ad939ae        gcr.io/google_containers/pause-amd64:3.0              ""/pause""                 4 minutes ago       Up 4 minutes                            k8s_POD.d8dbe16c_web-3376332856-6x0s1_default_939512e9-45ac-11e7-bd4c-129b80d9a4d4_590b466b
root@ip-172-31-63-82:/home/ubuntu# docker inspect ba562a75a72a|grep -i pid
            ""Pid"": 14082,
            ""PidMode"": ""host"",
            ""PidsLimit"": 0,
```.
 @gitlawr yes came across this issue then realized that it was problem with the k8s I was using! It is problem of `1.6.0`.

Rebase and I think we can go ahead with it!.
 Rebased and resolved the conflict..
 "
,,616,"Add provider to file output.
 Adds the provider name to the file output. For example:

```sh
INFO OpenShift file ""frontend-service.yaml"" created
INFO OpenShift file ""redis-master-service.yaml"" created
INFO OpenShift file ""redis-slave-service.yaml"" created
INFO OpenShift file ""frontend-deploymentconfig.yaml"" created
INFO OpenShift file ""frontend-imagestream.yaml"" created
INFO OpenShift file ""redis-master-deploymentconfig.yaml"" created
INFO OpenShift file ""redis-master-imagestream.yaml"" created
INFO OpenShift file ""redis-slave-deploymentconfig.yaml"" created
INFO OpenShift file ""redis-slave-imagestream.yaml"" created
```.
 @cdrage code LGTM, also you will have to update the docs!.
 @surajssd Will do once this is merged! :)

@surajnarwade @kadel please review!.
 "
,,615,"Remove version column from conversion document.
 Removes the version column in order to expand the width of the
conversion document as well as indicate that the table expands on ALL
versions (1,2,3).
 after expanding width, table looks good now.
 Table looks like this right now!
![screenshot from 2017-05-29 15-18-45](https://cloud.githubusercontent.com/assets/5815795/26545156/2e2958a0-4482-11e7-9052-d671f5269337.png)
.
 @surajssd Ah shoot. I'll fix it..
 @surajssd @surajnarwade Fixed. I've also added spacing for those reading directly from a non-formatted markdown file.

Feel free to check it out now..
 https://github.com/cdrage/kompose/blob/update-table/docs/conversion.md.
 cool this LGTM!.
 "
,,614,"Unable to run `make test-openshift`.
 Seems it's saying it's missing a command?

```
Testing buildconfig on kompose


Running kompose up ...

Error: unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/examples/buildconfig/docker-compose.yml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/examples/buildconfig/docker-compose.yml"" for ""kompose""
FAIL: kompose up has failed

Running tests with entrypoint/command option


Running kompose up ...

Error: unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test_in_openshift/compose-files/docker-compose-command.yml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test_in_openshift/compose-files/docker-compose-command.yml"" for ""kompose""
FAIL: kompose up has failed

Testing kompose up/down with etherpad docker-compose file


Running kompose up ...

Error: unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad/docker-compose.yml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad/docker-compose.yml"" for ""kompose""
FAIL: kompose up has failed

Running tests for replica option

Error: unknown command ""2"" for ""kompose""

Did you mean this?
        up

Run 'kompose --help' for usage.
unknown command ""2"" for ""kompose""

Did you mean this?
        up

FAIL: kompose up has failedMakefile:62: recipe for target 'test-openshift' failed
```

Bit confused on what's happening..
 Looks like '--emptyvols' is broken. OpenShift tests pass --emptyvols while  running `kompose up`:

```
$ kompose version
0.7.0 (c25b7e8)
```

```
$ kompose --provider=openshift --emptyvols -f examples/docker-compose.yaml up
Error: unknown command ""examples/docker-compose.yaml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""examples/docker-compose.yaml"" for ""kompose""
```

Without --emptyvols, `kompose up` runs fine:
```
$ kompose --provider=openshift -f examples/docker-compose.yaml up
INFO We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 
 
INFO Deploying application in ""myproject"" namespace 
INFO Successfully created Service: frontend       
INFO Successfully created Service: redis-master   
INFO Successfully created Service: redis-slave    
INFO Successfully created DeploymentConfig: frontend 
INFO Successfully created ImageStream: frontend   
INFO Successfully created DeploymentConfig: redis-master 
INFO Successfully created ImageStream: redis-master 
INFO Successfully created DeploymentConfig: redis-slave 
INFO Successfully created ImageStream: redis-slave 

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.

$ kompose --provider=openshift -f examples/docker-compose.yaml down
INFO Deleting application in ""myproject"" namespace 
INFO Successfully deleted Service: frontend       
INFO Successfully deleted Service: redis-master   
INFO Successfully deleted Service: redis-slave    
INFO Successfully deleted DeploymentConfig: frontend 
INFO Successfully deleted ImageStream: frontend   
INFO Successfully deleted DeploymentConfig: redis-master 
INFO Successfully deleted ImageStream: redis-master 
INFO Successfully deleted DeploymentConfig: redis-slave 
INFO Successfully deleted ImageStream: redis-slave 

```.
 @surajnarwade , think this is the same issue you faced too..
 @ashetty1 yeah.
 Can we close this?.
 @ashetty1 Yup. Thank you..
 "
,,613,"Fix incorrect tag in BuildConfig..
 For services with build and image keys DeploymentConfig respects tag from docker-compose image key.
But BuildConfig image tag was always set to  'latest'.
Result of this was that deployment wasn't trigired after successful build.
This fixes it by setting BuildConfig output image tag to the same tag that is used for  DeploymentConfig (tag from docker-compose image key)

fixes #611 .
 This PR includes small refactoring for `TestInitBuildConfig` function.
The way it was done before was making it hard to add new test for new services..
 LGTM :+1: .
 LGTM :+1: .
 "
,,612,"Update `kompose completion`.
 Updates Kompose completion with neutral language (using shell instead of
bash).

Fixes the indentation issues when outputting `kompose completion --help`.
 lgtm :+1: .
 "
,,611,"image tag name absent from generated imagestream config.
 On running `kompose up --provider openshift` the image build is completed, but the container never starts. All I see on `oc get pods` is:

```
myproject   web-1-build                     0/1       Completed           0          10m
```

On manually triggering the container through `oc rollout latest dc/web`, I get 
```
Error from server (BadRequest): cannot trigger a deployment for ""web"" because it contains unresolved images
```
On checking `oc edit is web` I get 
```
spec: {}
```

so then on checking `oc get is` I see:
```
web           172.30.1.1:5000/myproject/web           latest    20 minutes ago
```
But my docker compose file contains the following info:

```
<snip>
  web:
    restart: always
    build:
      context: lib/backend
      args:
        BACKEND_SERVER_PORT: $BACKEND_SERVER_PORT
    env_file: .env
    image: sarjitsu:backend
    ports:
    - ""${BACKEND_PORT_MAPPING}:${BACKEND_SERVER_PORT}""
    depends_on:
...
</snip>
```

The `:backend` tag should've been applied to the image, but that field `spec` in `is` is empty. Hence we see `..because it contains unresolved images` and no container launches.

We could workaround this through `oc edit dc web` ..by changing `name: web:backend` to `name: web:latest`  like this:

```
  test: false
  triggers:
  - type: ConfigChange
  - imageChangeParams:
      automatic: true
      containerNames:
      - web
      from:
        kind: ImageStreamTag
        name: web:latest
        namespace: myproject
      lastTriggeredImage: 172.30.1.1:5000/myproject/web@sha256:a906e1715d23ac84f431c565cd32ee148b997d49bf8b5a529351f2a1c2a812e7
    type: ImageChange
```

Conclusion is, the tag `:backend` is not appearing in image stream, but is present in deployment config.

The same error could be verified by checking contents of `web-imagestream.yaml`  when generating config files `kompose convert -f docker-compose.yml  --provider openshift` ..where the `:backend` tag is absent :
```
apiVersion: v1
kind: ImageStream
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: web
  name: web
spec: {}
status:
  dockerImageRepository: """"
``` 

### Versions

#### kompose
0.6.0 (HEAD)
(built from repo's master branch)

#### openshift
```
oc v1.5.0
kubernetes v1.5.2+43a9be4
features: Basic-Auth GSSAPI Kerberos SPNEGO

Server https://10.209.68.209:8443
openshift v1.5.0+031cbe4
kubernetes v1.5.2+43a9be4
```

### Supplementary info
Docker compose config being referred to in here, is at https://github.com/arcolife/sarjitsu/blob/master/docker-compose.yml#L82-L103

### Related

Not sure this should be the way it is, but a tangentially related issue is that [this image name `sarjitsu:backend`](https://github.com/arcolife/sarjitsu/blob/non-root/docker-compose.yml#L63) is not appearing anywhere in openshift's imagestreams / pod names, while It appears that way when using docker-compose:
```
sarjitsu_web_1           /docker-entrypoint.sh backend    Up      0.0.0.0:9704->80/tcp   
```

Rather, it's all based out of the service names I assign, like `web:backend`

cc/ @procrypt @surajnarwade @containscafeine .
 I *believe* we'll be fixing this in #521 .. See one of the comments in regards to ImageStream. I'm using https://github.com/novln/docker-parser in order to fix the problem with tags not being added correctly..
 Oh okay. That 521 thread seems like a pretty huge deal, so I'll wait.. 

docker-parser looks interesting. thanks!.
 The issue here is that image tag is not correctly propagated to BuildConfig. 

DeploymentConfig is correctly set to watch `backend` tag in this case, but BuildConfig is pushing image to `latest` tag. If `image` with tag was set in docker-compse.yaml we should respect that. In this case BuildConfig should output to `web:backend`.

.
 @cdrage I don't think this is related to  #521, as it looks like a bug in how BuildConfig is generated..
 @arcolife @cdrage Just created new PR #613 that should fix this..
 precisely so :) https://github.com/kubernetes-incubator/kompose/pull/613/files#diff-91f3ad308c13930dc408cd92991debeaR248 .
 Reason: cannot trigger a deployment for ""dbtest-220"" because it contains unresolved images 

This is error I get. Is this related..
 "
,,610,"Add support for 'pid' key.
 In compose file, [pid](https://docs.docker.com/compose/compose-file/#pid) key is merely used to set the PID mode to the host PID mode (and no support for pid=container:id). Therefore I think it can be converted to [Pod.Spec.HostPid](https://kubernetes.io/docs/resources-reference/v1.6/#podspec-v1-core) in K8s..
 @gitlawr , but k8s spec is boolean here.
 yes, but it seems to be the same in compose file, you choose pid='host' or not.
 @surajssd @kadel thoughts ?.
 It should be fine.. `if pid==""host` make the boolean true in k8s....
 "
,,609,"Validate dockerfilepath in buildconfig.
 This PR will resolve #594 by validating dockerfilepath based on whether
it is relative path or not..
 cc @cdrage @kadel @surajssd needs review.
 hmm, I can't make it work :-( 

```yaml
version: ""2""

services:
    foo:
        build:
          context: ""./build""
          dockerfile: /Dockerfile
        image: ""tomaskral/foobar""
        command: ""sleep 3600""
```
output:
```
▶ kompose --provider openshift convert --stdout
apiVersion: v1
items: null
kind: List
metadata: {}
```.
 @surajnarwade same issue as @kadel 

```
github.com/kubernetes-incubator/kompose  pr_609 ✔                                                                                                                                                                                                                            7d  
▶ ./kompose --provider=openshift convert --stdout 
apiVersion: v1
items: null
kind: List
metadata: {}

```.
 @cdrage @kadel, can you please try now, i have updated the PR.
 @ashetty1 can you see if this PR works for you and solve your issue then we can go ahead with it, otherwise the code LGTM, but if @ashetty1 gives a +1 we can merge it, also @surajnarwade can you please also write command line tests?.
 @cdrage updated PR with required changes,
@ashetty1 , your review needed..
 LGTM @surajnarwade .
 LGTM.
 "
,,608,"Add support for stop_grace_period.
 To solve #440
This commit Add support for stop_grace_period which maps to
Pod.Spec.TerminationGracePeriodSeconds
Updated conversion.md on support for the key.
 @gitlawr , LGTM :+1: , let's wait for one more lgtm.
 @gitlawr thanks for this PR really appreciate it, apart from the above comment everything else LGTM!.
 Updated and rebased. Thanks for the reviews!.
 @gitlawr Thanks again for your contribution! We're inching closer and closer to full key coverage thanks to you! :+1: .
 LGTM.
 "
,,607,"Add design decisions for contributors.
 It would be great to have certain design decisions in a developers doc or CONTRIBUTING.md suggesting the conventions being followed throughout the project.

One would not to use `log.Fatal` at places, instead pass the error up the call stack.
Another would be to use the `errors` package to wrap and pass the errors up the stack..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,606,"Replace underscores with dashes while rendering container names.
 Kubernetes container names must match the regex [a-z0-9]([-a-z0-9]*[a-z0-9])?
This excludes underscores, which is common in container names in compose. Given this docker compose file
```
version: '2'
services:
  app:
    build: app
    container_name: forest_app
    image: app
```
Before this patch, compose generates this deployment
```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  name: app
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: app
    spec:
      containers:
      - image: app
        name: forest_app
        resources: {}
      restartPolicy: Always
status: {}
```
After the patch, it generates
```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  name: app
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: app
    spec:
      containers:
      - image: app
        name: forest-app
        resources: {}
      restartPolicy: Always
status: {}
```
The CLI output:
```
# ./kompose -f test.yaml convert
INFO Container name in docker-compose has been changed from ""forest_app"" to ""forest-app""
WARN Kubernetes provider doesn't support build key - ignoring
INFO file ""app-service.yaml"" created
INFO file ""app-deployment.yaml"" created
```.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Signed!.
 @achanda This looking great! Code LGTM :+1: :100: .
 @cdrage I took the liberty of refactoring this so that we call the normalization code only once..
 @achanda thanks for the PR, apart from that nit code LGTM!.
 @surajssd thanks, done!.
 @achanda LGTM.
 @achanda awesome!.
 "
,,605,"Add support for providing URL.
 Would be awesome to be able to supply:
```
kompose up -f https://foobar.com/docker-compose.yaml
```

As an input!

@containscafeine .
 Looks cool:smirk_cat:, what if 'build' is used in the file.
 @gitlawr valid point though! It will fail maybe!.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 "
,,604,"Failing test should show diff.
 If one test in  `make test-cmd` fails it just shows following message:
```
FAIL: converted output does not match
```

It is quite annoying to debug why this test is failing because you have to run it again manually to catch output and do `diff` with the expected output.

Diff should be shown automatically for..
 I totally agree. It's annoying to not know what's exactly wrong between the two :-1: .
 taking this up :).
 @cdrage @kadel we can close this as #638 is merged now .
 "
,,603,"PVC name changes if volumes containes .(dot) in it.
 If the `docker-compose.yml` has `volumes` defined like this 
```yaml
   volumes:
     - .:/code
```
Then `pvc` generated by `kompose` will be like `.-persistentvolumeclaim.yaml`. This PR handles the `.(dot)` in the `pvc` name.

`docker-compose.yml` file used
```yaml
web:
  image: flask_web      
  command: python app.py
  ports:
   - ""5000:5000""
  volumes:
   - .:/code
  links:
   - redis
redis:
  image: redis
```
Master output
```bash
$ kompose convert -f volume.yml -o sample/
INFO file ""sample/redis-service.yaml"" created     
INFO file ""sample/web-service.yaml"" created       
INFO file ""sample/redis-deployment.yaml"" created  
INFO file ""sample/web-deployment.yaml"" created    
INFO file ""sample/.-persistentvolumeclaim.yaml"" created 
```
This PR output.
```bash
$ kompose convert -f volume.yml -o config/
INFO file ""config/redis-service.yaml"" created     
INFO file ""config/web-service.yaml"" created       
INFO file ""config/redis-deployment.yaml"" created  
INFO file ""config/web-deployment.yaml"" created    
INFO file ""config/web-claim0-persistentvolumeclaim.yaml"" created
```

Fixes: #584 

cc: @surajssd @cdrage @surajnarwade .
 All tests are passing locally..
 @procrypt Nope, they're not. Travis still says failing..
 @procrypt update the fixtures with the latest code changes, I mean regenerate them again, it seems that it is taking name of fixture as ''.""..
 @procrypt openshift output matches but k8s does not?.
 @surajssd Test are passing locally..
 @procrypt Doesn't matter if tests are passing locally or not, it has to  pass on Travis in order to get approval. You may have to run these tests manually and troubleshoot to figure out what may be the issue..
 @cdrage I have no idea why kubernetes test is failing on travis :(
@kadel can you please take a look at it.
.
 Yeh, this will be quite hard to debug.
It might be time look at https://github.com/kubernetes-incubator/kompose/issues/604 it will make it easier to debug issues like this.
 @procrypt tests are failing locally for me with kubernetes. I see that the patch fixes the bug; so it could be a case where the output file you are comparing against is incorrect?.
 @surajssd @cdrage @kadel @ashetty1 Ping all tests are passing now..
 LGTM .
 The commit message needs to framed better also the extra tab space makes it look more weird.
 tried running this locally, it fails for some reason:

The test fails:

```bash
$ kompose version
0.6.0 (6faa732)

$ make test-cmd 
./script/test/cmd/tests.sh
...
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert -f
/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/change-in-volume/docker-compose.yml
--stdout -j' expected_output:
'/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/change-in-volume/output-k8s.json'
expected_warning: 'Volume mount on the host ""."" isn't supported - ignoring path on the host'
FAIL: converted output does not match
...
```

So when I tried re-generating the `output-k8s.json` it is not generating `labels`.

regenerate:

```bash
✔ ~/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/change-in-volume [pr_603 L|✔] 
12:02 $ kompose convert --stdout -j > ./output-k8s.json 
WARN Volume mount on the host ""."" isn't supported - ignoring path on the host 
✔ ~/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/change-in-volume [pr_603 L|✚ 1] 
```

diff:

```diff
$ git diff
diff --git a/script/test/fixtures/change-in-volume/output-k8s.json b/script/test/fixtures/change-in-volume/output-k8s.json
index ea27825..6ee4489 100644
--- a/script/test/fixtures/change-in-volume/output-k8s.json
+++ b/script/test/fixtures/change-in-volume/output-k8s.json
@@ -61,10 +61,7 @@
       ""apiVersion"": ""extensions/v1beta1"",
       ""metadata"": {
         ""name"": ""redis"",
-        ""creationTimestamp"": null,
-        ""labels"": {
-          ""io.kompose.service"": ""redis""
-        }
+        ""creationTimestamp"": null
       },
       ""spec"": {
         ""replicas"": 1,
@@ -95,10 +92,7 @@
       ""apiVersion"": ""extensions/v1beta1"",
       ""metadata"": {
         ""name"": ""web"",
-        ""creationTimestamp"": null,
-        ""labels"": {
-          ""io.kompose.service"": ""web""
-        }
+        ""creationTimestamp"": null
       },
       ""spec"": {
         ""replicas"": 1,
```.
 @surajssd can you review it again when you get some time, I have updated the PR..
 waiting on @cdrage to approve and merge!.
 Awesome :).
 LGTM :+1: .
 @cdrage you need to approve to merge this!.
 "
,,602,"remove duplicate import with different name.
 `k8s.io/kubernetes/pkg/api` is imported directly and once with the alias import name `kapi` so remove the original import and keep the aliased with `kapi` one and also replace the code bits which call it with `api` name..
 LGTM..
 @cdrage you will have to approve it to merge it!.
 @surajssd Got to wait for one more approval.

@surajnarwade @kadel @containscafeine @rtnpro ?.
 @cdrage thanks :+1:.
 @surajssd Try to wait until 2 people approve it :+1: before any merges :).
 @cdrage sure ! I thought this is smaller one, with mainly name changes so merged it!.
 "
,,601,"Updated Vendoring.
 It resolves issues #474 and #589 which were coming from libcompose,
as well as resolves #440 and #437 partially as `group_add` & `stop_grace_period`
are supported by libcompose now..
 LGTM! :+1: .
 @surajnarwade also comment on each issue you mentioned with the their failing example if it is passing? Also why do you say #440 and #437 is partially fixed?.
 "
,,600,"Add v3 support of Docker Compose.
 This does a major refactor on the compose.go functions as well as brings
in a new era of v3 support to Kompose.

Similar to how we utilize libcompose, we utilize docker/cli's ""stack
deploy"" code which has a built-in v3 parser. We convert the parsed
structure to our own and then convert it to Kubernetes/OpenShift
artifacts..
 FYI, this is a work-in-progress..
 Hey @cdrage.  Just curious, did you guys decide to not wait for libcompose to update to v3 and just start consuming code directly from docker?  Have you found it to be robust enough to consume as a library so far?.
 @jritsema Yes, and no.

*Ideally* we would like to use libcompose. Essentially we only use libcompose in order to correctly parse the docker compose file into a proper Go struct, that's it. We could actually possibly integrate our *own* code in the future to parse the docker-compose file into a proper structure.

So essentially, it ends up being easy to simply use http://github.com/docker/cli instead of http://github.com/docker/libcompose because we don't need the ""deployment"" functionality of libcompose, only the parsing capability.

Funny enough, the code is *very* similar! 

See: https://github.com/docker/cli/blob/master/cli/compose/types/types.go#L72 vs https://github.com/docker/libcompose/blob/56b0613aac7d6d524d29dacb6b4221b5e4618d45/config/types.go#L87.
 Interesting, thanks @cdrage.  So does it support all of the compose semantics like multiple compose files and extends, etc?

https://docs.docker.com/compose/extends/.
 @jritsema At the moment, no, but *eventually*....
 So the POC works now! You're able to go ahead and convert your v3 Docker Compose file to Kubernetes / OpenShift artifacts.

Feel free to pull / build this PR and use it!

At the moment there are some missing parts (mem_limit, CPUQuota, etc.) that I need to figure out before it's 100% complete. .
 Unfortunately I have to also update the vendoring to a higher version of docker/docker due to the cli being split into docker/cli. Need to resolve conflicts!.
 DONE! :100: 

Tests have been added (integration and unit tests). All aspects of conversion has been added too (with the exception of build, see the in-line code comment on why build does not work yet with v3, need to fix this upstream and a new issue opened after this PR is merged).

More tests can be written to encompass everything, but I want this merged / put in Kompose ASAP so people can test it out / use it. Even if it means putting a ""beta"" disclaimer when v3 is detected.

Another thing is that I re-organized much of the `compose.go` code to separate between v1/v2 and v3 of compose. In the future, it should be refactored again (ideally in different files).

Please feel free to test this out and review it! There's a lot happening in this PR.

@kadel @jritsema @surajnarwade @surajssd @containscafeine 

.
 Any of you mind doing a review? :)

@kadel @jritsema @surajnarwade @surajssd @containscafeine.
 @containscafeine 
Thanks for the review, I've gone ahead and updated my PR!.
 @cdrage can you rebase it on current master?.
 @surajssd Already been re-based :).
 So I've gone ahead and abstracted everything to it's own folder so it's a tad more organized as per @surajssd 's comments!

It looks like he'll be away for a while however, @surajnarwade or @kadel wanna take a look at this?.
 @containscafeine DONE! Everything's been separated into it's own file so it's easier to understand / place everything if it's either v1/v2 conversion or v3.

One LGTM :+1: down, @surajssd @kadel @surajnarwade Want to take a second look? .
 @kadel @surajssd 

For missing the env variables: they now appear in the script/test/fixtures/v3/output* as well as I have added an explicit test for them.

A full example for v3 support is located here: `script/test/fixtures/v3/docker-compose-full-example.yaml`.

I've also added the normalizeVolumeNames as well as another explicit test on volumes..
 @kadel @surajnarwade @surajssd @containscafeine 

For secondary review!.
 This is great work! Thanks a bunch!.
 @kadel made the change for vol target! :+1: .
 "
,,599,"Volume mount on the host isn't supported .
 Hi!
I'm using  [https://github.com/docker/notary/blob/master/docker-compose.yml](docker-compose.yml)  Docker Notary. My plan is deploy the Docker Notary Server on Openshift so I'm using 
`kompose -f docker-compose.yml --provider openshift up -v` but the volumes keep ever in pending state.

Also when I use `kompose -f docker-compose.yml --provider openshift down -v` 
I'm having this warning that I'm not sure if is important or not to (sorry I'm still new with containers things)

> WARN Volume mount on the host ""./notarysql/mysql-initdb.d"" isn't supported - ignoring path on the host 

How can I fix this issue? I appreciate any comment .
 @judavi 
Hi!

Just to make sure, but have you created any PersistentVolume's before you've used the PersistentVolumeClaims (what Kubernetes is creating within OpenShift).
 @cdrage 
thanks man for the response!
now that you mention, even if a try to create a persistent volume manually it keeps in pending state so my issue looks like it's not directly related with kompose

![image](https://cloud.githubusercontent.com/assets/1766933/26005314/99df7a52-3730-11e7-9588-608008748ffa.png)
.
 @judavi Here is what I did to deploy the app on openshift

I created the config here with help of kompose but it has few tweaks(added the configmap where host mount is done in mysql deploymentconfig and also there is issue with reading the info about git repo, so update the buildconfigs):

Link to following big config file from [pastebin](http://pastebin.centos.org/92276/):

<details>

```yaml
$ cat config.yaml
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: mysql
    name: mysql
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: mysql
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: server
    name: server
  spec:
    ports:
    - name: ""8080""
      port: 8080
      targetPort: 8080
    - name: ""4443""
      port: 4443
      targetPort: 4443
    selector:
      io.kompose.service: server
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: signer
    name: signer
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: signer
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: mysql
    name: mysql
  spec:
    replicas: 1
    selector:
      io.kompose.service: mysql
    strategy:
      resources: {}
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: mysql
      spec:
        containers:
        - args:
          - mysqld
          - --innodb_file_per_table
          env:
          - name: TERM
            value: dumb
          - name: MYSQL_ALLOW_EMPTY_PASSWORD
            value: '""true""'
          image: ' '
          name: mysql
          resources: {}
          volumeMounts:
          - mountPath: /docker-entrypoint-initdb.d
            name: mysql-config
          - mountPath: /var/lib/mysql
            name: notary-notary-data
        restartPolicy: Always
        volumes:
        - name: mysql-config
          configMap:
            name: mysql
        - name: notary-notary-data
          persistentVolumeClaim:
            claimName: notary-notary-data
    test: false
    triggers:
    - type: ConfigChange
    - imageChangeParams:
        automatic: true
        containerNames:
        - mysql
        from:
          kind: ImageStreamTag
          name: mysql:10.1.10
      type: ImageChange
  status: {}
- apiVersion: v1
  kind: ImageStream
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: mysql
    name: mysql
  spec:
    tags:
    - annotations: null
      from:
        kind: DockerImage
        name: mariadb:10.1.10
      generation: null
      importPolicy: {}
      name: 10.1.10
  status:
    dockerImageRepository: """"
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: mysql-claim0
    name: mysql-claim0
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: notary-notary-data
    name: notary-notary-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: server
    name: server
  spec:
    replicas: 1
    selector:
      io.kompose.service: server
    strategy:
      resources: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: server
      spec:
        containers:
        - args:
          - -c
          - ./migrations/migrate.sh && notary-server -config=fixtures/server-config.json
          command:
          - /usr/bin/env
          - sh
          image: ' '
          name: server
          ports:
          - containerPort: 8080
          - containerPort: 4443
          resources: {}
        restartPolicy: Always
    test: false
    triggers:
    - type: ConfigChange
    - imageChangeParams:
        automatic: true
        containerNames:
        - server
        from:
          kind: ImageStreamTag
          name: server:latest
      type: ImageChange
  status: {}
- apiVersion: v1
  kind: ImageStream
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: server
    name: server
  spec: {}
  status:
    dockerImageRepository: """"
- apiVersion: v1
  kind: BuildConfig
  metadata:
    creationTimestamp: null
    name: server
  spec:
    nodeSelector: null
    output:
      to:
        kind: ImageStreamTag
        name: server:latest
    postCommit: {}
    resources: {}
    runPolicy: Serial
    source:
      git:
        ref: master
        uri: https://github.com/docker/notary.git
      type: Git
    strategy:
      dockerStrategy:
        dockerfilePath: server.Dockerfile
      type: Docker
    triggers:
    - type: ConfigChange
    - type: ImageChange
  status:
    lastVersion: 0
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: signer
    name: signer
  spec:
    replicas: 1
    selector:
      io.kompose.service: signer
    strategy:
      resources: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: signer
      spec:
        containers:
        - args:
          - -c
          - ./migrations/migrate.sh && notary-signer -config=fixtures/signer-config.json
          command:
          - /usr/bin/env
          - sh
          image: ' '
          name: signer
          resources: {}
        restartPolicy: Always
    test: false
    triggers:
    - type: ConfigChange
    - imageChangeParams:
        automatic: true
        containerNames:
        - signer
        from:
          kind: ImageStreamTag
          name: signer:latest
      type: ImageChange
  status: {}
- apiVersion: v1
  kind: ImageStream
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: signer
    name: signer
  spec: {}
  status:
    dockerImageRepository: """"
- apiVersion: v1
  kind: BuildConfig
  metadata:
    creationTimestamp: null
    name: signer
  spec:
    nodeSelector: null
    output:
      to:
        kind: ImageStreamTag
        name: signer:latest
    postCommit: {}
    resources: {}
    runPolicy: Serial
    source:
      git:
        ref: master
        uri: https://github.com/docker/notary.git
      type: Git
    strategy:
      dockerStrategy:
        dockerfilePath: signer.Dockerfile
      type: Docker
    triggers:
    - type: ConfigChange
    - type: ImageChange
  status:
    lastVersion: 0
kind: List
metadata: {}
```

</details>

After that creating a project that allows anyuid to run on the openshift:

```bash
oc login -u developer -p developer
oc new-project not
oc login -u system:admin
oc adm policy add-scc-to-user anyuid -n not -z default
oc login -u developer -p developer
```

Create a config map so that mysql comes up properly (in the [notary repo](https://github.com/docker/notary/))

```bash
cd notarysql/mysql-initdb.d/
oc create configmap mysql --from-file initial-notaryserver.sql --from-file initial-notarysigner.sql 
```

And finally deploy the configs:

```bash
$ oc create -f config.yaml 
service ""mysql"" created
service ""server"" created
service ""signer"" created
deploymentconfig ""mysql"" created
imagestream ""mysql"" created
persistentvolumeclaim ""mysql-claim0"" created
persistentvolumeclaim ""notary-notary-data"" created
deploymentconfig ""server"" created
imagestream ""server"" created
buildconfig ""server"" created
deploymentconfig ""signer"" created
imagestream ""signer"" created
buildconfig ""signer"" created
```

This all comes up nice and good the only problem is that there is some errors like this in `server` pod:


```bash
$ oc logs server-1-kx851
[SNIP]

{""level"":""error"",""msg"":""Trust not fully operational: rpc error: code = 14 desc = grpc: the connection is unavailable"",""time"":""2017-05-15T14:02:46Z""}
{""level"":""error"",""msg"":""Trust not fully operational: rpc error: code = 14 desc = grpc: the connection is unavailable"",""time"":""2017-05-15T14:02:56Z""}
{""level"":""error"",""msg"":""Trust not fully operational: rpc error: code = 14 desc = grpc: the connection is unavailable"",""time"":""2017-05-15T14:03:06Z""}
{""level"":""error"",""msg"":""Trust not fully operational: rpc error: code = 14 desc = grpc: the connection is unavailable"",""time"":""2017-05-15T14:03:16Z""}
2017/05/15 14:03:25 grpc: addrConn.resetTransport failed to create client transport: connection error: desc = ""transport: dial tcp: lookup notarysigner on 192.168.42.157:53: server misbehaving""; Reconnecting to {notarysigner:7899 <nil>}
{""level"":""error"",""msg"":""Trust not fully operational: rpc error: code = 14 desc = grpc: the connection is unavailable"",""time"":""2017-05-15T14:03:26Z""}

[SNIP]
```.
 @surajssd WOW!!! thanks man ! this guide is really helpful for me!!
I will try with your solution and let you know if could fix the final issue. Thanks!.
 @surajssd I'm still stuck with ""Trust not fully operational: rpc error"" error. Did you have luck finding a solution?.
 I'm sure that is related with the alias from the docker-compose file but I'm not sure how deal with aliases in OpenShift
![image](https://cloud.githubusercontent.com/assets/1766933/26346026/ce0c0e02-3f9c-11e7-92af-92dd8b0175b1.png)
.
 @surajssd the problem it's that! so to fix that issue I update the code on https://github.com/docker/notary/blob/7c26a98a3ff2bef958850ae7a027435fdb5f010d/fixtures/server-config.json to not use the alias (just use signer).

![image](https://cloud.githubusercontent.com/assets/1766933/26349210/02d75bbe-3fa7-11e7-88ed-582c626685c7.png)


Apart of that you need to update the default certs to include also signer as a valid alternative 

![image](https://cloud.githubusercontent.com/assets/1766933/26349050/8f32da1c-3fa6-11e7-9f59-b8ba4b56b8ff.png)

After that you just execute the script to rebuild the certs and after that you rebuild you signer server and that's all!


.
 @judavi hey if you blog about it tell us as well! :smiley: .
 @surajssd one question, after you create each one of the yaml configs how you start each one of the containers? at this moment I'm using - kompose up - but that rewrites any change made in the yaml configs from openshift so how you manually start each one of the containers?.
 @judavi I have converted once and then using following command:

```bash
oc create -f config.yaml 
```.
 "
,,598,"Remove 1.6 and 1.7 testing from Travis.
 Let's speed up travis by only testing against 1.8.

There hasn't been any problems with other version (1.6 and 1.7)
and Travis has been unbearibly slow.

Let's switch to only doing 1.8 (since Travis at times refuses to do all
three concurrently!)..
 NACK, I think we should keep those tests running because we package kompose for centos which has 1.6 and then we might not find the issues that exist with 1.6 if any..
 Ah, no worries then. I'll close this @surajssd didn't realize CentOS was on 1.6 ATM..
 "
,,597,"<docs> Update version number.
 Updates version number within setup installation instructions for docs.
 LGTM, merging!.
 "
,,596,"update generated artifacts for k8s and openshift so that env variables are loaded in a particular order.
 Fixes: #595 
cc: @surajssd .
 Although this sucks in terms of order, having ${FOOBAR} would be against what's promised in the spec file :( https://docs.docker.com/compose/compose-file/#args having $FOOBAR would help in terms of testing to *make sure* environment variables work..
 @cdrage , I didn't get what you said 
.
 @surajnarwade 

@procrypt Changed the variables to ${FOOBAR} from $FOOBAR. They should stay $FOOBAR.
 @procrypt yes that should not make any difference, keeping it without brackets `{` or `}` should be okay..
 @surajssd Updated..
 Ping @surajssd @cdrage @surajnarwade need review..
 This means that we are no longer testing doceker-compose files with evn variables in map?.
 Tests are failing :( Isn't this PR only re-organizing the env variables in the tests? I don't believe it's removing them? @kadel .
 If I'm looking correctly this PR changes env vars. in all docker-compose files from map to array no?.
 @kadel Yes..
 @kadel Some file [1](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/restart-options/docker-compose-restart-no.yml)  and [2](https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/restart-options/docker-compose-restart-onfail.yml) has not been changed. .
 ping @cdrage @surajssd updated PR.
 LGTM.
 @kadel I might have dome it by mistake, updated the PR..
 @procrypt this change is done on basis of what code now? Also how is this sorting being done? Also if this sorting is done on basis of `env`'s `name` then I see bunch of them not sorted!

![screenshot from 2017-06-14 12-20-53](https://user-images.githubusercontent.com/5815795/27119070-f8527370-50fb-11e7-8d70-078312c10655.png)


See the screenshot above, like `DB_HOST` is before `DB_DBID` which wrong sorting!.
 @surajssd I'm checking it..
 @surajssd once #631 gets merged this issue will be solved. I have updated #631 and it already have 2 LGTM can you PTAL and merge it soon..
 @surajssd Ping.
 @procrypt please rebase on current master, lot of new changes have been added since morning, and also update the commit message since we are just updating the fixtures/configs and not changing the docker-compose!

For me lot of tests fail, not sure why!.
 @surajssd rebased.
 @procrypt tests pass for me, please update the commit message since we are not changing docker-compose file?.
 @surajssd Done..
 @procrypt but seems like it needs rebase now .
 @surajssd Rebased..
 LGTM :)
.
 "
,,595,"environment variables are populated in random order in the created artifacts..
 If we are loading the some variables from the environment to `docker-compose` file they get populated in any random order. This is generates different output every time when we run `kompose convert --stdout`.   .
 "
,,594,"`kompose convert` should validate dockerfilepath .
 Would it be possible for `dockerfilepath` to be validated with `kompose convert` on OpenShift? Suppose an absolute path is provided instead of relative path, it gets detected only with `oc create`. 

docker-compose file here:
```
version: ""2""

services:
 foo:
  build:
   context: ""../../script/test_in_openshift/buildconfig""
   dockerfile: ""/Dockerfile""
  command: ""sleep 120""
```
...
```
$ kompose version
0.6.0 (ebd9dcf)

$ kompose --provider=openshift -f examples/buildconfig/docker-compose.yml convert -o /tmp/bc2
INFO Buildconfig using https://github.com/kubernetes-incubator/kompose.git::master as source.

$ oc create -f /tmp/bc2
Error from server: BuildConfig ""foo"" is invalid: spec.strategy.dockerStrategy.dockerfilePath: Invalid value: ""/Dockerfile"": dockerfilePath must be a relative path within your source location
```



.
 @ashetty1 yes this should be done, thanks for reporting!.
 @surajssd @ashetty1 , I will take this up.
 "
,,593,"Is this a case of buildconfig contextDir being incorrectly set?.
 My docker-compose file:

```
version: ""2""

services:
 foo:
  build:
   context: ""./build""
  command: ""sleep 120""

```
And when I run `kompose convert`:

```
""runPolicy"": ""Serial"",
        ""source"": {
          ""type"": ""Git"",
          ""git"": {
            ""uri"": ""https://github.com/kubernetes-incubator/kompose.git"",
            ""ref"": ""master""
          },
          ""contextDir"": ""examples/buildconfig/examples/buildconfig/build""
        },
        ""strategy"": {
          ""type"": ""Docker"",
          ""dockerStrategy"": {}
```

I don't see the same behaviour with this docker-compose file:

```
version: ""2""

services:
 foo:
  build: ""./build""
  command: ""sleep 120""
```

The contextDir is set correctly with the above docker compose file:

```
 ""runPolicy"": ""Serial"",
        ""source"": {
          ""type"": ""Git"",
          ""git"": {
            ""uri"": ""https://github.com/kubernetes-incubator/kompose.git"",
            ""ref"": ""master""
          },
            ""contextDir"": ""examples/buildconfig/build""
        },
        ""strategy"": {
          ""type"": ""Docker"",
          ""dockerStrategy"": {}
        }
```
Can you please confirm, @surajnarwade .
 @ashetty1 , contextdir is same when I run both examples,

```
 contextDir: examples/buildconfig/build/
```

I think you didn't pull latest changes, becuase every time `contextdir` will have `/` at the end which is not reflecting in your output.
 Thanks, @surajnarwade..
 "
,,592,"Use old git command.
 Some versions of git don't have git-url (case in point on Debian 8, no
get-url on packaged git).

Use old command in getting URL..
 Yup, that was the stackoverflow link I used :+1: .
 LGTM!.
 "
,,591,"Problems running tests with latest master?.
 Seems that the tests are no longer working?

```
github.com/kubernetes-incubator/kompose  master ✔                                                                                                                                                                                                                            4d  
▶ ./kompose -f script/test/fixtures/etherpad/docker-compose.yml convert --stdout -j
WARN The DB_PORT variable is not set. Substituting a blank string. 
WARN The ROOT_PASS variable is not set. Substituting a blank string. 
WARN The DB_NAME variable is not set. Substituting a blank string. 
WARN The DB_PASS variable is not set. Substituting a blank string. 
WARN The DB_USER variable is not set. Substituting a blank string. 
WARN The DB_HOST variable is not set. Substituting a blank string. 
WARN The DB_NAME variable is not set. Substituting a blank string. 
WARN The DB_PASS variable is not set. Substituting a blank string. 
WARN The DB_PORT variable is not set. Substituting a blank string. 
WARN The DB_USER variable is not set. Substituting a blank string. 
ERRO Could not parse config for project etherpad : Service 'mariadb' configuration key 0 value Does not match format 'ports' 
FATA composeObject.Parse() failed, Failed to load compose file: Service 'mariadb' configuration key 0 value Does not match format 'ports' 
```.
 @cdrage , have you exported environment variables ?

```
export $(cat envs)
```

it works for me..
 @surajnarwade ARGHHH, I *always* forget about this. I need to add a note for this somewhere!.
 @cdrage Can we close this one? Or do you want to add a comment of some kind in tests?.
 "
,,590,"Failing when port is specified with labels.
 Resolves #522
Kompose will give FATAL error if labels are given but ports are not defined.
 cc @kadel @cdrage .
 @surajnarwade tests and docs update.
 @cdrage @surajssd needs review.
 LGTM :+1: .
 @surajnarwade tests and docs update.
 Would it be better if it return error here and leave the Fatalf() work to upper layer?
 I'm investigating https://github.com/kubernetes-incubator/kompose/issues/464 and I think logrus.Fatalf(...) may be a broker because it finally invokes os.Exit()
Anyway, returning an error consists with other parts of the codes:
https://github.com/surajnarwade/kompose/blob/8198246bd8363642800941be75a2b9bf414ee9b5/pkg/loader/compose/compose.go#L352.
 @gitlawr , `return error here`, I didn't get you .
 @surajnarwade 
I mean 
```
return kobject.KomposeObject{}, errors.New(""xxx defined in service xxx with no ports present. Issues may occur when bringing up artifacts."")
```
instead of
```
log.Fatalf(...)
```.
 @surajssd , needs review on this .
 @surajnarwade bear with me, also please add functional tests! so when I meant tests == (unit tests and functional tests).
 @cdrage , @surajssd I have updated PR with changes and added tests as well.
 @kadel @surajssd @containscafeine can you please test now.
 @cdrage review please :)
.
 All green now, @cdrage @surajssd .
 "
,,589,"crashes on launch.
 Crashes on launch. Note that removing the networks section fixes the problem. This bug occurs in version 0.6.0. I tried to build the project from HEAD but wasn't able to get it working.

version: '2'

services:
  dynamodb:
    image: deangiberson/aws-dynamodb-local
    expose:
    - 8000
    networks:
     - appnet

  redis:
    image: redis:3.0-alpine
    expose:
      - 6379
    networks:
     - appnet
  
  appseed1:
    image: justinhj/app:latest
    expose:
      - 1600
    environment:
      - APP_CONFIG=/app/appseed1.conf
    networks:
     - appnet

  appseed2:
    image: justinhj/app:latest
    ports:
      - 11080:11080
    expose:
      - 1601
    environment:
      - APP_CONFIG=/app/appseed2.conf
    networks:
     - appnet

  justapp:
    image: justinhj/app:latest
    environment:
      - APP_CONFIG=/app/justapp.conf
    networks:
     - appnet

networks:
  appnet:


justinhjmbp1:dockerlocal justinhj$ kompose -f docker-compose.yml convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x21f008c]

goroutine 1 [running]:
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleNetworkConfig(0xc4200c01c0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:292 +0x19c
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc4200c01c0, 0x7fff5fbffa23, 0x12, 0xc420092b00, 0x30c, 0x50c, 0xc4204cb340, 0xc4204cb340)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:245 +0x490
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc4200c01c0, 0x0, 0x0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:123 +0x162
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3673be8, 0xc42025a410, 0x1, 0x1, 0xc4201ef830, 0x0, 0xfeb5e8fa9faab678, 0xc4204cb9e0, 0x100141e)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:306 +0x10f
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc42025a410, 0x1, 0x1, ...)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:213 +0x145
github.com/kubernetes-incubator/kompose/cmd.glob..func3(0x3645be0, 0xc4201f1b40, 0x0, 0x2)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:85 +0x5a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x3645be0, 0xc4201f1ae0, 0x2, 0x2, 0x3645be0, 0xc4201f1ae0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:635 +0x23a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x3646060, 0xc42006e058, 0x0, 0xc4204cbf48)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:710 +0x339
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x3646060, 0x1, 0x1)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:669 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x20.
 @justinhj That is REALLY odd, how did you get the ""wikus"" log and all? Looks like you may have copied and pasted the wrong log from a different issue?.
 @justinhj @cdrage , error is due to root level `network` key and it's coming from libcompose which is tracked here, https://github.com/docker/libcompose/issues/456
same issue was reported earlier at https://github.com/kubernetes-incubator/kompose/issues/474.
 @surajnarwade Yup, but his logs say ""wikus"" and has the dropbox dir, which is my computer username.
 @cdrage , didn't get you ?.
 @surajnarwade 

For some reason, his logs show:
```
justinhjmbp1:dockerlocal justinhj$ kompose -f docker-compose.yml convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x21f008c]

goroutine 1 [running]:
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleNetworkConfig(0xc4200c01c0)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:292 +0x19c
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc4200c01c0, 0x7fff5fbffa23, 0x12, 0xc420092b00, 0x30c, 0x50c, 0xc4204cb340, 0xc4204cb340)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:245 +0x490
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc4200c01c0, 0x0, 0x0)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:123 +0x162
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3673be8, 0xc42025a410, 0x1, 0x1, 0xc4201ef830, 0x0, 0xfeb5e8fa9faab678, 0xc4204cb9e0, 0x100141e)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:306 +0x10f
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc42025a410, 0x1, 0x1, ...)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:213 +0x145
github.com/kubernetes-incubator/kompose/cmd.glob..func3(0x3645be0, 0xc4201f1b40, 0x0, 0x2)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:85 +0x5a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x3645be0, 0xc4201f1ae0, 0x2, 0x2, 0x3645be0, 0xc4201f1ae0)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:635 +0x23a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x3646060, 0xc42006e058, 0x0, 0xc4204cbf48)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:710 +0x339
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x3646060, 0x1, 0x1)
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:669 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x20
```

Which is actually from MY computer (hence the `wikus` part). So I'm asking whether or not he may of copied-and-pasted a different issue or if he actually had these errors appear on his computer..
 That is strange. Pretty sure I copied straight from my prompt and you can see my name at the start. I'll reproduce the error and check.
 I ran again and no wikus, so yeah it's possible something unintended happened when copy and pasting the issue. Here's the updated version...

justinhjmbp1:dockerlocal justinhj$ kompose convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x21f6a8c]

goroutine 1 [running]:
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleNetworkConfig(0xc42038c0e0)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:292 +0x19c
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc42038c0e0, 0x2880c6a, 0x12, 0xc420096580, 0x30c, 0x50c, 0xc4204df340, 0xc4204df340)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:245 +0x490
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc42038c0e0, 0x0, 0x0)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:123 +0x162
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x368df28, 0xc4203ad8f0, 0x1, 0x1, 0xc420051ef0, 0x0, 0x1040bfb, 0x20, 0x25865a0)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:306 +0x10f
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc4203ad8f0, 0x1, 0x1, ...)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:213 +0x145
github.com/kubernetes-incubator/kompose/cmd.glob..func3(0x365ff60, 0x368df28, 0x0, 0x0)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:85 +0x5a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x365ff60, 0x368df28, 0x0, 0x0, 0x365ff60, 0x368df28)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:635 +0x23a
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x36603e0, 0xc420072058, 0x0, 0xc4204dff48)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:710 +0x339
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x36603e0, 0x1, 0x1)
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:669 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
	/private/tmp/kompose-20170428-47922-jvhlih/kompose-0.6.0/main.go:22 +0x20.
 @justinhj 
Are you running this in a Docker container (I see /private/ as well as `dockerlocal` username).

Any way that we can re-produce this setup? (I think you're on Mac OS X?).
 No, dockerlocal is just the directory name. I'm running in Mac OS X terminal 

.
 @cdrage @justinhj , since #601 is merged now, issue has been resolved
I tried with above docker-compose file, it works well,

```
$ kompose convert -f docker-compose.yml 
WARN Unsupported root level networks key - ignoring 
WARN Unsupported networks key - ignoring          
INFO file ""appseed1-service.yaml"" created         
INFO file ""appseed2-service.yaml"" created         
INFO file ""dynamodb-service.yaml"" created         
INFO file ""justapp-service.yaml"" created          
INFO file ""redis-service.yaml"" created            
INFO file ""appseed1-deployment.yaml"" created      
INFO file ""appseed2-deployment.yaml"" created      
INFO file ""dynamodb-deployment.yaml"" created      
INFO file ""justapp-deployment.yaml"" created       
INFO file ""redis-deployment.yaml"" created 
```
.
 closing this one then!.
 "
,,588,"Adding tests for kompose-specific labels and buildconfig dockerfile construct.
 * Two new scripts testing kompose-specific labels have been added:
	script/test_in_openshift/tests/routes-service-expose-hostname.sh
	script/test_in_openshift/tests/routes-service-expose-true.sh

* Ability to run individual scripts: Changes have been made to script/test_in_openshift/run.sh
  for running individual scripts:

	Eg. ./script/test_in_openshift/run.sh script/test_in_openshift/tests/routes-service-expose-true.sh.
 Cc: @surajssd .
 Two random files seem to have been added @ashetty1 ?

Files `0` and `1`.
 @cdrage deleted them. thanks..
 @cdrage @containscafeine @kadel @surajnarwade please to review :).
 Build worked for me, but  test for `kompose.service.expose:True`  failed for me.
I got `FAIL: Route *.xip.io has not been exposed`



.
 I've tested this on the latest origin (master) as of today, and its using `nip.io` instead of `xip.io`.

It got changed here:
https://github.com/openshift/origin/commit/d7d3b7c67dbeea844389bf2d23aa8e4ded6088cc

So I guess this is going to work for older `oc` versions.
.
 "
,,587,"Unable to run tests.
 Not too sure why I'm getting this:
```
github.com/kubernetes-incubator/kompose  master ✔                                                                                   1d  
▶ make test-unit
go test -ldflags=""-w -X github.com/kubernetes-incubator/kompose/cmd.GITCOMMIT=abf8192"" -race -cover -v ./cmd/... ./pkg/... ./script/... .
script/kompose/vendor/k8s.io/kubernetes/pkg/master/thirdparty_controller.go:26:2: cannot find package ""k8s.io/kubernetes/pkg/apiserver"" in any of:
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/kompose/vendor/k8s.io/kubernetes/pkg/apiserver (vendor tree)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/apiserver
        /usr/local/go/src/k8s.io/kubernetes/pkg/apiserver (from $GOROOT)
        /home/wikus/dropbox/dev/go/src/k8s.io/kubernetes/pkg/apiserver (from $GOPATH)
script/kompose/vendor/k8s.io/kubernetes/pkg/master/thirdparty_controller.go:27:2: cannot find package ""k8s.io/kubernetes/pkg/registry/thirdpartyresource/etcd"" in any of:
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/kompose/vendor/k8s.io/kubernetes/pkg/registry/thirdpartyresource/etcd (vendor tree)
        /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/registry/thirdpartyresource/etcd
        /usr/local/go/src/k8s.io/kubernetes/pkg/registry/thirdpartyresource/etcd (from $GOROOT)
        /home/wikus/dropbox/dev/go/src/k8s.io/kubernetes/pkg/registry/thirdpartyresource/etcd (from $GOPATH)
Makefile:47: recipe for target 'test-unit' failed
make: *** [test-unit] Error 1

github.com/kubernetes-incubator/kompose  master ✔                                                                                                                                                                                                                           1d  ⍉
▶ go version
go version go1.8 linux/amd64
```.
 Ended up being a rogue folder in `script/kompose` that caused the issue. Deleting that made tests run! :+1: .
 "
,,586,"Fix link to fedora setup in docs.
 .
 LGTM.
 "
,,585,"Latest kompose fails on many build-config tests locally.
 Building kompose

```bash
✘-127 ~/go/src/github.com/kubernetes-incubator/kompose [master L|✔]
17:14 $ make install
go install -ldflags=""-w -X github.com/kubernetes-incubator/kompose/cmd.GITCOMMIT=abf8192""
✔ ~/go/src/github.com/kubernetes-incubator/kompose [master L|✔]
17:15 $ kompose version
0.6.0 (abf8192)
```

Running tests:

```bash
✔ ~/go/src/github.com/kubernetes-incubator/kompose [master L|✔]
17:15 $ make test-cmd
./script/test/cmd/tests.sh


===> Starting test <===
convert::expect_failure: Running: 'kompose -f /home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad/docker-compose.yml convert --stdout'
PASS: errored out with exit status: 1

[SNIP]

===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose --provider=openshift -f /home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/nginx-node-redis/docker-compose.yml convert --stdout -j' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/nginx-node-redis/output-os.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.'
FAIL: converted output does not match

```
Above failed.


Below one failed
```bash
[SNIP]

===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert --provider openshift --stdout -j' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/nginx-node-redis/output-os.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.'
FAIL: converted output does not match


===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert --provider openshift --stdout -j -f nginx-node-redis/docker-compose.yml' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/nginx-node-redis/output-os.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.'
FAIL: converted output does not match


===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert --provider openshift --stdout -j -f ../docker-compose.yml' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/nginx-node-redis/output-os.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.'
FAIL: converted output does not match

[SNIP]

===> Starting test <===
convert::expect_success: Running: 'kompose --provider=openshift convert --stdout -j' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/yaml-and-yml/yml/output-os.json'
PASS: converted output matches
Makefile:67: recipe for target 'test-cmd' failed
make: *** [test-cmd] Error 1
```

How is this one passing on travis or for anyone else on their machines?.
 @surajssd  It doesn't fail on travis because travis does a git fetch on PRs. So  ""expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.' "" works on travis, but not when you are checked into master..
 What is the solution so that i have all local tests passing?.
 @surajssd see if running on detached HEAD works.
 @surajssd , this PR https://github.com/kubernetes-incubator/kompose/pull/577 will sove this issue.
 closed via https://github.com/kubernetes-incubator/kompose/pull/577.
 "
,,584,"Error with volume name with generated deployment file.
 Following is my compose file 

```
web:
  image: flask_web      
  command: python app.py
  ports:
   - ""5000:5000""
  volumes:
   - .:/code
  links:
   - redis
redis:
  image: redis

```

It works well. Now I want to create deployment and services for this compose file. 
As mentioned in docs `kompose -f docker-compose.yml convert`
It generates 5 files 

```
INFO file ""redis-service.yaml"" created
INFO file ""web-service.yaml"" created
INFO file ""redis-deployment.yaml"" created
INFO file ""web-deployment.yaml"" created
INFO file "".-persistentvolumeclaim.yaml"" created
```

When trying to run the deployment, `kubectl create -f web-deployment.yaml` I get an error 

```
The Deployment ""web"" is invalid:
* spec.template.spec.volumes[0].name: Invalid value: ""."": a DNS-1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')
* spec.template.spec.containers[0].volumeMounts[0].name: Not found: "".""
```

Whats gone wrong? How to rectify? Redis works fine, issues with web. 

Files 

Web Deployment - https://gist.github.com/codecraf8/5d41c752658ac6c2ec348befa3b89356
Web Service - https://gist.github.com/codecraf8/4cf6d4a34b71d74a0856e4c2b0dde795
.-persistentvolumeclaim.yaml -
 https://gist.github.com/codecraf8/87c2809f8e49b318ce1cdbc5d590c4cd.
 function [`isPath`](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/utils.go#L99) needs an additional check which checks for dot `.` i.e. if the string is `.`, because it is also valid path as in current directory..
 Could I request any ETA on this? .
 @surajnarwade @procrypt wanna take a stab at this one?.
 I'll take this :+1: .
 "
,,583,"Release script binary upload bug.
 Removes the '$CLI' portion of uploading the binaries / tarballs. Had a
naming error when uploading..
 "
,,582,"0.6.0 Release.
 "
,,581,"Update the release script again.
 Updates the release script to use the actual GOPATH directory as
previous problems with commit hashes / versions in `kompose version`.

Cleans this up in regards to all the `cd` and `cd ..` commands.

No need to `git clone`..
 Going to go ahead and merge this before the release today (so we can properly run this script)..
 "
,,580,"Add Support for cap_add & cap_drop.
 Fixes #575
This commit Add support for cap_add & cap_drop which maps to
Pod.Spec.Container.SecurityContext.Capabilities.Add/Drop
Added unit tests for ConfigCapabilities function
Updated conversion.md on support for these keys.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 signed.
 Woow, that was quick! 
Thank you @gitlawr for great PR..
 Wow! This is great!

LGTM. Thanks @gitlawr this will come in-time for the 0.6.0 release today :100: .
 Glad to hear that :wink:.
 "
,,579,"Update PR for ROADMAP.
 We're going to have push/pull support in 0.7.0.
 "
,,578,"Add io.kompose.service label to every object & use reaper to delete BuildConfig.
  - Add  `io.kompose.service` label to BuildConfig, DaemonSet, ReplicationController and Pod.
 - Use reaper to delete BuildConfig (deletes also pods used for build)

Now every object created by Kompose should have this label.
Only some of the objects had this label before. This fixes #382 

.
 @surajssd `template.ObjectMeta.Labels = transformer.ConfigLabels(name)`  sets labels only for `PodTemplate` in controller object, but on for object itself.

.
 @kadel oh yes, thanks for clarifying that one..
 ping @cdrage @surajssd @procrypt @containscafeine .
 I don't see anything wrong with the code, testing it, it works as intended!

LGTM!.
 "
,,577,"Fixes fixture test for build context.
 Resolves #576

This PR includes `output-os-template.json` in `nginx-node-redis` example,
which is basically output template contains `%URI%` and `%REF%` variables
which will be filled while initializing test cases and new will be stored as
`/tmp/output-os.json`
This will remove the problem of git uri and ref..
 Tests fail?.
 cc @cdrage  @surajssd .
 Other than my comment, LGTM.

Side note: Can't wait for #89 is fixed so we don't run into these issues in the future :+1: 

.
 @cdrage done.
 "
,,576,"Fixture regarding build context fails each time.
 Fixtures which are regarding build context, for example `script/test/fixtures/nginx-node-redis`
it will always fails on individual machine because it will always return different `URI` and `REF` as each individual have different git environment..
 "
,,575,"Support for cap_add,cap_drop.
 Currently these keys are marked as unsupported and kompose generates WARNINGs when they are used. But I think there is equivalent in Kubernetes.
see:
https://kubernetes.io/docs/concepts/policy/container-capabilities/
My proposal is to convert `cap_add/cap_drop` to `Pod.Spec.Container.SecurityContext.capabilities.add/drop`
For example with such a docker-compose.yml


```
version: ""2""

services:
    hello-world:
        image: alpine:3.4
        command: [""/bin/echo"", ""hello"", ""world""]
        cap_add:
          - SYS_NICE
        cap_drop:
          - KILL
```
kompose generate
```
metadata:
  labels:
    service: hello-world
spec:
  containers:
  - image: ""alpine:3.4""
    command: [""/bin/echo"", ""hello"", ""world""]
    securityContext:
      capabilities:
        add:
        - SYS_NICE
        drop:
        - KILL
```.
 Hi @gitlawr, You are right, it looks like this is something that could be added to Kompose.
 Hi @kadel . In that case, can I add a PR for this or wait for someone to handle it? I'm familiar with k8s but not with openshift by the way..
 You definitely can :wink: , that would be great :+1: , thank you! :yellow_heart:  

That is OK, you can start with doing it just for k8s. Once you send PR with k8s I can help with OpenShift bits, it should be easy once its done for Kubernetes..
 "
,,574,"0.6.0 Release.
 Let's merge these two before release:
 - https://github.com/kubernetes-incubator/kompose/pull/454
 - https://github.com/kubernetes-incubator/kompose/pull/557.
 https://github.com/kubernetes-incubator/kompose/pull/557 has been merged..
 and so has #454 let's do a release!.
 closing since https://github.com/kubernetes-incubator/kompose/pull/582 is merged.
 "
,,573,"Kompose should show an error when image is not given.
 kompose passes a kubernetes deployment without image, we should give an error about it.
Fixes: #571  

cc: @surajssd @cdrage .
 @procrypt fix the tests that are failing, you might need to change the test to `expect failure`..
 Errr this shouldn't error..

If we pass in build but no image, the assumption is that the service name takes up the image name. See my PR at how I get around this at #521 

It's by default in Docker Compose too :) You don't have to pass in `image:`..
 @cdrage about using the auto-generated name it's okay when user is doing the builds, but here we are not doing builds with k8s as of now, so not doing magic is what I would expect..
 I'd suggest we close this until #521 is merged as this will add build support for Kubernetes..
 "
,,572,"Blockers for running buildconfig tests on OpenShift.
 For executing buildconfig tests for OpenShift, both #561 and #382 need to be fixed. 

Creating an issue to track both the bugs..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 "
,,571,"kompose passes a kubernetes deployment without image .
 I have a docker-compose service with build specified but without image. So since kompose has no build support with kubernetes so it should error out saying that there is no image provided.

```bash
$ kompose up
WARN Kubernetes provider doesn't support build key - ignoring 
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: foo            
FATA Error while deploying application: Deployment.apps ""foo"" is invalid: spec.template.spec.containers[0].image: Required value 
```


I am using following docker-compose file:

```yaml
$ cat docker-compose.yml 
version: '2'

services:
  foo:
    build: .
```

So I would recommend that we suggest user to add one more additional field called `image` to provide the image name explicitly..
 @surajssd Working on this..
 I don't believe this is an issue.

If an image key isn't passed, it will use the service name as per how it works in Docker Compose. I work around this in #521 (and thus merging #521 will fix this issue).

For your example, it will build as image ""foo""..
 @cdrage I would not want to do magic here and ask user to specifically provide the image name, because then user might be confused why this is failing!.
 @surajssd I don't believe it's magic. This is how Docker Compose does it while building, so I don't see a problem with it converting to Kubernetes and taking the appropriate Docker Image name as the service name.

#521 will be adding the build functionality, so it may be best to wait until that's merged and then we can update this issue #571 in regards to warning the user that in-fact, there was no image specified and it will be using the service name for building / deployment..
 @surajssd @procrypt Should we close this? Did my comments address the problem?.
 This should fail now right ?.
 @surajssd No? I thought my comments address why having no image is still valid with build (it builds the docker container and tags it).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,570,"typo in nginx name..
 There is typo in `nginx` name, it's named as `ngnix`.

CC: @cdrage .
 Other than the one test failing, LGTM..
 @cdrage All green now :+1: .
 LGTM :+1: .
 "
,,569,"Add warning about change in the service name..
 Add warning about change in the service name of docker-compose file that contains `_` in it to `-`.

Fixes: #538 

cc: @cdrage @surajssd @surajnarwade @containscafeine .
 @pradeepto PTAL..
 LGTM but wait for someone else to +1. Then feel free to merge. cc @surajnarwade  @surajssd @containscafeine @kadel @cdrage .
 LGTM :+1: .
 LGTM.
 "
,,568,"fix output replication-controller and daemon-set.
 @cdrage  fix output   replication-controller and daemon-set.
 @nkysg Thanks! :D LGTM :dancing_women: .
 "
,,567,"Adds spacing to table.
 Adds some spacing to the table to better separate each section..
 "
,,566,"Update vendoring for libcompose and others.
 This updates the vendoring for libcompose because of the result of
https://github.com/docker/libcompose/pull/457 and
https://github.com/docker/libcompose/pull/450 being merged upstream..
 ping @surajnarwade .
 Restarting build since Travis messed up (Fedora git servers were down, so it was unable to pull the submodule).
 with https://github.com/docker/libcompose/pull/450 merged  we will  have to update how we handle build context. Our implementation is based on wrong implementation in libcompose :-) Fixing it in libcompose broke our code :-( .
 this vendor update should be probably handled by  https://github.com/kubernetes-incubator/kompose/pull/454/ with all proper fixes.
 @kadel Yeah, just realized after lunch that this won't do. Closing for now and doing it via #454 .
 "
,,565,"sort output when creating kubernetes/openshift objects.
 The objects created by `kompose` are not in order according to the `services` in `docker-compose` file. This makes it confusing to read the output of `kompose convert --stdout`. 
I have tested it with several `docker-compose` files to make sure it works as, we prefer `Service` to be deployed first as per `kubernetes` best practices.

cc: @cdrage @surajssd 
Fixes: #554 .
 @procrypt 

I agree. We shouldn't be sorting them out and simply go by docker-compose..
 @cdrage If we are not sorting the service based on `docker-compose` file then we can close #554 and this PR..
 @cdrage I have updated the PR as per the discussion [here](https://github.com/kubernetes-incubator/kompose/issues/554#issuecomment-296161877)..
 @procrypt I've updated vendoring at #566 since it's going to unblock a few PR's as well as close a few issues. Mind rebasing your PR once it's merged?.
 >I agree. We shouldn't be sorting them out and simply go by docker-compose.

@cdrage this is the same thing done for `kubernetes` and was missing in `openshift` so @procrypt added it. And I think this was required so that the results are consistent and folks who do check in the output in git, having consistent behavior helps in knowing what is extra thing generated not just config going upside down..
 @cdrage @kadel Can we merge this soon, this PR is a blocker for [this](https://github.com/kubernetes-incubator/kompose/pull/518)..
 needs second lgtm 
ping @cdrage @surajssd @containscafeine .
 Ping @surajssd @cdrage .
 Ping @cdrage @surajssd .
 this code LGTM please also add tests whenever newer function is introduced!.
 Add a small test and LGTM from me! :+1: .
 ping @cdrage @surajssd .
 @procrypt gofmt error, but otherwise, code LGTM as long as tests are green).
 @cdrage all green :+1: .
 LGTM :+1: .
 @surajssd @cdrage Can we merge this as #518 is blocked on this..
 Two approves. Let's merge!.
 "
,,564,"commenting test case temporarily .
 PR https://github.com/kubernetes-incubator/kompose/pull/562 is failing due to test case,

```
convert::expect_success_and_warning: Running: 'kompose --provider=openshift -f /home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/ngnix-node-redis/docker-compose.yml convert --stdout -j' expected_output: '/home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/ngnix-node-redis/output-os.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source.
```
So as of now. I think we should comment out the test case and will pass the https://github.com/kubernetes-incubator/kompose/pull/562, so that https://github.com/kubernetes-incubator/kompose/pull/454 will get pass. after successful build. I will again add the test case.
cc @cdrage @surajssd @procrypt @containscafeine .
 I am updating vendor in  https://github.com/kubernetes-incubator/kompose/pull/454 only,hence closing issue.
 "
,,563,"delete buildConfig based on label.
 `BuildConfig` was not getting deleted earlier using `kompose down`.
Fixes #382 
@cdrage .
 This is not the complete solution right because the build pods still remain around. @procrypt let;s keep the discussion here and not on https://github.com/kubernetes-incubator/kompose/pull/460 so it's easy to see what all this PR is doing..
 Ah, I didn't noticed this before :-(
I've just submited another PR, that is doing same thing and also solves problem with deleting build pods
https://github.com/kubernetes-incubator/kompose/pull/578.
 @procrypt are you OK with closing this PR in favor of #578?.
 @kadel Yeah sure go ahead :+1: .
 "
,,562,"Updating Vendor.
 As https://github.com/docker/libcompose/pull/457 and
https://github.com/docker/libcompose/pull/450 are merged now in libcompose.
 it's failing because, as this PR and https://github.com/kubernetes-incubator/kompose/pull/454 depend on each other, any one them needs to be merged before..
 "
,,561,"git repo with detached head generates wrong `bc`.
 here is my git env

```bash
✔ /tmp/kompose [:24e53f2|…6] 
08:28 $ git log | head
commit 24e53f20abca2e3fb8e8a31ade3ba8f0ca73df4a
Author: Anush Shetty <ashetty@redhat.com>
Date:   Wed Mar 1 16:07:21 2017 +0530

    Adding OpenShift functional tests for kompose up/down
    
    * This PR adds functional tests for kompose up/down. The test scripts
    are hosted under script/test_in_openshift. The directory structure,
    as follows:
    
✔ /tmp/kompose [:24e53f2|…6] 
08:28 $ git branch 
* (HEAD detached at anush/openshift_up_down_test)
  master
✔ /tmp/kompose [:24e53f2|…6] 
08:28 $ 
```

kompose generates wrong buildconfig for openshift in git repo that is detached

```bash
$ kompose convert -f examples/buildconfig/docker-compose.yml --provider openshift --stdout | grep git
INFO Buildconfig using https://github.com/kubernetes-incubator/kompose/.git::HEAD as source. 
      git:
        uri: https://github.com/kubernetes-incubator/kompose/.git
```.
 It fails because the git url is wrong `https://github.com/kubernetes-incubator/kompose/.git`.
 @surajssd Picking this up..
 even if https://github.com/kubernetes-incubator/kompose/pull/577 is merged this issue still remains.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 "
,,560,"Ignore Volume if similar mountpath found.
 Resolves #544

With this PR, kompose will give error if similar mountpaths are found
in case when `volumes_from` is being used..
 cc @procrypt @cdrage @surajssd @containscafeine .
 @surajssd done.
 @surajnarwade Need tests before merge.
 @cdrage added test..
 @cdrage added comments.
 I don't think that this is right solution here.

Following docker-compose file is completely valid with docker-compose :

```yaml
version: '2'

services:
  foo:
    image: busybox
    command: sleep 3600
    volumes:
       - /asdf

  bar:
    image: busybox
    command: sleep 3600
    volumes:
       - /asdf
    volumes_from:
       - foo
  ```

result is that `/asdf` volume is shared between both containers.

We should do the  same with Kubernetes. 
We are already using shared volumes for `volume_from`.

if container `bar` is mounting volumes from `foo` and one of the volumes has same path as is defined in bar `volumes` array we should ignore it , that will create same behavior as with docker-compose.



.
 cc @kadel @cdrage @surajssd .
 I am trying to convert the example @kadel has given. Since `/asdf` should be same volumes, so only one `pvc` should be created.

But after I convert I see two `pvc` created:

```bash
$ kompose convert 
[SNIP]
INFO file ""bar-claim0-persistentvolumeclaim.yaml"" created 
INFO file ""foo-deployment.yaml"" created           
INFO file ""foo-claim0-persistentvolumeclaim.yaml"" created 
```

Also see the `Deployment` it's not sharing the volumes.

```yaml
$ cat bar-deployment.yaml 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  name: bar
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: bar
    spec:
      containers:
      - image: busybox
        name: bar
        resources: {}
        volumeMounts:
        - mountPath: /asdf
          name: bar-claim0
      restartPolicy: Always
      volumes:
      - name: bar-claim0
        persistentVolumeClaim:
          claimName: bar-claim0
status: {}
```
See the mount from above command it is coming from `pvc` `bar-claim0`

and in the below example the mount is coming from `pvc` `foo-claim0`.


```yaml
$ cat foo-deployment.yaml 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  name: foo
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: foo
    spec:
      containers:
      - image: busybox
        name: foo
        resources: {}
        volumeMounts:
        - mountPath: /asdf
          name: foo-claim0
      restartPolicy: Always
      volumes:
      - name: foo-claim0
        persistentVolumeClaim:
          claimName: foo-claim0
status: {}
```

Rather they should be using same `pvc`..
 I'm afraid that we can't do it as it's currently implemented :-( 

This will require bigger refactoring of how we handle volumes.

In our code `volumes_from` is handled completely separately from code that handles rest of the volumes. It's making this almost impossible to implement. We need to consolidate it and handle everything that is related to volumes in one place..
 I am closing this PR in favour of this PR, https://github.com/kubernetes/kompose/pull/626.
 "
,,559,"Clarify tarball.
 Describe that it's a bandwidth-conservative alternative.
 Faster downloads, ah the small pleasures of life! @surajnarwade @surajssd @containscafeine @procrypt Can one of you please review and approve this?.
 LGTM :).
 Since this is a doc change, only one LGTM is good!

Remember @surajnarwade to go through the review-process rather than LGTM so it's all green when it's merged :).
 LGTM :+1: .
 "
,,558,"Add test dependencies.
 This clears up .travis.yaml as well as adds the test dependencies when
running `make test` so the user running the tests has the most
up-to-date ones available..
 :+1: looks good.
 LGTM .
 "
,,557,"fix driver:local in prefixing volumes with current dir name.
 If we have a `docker-file` with root level `volumes` and we do a `kompose up` using that `docker-file`, libcompose will add an additional `_` followed by the current directory name. 

`docker-compose.yml` used 
```yaml
version: '2'
services:
  mariadb:
    image: 'bitnami/mariadb:latest'
    volumes:
      - 'mariadb-data:/bitnami/mariadb'
    environment:
      - MARIADB_USER=bn_wordpress
      - MARIADB_DATABASE=bitnami_wordpress
      - ALLOW_EMPTY_PASSWORD=yes
  wordpress:
    image: 'bitnami/wordpress:latest'
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - 'wordpress-data:/bitnami/wordpress'
      - 'apache-data:/bitnami/apache'
      - 'php-data:/bitnami/php'
    depends_on:
      - mariadb
    environment:
      - MARIADB_HOST=mariadb
      - MARIADB_PORT=3306
      - WORDPRESS_DATABASE_USER=bn_wordpress
      - WORDPRESS_DATABASE_NAME=bitnami_wordpress
      - ALLOW_EMPTY_PASSWORD=yes
volumes:
  mariadb-data:
    driver: local
  wordpress-data:
    driver: local
  apache-data:
    driver: local
  php-data:
    driver: local
```
```yaml
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose_apache-data
    name: kompose_apache-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose_php-data
    name: kompose_php-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
kind: List
metadata: {}
```
```bash
$ kompose -f docker-compose.yml up
WARN Unsupported root level volumes key - ignoring 
WARN Unsupported depends_on key - ignoring        
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: mariadb        
INFO Successfully created Service: wordpress      
FATA Error while deploying application: Deployment.extensions ""mariadb"" is invalid: [spec.template.spec.volumes[0].name: Invalid value: ""komposefiles_mariadb-data"": must match the regex [a-z0-9]([-a-z0-9]*[a-z0-9])? (e.g. 'my-name' or '123-abc'), spec.template.spec.containers[0].volumeMounts[0].name: Not found: ""komposefiles_mariadb-data""] 
```
Since `kubernetes` doesn't allow `_` in the objects created so `kompose up` will fail to deploy it.

 As a solution we replace `_` to `-` and we can then deploy it successfully. 

```bash
$ kompose -f docker-compose.yml up
WARN Unsupported root level volumes key - ignoring 
WARN Unsupported depends_on key - ignoring        
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Deploying application in ""default"" namespace 
INFO Successfully created Service: mariadb        
INFO Successfully created Service: wordpress      
INFO Successfully created Deployment: mariadb     
INFO Successfully created PersistentVolumeClaim: komposefiles-mariadb-data 
INFO Successfully created Deployment: wordpress   
INFO Successfully created PersistentVolumeClaim: komposefiles-wordpress-data 
INFO Successfully created PersistentVolumeClaim: komposefiles-apache-data 
INFO Successfully created PersistentVolumeClaim: komposefiles-php-data 

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```
```yaml
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose-apache-data
    name: kompose-apache-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose-php-data
    name: kompose-php-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
kind: List
metadata: {}
```

CC: @kadel @cdrage  
Fixes #550 .
 @procrypt this doesn't seem to work, here's the full test (using Compose file from https://github.com/kubernetes-incubator/kompose/issues/554#issuecomment-294752322). Note that version says 0.4.0, but the SHA is correct.

    [dkarlovi@fredo kompose_underscore-test]$ kompose version
    0.4.0 (87fa7cb)
    [dkarlovi@fredo kompose_underscore-test]$ pwd
    /home/dkarlovi/Development/R&D/DevOps/Kubernetes/kompose_underscore-test
    [dkarlovi@fredo kompose_underscore-test]$ kompose -f underscore-pvc.yml convert --stdout | grep PersistentVolumeClaim -A 5
    WARN Unsupported root level volumes key - ignoring
    WARN Unsupported depends_on key - ignoring
    WARN Unsupported hostname key - ignoring
    WARN Kubernetes provider doesn't support build key - ignoring
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: komposeunderscoretest_broker
        name: komposeunderscoretest_broker
    --
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: komposeunderscoretest_cache
        name: komposeunderscoretest_cache
    --
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: komposeunderscoretest_db
        name: komposeunderscoretest_db
.
 I've figured it out: if you leave the root-level `volumes:` block, it doesn't work. If you remove it, it **does** work. 

`kompose` says it's ignoring it, but that doesn't seem to be the case.

Also, it works in HEAD too, without this PR..
 @dkarlovi Did you build `kompose` correctly after fetching my branch. It seems to work fine when I run `kompose convert`. Please take a look at the output below, I'm using the docker-compose file provided by you.

```bash
$ kompose convert -f dev.yml --stdout  | grep PersistentVolumeClaim -A 5
WARN Unsupported root level volumes key - ignoring 
WARN Unsupported depends_on key - ignoring        
WARN Unsupported hostname key - ignoring          
WARN Kubernetes provider doesn't support build key - ignoring 
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: komposefiles-broker
    name: komposefiles-broker
--
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: komposefiles-cache
    name: komposefiles-cache
--
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: komposefiles-db
    name: komposefiles-db
```
```bash
kompose version 
0.5.0 (HEAD)
```
Please make sure you build `kompose` correctly and try it again..
 @procrypt @dkarlovi , its working for me,

```
$ kompose version
0.5.0 (HEAD)
```

output is:

```
$ kompose convert -f docker-compose.yml --stdout  | grep PersistentVolumeClaim -A 5
WARN Unsupported root level volumes key - ignoring 
WARN Unsupported depends_on key - ignoring        
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: procrypt-mariadb-data
    name: procrypt-mariadb-data
--
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: procrypt-wordpress-data
    name: procrypt-wordpress-data
--
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: procrypt-apache-data
    name: procrypt-apache-data
--
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: procrypt-php-data
    name: procrypt-php-data
```

Make sure you are building from this PR only:

```
 git fetch upstream pull/557/head:driver_local
```
.
 @surajnarwade  @procrypt if it's working for you two, let's just assume I've PEBKACed because of my inexperience with Go and that it works for me too, I just can't reproduce it. :)

I've followed [the instructions](https://help.github.com/articles/checking-out-pull-requests-locally/) to check out the PR branch locally, did a build and my `kompose version` still doesn't say `HEAD`, it states the exact commit SHA1.

Here's what I did:

	[dkarlovi@fredo kompose]$ git remote
	origin
	[dkarlovi@fredo kompose]$ git fetch origin pull/557/head:driver_local
	From https://github.com/kubernetes-incubator/kompose
	 * [new ref]         refs/pull/557/head -> driver_local
	[dkarlovi@fredo kompose]$ git checkout driver_local
	Switched to branch 'driver_local'
	[dkarlovi@fredo kompose]$ git branch -vv
	* driver_local 12808ac vendor_update
	  master       46426fb [origin/master] Merge pull request #558 from cdrage/add-dependencies-to-makefile
	[dkarlovi@fredo kompose]$ make
	go build -ldflags=""-w -X github.com/kubernetes-incubator/kompose/cmd.GITCOMMIT=12808ac"" -o kompose main.go
	[dkarlovi@fredo kompose]$ cd ../kompose_underscore-test/
	[dkarlovi@fredo kompose_underscore-test]$ ../kompose/kompose version
	0.5.0 (12808ac)
	[dkarlovi@fredo kompose_underscore-test]$ ../kompose/kompose convert -f underscore-pvc.yml --stdout | grep PersistentVolumeClaim -A 5
	WARN Unsupported root level volumes key - ignoring 
	WARN Unsupported depends_on key - ignoring        
	WARN Unsupported hostname key - ignoring          
	WARN Kubernetes provider doesn't support build key - ignoring 
	  kind: PersistentVolumeClaim
	  metadata:
	    creationTimestamp: null
	    labels:
	      io.kompose.service: komposeunderscoretest_broker
	    name: komposeunderscoretest_broker
	--
	  kind: PersistentVolumeClaim
	  metadata:
	    creationTimestamp: null
	    labels:
	      io.kompose.service: komposeunderscoretest_cache
	    name: komposeunderscoretest_cache
	--
	  kind: PersistentVolumeClaim
	  metadata:
	    creationTimestamp: null
	    labels:
	      io.kompose.service: komposeunderscoretest_db
	    name: komposeunderscoretest_db
.
 @procrypt why this can't be fixed as it was done in https://github.com/kubernetes-incubator/kompose/pull/509 ?

I think here we need to normalize only in https://github.com/kubernetes-incubator/kompose/blob/master/pkg/loader/compose/compose.go#L341 ?.
 So with this we take care of it at source so we don;t have problems later since the data is scattered in all over the place..
 @surajssd Thanks I have updated the PR..
 @procrypt tests, functional ones..
 Hey @procrypt ! Almost there. Could you update your commit messages with what you wrote here? Otherwise, code LGTM..
 @procrypt @kadel Can you help to make sure this PR being merged in the upcoming release this week? We have some Bitnami compose files need this fix on this iteration (end by next Thursday). I tested it. The only concern from me is the vendor update..
 @cdrage @kadel @ngtuna I don't think vendor update is required so I removed it..
 @procrypt LGTM :).
 Ideally some tests should be added, but I don't see any issues arising because of this.

LGTM.

@kadel Wanna have a quick-lookover this before we merge this in before today's release?.
 @cdrage Tests added :+1: .
 I am gonna merge this as all reviewers have approved..
 "
,,556,"Update doc with better console output and add note on deployment config.
 Adds note on Deployment Config as well as updates console output for
Kubernetes example.
 LGTM. But @surajnarwade @surajssd @containscafeine Can one of you review and approve this? Thanks..
 LGTM :).
 "
,,555,"kompose convert --rc and kompose convert --ds not right.
 when i run `kompose convert --rc`
It show that 
Error: unknown flag: --rc

when i run ｀kompose convert --ds`
it shows `Error: unknown flag: --ds`.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

It may take a couple minutes for the CLA signature to be fully registered; after that, please reply here with a new comment and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 @nkysg Before we can do anything with your PR, you need to sign the k8s CLA. Please do so by following the link mentioned above. Thanks..
 I have retry @k8s-ci-robot .
 Hey @nkysg thanks for pointing that out, but before we move forward please sign the cla and update your PR with one more additional change [here](https://github.com/kubernetes-incubator/kompose/edit/master/docs/user-guide.md) on line number 259 one more `--rc` is present please correct that too..
 LGTM. Please squash your commits into a single commit..
 thanks @procrypt ! this is my first commit with my poor english.
 @procrypt I try to use git merge --squash.
 "
,,554,"[UX] Sort output when doing kind: list and --stdout.
 I'm doing some sort of post-processing on the generated YAML to be able to omit `BuildConfig` (as mentioned in #446) etc. When I'm done, I save it to a versioned file to be able to keep track of production config.

When running `kompose convert --provider openshift --verbose --stdout` (which produces a `kind: list`), services' and configuration blocks' order seems to be generated arbitrarily. As this is unimportant for general usage, you might provide a nice UX boost just by sorting the output which would make having it be stable and diffs actually meaningful.

For example, you might go with:
- serviceA, `BuildConfig`
- serviceA, `DeploymentConfig`
- serviceB, `BuildConfig`
- serviceB, `DeploymentConfig`
- etc.

Also, stuff like environment variables and service ports might get sorted by `name`..
 @dkarlovi The patten in which the artifacts are generated are intentional since we need the `service` to be created and deployed first as per kubernetes best practices. Although I tried and deployed a sample application in which `service` is deployed after `deploymentConfig` and it works. Can you provide me your `docker-compose` file so that I can try that too..
 @procrypt I think the whole file gets ingested first, then internally sorted and applied by Kubernetes, which makes sense. It doesn't matter WHAT the actual sort is as long as it's repeatable and stable.

Included are: Compose file and outputs of two consecutive runs of `kompose` (sorry about the long comment).

Here's the `docker-compose.yml` file:

    networks: {}
    services:
      app:
        build:
          context: /src
          dockerfile: ./.infra/docker/php/Dockerfile
        depends_on:
          - broker
          - cache
          - db
        image: dkarlovi/example:app
      broker:
        build:
          context: /src
          dockerfile: ./.infra/docker/rabbitmq/Dockerfile
        hostname: broker
        image: dkarlovi/example:broker
        volumes:
        - broker:/var/lib/rabbitmq:rw
      cache:
        build:
          context: /src
          dockerfile: ./.infra/docker/redis/Dockerfile
        image: dkarlovi/example:cache
        volumes:
        - cache:/data:rw
      db:
        build:
          context: /src
          dockerfile: ./.infra/docker/mysql/Dockerfile
        image: dkarlovi/example:db
        volumes:
        - db:/var/lib/mysql:rw
      web:
        build:
          context: /src
          dockerfile: ./.infra/docker/nginx/Dockerfile
        depends_on:
          - app
          - broker
        image: dkarlovi/example:web
        ports:
        - 80:80/tcp
        - 8000:80/tcp
      worker:
        build:
          context: /src
          dockerfile: ./.infra/docker/worker/Dockerfile
        depends_on:
          - app
          - broker
          - cache
          - db
        image: dkarlovi/example:worker
    version: 2
    volumes:
      broker: {}
      cache: {}
      db: {}

First output of: `kompose -f docker-kompose.yml convert --provider openshift --verbose --build-branch ""master"" --stdout`:

    apiVersion: v1
    items:
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: app
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: broker
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: cache
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: db
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec:
        ports:
        - name: ""80""
          port: 80
          targetPort: 80
        - name: ""8000""
          port: 8000
          targetPort: 80
        selector:
          io.kompose.service: web
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: worker
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec:
        replicas: 1
        selector:
          io.kompose.service: app
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: app
          spec:
            containers:
            - image: ' '
              name: app
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - app
            from:
              kind: ImageStreamTag
              name: app:app
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: app
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: app:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/php/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec:
        replicas: 1
        selector:
          io.kompose.service: broker
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: broker
          spec:
            containers:
            - image: ' '
              name: broker
              resources: {}
              volumeMounts:
              - mountPath: /var/lib/rabbitmq
                name: src_broker
            restartPolicy: Always
            volumes:
            - name: src_broker
              persistentVolumeClaim:
                claimName: src_broker
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - broker
            from:
              kind: ImageStreamTag
              name: broker:broker
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: broker
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: broker:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/rabbitmq/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_broker
        name: src_broker
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec:
        replicas: 1
        selector:
          io.kompose.service: cache
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: cache
          spec:
            containers:
            - image: ' '
              name: cache
              resources: {}
              volumeMounts:
              - mountPath: /data
                name: src_cache
            restartPolicy: Always
            volumes:
            - name: src_cache
              persistentVolumeClaim:
                claimName: src_cache
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - cache
            from:
              kind: ImageStreamTag
              name: cache:cache
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: cache
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: cache:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/redis/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_cache
        name: src_cache
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec:
        replicas: 1
        selector:
          io.kompose.service: db
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: db
          spec:
            containers:
            - image: ' '
              name: db
              resources: {}
              volumeMounts:
              - mountPath: /var/lib/mysql
                name: src_db
            restartPolicy: Always
            volumes:
            - name: src_db
              persistentVolumeClaim:
                claimName: src_db
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - db
            from:
              kind: ImageStreamTag
              name: db:db
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: db
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: db:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/mysql/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_db
        name: src_db
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec:
        replicas: 1
        selector:
          io.kompose.service: web
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: web
          spec:
            containers:
            - image: ' '
              name: web
              ports:
              - containerPort: 80
              - containerPort: 80
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - web
            from:
              kind: ImageStreamTag
              name: web:web
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: web
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: web:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/nginx/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec:
        replicas: 1
        selector:
          io.kompose.service: worker
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: worker
          spec:
            containers:
            - image: ' '
              name: worker
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - worker
            from:
              kind: ImageStreamTag
              name: worker:worker
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: worker
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: worker:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/worker/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    kind: List
    metadata: {}
    
Second output of: `kompose -f docker-kompose.yml convert --provider openshift --verbose --build-branch ""master"" --stdout`:

    apiVersion: v1
    items:
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: cache
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: db
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec:
        ports:
        - name: ""80""
          port: 80
          targetPort: 80
        - name: ""8000""
          port: 8000
          targetPort: 80
        selector:
          io.kompose.service: web
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: worker
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: app
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: Service
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec:
        clusterIP: None
        ports:
        - name: headless
          port: 55555
          targetPort: 0
        selector:
          io.kompose.service: broker
      status:
        loadBalancer: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec:
        replicas: 1
        selector:
          io.kompose.service: cache
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: cache
          spec:
            containers:
            - image: ' '
              name: cache
              resources: {}
              volumeMounts:
              - mountPath: /data
                name: src_cache
            restartPolicy: Always
            volumes:
            - name: src_cache
              persistentVolumeClaim:
                claimName: src_cache
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - cache
            from:
              kind: ImageStreamTag
              name: cache:cache
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: cache
        name: cache
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: cache
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: cache:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/redis/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_cache
        name: src_cache
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec:
        replicas: 1
        selector:
          io.kompose.service: db
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: db
          spec:
            containers:
            - image: ' '
              name: db
              resources: {}
              volumeMounts:
              - mountPath: /var/lib/mysql
                name: src_db
            restartPolicy: Always
            volumes:
            - name: src_db
              persistentVolumeClaim:
                claimName: src_db
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - db
            from:
              kind: ImageStreamTag
              name: db:db
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: db
        name: db
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: db
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: db:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/mysql/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_db
        name: src_db
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec:
        replicas: 1
        selector:
          io.kompose.service: web
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: web
          spec:
            containers:
            - image: ' '
              name: web
              ports:
              - containerPort: 80
              - containerPort: 80
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - web
            from:
              kind: ImageStreamTag
              name: web:web
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: web
        name: web
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: web
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: web:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/nginx/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec:
        replicas: 1
        selector:
          io.kompose.service: worker
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: worker
          spec:
            containers:
            - image: ' '
              name: worker
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - worker
            from:
              kind: ImageStreamTag
              name: worker:worker
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: worker
        name: worker
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: worker
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: worker:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/worker/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec:
        replicas: 1
        selector:
          io.kompose.service: app
        strategy:
          resources: {}
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: app
          spec:
            containers:
            - image: ' '
              name: app
              resources: {}
            restartPolicy: Always
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - app
            from:
              kind: ImageStreamTag
              name: app:app
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: app
        name: app
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: app
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: app:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/php/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: DeploymentConfig
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec:
        replicas: 1
        selector:
          io.kompose.service: broker
        strategy:
          resources: {}
          type: Recreate
        template:
          metadata:
            creationTimestamp: null
            labels:
              io.kompose.service: broker
          spec:
            containers:
            - image: ' '
              name: broker
              resources: {}
              volumeMounts:
              - mountPath: /var/lib/rabbitmq
                name: src_broker
            restartPolicy: Always
            volumes:
            - name: src_broker
              persistentVolumeClaim:
                claimName: src_broker
        test: false
        triggers:
        - type: ConfigChange
        - imageChangeParams:
            automatic: true
            containerNames:
            - broker
            from:
              kind: ImageStreamTag
              name: broker:broker
          type: ImageChange
      status: {}
    - apiVersion: v1
      kind: ImageStream
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: broker
        name: broker
      spec: {}
      status:
        dockerImageRepository: """"
    - apiVersion: v1
      kind: BuildConfig
      metadata:
        creationTimestamp: null
        name: broker
      spec:
        nodeSelector: null
        output:
          to:
            kind: ImageStreamTag
            name: broker:latest
        postCommit: {}
        resources: {}
        runPolicy: Serial
        source:
          contextDir: src
          git:
            ref: master
            uri: git@git.example.com:my/example.com.git
          type: Git
        strategy:
          dockerStrategy:
            dockerfilePath: ./.infra/docker/rabbitmq/Dockerfile
          type: Docker
        triggers:
        - type: ConfigChange
        - type: ImageChange
      status:
        lastVersion: 0
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_broker
        name: src_broker
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Mi
      status: {}
    kind: List
    metadata: {}
    
.
 @dkarlovi so this was intentional as @procrypt said also you can find the corresponding doc in upstream at 
https://kubernetes.io/docs/concepts/configuration/overview/

which says:

>It’s typically best to create a service before corresponding replication controllers, so that the scheduler can spread the pods comprising the service. 

so the decision..
 @surajssd thanks for the link. I've noted:
> It doesn't matter WHAT the actual sort is as long as it's repeatable and stable.

As you can see from my comment, order changes between runs for me..
 @dkarlovi thanks for reporting this seems to be an openshift issue!.
 With Kubernetes the output is right but with openshift the output is not alphabetically ordered.
 @surajssd great to hear. Sorting by docker-compose works too of course, as long as the order is kept between runs..
 @surajssd @dkarlovi I have updated the [PR](https://github.com/kubernetes-incubator/kompose/pull/565) accordingly, output with is in order `OpenShift` now..
 "
,,553,"Updated conversion doc.
 `docs/conversion.md` is updated as `tmpfs` is supported now..
 cc @kadel .
 I don't see any changes in the message.
Can you also add  reference to emptyDir to ""K8s / OpenShift"" column? It should say that its emptyDir with `medium:Memory` and link to https://kubernetes.io/docs/concepts/storage/volumes/#emptydir .
 @kadel . updated.
 @cdrage done.
 LGTM! Merging'.
 "
,,552,"Fixes the headers of the docs.
 Changes it to 1 `#`. Fixes the headers so they're consistent across all
docs..
 "
,,551,"Update document describing release process.
 Updated release process.
@cdrage, does is describe how you do it?
Is there something important that I forgot?.
 > I believe we should put down the processing of running the release.sh script, no?

yes

> I can elaborate on this and make this document more extensive (go into a lot of detail in regards to how we do the release and how to replicate it)

That would be great. I just wanted to update it to something that is at least partial true ;-) 

If what I wrote isn't  complete nonsense we could merge it, it will be better than what was there before, than you can expand/rewrite it later. What do you think?.
 @kadel 
I agree, let's move fast and merge this for now until we go with some more doc updates!.
 "
,,550,"driver:local in prefixing volumes with current dir name.
 ```yaml
version: '2'
services:
  mariadb:
    image: 'bitnami/mariadb:latest'
    volumes:
      - 'mariadb-data:/bitnami/mariadb'
    environment:
      - MARIADB_USER=bn_wordpress
      - MARIADB_DATABASE=bitnami_wordpress
      - ALLOW_EMPTY_PASSWORD=yes
  wordpress:
    image: 'bitnami/wordpress:latest'
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - 'wordpress-data:/bitnami/wordpress'
      - 'apache-data:/bitnami/apache'
      - 'php-data:/bitnami/php'
    depends_on:
      - mariadb
    environment:
      - MARIADB_HOST=mariadb
      - MARIADB_PORT=3306
      - WORDPRESS_DATABASE_USER=bn_wordpress
      - WORDPRESS_DATABASE_NAME=bitnami_wordpress
      - ALLOW_EMPTY_PASSWORD=yes
volumes:
  mariadb-data:
    driver: local
  wordpress-data:
    driver: local
  apache-data:
    driver: local
  php-data:
    driver: local
```

all PVC created from this file have names that are starting with name of current directory and `_` as separator.

```yaml
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose_apache-data
    name: kompose_apache-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: kompose_php-data
    name: kompose_php-data
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 100Mi
  status: {}
kind: List
metadata: {}
```

**Problem is that Kubernetes doesn't allow `_` in object names**


From first quick look it seems to me that `libcompose` is doing that  for some reason.






.
 @kadel , if we remove unsupported root level key `volumes`, then it works fine.
 @kadel , https://github.com/docker/libcompose/blob/master/project/project.go#L335 line from libcompose is adding project directory name followed by `_` in volume name, if root level `volumes` key is present. as `volumes` key is unsupported,  it should be removed before `kompose convert`.
 @ngtuna maybe you can check this one out

All bitnami docker-compose examples use this type of local volume definitions, it would be great for kompose to support it..
 @sebgoa @procrypt started looking into this.
 @sebgoa I have started looking into it and almost finished will send the PR soon..
 ok terrific, thanks.
 @procrypt awesome, I'm getting hit by the same problem. <3.
 @dkarlovi Can you share your `docker-compose` file. Since, I need more testing on this. .
 @procrypt I'm creating an annonymized Compose file to send you and there I can't reproduce it?! But I'm trying it with my original Compose file and there it does add the prefix. Same `kompose` binary, different results, very weird. :(

I'll try to figure out what's the difference, in the meantime here's the Compose file I've used (but it's worthless to test with as it works for me too):

    version: 2
    services:
      web:
        image: registry.example.com/developers/docker:dkarlovi-web
        build:
          context: .
          dockerfile: ./.docker/nginx/Dockerfile
      app:
        image: registry.example.com/developers/docker:dkarlovi-app
        build:
          context: .
          dockerfile: ./.docker/php/Dockerfile
      db:
        image: registry.example.com/developers/docker:dkarlovi-db
        build:
          context: .
          dockerfile: ./.docker/mysql/Dockerfile
        volumes:
          - data:/var/lib/mysql
    volumes:
      data: ~.
 @procrypt managed to reproduce in https://github.com/kubernetes-incubator/kompose/issues/554#issuecomment-294752322.
 Hey @dkarlovi tired your `docker-compose` file I was able to deploy with `kompose up` but there were some issues with pulling images..
 @procrypt images are non-existent (original images are in a private registry anyway), you should use `convert` instead of `up` to verify created PVC names..
 @dkarlovi If you do `kompose up` using your file you should get an error because of the additional `_` added to the object name and it should `fail`, anyways I have tried it with `convert` too and it works fine..
 @procrypt you've used the Compose file linked in #554? The one here doesn't trigger the bug, as stated in the comment..
 @dkarlovi Yeah I have used the one you mentioned in #554..
 Then it should fail as it does for me, I'm getting an invalid PVC name, as seen below:

    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: src_db
        name: src_db

Your underscores to dashes fix should be enough as that's exactly what I do in my post-processing..
 @dkarlovi So does it works for you?.
 It does work with the Compose file linked in https://github.com/kubernetes-incubator/kompose/issues/550#issuecomment-294743241.
It does NOT work with the Compose file linked in https://github.com/kubernetes-incubator/kompose/issues/554#issuecomment-294752322.

Or do you mean, does your fix work for me? Haven't tested it yet..
 Can you test it with the [PR](https://github.com/kubernetes-incubator/kompose/pull/557) I just sent..
 Sure, can you tell me how to `go get` your branch? I'm not into Go enough to know, yet. :(.
 @dkarlovi You need to install `golang` then clone `kompose` after that fetch my branch and [build](https://github.com/kubernetes-incubator/kompose/blob/master/README.md#building-with-go) `kompose` using that..
 OK, I'll try to test it later today..
 [Done](https://github.com/kubernetes-incubator/kompose/pull/557#issuecomment-295369146).

Problem is related to root-level `volumes` block not being ignored even though `kompose` claims it is being ignored. If I comment out or remove it, everything works (ie. parent folder name is not being added in any way, so underscores are not a problem).

It even works in HEAD, without your PR..
 @dkarlovi Please make sure you build `kompose` correctly because it works fine when I do it. Have a look [here](https://github.com/kubernetes-incubator/kompose/pull/557#issuecomment-295579288)..
 @procrypt do you have any update on this issue's state ?.
 @ngtuna  I have already sent a [PR](https://github.com/kubernetes-incubator/kompose/pull/557) for this PTAL..
 @procrypt thanks 👍 .
 @ngtuna Can you review it if when you have some time..
 @procrypt Sure will do. We are having some bitnami stuffs are being blocked by this issue..
 @ngtuna Did you get some time to review [this](https://github.com/kubernetes-incubator/kompose/pull/557) PR..
 "
,,549,"Update ROADMAP.
 This is my attempt for Kompose roadmap.
We should at least try to keep this up to date this time :wink: 

ping @pradeepto @cdrage @surajssd @containscafeine .
 > Suggestion for 1.0.0 section. Should we add a note saying feature complete as well as adding a no future changes + added backwards compatibility of releases?

I don't want to say feature complete. It sound like we are not planing to add new features to Kompose.
Maybe it could say something like that it will support all important keys (all keys that are possible to map to K8S) from docker-compose or something in that sense. I can't properly formulate that right now :-(.
 Another question. If we are doing time based releases does it even make sense to have feature target for 1.0?.
 @kadel Having a general 1.0.0 features list is required for the Kubernetes incubator as well as having an outline of what features need to be implemented / backwards compatibility would be nice..
 > @kadel Having a general 1.0.0 features list is required for the Kubernetes incubator as well as having an outline of what features need to be implemented / backwards compatibility would be nice.

Really?  I didn't know that incubation process says something about 1.0.0.
I must have missed that somewhere. .
 LGTM!.
 "
,,548,"update docs/conversion.md.
 docs/conversion.md is slightly out of the for example `tmpfs` is as unsupported.
 we can close this now.
 done.
 "
,,547,"Support insecure registry and enhance parsing of image stream tag.
 Add 2 enhancements for openshift:
	- support insecure docker registry for generation of openshift image stream
	    we add an import policy for the image stream tag by following instruction of the command argument
	- enhance parsing of image tag
	    current implementation doesn't support format like ""myregistryhost:5000/fedora/httpd:version1.0"". Enhance the parsing logic..
 @cdrage @kadel ,

Please kindly review this PR again. Very sorry for the inconvenience.

I close the #506 because I messed things up while merging from upstream..
 @qujinping Saw the changes!

One last thing and we can merge! Can you please squash your commits? .
 > One last thing and we can merge! Can you please squash your commits?

yep, this is last think even for me. Once this get squashed its ready to be merged..
 
Squashed as it should be :)

Thanks.
.
 LGTM! Thanks a lot for your contributions @qujinping!!.
 "
,,546,"Add setup.md.
 Adds setup.md to the docs folder in order to sync with changes to
http://kompose.io site (whenever we update setup.md here, it'll update
on the gh-pages branch)..
 This is creating duplication with README.md :smirk: 
How we are going to keep those in sync?.
 @kadel Yup, it's a duplication of README.md which is edited when we do a release (version change).

The doc syncs with the setup.md in gh-pages as well.

Yes, we need to update README.md to reflect the new doc. .
 I meant how we are going to keep setup.md and readme in sync.

Its going to be hard  to maintain  install instruction in two places :-(
We are already bad in keeping docs up to date and remembering it to edit it in two places will just add to it :-(.
 It is better to have install instruction in readme, but rather that having it in two places we could just link to setup.md from readme
.
 @kadel Yup, that's what I meant. In the README.md we'll have our recommend way (installation via binary), in the `docs` section, we'll have the elaborate way (CentOS, Fedora, etc.) as we get more packaging and other installation methods added..
 @kadel Ready for review, I ended up re-working the installation methods on our README.md to emphasize binary installation as well as have the setup.md document list *all* of our installation methods (much cleaner than our current README).
 @kadel updated!.
 "
,,545,"kompose should give warning on providing blank environment variables.
 Sometimes docker-compose files have environment variables which are not set, In that case, we should give warning to user.

inspired from https://github.com/redhat-developer/opencompose.
 I don't know if this makes sense for docker-compose.
environment variables has one additional feature in docker-compse.
If value is not set for in docker-compose file, than value is taken from environment that runs `docker-compose` command.

.
 @kadel @surajnarwade If a value isn't provided, docker-compose will retrieve it from the host machine.

Should we close this issue?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,544,"Fatal error saying ""/etc/nginx/certs"": must be unique.
 I'm using `jrcs/letsencrypt-nginx-proxy-companion` in my `docker-compose.production.yml` and `kompose -f docker-compose.production.yml up` throws an error saying

```
WARN Unsupported logging key - ignoring
WARN Volume mount on the host ""/var/run/docker.sock"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""./certs"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""/var/run/docker.sock"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""./certs"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""/var/run/docker.sock"" isn't supported - ignoring path on the host
WARN Volume mount on the host ""./certs"" isn't supported - ignoring path on the host
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead.

INFO Successfully created Service: letsencrypt
INFO Successfully created Service: proxy
FATA Error while deploying application: Deployment.extensions ""letsencrypt"" is invalid: spec.template.spec.containers[0].volumeMounts[4].mountPath: Invalid value: ""/etc/nginx/certs"": must be unique
```

How can I fix this issue?

---

My `kompose version` is `0.5.0 ()`

And my `docker-compose.production.yml` below.

```yml
version: ""2""

services:

  proxy:
    image: jwilder/nginx-proxy
    privileged: true
    container_name: proxy
    ports:
      - 80:80
      - 443:443
    volumes:
      - /etc/nginx/vhost.d
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./certs:/etc/nginx/certs:ro
      - /usr/share/nginx/html
    restart: always
    logging:
      options:
        max-size: 5m
        max-file: ""10""

  letsencrypt:
    image: jrcs/letsencrypt-nginx-proxy-companion
    privileged: true
    container_name: ssl
    volumes_from:
      - proxy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./certs:/etc/nginx/certs:rw

networks:
  default:
    external:
      name: shared
```
.
 @RyoIkarashi , `HOST:CONTAINER` or an access mode `HOST:CONTAINER:ro` is not supported by kompose.
 @surajnarwade Thanks for your quick reply! Do you have any plan to support those functionalities?.
 @RyoIkarashi, it may be problematic if you have multinode clusters, it may cause troubles.
@kadel thoughts ?.
 @RyoIkarashi 
It looks like there are two issues.

One is what @surajnarwade mentioned. This is not going to work as expected, because Kompose doesn't support copying local data to Kubernetes cluster (this is what all warning about ""WARN Volume mount on the host"" mean.) And side effect is of this is that mounting docker.sock to container wont work also :-( But I'm not sure if that is good idea to do that in Kubernetes. Cant this app work without docker socket?

Second issue is causing that  FATAL Error. From quick look it seems like this is bug in Kompose.
Kompose generates Kubernetes Deployment with two volumeMounts for same path `/etc/nginx/certs`.
`letsencrypt` service defines volume for `/etc/nginx/certs` and also uses `volumes_from` to share all volumes from `proxy` service. `proxy` service has its own volume for same `etc/nginx/certs`. Result is that Deplyment that gets generated has two volumeMounts for same path :-(

Quick workaround for second issue would be removing `./certs:/etc/nginx/certs:rw` volume from `letsencrypt` service and changing `./certs:/etc/nginx/certs:ro` in `proxy` to `./certs:/etc/nginx/certs:rw`
Down side of this that it key will be writable in `proxy` service :-(


.
 I take this up.
 I think we should FATAL. Since it's unable to transpose the volume keys to Kubernetes correctly, fataling before it get's a failing deploy would be ideal.

Although the output could be more informative / suggest an alternative?.
 @cdrage yeah, FATAL with info whats happening might help, I am onto it.
 > I think we should FATAL. Since it's unable to transpose the volume keys to Kubernetes correctly, fataling before it get's a failing deploy would be ideal.
> 
> Although the output could be more informative / suggest an alternative?

I don't think that it kompose should show FATAL err if this works in docker-compose.
We should handle this in the same way as docker-compose does..
 "
,,543,"Moved cpu_shares and cpuset to unsupported keys.
 Resolves #272 and #267

As there is no direct mapping of `cpushares` and `cpuset` to kubernetes,
it should not be read and should be moved to unsupported keys..
 LGTM other than the small comment.

Perhaps it would be good (in the future) to advise users to use cpu_quota instead of cpu_share or cpu_set!

Thanks for the contribution!.
 LGTM.
 "
,,542,"0.5.0 release.
 Mergin'!.
 "
,,541,"Kompose binary for ARM.
 I think, we should have kompose binary for ARM :).
 closes via https://github.com/kubernetes-incubator/kompose/pull/540.
 "
,,540,"Add ARM to make cross..
 This adds a linux/arm build to Makefile which will be included in the
release.sh script..
 ping @surajnarwade and @kadel 

Would need a quick review of this before I release 0.5.0 today :).
 #541 .
 Hey @surajnarwade and @kadel 

I'm going to go ahead and merge this in so I can do the 0.5.0 release today! .
 LGTM :).
 "
,,539,"Removed unused functions.
 Fixes #534 by removing functions askForConfirmation in app.go, TransformData and RandStringBytes in utils.go.
 LGTM.
 "
,,538,"add documentation about renaming service.
 We should add warning to docs explaining why, when and how we rename service as it may break some docker-compose files

see https://github.com/kubernetes-incubator/kompose/pull/509.
 I will pick this :).
 @surajnarwade I'm working on this .
 Sorry I didn't mentioned it here.
.
 @procrypt no issue :)
.
 "
,,537,"Update roadmap wrt to k8s 1.7 release.
 $subject

also needs to be put in https://docs.google.com/document/d/1g5yzEIWoNWJ4tdYRRQP8CE9JSoj4KFemAwayiTE6wnM/edit.
 We don't have to work in sync with Kubernetes releases.
We have our own pace.

But we definitely need roadmap for next few months. 
Its one of the criteria for graduation from incubator.

Lets create our separate roadmap and just link it in that document.

.
 done.
 "
,,536,"new take on ""Kompose will keep trying its job #477"".
 This is reopening of #477 there were some issues that we forgot to address. 

Issue was that if it can't connect to cluster it panics.
Problem is that we continue after every error.
There should be return after some errors, and after every error in switch should be break so we don't 
try to get reaper using client which creation field or calling `Stop` on reaper that field to create.

I've added new commit on top of  original @surajnarwade's commit, so its easier to review.
Once we agreed that this is the way we wan't to do it we can squash it
.
 LGTM.
 "
,,535,"Revert ""Kompose will keep trying its job"".
 Reverts kubernetes-incubator/kompose#477.
 ping @kadel 

Let's revert this for now since we're releasing Kompose today. Don't want this in / extra-test the PR..
 "
,,534,"Unused functions in app.go and utils.go.
 functions `askForConfirmation` in `app.go`, `TransformData` and `RandStringBytes` in `utils.go` are not called anywhere in kompose, shall we remove them   or they are there for any purpose ?.
 @surajnarwade yes if that is the case we remove it, do you wanna give it a stab?.
 @surajssd yeah.
 "
,,533,"Only ignore the docker-compose yaml file in the root directory.
 Woops! It was ignoring all of them in the directory. We should only be
avoiding the root dir docker-compose files!.
 LGTM :+1: .
 ` examples/docker-compose.yaml` and `script/test/fixtures/docker-compose.yml` were deleted before? What are those? Maybe leftovers from https://github.com/kubernetes-incubator/kompose/pull/528 ?.
 @kadel Yup, they were, I rebased and removed them..
 "
,,532,"kompose fails to build on ppc64 and ppc64le arches due to old sys/unix vendor package.
 Hi,

Kompose-v0.4.0 fails to build on ppc64(le) architectures with following error message:
\# github.com/kubernetes-incubator/kompose/vendor/github.com/fsnotify/fsnotify
src/github.com/kubernetes-incubator/kompose/vendor/github.com/fsnotify/fsnotify/inotify_poller.go:48: undefined: unix.Pipe2

It seems that vendored sys/unix package is old because /vendor/golang.org/x/sys/unix/syscall_linux_ppc64x.go doesn't contain definition of function Pipe2 for ppc64x while upstream has the fixes available https://github.com/golang/sys/commit/b776ec39b3e54652e09028aaaaac9757f4f8211a#diff-ed5775d43461429a9a5247567c3c9fd9R117 .

I built locally and in koji  by replacing /vendor/golang.org/x/sys/unix content with https://github.com/golang/sys/tree/master/unix/ and it builds successfully. 

I tried to update sys package in kompose using ""glide get golang.org/x/sys/unix"" , didn't use glide up because glide.yaml doesn't have entry for sys/unix . It doesn't seem to go successfully for me, details are at https://paste.fedoraproject.org/paste/nPuAB0vbRIXDwIqyA0YWE15M1UNdIGYhyRLivL9gydE=
. 

Reference
---------------
Complete build log - https://kojipkgs.fedoraproject.org//work/tasks/1264/18671264/build.log
Failed koji build link - https://koji.fedoraproject.org/koji/taskinfo?taskID=18671235
Successful koji build link after sys/unix update - https://koji.fedoraproject.org/koji/taskinfo?taskID=18697032.
 ping @kadel @surajssd - this is why we can't get 0.4.0 out into Fedora right now. It looks like we need to update golang.org/x/sys/unix to latest version. .
 Hey @dustymabe  @sinnykumari 
I've updated this in #529 

Give it your LGTM and this issue will be fixed :).
 "
,,531,"Move docker-compose.yml test file to tests.
 Moves a file that was incorrectly being used from examples to
script/test/fixtures..
 Unblocks #528.
 it might be better to move ` script/test/docker-compose.yml` to its own directory in `fixtures` so its inline with other tests.
 @kadel Done! Moved it to `redis-example`..
 There, tests should pass now!.
 Woo :+1: .
 "
,,530,"Timestamps are added again to compose..
 Noticed that timestamps were added again for some odd reason, found it was an odd vendor update that messed it up: https://github.com/kubernetes-incubator/kompose/commit/e9544ca89477ed76bd75f1160f9a89686f75e95d

See:

```
github.com/kubernetes-incubator/kompose  fix-logrus-bug ✔                                                                                                                                                                                                                   5m  ⍉
▶ ./kompose convert
FATA[0000] No 'docker-compose' file found: stat docker-compose.yaml: no such file or directory 
```

I've fixed this in #529 .
 Fixed in #529 so going ahead and closing this..
 "
,,529,"Update vendoring + fix issue with timestamps being added to log.
 As per the vendoring here:
https://github.com/kubernetes-incubator/kompose/commit/e9544ca89477ed76bd75f1160f9a89686f75e95d
for some odd issue, text_formatter.go in the logrus package was updated
to an older file.

This commit updates the vendoring as well as specifies a specific
version for logrus to be used..
 Closes #529 .
 Thanks Charlie! This commit looks good to me in terms of /vendor/golang.org/x/sys update and should fix issue#532.
 @cdrage, do you have any comprehensive tests you can run?.
 @cdrage can you add that this fixes #532 to the commit comment?

also I have a question, if we are updating a lot of different things then I think we might need a new release of kompose in order to put it out. would rather not pull back a patch if its going to be a large change. .
 @dustymabe No comprehensive tests are being run right now, we're working on adding more integration tests. But unit tests + cmd tests are the only ones being ran at the moment.

Yup. We can do another release on Monday! .
 sounds good. once you commit PR we can have @surajssd build an srpm from this commit (don't need a release yet) and I can run it through the fedora build system to verify everything works on ppc **before you do a release**. .
 I've confirmed that this commit works and we've gotten a LGTM.

Let's merge this!.
 "
,,528,"Fix the examples.
 Moves `docker-compose.yaml` to `docker-compose-counter.yaml` and
replaces the default docker-compose.yaml with the example from the
Kompose.io website.

We also rename each file from yml to yaml.

As well as do some slight modifications / formatting to
docker-compose-bundle.dab.
 Uh oh. Looks like we relied on those examples for some odd-reason in the tests. I'll update this..
 I noticed that you've deleted `examples/docker-guestbook.yml` ?.
 @kadel 

Yes. That's replaced by `docker-compose.yaml` which is the guestbook example we use on http://kompose.io.
 @kadel `docker-compose.yaml` was missing since it was added to `.gitignore`. I've updated this PR..
 @cdrage , functional tests need to be updated as you renamed the file `docker-compose.yml` -> `docker-compose.yaml`
https://github.com/kubernetes-incubator/kompose/blob/master/script/test/cmd/tests.sh#L182-L188.
 I'm lost in all this :-)

now you are reneaming `docker-guestbook.yml` to `docker-compose.yaml`?
Maybe you wanted `docker-guestbook.yaml`?.
 @kadel 
Yes, I'm renaming it. If you check http://kompose.io both docker-guestbook.yaml and the example on the site is the same. Since it's our go-to-example. I've renamed docker-guestbook.yaml to docker-compose.yaml in the examples folder..
 @surajnarwade Yes, as referenced in this PR, https://github.com/kubernetes-incubator/kompose/pull/531 unblocks this PR..
 > Yes, I'm renaming it. If you check http://kompose.io both docker-guestbook.yaml and the example on the site is the same. Since it's our go-to-example. I've renamed docker-guestbook.yaml to docker-compose.yaml in the examples folder.

OK

.
 I guess this will need rebase once #531 is merged.
 Rebased and waiting for Travis to pass then mergin'.
 Woop woop! Mergin' awayyy.
 "
,,527,"Update contributing doc for reviewing, update owners file.
 Owners file currently isn't being used (unless we have the Kubernetes
bot in-use), however, it needed a well-overdue update.

I've gone ahead and updated the CONTRIBUTING.md doc to add the change
that it requires *two* reviews for a code-review and one for a doc
review..
 few stupid questions as always :innocent: 
What is difference between assignees, reviewers and reviewers in OWNERS file?

It might be better to write names in alphabetical order, it will easier to find name there.

Are we going to require 2 acks for every code PR? 
I know that we discussed that before, and decided that we will do it only for some PR, but didn't set any rules around that :-(
I'm OK with requiring 2 ack from now on, we can try it to see how much it will slow us down, or if at all.


.
 @kadel 

It's to do with their ""mungebot"" for merging. Difference is that you can /lgtm to the bot as an reviewer, same as the asignee. Approvers of course are able to /merge the PR with mungebot.

Honestly, I doubt we're going to use mungebot here (I've tried configuring it once before and found it too cumbersome for our needs), but it's nice to have consistency here.

:+1: for two ack's comment. If it slows us down let's switch back to one ack. Or we could have it that it's 1 maintainer ack and 1 other maintainer OR non-maintainer ack..
 OK, lets go with 2 maintainers lgtm for now, if will be too much we can relax rules to 1 maintainer and one other.

There is no way to enforce 2 lgtms without bot :-(,  we will have to keep that in mind and trust each other..
 @cdrage my username is added twice in reviewer section, i think you wanted to add @surajnarwade.
 @surajssd Updated! Just need another review and then we can merge this in..
 @kadel Done!.
 "
,,526,"Fixed functional tests.
 Fixes #431

fixed commands where output showing `command not found` and k8s output
added for restart-options example..
 "
,,525,"Fix typo in tarball link in readme.
 Fixes the link on the README.md related to the tarball archive.
 "
,,524,"Fix typo in replicas and organize flags.
 Fixes a typo in the `--replicas` command as well as changes up some
grammar and moves the 'markashidden' flag values elsewhere..
 "
,,523,"Remove unused parameters from Kompose down.
 Remove --replicas and --emptyvols from Kompose down.
 LGTM :) .
 "
,,522,"kompose.service.type label not working as expected.
 According to the documentation ( [User Guide - labels](https://github.com/kubernetes-incubator/kompose/blob/master/docs/user-guide.md#labels) ) I should be able to specify the label kompose.service.type: NodePort in docker-compose.yml. However it is not behaving as expected. My understanding is the services should be configured as described here https://kubernetes.io/docs/user-guide/services/#type-nodeport

docker-compose.yml

    version: ""2""
    services:
      webapiapplication:
        image: webapiapplication
        labels:
          kompose.service.type: NodePort

Powershell command and output

    PS C:\agents\windows_01\_work\1\a> kompose -f .\docker-compose.yml convert
    INFO[0000] file ""webapiapplication-service.yaml"" created
    INFO[0000] file ""webapiapplication-deployment.yaml"" created

webapiapplication-service.yaml

    apiVersion: v1
    kind: Service
    metadata:
      annotations:
        kompose.service.type: NodePort
      creationTimestamp: null
      labels:
        service: webapiapplication
      name: webapiapplication
    spec:
      clusterIP: None
      ports:
      - name: headless
        port: 55555
        targetPort: 0
      selector:
        service: webapiapplication
    status:
      loadBalancer: {}


webapiapplication-deployment.yaml

    apiVersion: extensions/v1beta1
    kind: Deployment
    metadata:
      annotations:
        kompose.service.type: NodePort
      creationTimestamp: null
      name: webapiapplication
    spec:
      replicas: 1
      strategy: {}
      template:
        metadata:
          creationTimestamp: null
          labels:
            service: webapiapplication
        spec:
          containers:
          - image: webapiapplication
            name: webapiapplication
            resources: {}
          restartPolicy: Always
    status: {}.
 Found the below article which shows the use of the labels in a slightly different manner and this is also not working. 

http://sysadvent.blogspot.com/2016/12/day-11-going-from-local-docker-compose.html

docker-compose.yml

    version: ""2""
    services:
      webapiapplication:
        image: webapiapplication
        labels:
         - ""com.example.description=MyDescription""
         - ""kompose.service.type=nodeport"".
 @Minx-SigEp 

You're missing a port!

Since there's no port being added, it's being created as a headless service.

@kadel I think we should still have ClusterIP / LoadBalancer / Whatever-they-choose added as a `type:` regardless if they have specified a port or not, do you agree?



.
 > @kadel I think we should still have ClusterIP / LoadBalancer / Whatever-they-choose added as a type: regardless if they have specified a port or not, do you agree?

We can try that. But I'm afraid that it won't work as expected. 
If there there is a docker-compose service without port, create kubernetes [headless service](https://kubernetes.io/docs/user-guide/services/#headless-services), I'm afraid that it doesn't make sense or is even possible to create headless service that is  NodePort or LoadBalancer, in all those cases you need to know port number.

Haven't done any research around that, there might be some workaround that I don't know about..
 @kadel So best thing to do would be to warn instead. .
 @cdrage Yes, I would even consider failing. It doesn't really make sense to use LoadBalancer or NodePort without specifying port..
 @cdrage I tried it out using the with the docker-compose file

`docker-compose.yml`
```yaml
version: ""2""
services:
  webapiapplication:
    image: centos/httpd
    labels:
      kompose.service.type: NodePort
```

`webapiapplication-service.yaml`
```yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.service.type: NodePort
  creationTimestamp: null
  labels:
    io.kompose.service: webapiapplication
  name: webapiapplication
spec:
  clusterIP: None
  type: NodePort
  ports:
  - name: headless
    port: 55555
    targetPort: 0
  selector:
    io.kompose.service: webapiapplication
status:
  loadBalancer: {}
```

`webapiapplication-deployment.yaml`
```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    kompose.service.type: NodePort
  creationTimestamp: null
  name: webapiapplication
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: webapiapplication
    spec:
      containers:
      - image: centos/httpd
        name: webapiapplication
        resources: {}
      restartPolicy: Always
status: {}
```
The application has been deployed but it is not reachable from outside the container

```bash
$ kubectl describe service webapiapplication
Name:                   webapiapplication
Namespace:              default
Labels:                 io.kompose.service=webapiapplication
Selector:               io.kompose.service=webapiapplication
Type:                   NodePort
IP:                     None
Port:                   headless        55555/TCP
NodePort:               headless        30289/TCP
Endpoints:              172.17.0.3:55555
Session Affinity:       None
No events.
```

```bash
$ curl `minikube ip`:30289
curl: (7) Failed to connect to 192.168.99.100 port 30289: Connection refused
```

Its not reachable even inside the container

```bash
$ kubectl logs webapiapplication-3252267673-kjdzt 
AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.17.0.3. Set the 'ServerName' directive globally to suppress this message
```
```bash
$ kubectl exec -it webapiapplication-3252267673-kjdzt bash
[root@webapiapplication-3252267673-kjdzt /]# curl 172.17.0.3:55555
curl: (7) Failed connect to 172.17.0.3:55555; Connection refused
```.
 @kadel , Shall we add FATAL error  if  LoadBalancer or NodePort are given  without specifying port ?.
 > @kadel , Shall we add FATAL error if LoadBalancer or NodePort are given without specifying port ?

yes, that makes sense, we should fail, as it doesn't make sense to use `NodePort` or `LoadBalancer` without port defined..
 @surajnarwade are you working on this?.
 @surajssd yeah.
 "
,,521,"Add build and push support.
 This adds support for building and pushing docker containers
when you perform either `kompose convert` or `kompose up`.

Docker Compose files who have build parameters with their respective
image and build keys will automatically be both built and pushed..
 Tests are going to fail + no new tests written (yet!).
 Current tests pass :tada: 

Now it's time to add some new unit tests!.
 Ready for review @containscafeine @surajssd @kadel 

Honestly, I couldn't come up with a (decent) way of testing BuildImage... I tried emulating what was used here: https://github.com/fsouza/go-dockerclient/blob/master/build_test.go but it proved to be too integrated into their own code.

Ideally, we need to create some integration tests for building an image..
 @kadel That makes total sense, I interpreted the implementation wrong. You are correct, if we pass in build, we should build it by default. However, should we simply enable this by default with the parameter (default value true) so you can choose if you'd like to build it or not? For example, maybe the image is already updated externally and doesn't need a rebuild (which may take longer).

Yes, I'd be viable to have both functionalities working when we add this, but I don't think it'd ""break"" anything. `--push` Simply pushes the Docker image to an external repository, if you have a local build. the K8s or OpenShift cluster would still pick up the image..
 I think the decision should go like this 

**NOTE**: here `build` and `image` are from docker-compose. `no-builds` and `local-build` are flags

for `k8s` add one flag to `no-builds`


```
if build && image 

    build image with this image name


if build

    build by giving some intelligent name to image


if build && image && no-build flag 

    just use the image name and dont build


if image && no build flag

    just ignore the flag and use image name as we do


if image

    just use image as we do


if build &&  no build flag

    fail on this
```



for `openshift` add two flags `no-builds` and `local-build`

```
if image

    use image to generate 'dc' as usual


if image && no-build-flag

    use image to generate 'dc' as usual


if image && local-build-flag

    fail since no build info is given


if image && local-build-flag && no-build-flag

    fail since local building and not building cannot go together


if build

    create 'bc' like we do already


if build && no-build-flag

    fail since conflicting things are happening here


if build && local-build-flag

    do local build and then generate deployment config with the image name that was generated
    no 'bc' only 'dc'


if build && image && local-build-flag

    do local build, name image the name given and then generate 'dc' with the image name


if build && image && no-build-flag

    do not do any build use image name to generate 'dc' without 'bc'


if build && image given

    generate 'bc' with image name given


if build && image && local-build-flag && no-build-flag

    fail since all are conflicting
```.
 > if build && image && no-build-flag
    do not do any build use image name to generate 'dc' without 'bc'

seems like that should be an error since the build and no-build flags are conflicting.
.
 >seems like that should be an error since the build and no-build flags are conflicting.

this flag is to over-ride the build in the docker-compose file..
 when I run it 

```bash
$ ~/.local/bin/kompose up --build
WARN Kubernetes provider doesn't support build key - ignoring 
INFO Building image foomyimagename                
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Successfully created Service: foo            
INFO Successfully created Deployment: foo         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

I get `WARN Kubernetes provider doesn't support build key - ignoring` which should be removed. Also we are not specifying anything about where the image is built and how a user can push it somewhere and things like that.

in `INFO Building image foomyimagename` if the image name would have been in double quotes it will make it more readable.

And since I am running minikube locally the cluster has no idea how to pull the image since it is built and saved somewhere else.

```bash
$ kubectl get pods
NAME                   READY     STATUS         RESTARTS   AGE
foo-1414336575-t1mpt   0/1       ErrImagePull   0          15s
```

after sometime
```
$ kubectl get pods
NAME                   READY     STATUS             RESTARTS   AGE
foo-1414336575-t1mpt   0/1       ImagePullBackOff   0          1m
```

using following Dockerfile
```
$ cat Dockerfile 
FROM busybox

ADD . /

ENTRYPOINT [""sleep"", ""infinity""]
```

using following docker-compose file
```
$ cat docker-compose.yml 
version: ""2""

services:
  foo:
    build: .
    image: foomyimagename
    ports:
    - ""80""
```.
 using following docker-compose file
```yaml
$ cat docker-compose.yml 
version: ""2""

services:
  foo:
    build: .
    ports:
    - ""80""
```

the one with `build` construct only:

```bash
$ kompose up --build
WARN Kubernetes provider doesn't support build key - ignoring 
INFO Building image foo                           
INFO We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 
 
INFO Successfully created Service: foo            
FATA Error while deploying application: Deployment.apps ""foo"" is invalid: spec.template.spec.containers[0].image: Required value 

```

here it is missing the image name so it is failing.
 So putting the image name of the image built into deployments is what we need to do here.
 also the build step is opaque, is there a way to know what is actually happening? For builds that take sometime it will be really hard to know if the image is built or the build step is just hung on something as it usually happens?.
 > --push Simply pushes the Docker image to an external repository, if you have a local build. the K8s or OpenShift cluster would still pick up the image.

This assumes that you have single node cluster and docker daemon that is running build is the same daemon that kubernetes uses. You can't count on that. Most of the setup are not like that. 
You have to think as cluster is running outside of your machine (VM, cloud, etc...).
 @surajssd 

> if build &&  no build flag
>  fail on this

this can't be fail if following works

> if build
>  build by giving some intelligent name to image

In the case of `build && no build flag` it should assume same intelligent image name.


**But I don't think that `no build` flag is needed, It just complicates things a lot.**
It adds a lot of complexity and I don't think there is need for that.
If I'm wrong, we can always add it later..
 Hey guys! Thanks so much for the updates.

I've changed this back to a WIP title and i'm going through and updating this PR based on the comments.

I'll be adding push support to this as well as the build support. I'm going through Kubernetes support first and then will be doing OpenShift support..
 @kadel @containscafeine @surajssd 
So I need some insight on whether this is correct or not. 

Here is the output, please check to see if the OpenShift output is correct with BuildConfig, etc!

# Docker Compose

```
version: ""2"" 

services:
    foo:
        build: ""./build""
        image: foobar
```

```
github.com/kubernetes-incubator/kompose  add-build-support ✗                                                                                                                                                                                                          23h13m ◒  ⍉
▶ cat foo-buildconfig.yaml 
apiVersion: v1
kind: BuildConfig
metadata:
  creationTimestamp: null
  name: foo
spec:
  nodeSelector: null
  output:
    to:
      kind: ImageStreamTag
      name: foobar:latest
  postCommit: {}
  resources: {}
  runPolicy: Serial
  source:
    contextDir: examples/buildconfig/build
    git:
      ref: add-build-support
      uri: git@github.com:cdrage/kompose.git
    type: Git
  strategy:
    dockerStrategy: {}
    type: Docker
  triggers:
  - type: ConfigChange
  - type: ImageChange
status:
  lastVersion: 0

github.com/kubernetes-incubator/kompose  add-build-support ✗                                                                                                                                                                                                           23h13m ◒  
▶ cat foo-deploymentconfig.yaml 
apiVersion: v1
kind: DeploymentConfig
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: foo
  name: foo
spec:
  replicas: 1
  selector:
    io.kompose.service: foo
  strategy:
    resources: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: foo
    spec:
      containers:
      - image: ' '
        name: foo
        resources: {}
      restartPolicy: Always
  test: false
  triggers:
  - type: ConfigChange
  - imageChangeParams:
      automatic: true
      containerNames:
      - foo
      from:
        kind: ImageStreamTag
        name: foobar:latest
    type: ImageChange
status: {}
github.com/kubernetes-incubator/kompose  add-build-support ✗                                                                                                                                                                                                           23h13m ◒  
▶ cat foo-imagestream.yaml 
apiVersion: v1
kind: ImageStream
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: foo
  name: foo
spec: {}
status:
  dockerImageRepository: """"

github.com/kubernetes-incubator/kompose  add-build-support ✗                                                                                                                                                                                                           23h13m ◒  
▶ cat foo-service.yaml 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: foo
  name: foo
spec:
  clusterIP: None
  ports:
  - name: headless
    port: 55555
    targetPort: 0
  selector:
    io.kompose.service: foo
status:
  loadBalancer: {}
```

Is that all correct?

I'm going to start on the ""push"" functionality now until I get some feedback. I just wanted to make-sure that my OpenShift implementation works correctly.

Thanks! :dancer: .
 on your buildconfig: you can't have an imagechangetrigger w/ no triggering image specified if you aren't specifying the FROM image in your docker strategy.

see:
https://github.com/openshift/origin/blob/master/examples/sample-app/application-template-dockerbuild.json#L136-L142

So you have three choices:
1) omit the imagechangetrigger
2) specify the imagestreamtag that's going to trigger the imagechangetrigger explicitly, as part of the imagechangetrigger definition
3) specify the imagestreamtag that will serve as the base image for the build, in the docker strategy section (this will result in overwriting the FROM value in the Dockerfile when the build runs).

Since you're not creating imagestreamtags for the base image, (1) is probably your only realistic option here.
.
 @bparees Okay, removing `  - type: ImageChange` it is? do you agree @kadel @surajssd ? Excuse my OpenShift newbieness..
 >  Excuse my OpenShift newbieness.

no problem, pretty sure you would have gotten a validation error from openshift if you tried to create the buildconfig like that anyway.
.
 Okay, I've gone ahead and remove the 'ImageChange' trigger from this section:
```
▶ cat foo-buildconfig.yaml 
apiVersion: v1
kind: BuildConfig
metadata:
  creationTimestamp: null
  name: foo
spec:
  nodeSelector: null
  output:
    to:
      kind: ImageStreamTag
      name: foobar:latest
  postCommit: {}
  resources: {}
  runPolicy: Serial
  source:
    contextDir: examples/buildconfig/build
    git:
      ref: add-build-support
      uri: git@github.com:cdrage/kompose.git
    type: Git
  strategy:
    dockerStrategy: {}
    type: Docker
  triggers:
  - type: ConfigChange
  - type: ImageChange
status:
  lastVersion: 0
```

To:
```
▶ cat foo-buildconfig.yaml 
apiVersion: v1
kind: BuildConfig
metadata:
  creationTimestamp: null
  name: foo
spec:
  nodeSelector: null
  output:
    to:
      kind: ImageStreamTag
      name: foobar:latest
  postCommit: {}
  resources: {}
  runPolicy: Serial
  source:
    contextDir: examples/buildconfig/build
    git:
      ref: add-build-support
      uri: git@github.com:cdrage/kompose.git
    type: Git
  strategy:
    dockerStrategy: {}
    type: Docker
  triggers:
  - type: ConfigChange
status:
  lastVersion: 0
```

Hopefully this is correct! I've got to try this against MiniShift...
 Phew. That was a lot of coding.

So I've got both the build and push support completed! This is good for a preliminary review! @kadel @surajnarwade @surajssd @containscafeine 

Use (for example) with this PR:
```
version: ""2""
services:
    foo:
        build: ""./build""
        image: cdrage/foobar
```.
 @kadel @surajssd @bparees 

Need a little bit of OpenShift help!

Tests are failing and that's due to the image names only having the last name of it, for example, `swordphillic/postgresql:latest' is being propagated as `postgresql:latest` in the current version of Kompose.

```
      ""spec"": {
        ""tags"": [
          {
            ""name"": ""latest"",
            ""annotations"": null,
            ""from"": {
              ""kind"": ""DockerImage"",
              ""name"": ""centos/etherpad:latest""
            },
            ""generation"": null,
            ""importPolicy"": {}
          }
        ]
      },
```

Is this correct? Is the value `centos/etherpad:latest` a correct value to put? Or does OpenShift *only* rely on local builds (ex. `etherpad:latest` instead).

Stupid question, I know, but I just wanted to make sure 100% before I start going through and changing the test comparisons (hence why they're failing). .
 > Is this correct? Is the value centos/etherpad:latest a correct value to put? Or does OpenShift only rely on local builds (ex. etherpad:latest instead).

centos/etherpad:latest is a valid DockerImage reference value for openshift.  anything you can ""docker pull"" is a valid value.  We're going to take that value and substitute it into the top of your Dockerfile, replacing your existing FROM line in your Dockerfile.

Note that you can also forgo providing that value entirely, since you're doing a docker build and we know you're going to supply a Dockerfile with a FROM in it.
.
 @bparees Awesome! Thanks! :dancer: .
 Tests pass!

@surajssd @surajnarwade @containscafeine Could any of you test / give a review? :)

Perhaps @ashetty1 @procrypt @rtnpro if you are not busy?.
 At first attempt, I can understand what is the error here by looking at the image name:
```bash
$ kompose convert --build                                                                                                                                       
INFO Building image 'docker.io/cdrage/foobar' from directory 'build' 
INFO Pushing image 'cdrage/foobar:latest' to registry 'docker.io' 
ERRO Unable to push image 'cdrage/foobar:latest' to registry 'docker.io': unauthorized: incorrect username or password 
ERRO Unable to push image 'cdrage/foobar:latest' to registry 'docker.io': unauthorized: authentication required 
ERRO Unable to push docker image(s). Check that `docker login` works successfully on the command line. 
INFO file ""foo-service.yaml"" created              
INFO file ""foo-deployment.yaml"" created     
```
But a newbie might not find out that the image name i have given is wrong. So a mechanism to drill down the issue saying that image name is wrong would be better thing to do.

---

Now that I have edited the docker-compose file to have the image name with my docker.io user name. This was weird here it first said it was not able to authorize with the registry, but then also pushed image successfully.
```
$ kompose convert --build                                                                                                                                       
INFO Building image 'docker.io/surajd/foobar' from directory 'build' 
INFO Pushing image 'surajd/foobar:latest' to registry 'docker.io' 
ERRO Unable to push image 'surajd/foobar:latest' to registry 'docker.io': unauthorized: incorrect username or password 
INFO Successfully pushed image 'surajd/foobar:latest' to registry 'docker.io' 
INFO file ""foo-service.yaml"" created              
INFO file ""foo-deployment.yaml"" created 
```
---

If I am using the `--build` flag then I don't need to have a buildconfig created right? I just want a `dc`, `is` and `svc` created. Because my openshift cluster won't allow a build that needs operations like installing things using `yum`?

```bash
$ kompose convert -o configs/ --build --provider openshift
INFO Building image 'foo' from directory 'build'  
WARN No image name has been passed for service foo, skipping pushing to repository 
INFO Buildconfig using git@github.com:surajssd/kompose.git::pr_521 as source. 
INFO file ""configs/foo-service.yaml"" created      
INFO file ""configs/foo-deploymentconfig.yaml"" created 
INFO file ""configs/foo-imagestream.yaml"" created  
INFO file ""configs/foo-buildconfig.yaml"" created  
```.
 Down here I am also creating a test matrix as we go ahead with it, where I will keep adding what I did to test the setup.

- A docker-compose file with wrong image name, specifially username of `cdrage` while it should be `surajd`, when running `kompose convert --build`, it should error out saying the image name is wrong rather than saying that I an unauthorized. For more details see the [comment](https://github.com/kubernetes-incubator/kompose/pull/521#issuecomment-301988312)..
 @surajssd Thanks so much for testing!

To answer some of your questions:

1. Yes, ideally when it fails to push the image, it should fail immediately. Instead of continuing (it works as intended that you're unable to push the image to my username on Docker Hub! I'll make this more verbose!)

2.  So what's happening with the whole ""unable to authorize"" on the first attempt, but works on the second is that it's iterating through your docker config json file. It failed on the first one (since it picked up the first configuration), but not on the second. It should *warn* on this.

3. The `--build` flag is True by default. If you wish to build without actually building the images, you'll have to set it to `--build False`

Let me know if number 3 is suitable! I don't know what other parameter would perhaps suit it better!.
 I also believe that it should *not* error out if the username is wrong. Besides, what if people have orgs / different usernames on there? Failing based on not being able to authenticate is correct and it is what Docker does as well as when you do `docker push`..
 Is build not supported in  `kompose up`? 

I'm not sure if `kompose convert` should build images. I would kind of expect this to be only part of `kompose up`, but not sure about that.

.
 Does it make sense to build image if there is no image name in docker-compose file?
```
INFO Building image 'bar' from directory 'build2' 
WARN No image name has been passed for service bar, skipping pushing to repository 
```

Maybe we could just error out? 

.
 "
,,520,"Removing unused variable from convert.go.
 Fixes #513
removed `ConvertSource` and `ConvertBuildConfig`, since they are no longer used..
 LGTM.
 "
,,519,"Added warning after PVC creation.
 Partially resolve #376
Added warning, such that PV should be created before PVC or
if dynamic provision is there, no need to create PV..
 @surajnarwade I commented earlier on the INFO but I still believe that your output is *way* too long:
```
			log.Infof(""volume %q of size \""100 Mi\"" created, PersistentVolume should be created before in order to PersistentVolumeClaim start working, unless it will be in pending state \n If Cluster has dynamic Provisioning and Storage Classes, So you don't have to do anything"", volumeName)
```

This can be shortened to something along the lines of:
```
PersistentVolumeClaim of size 100Mi created. PVC's will not work unless a PersistentVolume has been created.
```

It should be straight-to-the-point!.
 I think one of the tests may be giving a false positive... I believe this INFO needs to be added to `openshift.go`..
 Also, the additional information would be best added here: https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/kubernetes.go#L667

Or else you'll just get two outputs..
 cc @cdrage @kadel .
 This LGTM. Sorry to nitpick again, but would it be better to get the `100` value from a constant? (so we don't have to change the log info if we decide to change the default value).
 @cdrage ,done with changes.
 @surajnarwade Could you change these lines too to take from the constant? 

https://github.com/surajnarwade/kompose/blob/c37831c29c0c9d78f8138858d236f86ef502c88d/pkg/transformer/kubernetes/kubernetes.go#L247.
 LGTM, does this look good to you too @kadel ?.
 cc @kadel .
 "
,,518,"Functional tests in golang.
 This is the work I had done last week for writing functional test in golang. Here I am providing the `output.json` file to `ioutil.ReadFile` and then comparing it with the stdout of `kompose convert`.

In context to #432 
@kadel @cdrage @containscafeine  Let me know if this is the correct way to proceed..
 @procrypt 

This looks great to me! :+1: Awesome work! 

Just missing ExpectFailure right?.
 @cdrage Thanks. I'll finish it soon :relaxed: .
 @cdrage Please review..
 Travis still failing / not working :(
```
script/test/cmd/tests.go:121: not enough arguments in call to ExpectSuccessK8s
script/test/cmd/tests.go:122: not enough arguments in call to ExpectSuccessOpenShift
script/test/cmd/tests.go:123: not enough arguments in call to ExpectSuccessAndWarningK8s
script/test/cmd/tests.go:124: not enough arguments in call to ExpectSuccessAndWarningOpenShift
script/test/cmd/tests.go:125: not enough arguments in call to ExpectFailureK8s
script/test/cmd/tests.go:126: not enough arguments in call to ExpectFailureOpenShift
```

ping @procrypt .
 @containscafeine I have moved all `kompose convert` test to golang..
 Ping @cdrage @surajssd .
 @procrypt Tests still failing :(.
 @procrypt This one is blocked on https://github.com/kubernetes-incubator/kompose/pull/565 right ?.
 @surajssd Yeah I'm almost done working on this PR, will update #565 soon with the test..
 Ping @cdrage @surajssd  All green now :+1: .
 I think the diff will be smaller once https://github.com/kubernetes-incubator/kompose/pull/596 is merged.
 Also if you are moving the file @procrypt use `git mv` maybe https://git-scm.com/docs/git-mv this will only show those moved files as moved and not as deleted and added will again reduce the diff.
 Ping @surajssd @cdrage .
 @cdrage @surajssd @containscafeine @surajnarwade  please review, all tests are passing locally..
 @kadel @cdrage @surajssd Tests are passing on `go 1.7`,  `go 1.8` and `go 1.6.3` but there is some issue with `go 1.6` :(.
 Odd, says:
```
go test -v script/test/cmd/cmd_test.go
# command-line-arguments
script/test/cmd/cmd_test.go:5:2: cannot find package ""comman/vendor/github.com/Sirupsen/logrus"" in any of:
	/home/travis/.gimme/versions/go1.6.linux.amd64/src/comman/vendor/github.com/Sirupsen/logrus (from $GOROOT)
	/home/travis/gopath/src/comman/vendor/github.com/Sirupsen/logrus (from $GOPATH)
FAIL	command-line-arguments [setup failed]
make: *** [test-cmd] Error 1
```.
 @cdrage you have to run it like this `go test -v github.com/kubernetes-incubator/kompose/script/test/cmd`.
 @cdrage @kadel @surajssd @containscafeine @surajnarwade All green now please review :).
 Also, both commits have blank messages, no information regarding what's changed, only titles..
 @cdrage Done..
 @containscafeine review please..
 Interesting, If I run `make test-cmd` couple times in the row, somethings ""BuildConfig"" test fails.
 @kadel this is because of the environment variables, PR #631 will fix this..
 > @kadel this is because of the environment variables, PR #631 will fix this.

But it's affecting only BuildConfig and nothing else.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,517,"Added support for different namespaces.
 Now we can deploy application in different namespaces using the `--namespace=<value>` flag with `kompose up` and `kompose down`. The `--namepace` flag will deploy the application in that particular `namespace` if, exist.

`docker-compose` file used.
```yaml
version: ""2""
services:
  web:
    image: tuna/docker-counter23:latest
    ports:
      - ""5000:5000""
    links:
      - redis
  redis:
    image: redis:latest
    ports:
      - ""6379""
```
Current `namespaces` in k8s cluster
```bash
$ kubectl get namespace 
NAME          STATUS    AGE
default       Active    3m
development   Active    3m
kube-system   Active    3m
```

Deploy application in `namespace=development`
```bash
$ kompose up --namespace=development
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Deploying application in ""development"" namespace
 
INFO[0000] Successfully created Service: redis          
INFO[0000] Successfully created Service: web            
INFO[0000] Successfully created Deployment: redis       
INFO[0000] Successfully created Deployment: web         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

Verify application been deployed in the `namespace=development` correctly
```bash 
$ kubectl get deployment,svc,pods,pvc --namespace=development
NAME                        DESIRED      CURRENT             UP-TO-DATE   AVAILABLE   AGE
redis                       1            1                   1            0           2m
web                         1            1                   1            0           2m
NAME                        CLUSTER-IP   EXTERNAL-IP         PORT(S)      AGE
redis                       10.0.0.110   <none>              6379/TCP     2m
web                         10.0.0.55    <none>              5000/TCP     2m
NAME                        READY        STATUS              RESTARTS     AGE
mlbparks-3930800586-mblgc   0/1          Terminating         0            4m
redis-741327525-om0xc       0/1          ContainerCreating   0            2m
web-519030457-28arz         0/1          ContainerCreating   0            2m
```

Delete the application that has been deployed in the `namespace=development`
```bash
$ kompose down --namespace=development
INFO[0000] Deleting application from ""development"" namespace
 
INFO[0000] Successfully deleted Service: redis          
INFO[0000] Successfully deleted Service: web            
INFO[0003] Successfully deleted Deployment: redis       
INFO[0006] Successfully deleted Deployment: web  
```

Fixes: #473 

CC: @kadel @cdrage @containscafeine @surajssd .
 if this is being done for `up` and `down` then this can/should also be done for `convert` ??.
 @surajssd How does it make sense to add this to `convert`? We can deploy the artifacts created by `kompose convert` in any `namespace` we want using `kubectl` for example,
```bash
$ kubectl create -f <file> --namespace=development
```
Please CMIIW..
 I agree with @procrypt that this doesn't make sense to add to convert. Convert simply converts the files and outputs it in the same directory. Using `kubectl` to bring them up..
 @cdrage Updated PR.
 LGTM!.
 Ping @kadel @cdrage .
 @kadel @cdrage All green now :relaxed: .
 "
,,516,"Ignore Docker Compose files in the root directory.
 When developing Kompose, it's common to have the Docker Compose file in
the root directory.

Adding it to gitignore ignores it for any changes that could be
committed / pushed by accident..
 "
,,515,"Fix the DAB spelling error.
 It's Distributed Application Bundle (DAB)..
 "
,,514,"make flags global which are common.
 flags like `replicas` and other flags that are repeating should be implemented only once, which means make it global.

This came to my mind after reading #506.
 but `replicas` doesn't make sense for `down` command :-(

Shouldn't be global parameters valid for all (up,down,convert) commands? .
 @kadel didn't think about that! just thought about the repetition!.
 agreed that repetition is ugly, and we should figure out how to reuse flags between `up` and `convert` so we can define them in only one place.

But solution shouldn't be making it global, because that we will have to ignore some flags for commands where it doesn't make sense, and thist might be even more confusing :-(.
 I think we can remove the `--emptyvols` and `--replicas` flags from `kompose down`:

```
▶ kompose down --help
Delete instantiated services/deployments from kubernetes. (default ""kubernetes"")

Usage:
  kompose down [flags]

Flags:
      --emptyvols      Use Empty Volumes. Do not generate PVCs
      --replicas int   Specify the number of repliaces in the generate resource spec (default 1)
```.
 > I think we can remove the --emptyvols and --replicas flags from kompose down:

yes we should do that.

but we still have same flags defined in two places.
for example `--replicas` is in `up.go` and in `convert.go`
.
 @kadel Unfortunately I don't think there is a way to define a global parameter and remove it from only one particular one. Having it in both up.go and convert.go seems the best bet. At least it's better than how we did it with urfave/cli :+1: .
 I've some ideas that might work, but I have to try it.
 Hey @kadel emptyvols and replicas was removed from Kompose down, should we close this issue or is there anything else we need to discuss  to refactor this?.
 Going to close this for now, let's re-open at a later-date if we find a refactor for global flags :+1:  .
 "
,,513,"unused global constants in convert.go.
 In convert.go we have some consts that are not used anywhere, for e.g. `ConvertSource` and `ConvertBuildConfig`. This needs a cleanup.
.
 I would like pick it up.
 "
,,512,"Fixes image (uses / to get the root dir).
 Fixes the image when syncing between docs. Adds a '/'..
 "
,,511,"add missing 'io.kompose.service' label to Route and Ingress.
 This was caussing 'kompose down' not to delete Route and Ingress

fixes #510 .
 @kadel I tried this out but seems it doesn't delete the route in OpenShift :(.
 really? :confused: 
I just tried that again, and it is working for me..
 @kadel , @procrypt I tried this and it works for me :)
@procrypt , I think you created route manually, then it will not delete the route.
 ping @cdrage @procrypt @surajssd .
 Ah this works for me now, tested again, @kadel LGTM..
 LGTM :+1: .
 "
,,510,"kompose down is not deleting ingress and route.
 .
 "
,,509,"Propagate underscore into valid name.
 Now we can provide service name with `_` in docker-compose files and they will by converted as `-` in the generated artifacts by kompose eg, if the service name in docker-compose file is ""foo_bar"" then it will be converted into ""foo-bar"" in the generated artifacts.

`docker-compose.yml` containing `_` in service name.
```yaml
version: ""2""
services:
  web_service:
    image: tuna/docker-counter23:latest
    ports:
      - ""5000:5000""
    links:
      - redis_service
  redis_service:
    image: redis:latest
    ports:
      - ""6379""
````
```bash
$ kompose up
INFO[0000] Service name in docker-compose has been changed from ""redis_service"" to ""redis-service"" 
INFO[0000] Service name in docker-compose has been changed from ""web_service"" to ""web-service"" 

We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created Service: redis-service  
INFO[0000] Successfully created Service: web-service    
INFO[0000] Successfully created Deployment: redis-service 
INFO[0000] Successfully created Deployment: web-service 

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

`docker-compose.yml` without `_` in service name.
```yaml
version: ""2""
services:
  web:
    image: tuna/docker-counter23:latest
    ports:
      - ""5000:5000""
    links:
      - redis
  redis:
    image: redis:latest
    ports:
      - ""6379""
````

```bash
$ kompose up
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created Service: redis          
INFO[0000] Successfully created Service: web            
INFO[0000] Successfully created Deployment: redis       
INFO[0000] Successfully created Deployment: web         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```
cc: @kadel @cdrage 
Fixes: #420 .
 We shouldn't do this in every place where name is used.
This should be fixed when docker-compose file is loaded into KObject. (https://github.com/kubernetes-incubator/kompose/blob/ec897ef50facdd1c2518cd074bf3b5fcc56bae7c/pkg/loader/compose/compose.go#L377)

Than you have to do it only once, and you can be sure that it will be correct  in every place after that.
.
 @kadel @surajssd Rebased and updated..
 @kadel Updated :wink: .
 Excited for this to get in so can properly use kompose :) Thanks so much!.
 > Excited for this to get in so can properly use kompose :) Thanks so much!

Just beware that in some cases this also renames dns name that points to renamed service. In some cases this can break communication between services :-( .
 "
,,508,"Update minor bug in syncing files.
 Didn't catch this when testing all the pages (saw that setup and index
worked but not others).

Removes '.md' from the permalink..
 "
,,507,"Update the readme with tarball and installation instructions.
 Updates the readme to reflect that we now have a tarball as well as
latest development instructions on prefering the binary installation
over `go get`..
 It looks like something went wrong with you branch. 0f7c13b00f570239f6afa6ec9c3858f2595c999c shouldn't be in this pr.
 Crap, my mistake. My ""master"" branch was two commits ahead since I was testing against #500 

Should be corrected / updated now..
 "
,,506,"Support insecure registry and enhance parsing of image stream tag.
 2 enhancements for openshift:
1) support insecure docker registry for generation of openshift image stream
we add an import policy for the image stream tag by following instruction of the command argument  
2) enhance parsing of image tag
current implementation doesn't support format like ""myregistryhost:5000/fedora/httpd:version1.0"". Enhance the parsing logic..
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

Once you've signed, please reply here (e.g. ""I signed it!"") and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/commands.md).
</details>
	.
 Hey @qujinping , Thank you for your patch. This is really nice, we will look at it. But can you please sign the CLA first or else this PR is blocked..
 I signed it.
 @qujinping It look like k8s-ci-robot  is not picking that up :-(
Have you used same email as you have in git commit?

Or you could try push something to your branch so it forces bot to recheck.



.
 ping @cdrage @surajssd .
 @qujinping Almost there! Thanks a lot for this contribution. The code LGTM.

One thing that needs to be adding is here: https://github.com/qujinping/kompose/blob/e4302af6fe3fdf7eb9944438cd13022f2e62f2a5/cmd/convert.go#L147

Since we have a custom output for `--help` an entry for Insecure Registry should be there. 

I also have another comment in regards to the description which I'll put in a code review..
 @cdrage, thanks for your comment, accepted. 

Pls review my update..
 I close this PR because I messed things up while merging from upstream.

A new PR will be created instead. Very sorry for the inconvenience.  .
 "
,,505,"`kompose up` fails with restart options on openshift.
 When I try running `kompose up` with  docker-compose file containing restart key[1], it fails. It doesn't fail with `kompose convert`. What should be the expected behviour?

for kompose up: 

```
$ kompose --provider=openshift --emptyvols -f kompose/script/test/fixtures/restart-options/docker-compose-restart-no.yml --verbose up 


DEBU[0000] Opening compose files: kompose/script/test/fixtures/restart-options/docker-compose-restart-no.yml 
We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

DEBU[0000] [0/1] [foo]: Adding                          

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

```

in case of kompose convert:

```
$ kompose --provider=openshift --emptyvols -f kompose/script/test/fixtures/restart-options/docker-compose-restart-no.yml convert -y

INFO[0000] file ""foo-pod.yaml"" created                  

$ oc create -f foo-pod.yaml 
pod ""foo"" created

$ oc get pods
NAME      READY     STATUS              RESTARTS   AGE
foo       0/1       ContainerCreating   0          6s

```


[1] https://github.com/kubernetes-incubator/kompose/blob/master/script/test/fixtures/restart-options/docker-compose-restart-no.yml.
 @ashetty1 , I tried both cases and working fine for me.
* In case of kompose up:

```
$ kompose  --provider=openshift --emptyvols -f docker-compose-restart-no.yml up
We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO[0000] Successfully created Pod: foo                

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
$ oc get pods
NAME      READY     STATUS              RESTARTS   AGE
foo       0/1       ContainerCreating   0          3s
```
* In case of kompose convert:

```
$ kompose  --provider=openshift --emptyvols -f docker-compose-restart-no.yml convert 
INFO[0000]  file ""foo-pod.yaml"" created       
$ oc create -f foo-pod.yaml 
pod ""foo"" created
$ oc get pods
NAME      READY     STATUS              RESTARTS   AGE
foo       0/1       ContainerCreating   0          3s
```
.
 @surajnarwade Oops, sorry. some version mismatch on my end. Thanks..
 "
,,504,"Removed Duplicate line(build) from compose.go.
 .
 "
,,503,"Ignore the /bin folder.
 Bin folder is used for binary generation. Ignore it..
 "
,,502,"0.4.0 release.
 "
,,501,"0.4.0 release.
 Any blockers for this weeks release?

I'll be including a SHA256 hashsum for each binary generated for integrity.

I was thinking of including a signed GPG tarball but according to our previous discussion with @sebgoa and @ngtuna it wasn't feasible to include it since Kubernetes projects don't. A shasum should be enough.

ping @kadel @containscafeine @surajssd @surajnarwade if you have any issues / blockers before the release :).
 @cdrage , no blockers :).
 @cdrage none from my side :shipit:.
 @cdrage no blockers from my side!.
 0.4.0 out! Closing..
 "
,,500,"Sync changes from master to gh-pages on each merge request.
 This adds the functionality for Travis to sync with http://kompose.io in
regards to ""syncing"" the docs directory in master and the docs within
gh-pages.

Two things are added:
  script/sync-docs/sh
  script/deploy_key.enc

The encrypted key follows the conventions here:
https://gist.github.com/domenic/ec8b0fc8ab45f39403dd
and the functionality of running: `travis encrypt-file encrypt_key`

The script is ran each-time a PR is merged (and only if it's
sucessful!) as per the modifications in `.travis.yml`.

Thus each time we make a change in master, there's no need to open up
another PR for syncing the changes with `gh-pages`..
 ~~This is a WORK IN PROGRESS and is open in order to track current work and test the integration with Travis CI.~~

Up for review now!

~~No, this will not 100% work. I still need to *fully* test this.~~

.
 ping @containscafeine @kadel and whoever-else-wants-to-do-a-quick-review

I tested this at https://github.com/cdrage/kompose/ and it seems to work.

Only way to test this on the Kompose repo is to have it merged in and then merge a change to a doc.

This only runs the doc sync on 1.6 of Go (so it only runs once!).
 Note:

I'm avoiding using: https://docs.travis-ci.com/user/deployment/pages/ since it won't sync between the master branch and gh-pages. Also, since it's unable to run pre_run and post_run scripts (so we can update the docs!).
 Had some issues with replication  / travis that may help for review:

To replicate:

(following: gist.github.com/domenic/ec8b0fc8ab45f39403dd)

!!! Edit `/scripts/syncdocs.sh` to match your fork for $DOCS_REPO_URL !!!

1. Create a new SSH key: `ssh-keygen -t rsa -b 4096 -C ""your_email@example.com""`. Add the public key to GitHub.
2. Copy the private key to the fork directory (with this PR applied as a patch) with the name deploy_key
3. Use the travis client `gem install travis` and run command `travis encrypt-file deploy_key -r YOURUSERNAME/kompose` !! important. forgetting -r wont add the values to travis-ci.org
4. Using the above output from the travis client, replace the iv / key values in `/script/syncdocs.sh`.
5. Remove `deploy_key` and make sure your `deploy_key.enc` is in the `/script/` directory.
6. Push the changes to your master branch
7. Open up a PR with changes to a `/docs` file and merge it.
8. Travis should then run the build and sync between the /docs/ folder in master and gh-pages
9. Wait patiently for the build to complete and look at your `gh-pages` branch.
.
 @kadel @containscafeine 

I can confirm that it works at https://github.com/cdrage/kompose/tree/gh-pages

I don't think there's any harm to merge this in and test it with a documentation update! Should we try it?.
 What key are you using?
Is it tied to you account? Shouldn't we use special user for this?.
 @kadel 

Yes, it's a new SSH key that's been generated that's tied to my personal account.

We could use this key temporarily untill...

We create a secondary user / ""bot"" and use it for SSH, although we would have to go through the process of getting it into kubernetes-incubator / invited by an administrator..
 This is something that I'm a little bit afraid of. That ssh key will have access to all your repositories. But it is your user account so if you are OK with it .... :wink: 

It looks like we can add new users to Kompose repo without adding them to kubernetes-incubator group.
I just tested it with @surajnarwade ;-)
We could create kompose-bot user and use that instead.


.
 @kadel Hello world! I'm @cdrage 's bot :) Add me!.
 @kadel 

I've gone ahead and created @komposebot 

I've also updated the deploy_key as well as the bash values. :) 

So it's all good-to-go now!.
 lets test it than ;-).
 "
,,499,"Added dockerfile key support.
 Fixes #486
This commit will add `dockerfilepath` key under Dockerstratergy in Buildconfig.
dockerfilepath allow us to use dockerfiles which are named different than `Dockerfile`.
 cc @kadel @surajssd @cdrage .
 @surajnarwade 

Wouldn't it have to be removed from: https://github.com/kubernetes-incubator/kompose/blob/master/pkg/loader/compose/compose.go#L80 as well?.
 Tests need to be added too (cmd tests).
 > Wouldn't it have to be removed from: https://github.com/kubernetes-incubator/kompose/blob/master/pkg/loader/compose/compose.go#L80 as well?

yes, It shouldn't be there in the first place :-D This only tracks top level service keys, dockerfile is hidden in build key.
 @cdrage , for cmd-test, I have to add context in docker-compose, which will fail the test as PR https://github.com/kubernetes-incubator/kompose/pull/454 is blocked, once that PR is merged, I will add functional test for this one..
 Few spelling errors in the commit message:
```
Fixes #486
This commit will add `dockerfilepath` key under Dockerstratergy in Buildconfig.
dockerfilepath allow us to use dockerfiles which are named different than `Dockerfile`
```

Please give an example as well in the commit message / elaborate :).
 needs rebase, but otherwise lgtm.
 @kadel , done with rebase.
 @surajnarwade thank you for updating the commit message. LGTM! :+1: .
 "
,,498,"do not fail if there is a golint violation.
 golint output is just suggestion. Show output, but don't fail.
This also remove unnecessary bash script that is no longer needed..
 LGTM.
 "
,,497,"travis-ci: send report to coveralls in after_success section.
 Connection to coveralls.io sometimes fails and its marking tests as fail
even then are OK. Exit code from after_success do not affects build
result..
 LGTM.
 "
,,496,"Docker build fails:  Failed to push image: unauthized:authentication required.
 Pushing image 172.30.46.106:5000/chat/chatback:latest ...
Pushed 0/20 layers, 0% complete
error: build error: Failed to push image: unauthorized: authentication required

After running kompose convert, and editing the resulting buildconfig such that it has a dockerfilePath (dunno if this should make a difference), the resulting build fails with the above failure.

The relevant test case is at:  https://github.com/stephanosbacon/chatBack/tree/master/build/kompose
.
 If I delete the buildconfig, re-create it via oc-new-build, and then go edit the yaml to set the dockerfilePath, I get the following, which works:

apiVersion: v1
kind: BuildConfig
metadata:
  name: chatback
  namespace: chat
  selfLink: /oapi/v1/namespaces/chat/buildconfigs/chatback
  uid: 2de0fe2a-0a71-11e7-8156-f20cfd71a2ac
  resourceVersion: '1329'
  creationTimestamp: '2017-03-16T17:51:27Z'
  labels:
    build: chatback
  annotations:
    openshift.io/generated-by: OpenShiftNewBuild
spec:
  triggers:
    - type: GitHub
      github:
        secret: DJO8oSqrmDoNkzj7m4Cf
    - type: Generic
      generic:
        secret: rxdnhyBexz6kPqofQX43
    - type: ConfigChange
  runPolicy: Serial
  source:
    type: Git
    git:
      uri: 'https://github.com/stephanosbacon/chatBack.git'
      ref: master
  strategy:
    type: Docker
    dockerStrategy:
      dockerfilePath: build/Dockerfiles/Dockerfile_server
  output:
    to:
      kind: ImageStreamTag
      name: 'chatback:latest'
  resources: {}
  postCommit: {}
  nodeSelector: null
status:
  lastVersion: 2
.
 @stephanosbacon , I am trying to reproduce this error, this config also gives me the same error. this error is coming from openshift and is being tracked here https://github.com/openshift/origin/issues/12474.
 Hmm that is strange, I just tried that and it worked for me.

I've skipped `oc login` and `oc adm policy` commands from your `oc_setup` script. 
So it looks like it will be some issue with permissions.
.
 New observations.
with minishift v0.9.0 it works perfectly.
with new 1.0.0-beta.5 it fails

Something is different in new minishift :-(

.
 It looks like its bug in openshift. https://github.com/openshift/origin/issues/4518

If you create buildconfig first before imagestream it fails. If imagestream is created first it is ok..
 Will OpenCompose work around it?  (It seems to be a combination big deal/low priority to fix on the OpenShift side).
 with `kompose up` or if you save output to one file ImageStream will always be before BuildConfig. (Or at least it should be if I remember correctly :nerd_face:   ).
 @kadel , that worked :stuck_out_tongue:.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Can we close this?.
 cc @stephanosbacon .
 Sure.
 "
,,495,"Add rpm packaging.
 This adds rpm packaging for building on Fedora + CentOS + deploying to
Koji.

I've gone ahead and updates notes.txt to a README.md to better reflect
how to build.

This is copied from:
https://src.fedoraproject.org/cgit/rpms/kompose.git
and added as a submodule.

Closes kubernetes-incubator#481

Ping @surajssd @dustymabe.
 we should pull the content from here: https://src.fedoraproject.org/cgit/rpms/kompose.git/tree/

I only created that other repo because the fedora dist-git isn't fronted by pagure yet (where we can do pull requests). 

Also one thing to note is that there are different ""branches"" in the dist-git repo listed above that correspond to the different releases we support (epel7,f24,f25,f26,master == rawhide). This copy of the files would only reflect master/rawhide. - we should make it part of the procedure to sync the files between this repo and master of the other repo and make sure an rpm builds before we do a release..
 @dustymabe 

I agree, syncing it between the two git repo's would be the best option.

I've gone ahead and updated this PR with the latest changes (only saw a sha512 was changed). But we've got to add a note that https://src.fedoraproject.org/cgit/rpms/kompose.git is the main place. .
 how are we handling various versions, which are on different branch here?.
 @surajssd 

What we can do is copy in the .git that's included and make sure that we git sync / git pull it as well..
 @cdrage are you suggesting we have that other repo as a submodule or something? Maybe explain a little more.

@cdrage, also, update your git commit message to point to the right git repo. .
 @dustymabe 

Yes, using it as a submodule instead, having the external repository still here.

Git commit message: Done!.
 > Yes, using it as a submodule instead, having the external repository still here.

whatever works best for you guys. 
.
 Are we going to do this via submodule?
Do I understand it correctly that `https://src.fedoraproject.org/cgit/rpms/kompose.git/tree/` will be submodule in `build/rpm` ?.
 @kadel @dustymabe @surajssd 

I've gone ahead and added this a submodule as well as moved the README.md to the `/build` directory so we can make the appropriate instructions on how to build located-in-the-docs.

.
 Looks like there's some errors in `godeps.go` with lint...
 I was actually thinking about disabling lint. It can be too pedantic sometimes..
 @kadel @surajssd 
This is ready for review..
 "
,,494,"Remove extend from unused keys, add to conversion doc.
 This removes the ""unsupported"" extends from the list (since we actually
support) as well as add a clarificiation on the conversion.md document.

Closes https://github.com/kubernetes-incubator/kompose/issues/475
Closes https://github.com/kubernetes-incubator/kompose/issues/493.
 "
,,493,"remove extends from unsupported keys.
 extends actually works and it should be removed from unsupported keys.
 "
,,492,"Add install instruction for MacOS X (using brew).
 Kompose is homebrew - https://github.com/Homebrew/homebrew-core/blob/master/Formula/kompose.rb.
 Can't confirm it works (don't have a Mac!) But LGTM!

On Mar 14, 2017 13:26, ""Tomas Kral"" <notifications@github.com> wrote:

> Kompose is homebrew - https://github.com/Homebrew/
> homebrew-core/blob/master/Formula/kompose.rb
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/kubernetes-incubator/kompose/pull/492
> Commit Summary
>
>    - README.md - add brew install instruction for MacOS X
>
> File Changes
>
>    - *M* README.md
>    <https://github.com/kubernetes-incubator/kompose/pull/492/files#diff-0>
>    (8)
>
> Patch Links:
>
>    - https://github.com/kubernetes-incubator/kompose/pull/492.patch
>    - https://github.com/kubernetes-incubator/kompose/pull/492.diff
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes-incubator/kompose/pull/492>, or mute the
> thread
> <https://github.com/notifications/unsubscribe-auth/AGH-oEt1qb6MCFnrtWg3bvlvEwG1FVFYks5rls2wgaJpZM4Mc5lX>
> .
>
.
 "
,,491,"Add that we support volumes_from.
 Adds a note to the conversion doc that we support volumes_from.

Closes https://github.com/kubernetes-incubator/kompose/issues/476.
 "
,,490,"Update vendoring.
 This updates the libcompose vendoring as well as a general update to
vendoring (adds the latest git commit of libcompose).

Closes https://github.com/kubernetes-incubator/kompose/issues/426
Closes https://github.com/kubernetes-incubator/kompose/issues/471.
 "
,,489,"mongodb startup problem with simple dockerfile.
 The following dockerfile:

version: '2'
services:
  mongo:
    image: ""mongo""
    ports:
      - ""27017:27017""

when processed with:

kompose convert -f docker-compose.yml --provider OpenShift

will generate mongo-imagestream, mongo-deploymentconfig and mongo-service, which, when deployed to OpenShift (Minishift in this case) as follows:

oc create -f mongo-imagestream.yaml
oc create -f mongo-deploymentconfig.yaml
oc create -f mongo-service.yaml

will result in mongodb not starting with the following log [1]

However, if I say ""oc new-app --docker-image=mongo"" mongo starts up without a problem.

[1] The log: 

2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] MongoDB starting : pid=1 port=27017 dbpath=/data/db 64-bit host=cablegram-1-b1zua
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] db version v3.4.2
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] git version: 3f76e40c105fc223b3e5aac3e20dcd026b83b38b
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.1t  3 May 2016
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] allocator: tcmalloc
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] modules: none
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] build environment:
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten]     distmod: debian81
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten]     distarch: x86_64
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten]     target_arch: x86_64
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] options: {}
2017-03-13T17:26:40.695+0000 I STORAGE  [initandlisten] exception in initAndListen: 20 Attempted to create a lock file on a read-only directory: /data/db, terminating
2017-03-13T17:26:40.695+0000 I NETWORK  [initandlisten] shutdown: going to close listening sockets...
2017-03-13T17:26:40.695+0000 I NETWORK  [initandlisten] shutdown: going to flush diaglog...
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] now exiting
2017-03-13T17:26:40.695+0000 I CONTROL  [initandlisten] shutting down with code:100




.
 @stephanosbacon You are getting this error because you are trying to run an application which requires root privilege to inside the container. OpenShift by default, does not allow the container to run using `UID 0`. I tried the application using `oc new-app --docker-image=mongo` and got the same error. You need to set the cluster policy to allow containers running with `UID 0`. 
[Run containers with root in OpenShift.](https://docs.openshift.org/latest/admin_guide/manage_scc.html#modify-cluster-default-behavior)

.
 Actually, it works for me with oc new-app.. I'm using minishift by the way..
 problem is with volumes.

`mongo` image is using two volumes `/data/db` and `/data/configdb`

`oc new-app` is a bit smarter than `kompose`, it inspects image, detects docker volumes and creates kubernetes volumes that are non-persistant and host-local (aka. `emptyDir`)

with Kompose volumes have to be defined explicitly.

```yaml
version: '2'

services:
  mongo:
    image: ""mongo""
    ports:
      - ""27017:27017""
    volumes:
      - /data/db
      - /data/configdb
```

If you want deploy this to minishift (or any other cluster that doesn't support PersistentVolumes) you have to add `--emptyvol` option. This will do exactly same think that `oc new-app` does.
```
./kompose --provider openshift convert --emptyvols
```

For cluster with PersistentVolumes or with storage auto-provisioning setup you can omit `--emptyvols`. Than Kompose will create regular `PersistentVolumeClams` and mongo data will be persistent even if mongo pods gets restarted and moved to another machine.

```
▶ ./kompose --provider openshift convert                                                                  
INFO file ""mongo-service.yaml"" created            
INFO file ""mongo-deploymentconfig.yaml"" created   
INFO file ""mongo-imagestream.yaml"" created        
INFO file ""mongo-claim0-persistentvolumeclaim.yaml"" created 
INFO file ""mongo-claim1-persistentvolumeclaim.yaml"" created
```
.
 Thanks!.
 i think we can close this.
 "
,,488,"Add three-week cycle comment to README.
 This adds a comment about our three-week cycle to the README.md..
 :+1: Thank you for adding it. I wanted to add it there, and completely forgot about it :-( .
 "
,,487,"no commit hash in kompose 0.3.0 version information.
 [link-to-rpm](https://kojipkgs.fedoraproject.org//packages/kompose/0.3.0/0.1.git135165b.fc25/x86_64/kompose-0.3.0-0.1.git135165b.fc25.x86_64.rpm)

For last release I saw:
```
$ kompose --version
kompose version 0.1.2 (92ea047)
```

With newer rpm I see:
```
[vagrant@f25vanilla ~]$ kompose version
0.3.0 (HEAD)
```

also the move from `kompose --version` to `kompose version` is odd. We should probably support `--version` as well, if possible.

```
[vagrant@f25vanilla ~]$ kompose --version
Error: unknown flag: --version
...
```.
 @dustymabe 

We moved to `kompose version` instead of `kompose --version` in order to familiarize those who have used `kubectl` or `oc`. Since development usually overlaps between all three, we found that having similar commands help!

Yup, the has was my fault. I added that manually last version when it should of been just (HEAD).  See https://github.com/kubernetes-incubator/kompose/issues/422.
 We need to have a discussion about including git hash in the version as per #422 ... I like having a commit ID within it, but the problem is when people `go get` it, it'll appear as the git commit hard-coded in when in reality it's the latest dev branch..
 hmm. what I'm saying is that I prefer the more verbose output. I wish it was:

```
[vagrant@f25vanilla ~]$ kompose version
0.3.0 (aaabbbc)
```
.
 if this can't be achieved, that is ok.
 It can be achieved, but it has to be build from source cloned from git with proper [ldflags](https://github.com/kubernetes-incubator/kompose/blob/master/Makefile#L18) or using `make build` .
 I think this is solved so closing it!.
 "
,,486,"kompose should respect the dockerfile key in docker-compose.yml.
 If one doesn't use the default Dockerfile, but specified it using dockerfile: in the yml, the generated build config does not have a dockerFilePath:  under dockerStrategy.  This is in version 0.3.0 (HEAD).
 I would like to work on it :)
.
 "
,,485,"Update the link to the conversion doc.
 This updates user-guide.md to link to conversion.md when talking about
unsupported keys used by Kompose..
 "
,,484,"Added support for tmpfs.
 fixes #436.
 cc @cdrage @kadel @surajssd @containscafeine .
 Missing tests! Will do a review now however..
 @surajnarwade 

This doesn't work..
```
redis:                                                                                                                                                                                                                                                                            
  image: redis:3.0                                                                                                                                                                                                                                                                
  ports:                                                                                                                                                                                                                                                                          
    - ""6379""                                                                                                                                                                                                                                                                      
  tmpfs: /run
```

```
github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                       4h29m ◒  
▶ ./kompose convert --stdout
ERRO Could not parse config for project kompose : Unsupported config option for redis service: 'tmpfs' 
FATA Failed to load compose file: Unsupported config option for redis service: 'tmpfs' 
```
.
 Hiya @surajnarwade 

So a few things!

Great code, but there's a lot of missing comments, explaining what's happening in a few sentences would really help with some parts of the code.

The commit description is lacking, please type up what you do, why it's necessary and link the issue (like you already did), you can modify it with `git commit --amend`.
 A good example for a descriptive git message is @containscafeine 's one he used on a recent PR:

```
This commit refactors the code to remove more or less
all occurences of logrus.Fatalf() from the code under
pkg/ except for app.go where all the errors are being
handled currently.

This is being done since random logrus.Fatalf() calls
all around the code was making handling the errors,
unit testing and troubleshooting a bit more painful.

logrus.Fatalf() calls are either replaced by
return errors.New(""new error"")
or
return errors.Wrap(err, ""annonate error"")
calls, and the function signatures are accordingly
changed to accomodate the new return values.

The unit tests which previously used to check
if logrus.Fatalf() calls worked fine have also
been fixed to only check for errors now.

Fixes #416
```.
  
> This doesn't work..
> 
> redis:                                                                                                                                                                                                                                                                            
>   image: redis:3.0                                                                                                                                                                                                                                                                
>   ports:                                                                                                                                                                                                                                                                          
>     - ""6379""                                                                                                                                                                                                                                                                      
>   tmpfs: /run
> github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                       4h29m ◒  
> ▶ ./kompose convert --stdout
> ERRO Could not parse config for project kompose : Unsupported config option for redis service: 'tmpfs' 
> FATA Failed to load compose file: Unsupported config option for redis service: 'tmpfs'


`tmpfs` is not in docker-compose from v2 and up ;-).
 There we go, my mistake!

```
github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                      4h53m ◒  ⍉
▶ cat docker-compose.yml 
version: '2'

services:

  redis:
    image: redis:3.0
    tmpfs: /foobar

github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                       4h54m ◒  
▶ ./kompose convert --stdout
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      service: redis
    name: redis
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      service: redis
  status:
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    name: redis
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          service: redis
      spec:
        containers:
        - image: redis:3.0
          name: redis
          resources: {}
          volumeMounts:
          - mountPath: /foobar
            name: redis-tmpfs0
        restartPolicy: Always
        volumes:
        - emptyDir:
            medium: Memory
          name: redis-tmpfs0
  status: {}
kind: List
metadata: {}
```.
 And I can confirm it works with a list:

```
github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                      4h54m ◒  ⍉
▶ cat docker-compose.yml 
version: '2'

services:

  redis:
    image: redis:3.0
    tmpfs: 
      - /foobar
      - /foobar2

github.com/kubernetes-incubator/kompose  pr_484 ✗                                                                                                                                                                                                                       4h54m ◒  
▶ ./kompose convert --stdout
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      service: redis
    name: redis
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      service: redis
  status:
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    name: redis
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          service: redis
      spec:
        containers:
        - image: redis:3.0
          name: redis
          resources: {}
          volumeMounts:
          - mountPath: /foobar
            name: redis-tmpfs0
          - mountPath: /foobar2
            name: redis-tmpfs1
        restartPolicy: Always
        volumes:
        - emptyDir:
            medium: Memory
          name: redis-tmpfs0
        - emptyDir:
            medium: Memory
          name: redis-tmpfs1
  status: {}
kind: List
metadata: {}

```.
 cc @kadel @cdrage .
 Saw the new comments added to the code, thanks!

This LGTM..
 @kadel , done with correction..
 @surajnarwade 

Almost there! Just need to resolve the conflicts from me merging in #416 

After that, I think it's ready to be merged! Cause as of right now, the code LGTM :+1: .
 @kadel , last thing updated ;-).
 "
,,483,"delete objects based on label.
 @kadel @containscafeine @surajssd @cdrage 

This PR uses the `SelectorFromSet()` function which takes a`label or selector` as an argument returns all the object that uses that `label or selector`. Once we get the object that uses a particular label we can further do the delete operation on them. This is similar to `kubectl delete <object> --selector=<key>=<value>`. Also the label has been modified from `service` to `io.kompose.service`.
Thanks @kadel for all the help :)
Review please.
Fixes #255.
 Hi @procrypt 

Just two things before reviewing!

1. Please split the commits, one for updating vendoring, and the other the actual code you're modifying. Otherwise, it's really hard to review on GitHub / `gif dif`

2. Please update your Git commit messages outlining what's changed / more descriptive rather than `Fixes #255`. You can do this with `git commit --amend`.
 Hey @cdrage I have split the commit into two different commit one for the _code_ and other for _vender_.
Also I have elaborated what this PR is doing.
Ready for review :).
 @procrypt 

Commit titles shouldn't have underscores in them, and it looks like you haven't put your updated message into your commit, you need to `git commit --amend`, add then `git push -f` it. And it's vendor :).
 @cdrage Done :D.
 I wasn't excepting the labels to appear when using `kompose convert`, I've typed up my concerns in the issue #255 ! 

Great code however, I don't see any problems with it and I've tested the PR :+1: .
 I think we should get in the habit of commenting on our code, mind adding a few lines @procrypt to your implementation? .
 @kadel Updated PR..
 this will require new vendor update :-(

I think that easiest thing to do,  will be remove 'update vendor' commit from your branch, do rebase, and than update vendor again ;-)

.
 @kadel Done all green now :D.
 if nothing is deployed and  call `kompose down` is called:
```
./kompose down
panic: runtime error: index out of range

goroutine 1 [running]:
github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes.(*Kubernetes).Undeploy(0xc4202cc180, 0xc42033e8a0, 0x1c625c5, 0x7, 0x100, 0x0, 0x0, 0x0, 0x0, 0x0, ...)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:740 +0x14d6
github.com/kubernetes-incubator/kompose/pkg/app.Down(0x100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc42025fe50, 0x1, 0x1, ...)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:288 +0x2be
github.com/kubernetes-incubator/kompose/cmd.glob..func5(0x2a3b200, 0x2a69368, 0x0, 0x0)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/down.go:52 +0x4f
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x2a3b200, 0x2a69368, 0x0, 0x0, 0x2a3b200, 0x2a69368)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:603 +0x22b
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x2a3b420, 0xc420070058, 0x0, 0xc4204b9f48)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:689 +0x339
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x2a3b420, 0x1, 0x1)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:648 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x20
```.
 @kadel Ah this is bad, I guess I know what the problem is, when we call `kompose down` the 
```golang
client.Deployments(namespace).List()            returns  *extensions.DeploymentList
client.Services(namespace).List()               returns  *api.ServiceList
client.PersistentVolumeClaims(namespace).List() returns  *api.PersistentVolumeClaimList
```
and the struct 
```golang
DeploymentList            contains  Items []Deployment
ServiceList               contains  Items []Service
PersistentVolumeClaimList contains  Items []PersistentVolumeClaim
```
and to get the `Label` we are accessing the first index of the each of slice of 
```golang
Deployment              using  deployment.Items[0].Labels
Service                 using  svc.Items[0].Labels
PersistentVolumeClaim   using  pvc.Items[0].Labels
```
So this works when we do `kompose up` and then do `kompose down` because the application has been already deployed and `kompose down` get what needed to find the `Label`, but if we do `kompose down` and there is no application deployed the there is are `objects`, `kompose` tries to access the first element of the 
```golang
DeploymentList 
ServiceList
PersistentVolumeClaimList
```
and since there is nothing like
```golang
deployment.Items[0].Labels
svc.Items[0].Labels
pvc.Items[0].Labels
```
It panics with `runtime error: index out of range`
Working to fix this..
 @kadel Fixed `kompose down`
```bash
$ kompose down
FATA[0000] Error while deleting application: service `redis` not found
```.
 @kadel @cdrage Updated the PR Please Review.
 @kadel Updated and removed the check :wink: .
 "
,,482,"Roadmap is out of date..
 Kompose roadmap is out-dated and it is not reflecting current state of things. For example it references milestones, but we currently don't use milestones :-(.
 https://github.com/kubernetes-incubator/kompose/pull/645 updates this.
 closed in #645.
 "
,,481,"Add Fedora packaging data to Kompose repo.
 Move Fedora packaging information (located here: https://github.com/dustymabe/fedpkg-kompose) to the `/build` directory within the root of Kompose. Similar to https://github.com/kubernetes/kubernetes/tree/23cd9d7b05b1ef7ef5073ccc7cbeaf09771c8a43/build

1. It's not that much space to put it in this repo.
2. Keeps everything centralized and simple (can't have another repo on `kubernetes-incubator` called `kompose-packaging`)
3. Keeps everything out in the open for those who want to try packaging it themselves :+1: 

cc @surajssd .
 Sure it's not just fedora it's rpm in general!.
 "
,,480,"Modified user-guide on kompose.io.
 Fixes #479.
 I have stupid question :blush: Do we even need this list here? Is this duplicating what is already in [conversion.md](https://github.com/kubernetes-incubator/kompose/blob/master/docs/conversion.md)

I think we can just link to that document. It will be easier to keep it in one place.
 I agree with @kadel :).
 @cdrage  @kadel , I thought of updating list on [kompose.io](http://kompose.io/).
 @surajnarwade @kadel 

Yes, what @kadel is saying is removing it from both docs/user-guide.md in master as well as in gh-pages..
 > Yes, what @kadel is saying is removing it from both docs/user-guide.md in master as well as in gh-pages.

yes, and replacing it with link to conversion table.
 got it :).
 Oh, and update the commit message as well please! .
 @cdrage , updated both.
 @surajnarwade Thanks, the git commit message still isn't modified however..
 @cdrage , my bad, updated now :).
 LGTM! :+1: .
 "
,,479,"Update unsupported keys in kompose.io user guide.
 Remove keys which are supported now: `build`, `mem_limit`, `tty`, `stdin_open`, `user`

Add unsupported keys: `cap_add`, `cap_drop`, `sysctls`.
 solved in #480 .
 "
,,478,"Adding `networks:` results in a panic.
 When supplying the `networks` key within Kompose with a network, it results in a panic / nil pointer.

```
networks:
  foobar:
```

See issue #474 for a reference as to why this happens..
 "
,,477,"Kompose will keep trying its job.
 fixes #270.
 cc @surajssd @containscafeine @kadel .
 Please use `git commit --amend` as well to update your git message so it's more descriptive! .
 Anyway the code this PR is editing is gonna go away because @procrypt is working on new approach of deleting things! https://github.com/kubernetes-incubator/kompose/pull/483.
 It is not going to go away. This logic will be still needed, #483 is not solving this problem.
But it will create lot of annoying conflicts :-( .
 cc @kadel @surajssd @cdrage .
 > Okay, shouldn't we use https://golang.org/pkg/go/scanner/#ErrorList instead? @kadel

It looks like that `ErrorList` is specially made for scanner package..
 @cdrage done with changes.
 LGTM.
 I just found that there is a BIG mistake in there.

If it can't connect to cluster it panics.

Problem is that we continue after every error.
There should be `return` after some errors, and after every error in `switch`  should be `break`.
 @kadel Yeah. I thought we were brute-forcing the force down since we're iterating right through each-one of them.

I've opened up a PR to revert this so we can at least push a release today..
 yeh, that was a bit  too much brute-forcing :-) 
For example we can't continue and call `Stop` if client creation failed. In that case it should continue and try to create client again for next object. .
 "
,,476,"`volumes_from` is supported construct but conversion doc says opposite.
 In [conversion doc](https://github.com/kubernetes-incubator/kompose/blob/master/docs/conversion.md) its mentioned that `volumes_from` is unsupported which is not true.

So if I mention `volumes_from` in a service then in resulting conversion both the deployments/deploymentconfigs will share same PVC..
 yep, that is mistake in the conversion doc.
 "
,,475,"extends is supported construct but conversion doc says opposite.
 In [conversion doc](https://github.com/kubernetes-incubator/kompose/blob/master/docs/conversion.md) its mentioned that extends is unsupported which is not true.

Not all the forms of doing extends is supported right now but one specific way to do extends from docker-compose is supported in kompose and there is a issue in upstream libcompose to handle that: https://github.com/docker/libcompose/issues/428.
 You say it's unsupported, but then say that not all forms are supported for libcompose. So at the moment, it is indeed unsupported until https://github.com/docker/libcompose/issues/428 is fixed. I guess we can add that to the conversion doc?.
 What I mean here is you can still use extends and it works in one form and other one will fail..
 So it's still not 100%-supported. I believe we should still say no, but add a note that traditionally Kubernetes a flat-network and everything is interconnected, but when you do `extends` for each Docker container, that functionality will not work and service discovery (such as etcd) is required if you wish to talk for example to the other Docker container via  domain name..
 As I understand it, only thing that is not working is when you use shorter version (when `extends` is string).
But if you use full format (`extends` is object) than everything is fine.

> So it's still not 100%-supported. I believe we should still say no, but add a note that traditionally Kubernetes a flat-network and everything is interconnected, but when you do extends for each Docker container, that functionality will not work and service discovery (such as etcd) is required if you wish to talk for example to the other Docker container via domain name.

Maybe I missed something, but how can  use of `extends` break service discovery?.
 @kadel Ah crap, I mixed up `extends` with `external_links`. Ignore my previous comment.

Okay, so implement using `extends` as a string would be the best solution so we have both extends working as an object + string variable.
 > @kadel Ah crap, I mixed up extends with external_links. Ignore my previous comment.

now it makes sense :laughing:


> Okay, so implement using extends as a string would be the best solution so we have both extends working as an object + string variable

that needs to be fixed in  https://github.com/docker/libcompose/issues/428 


.
 Documentation should say that Kompose supports `extends`.
 @kadel @surajssd 

Bit confused as to whether this is supported or not, see the below output:

```
▶ cat docker-compose.yaml 
version: '2' 
services:
  foo:
    image: foo 

  bar:
    extends:
      service: foo

~                                                                                                                                                                                                                                                                                
▶ kompose convert --stdout
WARN Unsupported extends key - ignoring   
```.
 yeah :-(

That warning is actually wrong. I've just tested it and it works correctly..
 https://github.com/kubernetes-incubator/kompose/issues/493.
 "
,,474,"Bug: Adding `networks:` to docker-compose.yaml file results in a runtime error.
 `kompose version 0.3.0 (135165b3)`
`go version go1.8 darwin/amd64`

```go
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x21eda6c]

goroutine 1 [running]:
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleNetworkConfig(0xc42031c0e0)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:281 +0x19c
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc42031c0e0, 0x7fff5fbff5bb, 0x1a, 0xc42041c400, 0x69a, 0x89a, 0xc4200aa990, 0xc4204c9410)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:234 +0x490
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc42031c0e0, 0x0, 0x0)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:112 +0x162
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x365d9b0, 0xc420293480, 0x1, 0x1, 0xc4200aa8d0, 0x0, 0x10)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:304 +0x10f
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc420293480, 0x1, 0x1, ...)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:214 +0x145
github.com/kubernetes-incubator/kompose/cmd.glob..func3(0x362fb00, 0xc420284fc0, 0x0, 0x2)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:85 +0x4f
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x362fb00, 0xc420284e20, 0x2, 0x2, 0x362fb00, 0xc420284e20)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:650 +0x231
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x362ff40, 0xc42006e058, 0x0, 0xc4204c9f48)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:737 +0x339
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x362ff40, 0x1, 0x1)
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:695 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
	/home/tomas/dev/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x20
```.
 Uh oh, that doesn't look right. what commands did you use / docker-compose file to get this error? @peterpme .
 Hey @cdrage thanks for the quick response!

I ran `kompose -f docker-compose-staging.yml convert`.
 this seems to be coming from libcompose, and would like more info on this about how does the docker-compose file looks like?

@peterpme do you mind sharing docker-compose file?.
 @surajssd thanks for the quick response! Absolutely, if you could help me get this onto GCloud / Kubernetes I'd be very happy :)

It's an nginx reverse proxy splitting 3 different apps. Nginx handles SSL too.

`docker-compose-staging.yml`:

- cms `(/|blog|about-us|contact-us)`
- api `/api`
- search `/search`

```yaml
version: '2'

services:
  nginx:
    image: peterpme/nginx
    container_name: nginx
    networks:
      - peterpme-infra
    ports:
      - ""80:80""
      - ""443:443""
    environment:
      - CERTS=www.peterp.me
      - EMAIL=peter@peterp.me
    volumes:
      - /etc/ssl/dhparam:/etc/ssl/dhparam
      - /srv/letsencrypt:/etc/letsencrypt
  cms:
    image: peterpme/cms
    container_name: cms
    environment:
      - NPM_TOKEN
      - NODE_ENV=production
      - PORT=5000
      - MONGODB_URI=
      - CLOUDINARY_URL=
      - COOKIE_SECRET=
      - NEW_RELIC_ENABLED=false
    networks:
      - peterpme-infra
  search:
    image: peterpme/search
    container_name: search
    environment:
      - NPM_TOKEN
      - NODE_ENV=production
      - APP_ENV=
      - PORT=5000
      - GOOGLE_PLACES_API_KEY=
      - NEW_RELIC_ENABLED=false
    networks:
      - peterpme-infra
  api:
    image: peterpme/api-next
    container_name: api
    environment:
      - NPM_TOKEN
      - NODE_ENV=production
      - DB_CONNECTION_STRING=
      - MAILCHIMP_API_KEY=
      - NEW_RELIC_ENABLED=false
    networks:
      - peterpme-infra

networks:
  peterpme-infra:
```

Thank you!.
 Hey @peterpme 

It's 
```
networks:
  peterpme-infra:
```

That's somehow screwing it up, just remove those two lines and it'll convert fine. I'll open up another issue for this, these panics shouldn't be happening.

Thanks for opening up this issue and let us know if there is anything else we can do to help!.
 Hey @cdrage thanks! Will there be any implications on my end if I remove networks? Will the containers still be able to communicate with nginx?.
 @peterpme Since Kubernetes is a flat-design in terms of network (there's no segregation of networks) any container created will be able to communicate to the other one.

The objective is to get you _started_ with Kubernetes. Since your docker-compose file is quite complex ,it may take some modifications to get it running (the first being persistent volumes would need to be created!).
 Hey @peterme, I'm going to leave this issue open and simply rename the title :) Better to keep the context in here rather than another issue..
 @surajssd  @peterpme , kompose doesn't support `networks` key yet.
for [reference](http://kompose.io/user-guide/).
 @surajnarwade Yes. The problem here is that this panics, so some investigation is required. I have a feeling it's because it's trying to parse:
```
networks:
  peterpme-infra:
```

and it's coming up as incorrect yaml.
.
 @cdrage :+1: .
 @cdrage @peterpme  , I tried out above example and checked with https://docs.docker.com/compose/networking/ and its working in  following cases:

as `peterpme-infra` is present in all services, assuming that it's default network

```
networks:
     default:
             name: peterpme-infra
```

or if it is pre existing network:

```
networks:
     default:
         external:
             name: peterpme-infra
```

or if its not a default network, then mention network driver as below:

```
networks:
    peterpme-infra:
            driver: custom-driver
```



.
 It looks like this is bug in libcompose.

```
version: '2' 
services:
  foo:
    image: busybox
    networks:
        - foo
networks:
    foo:
```
works with docker-compose:
```
▶ docker-compose up     
Creating kompose_foo_1
Attaching to kompose_foo_1
kompose_foo_1 exited with code 0
```

but fails with libcompose:
```
▶ libcompose-cli_linux-amd64 up
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
panic: runtime error: invalid memory address or nil pointer dereference [recovered]
	panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x4d8738]

goroutine 1 [running]:
panic(0x868ac0, 0xc420010110)
	/usr/local/go/src/runtime/panic.go:500 +0x1a1
github.com/docker/libcompose/vendor/github.com/urfave/cli.HandleAction.func1(0xc420181cc8)
	/go/src/github.com/docker/libcompose/vendor/github.com/urfave/cli/app.go:472 +0x29e
panic(0x868ac0, 0xc420010110)
	/usr/local/go/src/runtime/panic.go:458 +0x243
github.com/docker/libcompose/project.(*Project).handleNetworkConfig(0xc420082620)
	/go/src/github.com/docker/libcompose/project/project.go:281 +0x1a8
github.com/docker/libcompose/project.(*Project).load(0xc420082620, 0x8f035e, 0x12, 0xc42028d400, 0x61, 0x261, 0xc420181620, 0x410c78)
	/go/src/github.com/docker/libcompose/project/project.go:234 +0x38f
github.com/docker/libcompose/project.(*Project).Parse(0xc420082620, 0xb18e40, 0xc4202f2200)
	/go/src/github.com/docker/libcompose/project/project.go:112 +0x15a
github.com/docker/libcompose/docker.NewProject(0xc4200c2870, 0x0, 0x0, 0x0, 0x18, 0xc420181810)
	/go/src/github.com/docker/libcompose/docker/project.go:58 +0x106
github.com/docker/libcompose/cli/docker/app.(*ProjectFactory).Create(0xb66c60, 0xc4202b6500, 0x0, 0x8, 0x8, 0xc4202c4b80)
	/go/src/github.com/docker/libcompose/cli/docker/app/factory.go:20 +0xae
github.com/docker/libcompose/cli/app.WithProject.func1(0xc4202b6500, 0x0, 0x0)
	/go/src/github.com/docker/libcompose/cli/app/app.go:45 +0x4e
reflect.Value.call(0x84d260, 0xc4202c4220, 0x13, 0x8e9d90, 0x4, 0xc420181c68, 0x1, 0x1, 0x4702f8, 0x8dbe60, ...)
	/usr/local/go/src/reflect/value.go:434 +0x5c8
reflect.Value.Call(0x84d260, 0xc4202c4220, 0x13, 0xc420181c68, 0x1, 0x1, 0x0, 0x140, 0x140)
	/usr/local/go/src/reflect/value.go:302 +0xa4
github.com/docker/libcompose/vendor/github.com/urfave/cli.HandleAction(0x84d260, 0xc4202c4220, 0xc4202b6500, 0x0, 0x0)
	/go/src/github.com/docker/libcompose/vendor/github.com/urfave/cli/app.go:481 +0x1e0
github.com/docker/libcompose/vendor/github.com/urfave/cli.Command.Run(0x8e9974, 0x2, 0x0, 0x0, 0x0, 0x0, 0x0, 0x8f1b92, 0x15, 0x0, ...)
	/go/src/github.com/docker/libcompose/vendor/github.com/urfave/cli/command.go:186 +0xc26
github.com/docker/libcompose/vendor/github.com/urfave/cli.(*App).Run(0xc4202a4180, 0xc42000a3c0, 0x2, 0x2, 0x0, 0x0)
	/go/src/github.com/docker/libcompose/vendor/github.com/urfave/cli/app.go:235 +0x60c
main.main()
	/go/src/github.com/docker/libcompose/cli/main/main.go:75 +0x16d4
```

.
 @kadel , I have opened an issue regarding this in libcompose, which can be tracked here, https://github.com/docker/libcompose/issues/456.
 @kadel, @cdrage  I have sent PR for this issue in libcompose, which can be tracked here,  https://github.com/docker/libcompose/pull/467.
 @peterpme @kadel  @cdrage ,

I tried above docker compose file, its working well now,

```
$ kompose convert -f docker-compose.yml 
WARN Unsupported root level networks key - ignoring 
WARN Unsupported networks key - ignoring          
WARN Volume mount on the host ""/etc/ssl/dhparam"" isn't supported - ignoring path on the host 
WARN Volume mount on the host ""/srv/letsencrypt"" isn't supported - ignoring path on the host 
INFO file ""api-service.yaml"" created              
INFO file ""cms-service.yaml"" created              
INFO file ""nginx-service.yaml"" created            
INFO file ""search-service.yaml"" created           
INFO file ""api-deployment.yaml"" created           
INFO file ""cms-deployment.yaml"" created           
INFO file ""nginx-deployment.yaml"" created         
INFO file ""nginx-claim0-persistentvolumeclaim.yaml"" created 
INFO file ""nginx-claim1-persistentvolumeclaim.yaml"" created 
INFO file ""search-deployment.yaml"" created
```

we can close this issue now.
 @cdrage @surajssd , we can close this now.
 "
,,473,"RFE: kompose up support specified namespace to deploy.
 I propose to have following syntax cli for kompose:

```bash
$ kompose up --namespace dev
```

Behaviour expected:

- Deploy all docker-compose container(s) specified in `docker-compose.yml` into given kubernetes namespace (e.g. `dev` for example above) 

Usage:

- Help developer easy to deploy into certain / isolate namespace in kubernetes, e.g. dev, staging, uat, and production.

This request relates to following issue, but I don't see anything could do / work around with my proposed feature:

https://github.com/kubernetes-incubator/kompose/issues/162

Thanks..
 Hi @zanhsieh,
adding `--namespace` is good idea it will make switching namespace more user friendly, thank you for bringing this up.

Currently you can deploy to different namespace  using `kompose up` only if you switch default namespace for `kubectl` before.

`~/.kube/config`.
```sh
# get current context
$ kubectl config get-contexts
CURRENT   NAME                                        CLUSTER                         AUTHINFO                              NAMESPACE
*         minikube                                    minikube                        minikube                              asdf
          myproject/10-34-129-45:8443/developer       10-34-129-45:8443               developer/10-34-129-45:8443           myproject


# set namespace for current context
$ kubectl config set-context minikube --namespace asdf
Context ""minikube"" set.

$ kompose up
```
.
 I agree that adding `--namespace` would be a good idea for Kompose up / down, especially since (ideally) we would want to test this against a test environment.

Having a INFO display what namespace is being deployed too at the time of `kompose up` and `kompose down` would also be beneficial..
 Another thing stuck in my mind was, should we also include `--force` switch? Ideas were:

1. If no given namespace existed, create one.
2a. [Ambiguous] if namespace given existed, wipe it out and create.
2b. [Ambiguous] if namespace given existed, merge and update whatever.
3. `kompose down --namespace <given> --force` shall tear down namespace, too.

2a, 2b, just some thoughts. Thanks @kadel for triggering this up..
 @kadel Taking this up..
 "
,,472,"index.md: made LoadBalancer Ingress a valid IPv4.
 .
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

Once you've signed, please reply here (e.g. ""I signed it!"") and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/prow/commands.md).
</details>
	.
 I signed it!.
 @ceocoder thanks man, good find!.
 @cdrage np, years of watching Hollywood movies and saying ""Wait! that is not a real IP!"" made it easy.  Like this one,

![hackers](https://s-media-cache-ak0.pinimg.com/736x/8a/31/64/8a3164c17b87c27a1d93689a50aa171e.jpg).
 @ceocoder 
![meirl](http://i.imgur.com/iVHfwLc.gif).
 "
,,471,"Panics parsing volume config.
 I think it maybe because they are at the top level

```
version: '2'
volumes:
  dynamo_db:
  redis:
```

then defined later in particular services:

```
    volumes:
     - dynamo_db:/var/dynamodb_local
```

exception:

```
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x90b6d7]

goroutine 1 [running]:
panic(0x15e3920, 0xc420010070)
	/usr/local/go/src/runtime/panic.go:500 +0x1a1
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleVolumeConfig(0xc4200440e0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:319 +0x1d7
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc4200440e0, 0x7fff5fbff8f3, 0x17, 0xc420218d80, 0x249, 0x449, 0xc4204c1408, 0xfe88)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:235 +0x3a0
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc4200440e0, 0x0, 0x0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:112 +0x15a
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x25e0eb8, 0xc4201f4ee0, 0x1, 0x1, 0xc420040990, 0x0, 0xf65e)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:262 +0x1c1
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc4201f4ee0, 0x1, 0x1, ...)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:195 +0x103
github.com/kubernetes-incubator/kompose/cmd.glob..func3(0x25b3120, 0xc42000fba0, 0x0, 0x2)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:80 +0x3f
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x25b3120, 0xc42000f900, 0x2, 0x2, 0x25b3120, 0xc42000f900)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:636 +0x443
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x25b3560, 0xc42006c058, 0x0, 0xc4204c1ed0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:722 +0x367
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x25b3560, 0x0, 0x0)
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:681 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:92 +0x31
main.main()
	/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x14
```.
 Hi @spullara,
Thank you for reporting it. It looks like this is issue in libcompose - https://github.com/docker/libcompose/issues/430 . Should be fixed in next release..
 @kadel Perhaps we can update the vendoring for Kompose ? :+1: .
 yep, lets update vendored libcopmose  and test  it. So we can get this to next release.
 "
,,470,"Update headers to better reflect each page on Kompose.io.
 "
,,469,"Adds conversion doc + updates css.
 This adds to the conversion doc to the website as well as updates the
css for mobile-width viewing (too much spacing at the top)..
 "
,,468,"Add cap_add and cap_drop to unsupported keys.
 Kompose reads `cap_add` and `cap_drop` from docker-compose.yml but than it is not used anywhere..
 LGTM :+1: .
 "
,,467,"Add architecture guide to Kompose site.
 Adds the architecture doc as well as the image that we have from the
main github repo to the kompose.io website..
 "
,,466,"Minor fix on user guide.
 "
,,465,"Update release script.
 Had an issue where I don't git pull / merge with master after the PR has
been merged.

This adds an option to sync with master before continuing..
 @kadel Updated :).
 "
,,464,"using kompose as a library.
 Is it possible to use `kompose` as a go library, which can just be imported and used.

Something like `artifacts := kompose.Convert(""/app1/docker-compose.yml"", ""kubernetes"")`.

It would be very useful to be able to use kompose as a library, we should investigate that :)

CC: @kadel .
 :+1: .
 This is going to take *a lot* of effort. Let's label this as a help wanted. I'll try and work on it this upcoming month..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 Will trying to check this in a few days, hope it's not a huge change..
 @hangyan 靠你了，哈哈.
 I would like to work on this @hangyan @containscafeine @kadel .
 @Vibzy19 Honestly, it's a huge task / epic, but feel free to try :+1: it may take way longer than expected..
 @cdrage Thank you for the heads up :) I have already started working on it, let's see till where can I take this. .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten.
 /remove-lifecycle rotten.
 "
,,463,"stripping kompose binary?.
 When doing a `go install`, the resulting binary is 73M, and on doing a `go install -ldflags ""-s""`, I am getting a 38M binary, which is essentially stripping the binary.

We can achieve the same by using the `strip` command on the binary.

Should we strip the kompose binary and release it? This gets the size down by about 50%, however there may be some tradeoffs like -
- https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=717172

More on stripping golang binaries here -
- https://blog.filippo.io/shrink-your-go-binaries-with-this-one-weird-trick/.
 Lets test on all arch with stripped binaries if functional test pass that should be good, then add it to the build script in Makefile..
 I wouldn't worry about that right now. It might bring more troubles than benefits..
 FYI, please don't do this https://twitter.com/davecheney/status/846844080227213312.
 I agree with @kadel and @ericchiang

Let's close this for now and focus rather on removing the big dependencies / reducing the binary the library-way..
 "
,,462,"Improve error handling, fix #416.
 .
 Phew, got the tests passing.
Up for review, ping @cdrage @kadel .
 Good job man! Did a review and the code LGTM :+1: 

Just need to rebase against master (I updated the vendoring in a different PR).
 @cdrage fixed! :).
 @cdrage fixed..
 LGTM! :+1: .
 "
,,461,"Wrong version, again.
 I just downloaded linux-0.3.0 and installed it. When I run `kompose version` I get `0.2.0 (10cff91)`.
Also, I gave 0.3.0 a try because I had troubles with underscores in volume names, and after running `kompose convert`, the underscore were still present. I'll try compiling from source to confirm, but could it be possible that the published version does not include that patch?.
 Hi @louisremi,
You are right, we uploaded binary that is showing wrong version number in `kompose version` :-(
Binary is correct it is compiled from latest source (in time of the release). 

Underscore problem got fixed in service names, but not in volume names :-(
We will fix that.
I've reopened https://github.com/kubernetes-incubator/kompose/issues/420




.
 @cdrage we need to do something to make sure that we don't release binaries with wrong version again..
 Yeah, this is totally my fault, I had forgotten to add a function from a previous project to this release script in regards to syncing with the master repo before upload / making of the binaries. 

I've fixed this in #465 .
 this has been fixed, shouldn't happen again :-).
 "
,,460,"Adding kompose up/down tests for openshift.
 Adding kompose up/down tests for openshift as part of #323.

The script runs kompose up/down using etherpad docker-compose file with `oc cluster up`. .
 please add `make test-openshift` to travis.yml (after `make test`) so we can see it in action ;-).
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

Once you've signed, please reply here (e.g. ""I signed it!"") and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/prow/commands.md).
</details>
	.
  I signed it!.
 A lot of the `;` can be removed from the bash file.
 I just noticed that tests take 22mins now :-( 
If I remember correctly there is 30min timeout in travis-ci, so we are getting dangerously close to that :-( 

I guess that `oc cluster up` is taking long as is downloading docker images.

Is possible to cache those images on travis-ci? 
What if we move this test to ci.centos.org. Is it going to be faster? Will it be possible to cache images there?


Otherwise it looks good. Thank you for creating `kompose_up_check` Tests look much  cleaner now


.
 @kadel what I could do is not have run `oc cluster up` for every test case. We should have it run it only once..
 There's over 7 60 second sleep calls as well as 30 second and 5 second sleep calls all over the place.

@ashetty1 here is some reference code: https://github.com/projectatomic/adb-tests/blob/master/cdrage-atomicapp-ci/functional-tests/providers/openshift.sh

as well as: https://github.com/projectatomic/adb-tests/blob/master/cdrage-atomicapp-ci/functional-tests/

Where we used curl + grep + grepping `oc` and `kubectl` to reduce this time. Only using `sleep` when absolutely necessary (`oc new-project` lags sometimes)

At the moment, this will take wayyyyy too long to run the tests each time. It already takes 10 minutes to run our ordinary tests, but with these tests it'll run even longer.

With the length of the tests, I'd suggest using the CentOS CI instead so we can run both in parallel. I originally suggested *just* Travis CI, but lately Travis has been running slow and it doesn't help that we're adding more and more unit / integration tests each day!.
 @cdrage the sleep has been used only to provide some lag while the pods are being brought up. I tried reducing the sleep time to 10, and then modified the kompose_down_check to look for ""Terminating' status; with both these changes, the tests took about 12mins. If this looks okay, I shall push the changes her: https://github.com/ashetty1/kompose/blob/entrypoint_cmd/script/test_in_openshift/lib.sh#L157.
 @ashetty1 
It would be much better if you wrote a bash loop instead of using sleep as it'll really cut down on the deployment times. It's hard to rely just on sleep as we don't know exactly what box the CI test is being ran on at TravisCI and there will be a lot of false positives / having to reset the build..
 Look at our solution here: https://github.com/projectatomic/adb-tests/blob/master/cdrage-atomicapp-ci/functional-tests/providers/openshift.sh#L86.
 @cdrage Sure, I could get rid of all the sleeping, but then the only issue is about handling failures. How do you think we should handle a scenario where pods aren't getting deleted/terminated?  That's the reason I have the retry count there. Sleep is useful there, I think. .
 In regards to actually clearing / deleting the pods to run the next test, we didn't run into any of those issues.

Besides, if a previous test didn't terminate correctly (`kompose down`) then the tests are working as intended!

Just have a look at how we ran all the tests here: https://github.com/projectatomic/adb-tests/tree/master/cdrage-atomicapp-ci/functional-tests and you'll see how we did it in terms of terminating / rebuilding the cluster to a clean-slate for each test being ran..
 ```
github.com/kubernetes-incubator/kompose  pr_460 ✔                                                                                                                                                                                                                         3h34m  
▶ make test-openshift 
./script/test_in_openshift/run.sh


===> Starting test <===
Functional tests on OpenShift
./script/test_in_openshift/run.sh: line 29: oc: command not found
FAIL: Please install the oc binary to run testsMakefile:62: recipe for target 'test-openshift' failed
make: *** [test-openshift] Error 1
```

I think there should be a newline after saying the FAIL error..
 @ashetty1 

Doesn't work it seems if a server isn't already up:

```
github.com/kubernetes-incubator/kompose  pr_460 ✔                                                                                                                                                                                                                        3h36m  ⍉
▶ make test-openshift 
./script/test_in_openshift/run.sh


===> Starting test <===
Functional tests on OpenShift
error: server took too long to respond with version information.
FAIL: Please install the oc binary to run testsMakefile:62: recipe for target 'test-openshift' failed
make: *** [test-openshift] Error 1
```

I believe you should be checking if the binary exists in /usr/local/bin or /usr/bin/ instead of checking via `oc version`.
 @cdrage Like this: https://github.com/kubernetes-incubator/kompose/pull/460/commits/79cc511d1dbe90d3248ff8000f47dbc19e97ecb2#diff-627568f7d5722e14bec5cf5a74719fb8L29 ?.
 @ashetty1 Yes. Checking if OC is there instead of `oc version`..
 @ashetty1 

Seems like I'm getting another error:
```
▶ make test-openshift 
./script/test_in_openshift/run.sh


===> Starting test <===
Functional tests on OpenShift
FAIL: oc cluster up failed.
Makefile:62: recipe for target 'test-openshift' failed
make: *** [test-openshift] Error 1
```

There's no output for `oc cluster up` when using `make test-openshift`. May be a good idea in order to diagnose issues.

Of course, there's an error in `oc` (I know what the issue is, was just testing it out):
```
github.com/kubernetes-incubator/kompose  pr_460 ✔                                                                                                                                                                                                                                                                                                                   3h59m  ⍉
▶ oc cluster up
-- Checking OpenShift client ... OK
-- Checking Docker client ... OK
-- Checking Docker version ... FAIL
   Error: Minor number must not contain leading zeroes ""03""
```

Which is unrelated, but of course, it'd be nice to have the output from the Makefile so people can diagnose why they can't run `make test-openshift`.
 Another note is that it would be nice to see the output of `oc cluster up` regardless if it errors or not..
 @kadel , @cdrage let me know if this looks good now..
 Hey @ashetty1 

Tests don't seem to work:
```
github.com/kubernetes-incubator/kompose  pr_460 ✔                                                                                                                                                                                                                                                                                                                      1d  ⍉
▶ make test-openshift 
./script/test_in_openshift/run.sh


===> Starting test <===
Functional tests on OpenShift
-- Checking OpenShift client ... OK
-- Checking Docker client ... OK
-- Checking Docker version ... 
   WARNING: Cannot verify Docker version
-- Checking for existing OpenShift container ... OK
-- Checking for openshift/origin:v3.6.0-alpha.0 image ... OK
-- Checking Docker daemon configuration ... OK
-- Checking for available ports ... OK
-- Checking type of volume mount ... 
   Using nsenter mounter for OpenShift volumes
-- Creating host directories ... OK
-- Finding server IP ... 
   Using 127.0.0.1 as the server IP
-- Starting OpenShift container ... 
   Creating initial OpenShift configuration
   Starting OpenShift using container 'origin'
   Waiting for API server to start listening
   OpenShift server started
-- Adding default OAuthClient redirect URIs ... OK
-- Installing registry ... OK
-- Installing router ... OK
-- Importing image streams ... OK
-- Importing templates ... OK
-- Login to server ... OK
-- Creating initial project ""myproject"" ... OK
-- Removing temporary directory ... OK
-- Checking container networking ... OK
-- Server Information ... 
   OpenShift server started.
   The server is accessible via web console at:
       https://127.0.0.1:8443

   You are logged in as:
       User:     developer
       Password: developer

   To login as administrator:
       oc login -u system:admin


Testing buildconfig on kompose


Running kompose up ...

INFO Buildconfig using git@github.com:cdrage/kompose.git::pr_460 as source. 
We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO Successfully created Service: foo            
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

Waiting for the pods to come up ...

FAIL: kompose up has failed to bring the pods up
NAME          READY     STATUS              RESTARTS   AGE
foo-1-build   0/1       ContainerCreating   0          2m
```

Most likely to do with the example that you use:
```
version: ""2""

services:
    foo:
        build: ""./build""
        command: ""sleep 3600""
```

Using the ""foo"" image, and thus the container is never created (stuck on ContainerCreating).
 @cdrage tried running it, and it worked: https://travis-ci.org/ashetty1/kompose/jobs/220470857

I am using the same docker-compose file listed in the examples directory. .
 @ashetty1 It works for you because you've already built the ""foo"" image on your machine. 

This fails because you have ""foo"" listed as the service name and thus OpenShift is trying to find/use an image named ""foo"" and get's stuck on ContainerCreating because it can't find it..
 Have a look at what you linked (https://travis-ci.org/ashetty1/kompose/jobs/220470857) there's even a FAIL in there and it still doesn't fail....
 Still get's stuck, here's an extended log:
```
-- Login to server ... OK
-- Creating initial project ""myproject"" ... OK
-- Removing temporary directory ... OK
-- Checking container networking ... OK
-- Server Information ... 
   OpenShift server started.
   The server is accessible via web console at:
       https://127.0.0.1:8443

   You are logged in as:
       User:     developer
       Password: developer

   To login as administrator:
       oc login -u system:admin


Testing buildconfig on kompose


Running kompose up ...

INFO Buildconfig using git@github.com:cdrage/kompose.git::pr_460 as source. 
We are going to create OpenShift DeploymentConfigs, Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO Successfully created Service: foo            
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo        

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

Waiting for the pods to come up ...

```

```
github.com/kubernetes-incubator/kompose  pr_460 ✔                                                                                                                                                                                                                            4d  
▶ oc get all
NAME      TYPE      FROM         LATEST
bc/foo    Docker    Git@pr_460   1

NAME           TYPE      FROM         STATUS    STARTED   DURATION
builds/foo-1   Docker    Git@pr_460   Pending             

NAME      DOCKER REPO                     TAGS      UPDATED
is/foo    172.30.1.1:5000/myproject/foo             

NAME      REVISION   DESIRED   CURRENT   TRIGGERED BY
dc/foo    0          1         0         config,image(foo:latest)

NAME      CLUSTER-IP   EXTERNAL-IP   PORT(S)     AGE
svc/foo   None         <none>        55555/TCP   1m

NAME             READY     STATUS              RESTARTS   AGE
po/foo-1-build   0/1       ContainerCreating   0          1m
```

@ashetty1 
It also seems that if one test fails, the whole test suite still exits with an exit error 0, which isn't correct..
 @cdrage will reinvestigate. I deleted all the images and ran it again. Still don't see the error:
```
$ oc get all
NAME      TYPE      FROM         LATEST
bc/foo    Docker    Git@master   1

NAME           TYPE      FROM          STATUS     STARTED         DURATION
builds/foo-1   Docker    Git@e8b98e3   Complete   4 minutes ago   4m11s

NAME      DOCKER REPO                         TAGS      UPDATED
is/foo    172.30.184.195:5000/myproject/foo   latest    28 seconds ago

NAME      REVISION   DESIRED   CURRENT   TRIGGERED BY
dc/foo    1          1         1         config,image(foo:latest)

NAME       DESIRED   CURRENT   READY     AGE
rc/foo-1   1         1         1         28s

NAME      CLUSTER-IP   EXTERNAL-IP   PORT(S)     AGE
svc/foo   None         <none>        55555/TCP   4m

NAME             READY     STATUS      RESTARTS   AGE
po/foo-1-build   0/1       Completed   0          4m
po/foo-1-mvjva   1/1       Running     0          26s

```
Will try a few more times just to confirm. The FAIL in the travis log is for `kompose down` which doesn't delete buildconfig pods. The exit status is a problem. Agree, we need to make sure is that make-openshift exits with a non-zero status when there are failures. .
 This may be a DNS issue on my end with the Docker containers... I'll see if
it is. I remember a similar issue happening a while back with DNS and
retrieving containers.

On Apr 10, 2017 10:02, ""Anush Shetty"" <notifications@github.com> wrote:

> @cdrage <https://github.com/cdrage> will reinvestigate. I deleted all the
> images and ran it again. Still don't see the error:
>
> $ oc get all
> NAME      TYPE      FROM         LATEST
> bc/foo    Docker    Git@master   1
>
> NAME           TYPE      FROM          STATUS     STARTED         DURATION
> builds/foo-1   Docker    Git@e8b98e3   Complete   4 minutes ago   4m11s
>
> NAME      DOCKER REPO                         TAGS      UPDATED
> is/foo    172.30.184.195:5000/myproject/foo   latest    28 seconds ago
>
> NAME      REVISION   DESIRED   CURRENT   TRIGGERED BY
> dc/foo    1          1         1         config,image(foo:latest)
>
> NAME       DESIRED   CURRENT   READY     AGE
> rc/foo-1   1         1         1         28s
>
> NAME      CLUSTER-IP   EXTERNAL-IP   PORT(S)     AGE
> svc/foo   None         <none>        55555/TCP   4m
>
> NAME             READY     STATUS      RESTARTS   AGE
> po/foo-1-build   0/1       Completed   0          4m
> po/foo-1-mvjva   1/1       Running     0          26s
>
>
> Will try a few more times just to confirm. The FAIL in the travis log is
> for kompose down which doesn't delete buildconfig pods. The exit status
> is a problem. Agree, we need to make sure is that make-openshift exits with
> a non-zero status when there are failures.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes-incubator/kompose/pull/460#issuecomment-292958526>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGH-oDJZzXT8NpgihKNj1TgbLD6wWaZQks5rujaSgaJpZM4MPf0P>
> .
>
.
 After all that, found it it was because of this: https://github.com/openshift/origin/issues/13281

Downgrading Docker now and seeing if it fixes the issue..
 @ashetty1 

I'm still having troubles trying to replicate this on my local machine.

What version of OC are you running as well as Docker @ashetty1 ?.
 @cdrage OC version: v1.4.1
docker on my system is 1.12.1, and on travis is  1.12.3. 

Should I update my docker and try this?
 .
 @ashetty1 I'm running 3.6.0 of OpenShift, let me downgrade and see what happens..
 "
,,459,"unsupported keys.
 @cdrage added `sysctls` to unsupported keys since we didn't find anything akin in Kubernetes.
Added `links` to unsupported keys since containers in the same pod can find and communicate with each other using `localhost:containerPort`

Fixes: #441 #439 .
 I don't think that we should display warning for `links`.
Only think `link` does is create env variables, same variables are create by Kubernetes for every service.

We can safely and silently ignore it..
 Agreed with @kadel and thanks for adding sysctls to ignore list :).
 "
,,458,"Update the release script again :).
 .
 "
,,457,"add sysctls to unsupported keys.
 @cdrage added `sysctls` to unsupported keys since we didn't find anything akin in Kubernetes.
Fixes #441 

.
 "
,,456,"Error with unsupported keys not showing up in warnings.
 Seems that nothing warns in regards to any of the unsupported keys from `compose.go`, with the exception of ""networks"".

This code:
```
  var unsupportedKey = map[string]bool{                                                                                                 
    ""CgroupParent"":  false,                                                                                                             
    ""Devices"":       false,                                                                                                             
    ""DependsOn"":     false,                                                                                                             
    ""DNS"":           false,                                                                                                             
    ""DNSSearch"":     false,                                                                                                             
    ""DomainName"":    false,                                                                                                             
    ""EnvFile"":       false,                                                                                                             
    ""Extends"":       false,                                                                                                             
    ""ExternalLinks"": false,                                                                                                             
    ""ExtraHosts"":    false,                                                                                                             
    ""Hostname"":      false,                                                                                                             
    ""Ipc"":           false,                                                                                                             
    ""Logging"":       false,                                                                                                             
    ""MacAddress"":    false,                                                                                                             
    ""MemSwapLimit"":  false,                                                                                                             
    ""NetworkMode"":   false,                                                                                                             
    ""Pid"":           false,                                                                                                             
    ""SecurityOpt"":   false,                                                                                                             
    ""ShmSize"":       false,                                                                                                             
    ""StopSignal"":    false,                                                                                                             
    ""VolumeDriver"":  false,                                                                                                             
    ""Uts"":           false,                                                                                                             
    ""ReadOnly"":      false,                                                                                                             
    ""Ulimits"":       false,                                                                                                             
    ""Dockerfile"":    false,                                                                                                             
    ""Net"":           false,                                                                                                             
    ""Networks"":      false, // there are special checks for Network in checkUnsupportedKey function                                     
  }   
```.
 For example, running:
```
version: ""2""                                                                                                                            
                                                                                                                                        
services:                                                                                                                               
    redis:                                                                                                                              
      image: redis:3.0                                                                                                                  
      build:                                                                                                                            
        context: .                                                                                                                      
        dockerfile: foobar                                                                                                              
                                                                                                                                        
dns: 8.8.8.8                                                                                                                            
                                                                                                                                        
hostname: foobar   
```

Only produces an error from `build` being passed in. That's it..
 Ahhhh nevermind, it was a problem with my build. a git --reset and a git clean -d -f then a make build solved it..
 "
,,455,"Clean up logrus.
 Replaces ""log"" from ""logrus"" as commonly used in large Go projects.

Makes it easier from a developer perspective to use `log.Info`,
`log.Debug`, etc..
 LGTM 👍.
 "
,,454,"Added consistency in build context.
 fixes #445.
 now it is broken other way around ;-)

```
▶ kompose --provider openshift convert --stdout -f compose-build-test/build.yaml | grep context
INFO Buildconfig using https://github.com/kadel/compose-build-test.git::master as source. 
      contextDir: ./build
                                                                                                                                                                               
▶ kompose --provider openshift convert --stdout -f compose-build-test/context.yaml | grep context
INFO Buildconfig using https://github.com/kadel/compose-build-test.git::master as source. 
      contextDir: compose-build-test/build

```

(same files as in #445).
 This might be great case where you can try test driven development. ;-)
Try to write unit tests for this first. Than you can easily check if both things work..
 @kadel , sure. it seems that its failing for first example.
 @kadel , it works for me :)

```
$ kompose convert --provider=openshift --stdout -f ex1/context.yml | grep context
INFO Buildconfig using git@github.com:surajnarwade/buildconfig_example.git::master as source. 
      contextDir: ex1/build

$ kompose convert --provider=openshift --stdout -f ex1/build.yml | grep context
INFO Buildconfig using git@github.com:surajnarwade/buildconfig_example.git::master as source. 
      contextDir: ex1/build
```

.
 That is strange. I'm still getting the same error as in #445.

Maybe something is wrong on my side. I'll check it.

Anyways, can you please add unit tests for this? We should have unit tests that covers both scenarios  (build and context). 

.
 I agree that we should really add unit tests to this as Travis passed on this and should probably fail judging from @kadel and @surajnarwade 's errors.
 I haven't look at the code yet, but i tested it and it is still not working as it should.

for 
```yaml
version: ""2""
services:
    foo:
        build:
           context: ""./build""
        command: ""sleep 3600""
```

it generates  `contextDir: /home/tomas/tmp/compose-build-test/build` instead of `./build`


.
 this PR works for me as:

```bash
✔ ~/tmp/buildcontextimproper [master L|✔] 
12:19 $ kompose --provider openshift convert --stdout -f compose-build-test/build.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: compose-build-test/build
```
and

```bash
✔ ~/tmp/buildcontextimproper [master L|✔] 
12:25 $ kompose --provider openshift convert --stdout -f compose-build-test/context.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: compose-build-test/build
```

which is certainly not correct.
 my dir structure

```bash
✔ ~/tmp/buildcontextimproper [master L|✔] 
12:25 $ tree
.
├── build
└── compose-build-test
    ├── build.yaml
    └── context.yaml

2 directories, 2 files
```.
 oops my bad I had docker-compose file with wrong build info so updated it and gave a correct relative path now

```bash
$ cat compose-build-test/build.yaml  | grep build
        build: ""../build""

$ kompose --provider openshift convert --stdout -f compose-build-test/build.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: build
```

and 


```bash
$ cat compose-build-test/context.yaml  | grep build
        build:
            context: ""../build""
$ kompose --provider openshift convert --stdout -f compose-build-test/context.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: compose-build-test/build

```.
 @surajnarwade I'm getting this :(

```bash
$ kompose  convert --provider=openshift --stdout -f test/build.yaml  
FATA [foo] Buildconfig cannot be created due to error in creating build context. 

$ kompose  convert --provider=openshift --stdout -f test/context.yaml  
FATA [foo] Buildconfig cannot be created due to error in creating build context. 
```.
 @surajnarwade for me it fails like this:

I am here
```bash
✘-1 ~/tmp/buildcontextimproper/compose-build-test [master L|✚ 1] 
18:23 $ pwd
/home/hummer/tmp/buildcontextimproper/compose-build-test
```
my dir looks like this
```bash
✔ ~/tmp/buildcontextimproper/compose-build-test [master L|✚ 1] 
18:23 $ tree ..
..
├── build
└── compose-build-test
    ├── build.yaml
    └── context.yaml

2 directories, 2 files
```
I run this
```bash
✔ ~/tmp/buildcontextimproper/compose-build-test [master L|✚ 1] 
18:23 $ kompose --provider openshift convert --stdout -f ../compose-build-test/build.yaml | grep -i context
FATA [foo] Buildconfig cannot be created due to error in creating build context. 
```
docker-compose file looks like this:
```bash
✘-1 ~/tmp/buildcontextimproper/compose-build-test [master L|✚ 1] 
18:23 $ cat ../compose-build-test/build.yaml 
version: ""2""
services:
    foo:
        build: ""./build""
        command: ""sleep 3600""
```.
 oh my bad again the build path was wrong in above example, it should be `../build` not `./build`, but the error was not very helpful!.
 @surajnarwade would recommend improving the error message if possible!.
 @surajssd @containscafeine , you are getting error because build directory you mentioned is not present there. you can use https://github.com/surajnarwade/compose-test as a example.
 @surajssd , added error message.
 @surajnarwade 

Still think your commit message could be improved:

```
fixes #445
Modified unit test cases
Added comments
```

Please elaborate on what's being changed / added and all :).
 @surajnarwade Hi, in order for this to be more consistent with the comments in here, I'd advise to close this PR and create a new PR for just the vendor update as well as update your commit message..
 cc @cdrage @surajssd @containscafeine .
 Files to review:
* [openshift.go](https://github.com/kubernetes-incubator/kompose/pull/454/files#diff-91f3ad308c13930dc408cd92991debea)

* [openshift_test.go](https://github.com/kubernetes-incubator/kompose/pull/454/files#diff-d138004ee5d369cc4ce608ebbee34753)
.
 @surajnarwade You've mixed up the vendor update and the code being changed in the same PR. Please make this PR code-only and update the vendoring in a seperate PR or wait until https://github.com/kubernetes-incubator/kompose/pull/566 is merged..
 @cdrage, vendoring and this code are interdependent, if we are going to put both things in separate PR, both are going to fail..
 @surajnarwade They won't fail. We've got multiple PR's out there relying on the same vendoring being updated, thus why #566 was created.

Regardless, you need to split up your code between vendoring and your actual code into different commits..
 @cdrage , I have split the PR into two separate commits for code and vendoring.
 @surajnarwade 
You need to update your Git messages as well. They are blank for both.

`git commit --amend`.
 @cdrage done.
 cc @cdrage @kadel @surajssd @containscafeine .
 @surajnarwade as we talked you gonna add some functional tests to this before we merge this right?.
 @surajssd , yeah I am going to add few more unit test.
 @surajssd have a look.
 "
,,453,"Update the README with -u in go get.
 Updates the readme to include -u in `go get` in order to upgrade
already-installed versions of Kompose..
 "
,,452,"Separate key:""value"" pairs in kobject.go.
 this was error in travis with GO 1.8 version
```
pkg/kobject/kobject.go:60: struct field tag `compose:""image"",bundle:""Image""` not compatible with reflect.StructTag.Get: key:""value"" pairs not separated by spaces
pkg/kobject/kobject.go:61: struct field tag `compose:""environment"",bundle:""Env""` not compatible with reflect.StructTag.Get: key:""value"" pairs not separated by spaces
...
...
```

I have added fix in PR #424.
 this was already fixed in https://github.com/kubernetes-incubator/kompose/pull/449.
 "
,,451,"Update the release script again :).
 "
,,450,"0.3.0 Release.
 All green :+1: .
 "
,,449,"Test with multiple go versions.
 `go vet` in go 1.8 started complaining about tag format.

```
pkg/kobject/kobject.go:60: struct field tag `compose:""image"",bundle:""Image""` not compatible with reflect.StructTag.Get: key:""value"" pairs not separated by spaces
```

This fixes tag formatting in KObject and updates travis.yaml so it runs tests on multiple go versions 1.6, 1.7 and 1.8


.
 LGTM :+1: .
 "
,,448,"Add conversion documentation.
 This adds a document regarding all the values which are converted from
Docker Compose to Kubernetes / OpenShift. Adding both notes as well as
the value that docker-compose is mapped to in Kubernetes / OpenShift..
 we should also have link to this document in readme.
 @kadel I agree. I'll add an ""index"" to the README eventually.

I've updated the PR based on your comments as well as converted it to a ""compact"" table instead of having all the spacing everywhere..
 @kadel Updated again, I shortened the unsupported column to Y/N as well as labeled the separate sections by boldness (volumes, services, networks, etc.). Looks better now :+1: .
 "
,,447,"Support for: top-level volumes..
 Using a top-level volume errors out and is unsupported:
```
version: ""2""

services:
    redis:
      image: redis:3.0

volumes:
  - /var/lib/mysql
```

```
ERRO Could not parse config for project wikus : yaml: unmarshal errors:
  line 8: cannot unmarshal !!seq into map[string]interface {} 
FATA Failed to load compose file: yaml: unmarshal errors:
  line 8: cannot unmarshal !!seq into map[string]interface {} 
```.
 @surajnarwade @procrypt 

Is it possible to investigate this to see what we could possibly do to implement it?

Of course, other top-level keys such as `networks` makes sense not to support, but `volumes` seems important..
 @cdrage Will look into it. @surajnarwade Do you have some time today we can discuss about it..
 @procrypt sure.
 @cdrage , I think top-level volumes keys dont make any sense.
.
 @surajnarwade Could you give your reasoning as to why they don't make sense?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Ping @surajnarwade .
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Don't we support this now @hangyan ? I think we do...
 @cdrage No, we haven't....
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,446,"Support for private Docker registry ImageStream.
 I'm trying to setup OS to pull images from my private registry:

    # docker-compose.yml
    services:
      web:
        image: registry.example.com/my/example.com:latest
        build:
          context: .
          dockerfile: ./.infra/docker/nginx/Dockerfile

My desired output would be:

    apiVersion: v1
    kind: ImageStream
    spec:
        tags:
        -
            from:
                kind: DockerImage
                name: registry.example.com/my/example.com:latest
            name: latest

without the `BuildConfig` because I wish to use pre-made images instead of making them on the OS cluster. The way I see it, currently `kompose` always uses source to image builder strategy, it would be cool to allow for this behavior too.

Please note I'm quite new to Openshift and` kompose` (much more experience with `docker-compose`) so if this doesn't make sense in this context, feel free to correct me. Thanks..
 Hey @dkarlovi,

Currently we do not have an option not to generate a BuildConfig if `build:` section is there in the docker compose file, so for this use case, it'd make sense to comment out the `build:` section in the docker compose file (that's what I do).

Also, the issue title says `Support for private repository ImageStream`, I'm not sure what does this mean? If you are talking about a private Docker or Git registry, then if your node can access that endpoint, everything should work.
If you are talking about an insecure registry, then you might have to run something like `oc patch is $imagestream -p '{""metadata"":{""annotations"":{""openshift.io/image.insecureRepository"": ""true""}}}}'` for the ImageStream to work.

Does this help?.
 @containscafeine thanks for your reply.

I'm talking about private Docker registry, not private Git repository, changed the title to reflect that, sorry about the confusion.

Idea is, my CI process builds the images and runs the whole process on them, it makes sense to use those exact images when actually running your production.

The poiint of this issue is to allow for additional semantic when converting, ie.
> My `docker-compose.yml` has a build section, but I'd like to use the Docker image based `ImageStream` instead of a source-to-image `BuildConfig`.

Ssay `--use-docker-image-stream` or similar? If it does exactly that by commenting out the build section, that's fine as a workaround, but why not enable it fully?.
 @dkarlovi that can be done I think need to add some checks here, that is:

if `image` and `build` given we can pick up the image name directly and not create `bc`

only if `build` provided create a `bc`.

WDYT @kadel @containscafeine @rtnpro  ? thoughts.
 @surajssd sounds good to me..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 I believe we should still implement this in the future. Let's freeze this..
 /lifecycle crozen.
 @cdrage typo. :).
 /lifecycle frozen.
 "
,,445,"Inconsistency in build context.
 I have two docker-compose files, that should do the same thing

build.yaml
```yaml
version: ""2""
services:
    foo:
        build: ""./build""
        command: ""sleep 3600""
```

context.yaml
```yaml
version: ""2""
services:
    foo:
        build:
            context: ""./build""
        command: ""sleep 3600""
```


I'm in the directory that is one level up from the directory where those docker-compose files are.

If run convert on first file like this:
```
kompose --provider openshift convert --stdout -f compose-build-test/build.yaml
```
I get BuildConfig that has `contextDir: build`. That is corrent.

But If I use second file that is using expanded way to define build
```
kompose --provider openshift convert --stdout -f compose-build-test/context.yaml
```
I get BuildConfig with `contextDir: compose-build-test/build`, which is wrong.


I also found out that if I'm in the same directory where those docker-compose files are, everything works as expected.
```
~/tmp/compose-build-test  master ✗ 
▶ kompose --provider openshift convert --stdout -f build.yaml | grep contextDir                   
INFO Buildconfig using https://github.com/kadel/compose-build-test.git::master as source. 
      contextDir: build

~/tmp/compose-build-test  master ✗ 
▶ kompose --provider openshift convert --stdout -f context.yaml | grep contextDir
INFO Buildconfig using https://github.com/kadel/compose-build-test.git::master as source. 
      contextDir: build
```

.
 contextDir should always be with respect to root directory of git repository, I have added fix in PR #424 .
 > contextDir should always be with respect to root directory of git repository, I have added fix in PR #424

hi @surajnarwade, thank  you for fixing it,  but it would be better to have this as separate PR.
 master works like this for me now:

dir structure
```
✔ ~/tmp/buildcontextimproper [master L|✔] 
12:18 $ tree
.
├── build
└── compose-build-test
    ├── build.yaml
    └── context.yaml

2 directories, 2 files
```


```bash
$ kompose --provider openshift convert --stdout -f compose-build-test/build.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: compose-build-test/build
```

and 

```bash
$ kompose --provider openshift convert --stdout -f compose-build-test/context.yaml | grep -i context
INFO Buildconfig using https://mycode.com.git::master as source. 
      contextDir: compose-build-test/compose-build-test/build
```.
 I have raised PR in libcompose regarding this and can be tracked here https://github.com/docker/libcompose/pull/450.
 https://github.com/docker/libcompose/pull/450 Has been merged. Update vendoring?.
 @cdrage https://github.com/kubernetes-incubator/kompose/pull/562 Not sure why he closed it. He mentioned somewhere that his updating vendoring along with some other issue https://github.com/kubernetes-incubator/kompose/pull/454 . Not sure if that is a good idea. IMO, updating vendoring could have been an independent PR but I will let you and others take the call on this..
 @pradeepto 
Opened up #566 to solve this and get us up-to-date with vendoring..
 Reopening this! :+1: needs https://github.com/kubernetes-incubator/kompose/pull/424 to close.
 @cdrage @surajssd we can close this issue now.
 "
,,444,"Support for: volumes_from.
 Does not warn / error out when used.

*Should* we generate a persistentvolumeclaim?.
 `volumes_from` is supported construct..
 I'm closing this as kompose haa support for `volumes_from`. If anyone disagree feel free to open it..
 "
,,443,"Support for: userns_mode.
 No error / warning when using this key.
 @cdrage This is libcompose issue.
```bash
$ libcompose up
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
ERRO[0000] Could not parse config for project komposefiles : Unsupported config option for web service: 'userns_mode' 
FATA[0000] Failed to read project: Unsupported config option for web service: 'userns_mode' 
```

Issue created on `libcompose` https://github.com/docker/libcompose/issues/444.
 Closing this as I've updated the conversion document to reflect that this is not supported in Kubernetes and this key is also dropped in Docker Compose Version 3..
 "
,,442,"Support for: ulimits.
 No error / warning when using this key.
 @cdrage Kompose gives us a warning when we use `ulimits`.
```yaml
web:
  image: tuna/docker-counter23
  ulimits:
    nproc: 65535
    nofile:
      soft: 20000
      hard: 40000
  ports:
    - ""5000:5000""
  links:
    - redis
redis:
  image: redis:3.0
  ports:
    - ""6379""
```
`$ kompose convert --provider=openshift`
```bash
WARN Unsupported ulimits key - ignoring           
INFO file ""web-service.yaml"" created              
INFO file ""redis-service.yaml"" created            
INFO file ""web-deploymentconfig.yaml"" created     
INFO file ""web-imagestream.yaml"" created          
INFO file ""redis-deploymentconfig.yaml"" created   
INFO file ""redis-imagestream.yaml"" created      
```.
 yes, we show warning for ulimit. And as far as I know, currently there is  no way in Kubernetes how to set ulimits .

Closing this, feel free to re-open it if you disagree. .
 Ah yeah, you're right, I missed that with ""ULimits"" in `compose.go`.
 "
,,441,"Support for sysctls.
 ```
▶ kompose convert --stdout
ERRO Could not parse config for project wikus : Unsupported config option for redis service: 'sysctls' 
FATA Failed to load compose file: Unsupported config option for redis service: 'sysctls' 
```.
 @cdrage I want to work on it, after we finish up with the discussion :).
 Yeah :) I think that we *shouldn't* support sysctls as I can't find anything compareable in Kubernetes..
 Adding it to list of unsupported keys would be helpful..
 @cdrage This is libcompose issue.
```bash
$ libcompose up
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
ERRO[0000] Could not parse config for project komposefiles : Unsupported config option for web service: 'sysctls' 
FATA[0000] Failed to read project: Unsupported config option for web service: 'sysctls'
```
issue created on `libcompose` https://github.com/docker/libcompose/issues/445.
 thanks @procrypt :) I'll subscribe to that issue..
 woops, closed by accident.
 this was again closed by accident it seems @procrypt @cdrage ?.
 because #459 never fixed this issue, it only added this directive to unsupported keys?.
 @surajssd You are right. it was not fixed in #459

There is different problem with `sysctls` - it is only in docker-compose v2.1 and that is not supported by libcompose.
 I probably shouldn't reopen it as this is more about adding support for v2.1 :smile: 
.
 I found a 1-1 mapping for this within Kubernetes: https://kubernetes.io/docs/concepts/cluster-administration/sysctl-cluster/ and thus we can implement it :+1: .
 Okay, two problems:

1. sysctls is not yet supported / added to libcompose
2. since sysctls is ignored by docker/cli, it is also not supported:
```
github.com/kubernetes/kompose  add-sysctls ✗                                                                                                                4h3m ◒  ⍉
▶ ./kompose convert --stdout -f script/test/fixtures/sysctls/docker-compose.yaml
FATA net.core.somaxconn Additional property net.core.somaxconn is not allowed 
```.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 This is wayyyyy too little of a use-case. I'm going to close this for now..
 "
,,440,"Support for: stop_grace_period.
 No error / warning when using this key..
 @cdrage Opened up an issue on `libcompose`.
https://github.com/docker/libcompose/issues/447.
 upstream issue was fixed and we should be able to move on .
 @cdrage @surajnarwade asking out of curiousity, where does this map to in k8s? And in code are we handing this info to something?.
 @surajssd I think stop_grace_period can be mapped to Pod.Spec.TerminationGracePeriodSeconds.
This issue hasn't been solved yet. Still no warning/error when using this key..
 @surajssd , can you please reopen the issue  ?
I agree with @gitlawr .
 closed by #608.
 "
,,439,"Error / Support for: links.
 No error / warning when using this key..
 `links` can be silently ignored.
Links are just injecting env variables with information about ips and ports. Kubernetes is injecting same env variables to pods by default..
 :+1: .
 "
,,438,"Support for: isolation.
 No error / warning when using this key..
 @cdrage `isolation` has only one value for Linux which is `default` and for windows it has a some value to pick from like `process`, `hyperv` and `default`. The doc says this option is useful in situations where you are running Docker containers on Windows.
Do we need to add support for this? [Reference](https://docs.docker.com/engine/reference/commandline/run/#specify-isolation-technology-for-container---isolation).
 It doesn't make sense to map this to Kubernetes. We can display warning if it is set to something else than default.
But I wouldn't worry about that for now. I don't think that this is used..
 Can we close this issue?.
 one note here. `isolation` is in compose version 2.1 and up. 
2.1 is not yet supported by libcompose..
 @kadel , @cdrage  label, `compose v2.1` and `libcompose` needed.
 Closing this as we are not supporting it :+1: .
 "
,,437,"Support for: group_add.
 No error / warning when using this key..
 @cdrage `group_add` is supported by `libcompose` but I'm having some trouble using it, opened up an issue on `libcompose`.
https://github.com/docker/libcompose/issues/446.
 upstream issue was fixed so I think we can take it a step further.
 @cdrage @procrypt i think, `group_add` mapping doesn't make any sense in kompose, so it will be better to add it in unsupported keys, sending PR for the same :).
 @surajnarwade @surajssd @gitlawr 

After some investigation, you are actually able to map this to securityContext: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/.
 @cdrage , for docker-compose file like,

```
version: '2'
services:
  myservice:
    image: alpine
    group_add:
      - ""1004""
```

it will be,

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: myservice
  name: myservice
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.service: myservice
    spec:
      containers:
      - image: alpine
        name: myservice
        resources: {}
      restartPolicy: Always
      securityContext:
        supplementalGroups:
        - 1004
status: {}
```

For, docker-compose we can mention group in string format but for kubernetes we need only group  id.
 @cdrage is that okay ?.
 @surajnarwade Yup. That works perfectly..
 @cdrage , awesome, sending PR for the same.
 This has been merged in! #739 .
 "
,,436,"Support for: tmpfs.
 No error / warning when using this key..
 There is actually equivalent in Kubernetes.
Its EmptyDir volume that has  `medium: ""memory""`

https://kubernetes.io/docs/user-guide/volumes/#emptydir.
 My proposal is to convert `tmpfs` to empty dir volume.

for docker-compose.yml like this:
```yaml
version: ""2""

services:
    foo:
        image: busybox
        command: [""sh"",""-c"", ""mount | grep /foo; sleep 3200""]
        tmpfs: 
           - /foo
```

kompose should generate objects that have PodSpec like this:
```yaml
      metadata:
        labels:
          service: foo
      spec:
        containers:
        - args:
          - sh
          - -c
          - mount | grep /foo; sleep 3200
          image: busybox
          name: foo
          volumeMounts:
          - mountPath: /foo
            name: foo-claim0
        restartPolicy: Always
        volumes:
        - name: foo-claim0
          emptyDir:
              - medium: ""Memory""
```

`volumeMounts` and `volumes` are important parts.




.
 @kadel That looks great. I think that'd be the best way to convert 'tmpfs"" to Kubernetes. Even if it's not used very much in docker-compose I think it's an *awesome* way to convert to a kubernetes-equivilant. .
 I would like to work on it :).
 "
,,435,"Add documentation for mem_limit.
 Add documentation for https://github.com/kubernetes-incubator/kompose/pull/414.
 Bumped into this issue while I was discussing other issues, I think we can close this issue. What do you think @kadel ?.
 @pradeepto Still pending for this being merged https://github.com/kubernetes-incubator/kompose/pull/448 as it's part of the documentation :).
 #448 was merged. That should be enough to document it for now..
 "
,,434,"Abstract out api.pod spec.
 Fixes: #348 
cc: @containscafeine @kadel @cdrage @surajssd .
 PodSpec is also used in OpenShift transformer. It would be great to use podspec function also there..
 @kadel We can't use `PodSpec` function in OpenShift because `PodSpec` in OpenShift is different.
PodSpec in `Kubernetes`
```go
	pod := api.PodSpec{
		Containers: []api.Container{
			{
				Name:  name,
				Image: service.Image,
			},
		},
	}
```

PodSpec in `OpenShift`
```go
	pod := api.PodSpec{
		Containers: []api.Container{
			{
				Name:  name,
				Image: "" "",
			},
		},
	}
```
.
 I think that if we are abstracting podSpec in one place it would be also great to have everywhere else.
 
If you change your `initPodSpec` function it can be used also in OpenShift. 
You don't have to pass whole `service kobject.ServiceConfig` struct down to `initPodSpec`.
All you need is `name` and `image`. It could look like this:

```go
func (k *Kubernetes) InitPodSpec(name string, image string) api.PodSpec {
... 
```
.
 LGTM.
 "
,,433,"Normalizing service name might break application.
 cc @surajssd @containscafeine .
 Good catch.

But I'm afraid that only thing that we can do here is show warning and make it clear what we are doing with service names in documentation



.
 oops saw this after commenting on https://github.com/kubernetes-incubator/kompose/issues/420#issuecomment-285030347.
 we can close this issue now.
 "
,,432,"move functional tests to golang.
 Hi,

Currently, currently all the functional tests being run by `make test-cmd` are written in shell scripts, which are very difficult to maintain, debug and produce _a lot_ of false positives e.g. #431, etc.

Should we move these to golang for better testing?

(thinking out loud: how about python which has a rich set of testing libraries e.g. `py.test`)?

Thoughts?.
 :+1:  for writing them in go.


> (thinking out loud: how about python which has a rich set of testing libraries e.g. py.test)?

I think it is better to avoid adding new language with additional dependencies, even if it is just for testing.

.
 @containscafeine @kadel I'm taking this up..
 I am :+1: for Python but it's just that people should know one more language for doing any contribution.

But if you know Python it will be very easier..
 Please no Python, no other language. 
I would rather stick with bash rather than introducing another language..
 Ack, let's move all of 'em to golang :metal: .
 maybe we can look at this framework https://github.com/DATA-DOG/godog it is for doing golang functional testing..
 @surajssd Do we really need to use a Framework for it, I mean we are just comparing the output. .
 @procrypt not really if we can achieve what we do now without any framework then it's good..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,431,"test showing PASS, even if command not found.
 I tried to run,
```
$ make test-cmd
```
but I found this output,
```
===> Starting test <===
convert::expect_success: Running: 'kompose -f /home/snarwade/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/restart-options/docker-compose-restart-no.yml --provider openshift convert --stdout -j' expected_output: '/home/snarwade/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/restart-options/output-os-restart-no.json'
PASS: converted output matches
./script/test/cmd/tests.sh: line 117: convert::failure: command not found

===> Starting test <===
convert::check_artifacts_generated: Running: 'kompose -f /home/snarwade/go/src/github.com/kubernetes-incubator/kompose/examples/docker-compose.yml convert -o /tmp/kompose/output_file -j'
PASS: /tmp/kompose/output_file exists
./script/test/cmd/tests.sh: line 181: convert::expect_success_warning: command not found
```
Test are passing even if it shows command not found.
.
 found one more similar

```bash
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose -f /home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/ngnix-node-redis/docker-compose.yml convert --stdout -j' expected_output: '/home/hummer/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/ngnix-node-redis/output-k8s.json' expected_warning: 'Kubernetes provider doesn't support build key - ignoring'
PASS: converted output matches
PASS: warning found: 'Kubernetes provider doesn't support build key - ignoring'./script/test/cmd/tests.sh: line 48: convert::expect_success_warning: command not found
```.
 "
,,430,"Deprecating v1 and only supporting v2 and v3.
 v1 will eventually be deprecated by docker-compose. As well as the fact that v1 honestly doesn't convert that well when going from Docker to Kubernetes (especially with the networking + volumes section of v2 providing a lot of ease for it).

Should we deprecate v1 and focus our efforts on only v2 and v3?.
 This made me thinking, so I tried to get some statistics how are different versions used.

docker-compose.yml files in github, only ~29% v2 files  and rest v1


How I got there:
I've used Google BigQuery with github public data set: https://cloud.google.com/bigquery/public-data/github

To make it easy I assume that there is no v3 (or at least right now it is so small number that it doesn't matter).
Another assumption is that v2 files are all the docker-compose.yml files that contains ""version:"" string. This gets a few false positives but I shouldn't be statistically significant.


I've used sample tables, they are smaller, but statistically it shouldn't matter.

all docker-compose.yml files: 197
files with ""version:"": 57 ~= 29%

queries I've used:
```sql
SELECT
  COUNT(*)
FROM
  [bigquery-public-data:github_repos.sample_contents]
WHERE
  sample_path LIKE ""%docker-compose.y%""
```

```sql
SELECT
  COUNT(*)
FROM
  [bigquery-public-data:github_repos.sample_contents]
WHERE
  sample_path LIKE ""%docker-compose.y%""
  AND content CONTAINS ""version:""
```

And now when I've done all this I'm not sure if it says anything :rofl: 
Reason behind big number of old v1 files might be that they are just old and nobody is using them :-D
It might be better to get only files that were modified in last year or so, but that will be tricky to do :-(

I'll keep it here, because someone might find it interesting. 

**+1 for deprecating v1 in kompose.**








.
 nice data query. I think it is very informative.
we could try to run a poll on Twitter (not that it would be super viable but it would give some data points).

I think we need to have v3 supported (in a branch), before removing v1.

We can have a policy to support the current version of compose and the one before.


.
 Agreed we shouldn't drop v1 before supporting v3.
 I agree with @kadel 

Let's stick with v2 / v3 for now  and still support v1 (it's not that hard to maintain).
 "
,,429,"normalize docker-compose service that has name with underscore.
 kubernetes or openshift does not allow underscores in the object
names, while docker-compose does, in this commit the code has been
added to convert underscores to hypens.

Fixes #420.
 "
,,428,"removed unnecessary objects in compose.go.
 In `compoese.go` while iterating on the `ServiceConfig` objects first it's keys were pulled and then data was pulled separately which can be done in one step by iterating on the dictionary..
 ping @kadel .
 "
,,427,"`make test-unit` does not run on uncomitted changes.
 ```bash
$ make test-unit
go test -ldflags=""-w -X github.com/kubernetes-incubator/kompose/version.GITCOMMIT=1712634"" -race -cover -v ./pkg/... ./cmd/... .
```

How do I run tests of kompose like it was before? I never had need to commit changes to test them?.
 I don't have to commit anything. Nothing changed there. `make test-unit` runs test on current state of the directory, doesn't matter if changes are commit or not, it doesn't even have to be git repo..
 yeah seems like I mis-understood something, sorry for the spam, closing this..
 "
,,426,".env file is checked at current directory instead of target directory.
 examples/docker-compose file -
```yaml
$ cat examples/docker-compose.yml 
version: ""2""
services:
  web:
    image: $imagename
```

examples/.env file -
```shell
$ cat examples/.env 
imagename=batman
```

When I run,
`kompose  convert -f examples/docker-compose.yml`, the environment variable does not get substituted and I get
```shell
WARN The imagename variable is not set. Substituting a blank string. 
```

However, when I do,
```shell
cd examples/
kompose convert -f docker-compose.yml
```
the value is substituted.

So, kompose is looking for the .env file in the current directory instead of the target directory where the docker-compose file is present..
 @containscafeine thanks for the issue, have you checked if this is coming from libcompose? If yes maybe needs to be filed in upstream..
 @surajssd @containscafeine , issue is coming from libcompose and I filed it in upstream, it can be tracked here https://github.com/docker/libcompose/issues/443.
 It is actually OK.
According docker-compose to documentation `.env` files should be placed in current directory.
""Compose supports declaring default environment variables in an environment file named .env placed in the folder where the docker-compose command is executed (current working directory)."" - https://docs.docker.com/compose/env-file/.
 @kadel @surajnarwade ack, but does it make sense for this to be a feature in kompose? Or maybe add a command line flag to specify the .env file?.
 Its docker-compose feature, so it makes sense to have it in Kompose .
 "
,,425,"Update vendoring.
 Updates vendoring to include
https://github.com/docker/libcompose/commit/1c4bd4542afb20db0b51afd71d9ebceaf206e2dd
as well as general update to all other packages..
 I noticed that you are updating libcompose to unreleased version, is there a reason for this? Is it going to fix    something that is currently broken with parsing?.
 @kadel this for fixing https://github.com/kubernetes-incubator/kompose/issues/410.
 @kadel Yeah, forgot to mention it's for #410 .
 "
,,424,"Add build_args support in buildconfig.
 now args provided under build in docker-compose file can be available in buildconfig.
it solves #406.
 Thanks for your pull request. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please follow instructions at <https://github.com/kubernetes/kubernetes/wiki/CLA-FAQ> to sign the CLA.**

Once you've signed, please reply here (e.g. ""I signed it!"") and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please sign in with your organization's credentials at <https://identity.linuxfoundation.org/projects/cncf> to be authorized.

<!-- need_sender_cla -->

<details>

Instructions for interacting with me using PR comments are available [here](https://github.com/kubernetes/community/blob/master/contributors/devel/pull-request-commands.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository. I understand the commands that are listed [here](https://github.com/kubernetes/test-infra/blob/master/prow/commands.md).
</details>
	.
 @surajnarwade  Please run `gofmt` on `pkg/transformer/openshift/openshift.go`  tests are failing..
 cc: @cdrage @kadel @containscafeine @surajssd .
 @surajnarwade works for me, good stuff :)

Let's add some unit and functional tests now.

For the functional ones, you can refer to the other tests in https://github.com/kubernetes-incubator/kompose/blob/master/script/test/cmd/tests.sh, should be straighforward.

For the unit tests, this can be covered under `func TestInitBuildConfig(t *testing.T)` in `openshift_test.go`.

Going through the other tests for the first time might take some time, so take some time :).
 I've tested this and it looks good.

Just one small note here, this doesn't solve entire #406 just one part of it.  But that is OK, just don't close #406 yet ;-)


@surajnarwade Can you please add tests to this PR? Mainly Go tests.  Otherwise code looks good.


.
 @containscafeine @kadel thanks, I am adding tests .
 cc @cdrage @kadel .
 Odd error happening:

```sh
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose --provider openshift -f /home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/buildargs/docker-compose.yml convert --stdout -j' expected_output: '/home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/buildargs/openshift-buildargs.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::master as source.'
FAIL: converted output does not match
```

Any idea? 
.
 > Odd error happening:
> 
```
 ===> Starting test <===
 convert::expect_success_and_warning: Running: 'kompose --provider openshift -f /home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/buildargs/docker-compose.yml convert --stdout -j' expected_output: '/home/travis/gopath/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/buildargs/openshift-buildargs.json' expected_warning: 'Buildconfig using https://github.com/kubernetes-incubator/kompose.git::master as source.'
 FAIL: converted output does not match
```
> Any idea?

I did some digging, and found out that it is caused by this: https://github.com/kubernetes-incubator/kompose/issues/445
.
 blocked - waiting for  https://github.com/kubernetes-incubator/kompose/pull/454.
 specifically, blocked on this libcompose issue: https://github.com/docker/libcompose/issues/449 which unblocks #454 which then unblocks this PR of #424 .
 All blocking issues/PRs are resolved/merged, ping @surajnarwade .
 @surajssd yeah, needs review
cc @kadel @cdrage .
 @surajnarwade 

Awesome work! One problem:

Specifying value from the environment doesn't work:
```
github.com/kubernetes-incubator/kompose  pr_424 ✗                                                                                                                                                                                                                         79d ⚑  
▶ export foo=test                                                                                     

github.com/kubernetes-incubator/kompose  pr_424 ✗                                                                                                                                                                                                                        79d ⚑  ⍉
▶ echo $foo
test

github.com/kubernetes-incubator/kompose  pr_424 ✗                                                                                                                                                                                                                         79d ⚑  
▶ cat script/test/fixtures/buildargs/docker-compose.yml 
version: ""2""

services:
    foo:
        build: 
          context: ""./build""
          args:
            - foo
        command: ""sleep 3600""

                                                                                                                                                                                                                                                                          [36/603]
github.com/kubernetes-incubator/kompose  pr_424 ✗                                                                                                                                                                                                                         79d ⚑  
▶ ./kompose convert --provider openshift --stdout -f script/test/fixtures/buildargs/docker-compose.yml
INFO Buildconfig using git@github.com:cdrage/kompose.git::pr_424 as source. 
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec:
    clusterIP: None
    ports:
    - name: headless
      port: 55555
      targetPort: 0
    selector:
      io.kompose.service: foo
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec:
    replicas: 1
    selector:
      io.kompose.service: foo
    strategy:
      resources: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          io.kompose.service: foo
      spec:
        containers:
        - args:
          - sleep
          - ""3600""
          image: ' '
          name: foo
          resources: {}
        restartPolicy: Always
    test: false
    triggers:
    - type: ConfigChange
    - imageChangeParams:
        automatic: true
        containerNames:
        - foo
        from:
          kind: ImageStreamTag
          name: foo:latest
      type: ImageChange
  status: {}
- apiVersion: v1
  kind: ImageStream
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec: {}
  status:
    dockerImageRepository: """"
- apiVersion: v1
  kind: ImageStream
  metadata:
    creationTimestamp: null
    labels:
      io.kompose.service: foo
    name: foo
  spec: {}
  status:
    dockerImageRepository: """"
- apiVersion: v1
  kind: BuildConfig
  metadata:
    creationTimestamp: null
    name: foo
  spec:
    nodeSelector: null
    output:
      to:
        kind: ImageStreamTag
        name: foo:latest
    postCommit: {}
    resources: {}
    runPolicy: Serial
    source:
      contextDir: script/test/fixtures/buildargs/build/
      git:
        ref: pr_424
        uri: git@github.com:cdrage/kompose.git
      type: Git
    strategy:
      dockerStrategy:
        env:
        - name: foo
          value: ""\0""
      type: Docker
    triggers:
    - type: ConfigChange
    - type: ImageChange
  status:
    lastVersion: 0
kind: List
metadata: {}
```
.
 @cdrage okay, looking into it.
 @cdrage , args in build should be mentioned in key: value format.
 @surajnarwade 
You're wrong, you've always been able to just supply the key to Docker Compose, here is the reference documentation that points out how it's suppose to be: https://docs.docker.com/compose/compose-file/#args.
 @cdrage my bad, Updated PR for the same.
 cc @cdrage .
 After all the changes, this LGTM :+1: .
 Cool this LGTM!.
 @surajnarwade thanks for the hard work!.
 @surajssd, finally :).
 thanks everyone!.
 "
,,423,"fix passing gitcommit in version output.
 fixes #422 .
 Yup. This was my fault from the release. LGTM..
 "
,,422,"wrong git revision number in version output.
 code revision from which binary is build is wrong.

```
▶ make
go build -ldflags=""-w -X github.com/kubernetes-incubator/kompose/version.GITCOMMIT=be042c7"" -o kompose main.go

▶ ./kompose version
0.2.0 (64433fd)

▶ git rev-parse --short HEAD
be042c7
```

`kompose version` should output same revision as current source.
 It looks like there is commitid inside [version.go](https://github.com/kubernetes-incubator/kompose/blob/master/cmd/version.go#L29)  Shouldn't this show HEAD as default or something like this?
 
What if we get rid of this? Do we need to show  commit id in version output?.
 Ahhh.. I changed it to show the Git Commit for the current version instead of HEAD... Should we just get rid of this instead?.
 @kadel you re-opened this? Why is that so?.
 I hoped that we might discuss here if maybe we wan't to get rid of whole commitid (showing commit id in `kompose version` output).
 @kadel Should we close this? Having the hash in the ID has actually helped in terms of releases as well as troubleshooting (whether or not it's been compiled locally against master, etc.).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,421,"Unable to build from source.
 I'm trying to create a [Homebrew](http://brew.sh/) formula for Kompose.

```
$ brew install -i kompose
==> Using the sandbox
==> Downloading https://github.com/kubernetes-incubator/kompose/archive/v0.2.0.tar.gz
Already downloaded: /Users/sam/Library/Caches/Homebrew/kompose-0.2.0.tar.gz
==> Entering interactive mode
Type `exit' to return and finalize the installation
Install to this prefix: /usr/local/Cellar/kompose/0.2.0
bash-3.2$ export GOPATH=`pwd`
bash-3.2$ echo $GOPATH
/private/tmp/kompose-20170210-81761-1bzgwbv/kompose-0.2.0
```

However, **I can't get the build to succeed**. I've tried all the build methods listed in [`README.md`](https://github.com/kubernetes-incubator/kompose/blob/master/README.md).

#### `make bin`
```
bash-3.2$ make bin
fatal: Not a git repository (or any of the parent directories): .git
make: glide: Command not found
go build -ldflags=""-w -X github.com/kubernetes-incubator/kompose/version.GITCOMMIT="" -o kompose main.go
main.go:19:8: cannot find package ""github.com/kubernetes-incubator/kompose/cmd"" in any of:
	/usr/local/Cellar/go/1.7.5/libexec/src/github.com/kubernetes-incubator/kompose/cmd (from $GOROOT)
	/private/tmp/kompose-20170210-81761-1bzgwbv/kompose-0.2.0/src/github.com/kubernetes-incubator/kompose/cmd (from $GOPATH)
make: *** [bin] Error 1
```

#### `go build -o kompose main.go`
```
bash-3.2$ go build -o kompose main.go
main.go:19:8: cannot find package ""github.com/kubernetes-incubator/kompose/cmd"" in any of:
	/usr/local/Cellar/go/1.7.5/libexec/src/github.com/kubernetes-incubator/kompose/cmd (from $GOROOT)
	/private/tmp/kompose-20170210-81761-1bzgwbv/kompose-0.2.0/src/github.com/kubernetes-incubator/kompose/cmd (from $GOPATH)
```

#### `CGO_ENABLED=0 GO15VENDOREXPERIMENT=1 go build -o kompose main.go`
```
bash-3.2$ CGO_ENABLED=0 GO15VENDOREXPERIMENT=1 go build -o kompose main.go
main.go:19:8: cannot find package ""github.com/kubernetes-incubator/kompose/cmd"" in any of:
	/usr/local/Cellar/go/1.7.5/libexec/src/github.com/kubernetes-incubator/kompose/cmd (from $GOROOT)
	/private/tmp/kompose-20170210-81761-1bzgwbv/kompose-0.2.0/src/github.com/kubernetes-incubator/kompose/cmd (from $GOPATH)
```

#### `make cross`
```
bash-3.2$ make cross
fatal: Not a git repository (or any of the parent directories): .git
make: glide: Command not found
gox -os=""darwin linux windows"" -arch=""386 amd64"" -output=""bundles/kompose_{{.OS}}-{{.Arch}}/kompose"" -ldflags=""-w -X github.com/kubernetes-incubator/kompose/version.GITCOMMIT=""
/bin/sh: gox: command not found
make: *** [cross] Error 127
```

Unfortunately, I am not familiar with Go. Can anyone point me in the right direction?.
 FWIW, we had a very early formulae before the move to the incubator, but it was not a source build:
https://github.com/skippbox/homebrew-tap

Why do you want to compile after doing a `brew install` ? 

`brew install` should get you the binary directly..
 @sambostock: 
It looks like your GOPATH is not right. This is reason you are getting `main.go:19:8: cannot find package ""github.com/kubernetes-incubator/kompose/cmd"" in any of:....`

`make: glide: Command not found` error should be fixed in the next version (once #418 is merged)


I was trying to do same thing yesterday :-). 

And this is what I come up with:

```ruby
class Kompose < Formula
  desc ""Tool to move from `docker-compose` to Kubernetes""
  homepage ""http://kompose.io""
  head ""https://github.com/kubernetes-incubator/kompose.git""
  url ""https://github.com/kubernetes-incubator/kompose/archive/v0.2.0.tar.gz""
  # url ""https://github.com/kubernetes-incubator/kompose.git"",
  #     :tag => ""v0.2.0"",
  #     :revision => ""bf8a03f1e9ed7206a712b99f82e26911d7243003""

  depends_on ""go"" => :build

  def install
    ENV[""GOPATH""] = buildpath
    dir = buildpath/""src/github.com/kubernetes-incubator/kompose""
    dir.install buildpath.children

    cd dir do
      system ""make""
      bin.install ""kompose""
    end
  end

  test do
    # TODO
    system ""false""  
  end
end
```



.
 @sambostock how it is going?
Were you able to build it?
.
 @kadel Someone else submitted a [formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/kompose.rb), so I didn't do any other work on it.

This issue can probably be closed. Thanks for checking in!.
 OK.
Kompose is in brew now, that is great new. Didn't noticed that someone else got it merged .
 "
,,420,"underscores get propagated into invalid names.
 searched for dupes, and found none.

docker compose file has name like: `phant_server:` in yaml, which contain embedded underscores. `kompose` does not normalize the name, resulting in invalid names being used.

#### pvc

```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  creationTimestamp: null
  name: phant_server-claim0
...
```

yields error

```
The PersistentVolume ""phant_server-persistent-volume"" is invalid: metadata.name: Invalid value: ""phant_server-persistent-volume"": must match the regex [a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)* (e.g. 'example.com')
```

#### deployment 

```
The Deployment ""phant_server"" is invalid:
* metadata.name: Invalid value: ""phant_server"": must match the regex [a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)* (e.g. 'example.com')
```

## possible normalization suggestions

phant_server -> phant.server
phant_server -> phant-server
phant_server -> phantserver
.
 @idcrook see if it works for you!.
 Thx.
 Opening this issue again as #429 fixed this problem only for service names, same problem is still in volume names..
 @kadel so @containscafeine found that there is a caveat with what #429 did.

Let say if a user defines a docker-compose file as

```bash
services:
  foo-bar:
...
  blah-blah:
...

``` 


Now if the `blah-blah` service tries to access `foo-bar` it will simply call out on `foo-bar` but here we are converting `foo-bar` to `foo_bar` so now the name resolution works in docker-compose but not in k8s because we just changed the name in config but code is using old name.

So we need to give out a WARNING saying this is done..
 so above is filed in https://github.com/kubernetes-incubator/kompose/issues/433.
 @surajssd @kadel Taking this up..
 @procrypt i think @surajnarwade is working on this.
 @surajssd @procrypt , its okay, I havn't started yet, will pick other one :)

.
 Ah, sorry @surajnarwade @procrypt I didn't know that, or even more probably forgot about it :blush: .
 Can be closed when #509 is released.
 ```
version: '2'

services:

  ca.org1.example.com:
```
docker-compose like upon, when ""kubectl create"" will ouput error 
```
The Service ""orderer.example.com"" is invalid: metadata.name: Invalid value: ""orderer.example.com"": a DNS-1035 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or 'abc-123', regex used for validation is '[a-z]([-a-z0-9]*[a-z0-9])?')

```.
 "
,,419,"publicly hosted API endpoint for kompose.
 Hey team,

We've had some discussions around it but never opened an issue, so here it is.

Does it make sense for `kompose` to have an publicly hosted API endpoint where users can just `curl` and send their Docker Compose files and it returns the converted artifacts?

I'm suggesting something like -

`curl -X POST -F file=@docker-compose.yml kompose.io/convert` and then we return Kubernetes artifacts, which can be piped directly to `kubectl create -f -`.

This will not require installing kompose, will be very useful and will be super cool to provide `kompose-as-a-service or kompaas` :)

Thoughts?.
 @containscafeine 

As an alternative, instead of an API, it would make more sense to have a demo on http://kompose.io similar to the ""Go"" playground. Build it with Go as a back-end with http server + react.js / vue.js as a front-end. Simply paste your docker-compose.yaml file in and output goes the kubernetes artifacts!.
 @cdrage makes sense, I have no idea about web stuff, but sounds cool. It can double up as an API as well..
 @containscafeine yup. that's what would be intended! :).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Yup, this one should be closed :+1: Kind friends made a GUI interface which people may use as a publicly hosting conversion: http://kompose.io/integrations/#kompose-ui-by-jad-chamoun-icann-and-joe-haddad-anghami.
 "
,,418,"Update Makefile - lazy set for PKGS variable.
 Using lazy set we can run targets that don't $PKGS without requiring glide.

Lazy set is expended when variable is used, not when declared..
 LGTM after merge conflicts are resolved :+1: .
 rebased.
 "
,,417,"Update the documentation to use LoadBalancer instead of NodePort.
 Updates the docs to use LoadBalancer instead of focuing on NodePort
since minikube automatically uses NodePort in the case of LoadBalancer
as well as many cloud providers automatically providing IP addresses.

Ping @kadel.
 "
,,416,"Improve error handling.
 In some places like for example [here](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/kubernetes.go#L491) we are printing errors using `logrus.Fatalf` deep inside code.  

It would be better if function returned error that can be processed outside of this function (higher in call stack). Code will be cleaner and it will be easier to write unit tests.

I think that we should invest some time in cleaning all error handling in Kompose codebase.

.
 Printing errors using `logrus.Fatalf`,  will need unit test to run a seperate `subprocess` to test the functionality of the code..
 @procrypt I think what @kadel is trying to say here is that instead of any function doing random `logrus.Fatalf` we just change that function to return errors and the function calling it should gracefully do `logrus.Fatalf` with all the resources giving back to the pool if there are any..
 @surajssd  Yeah I got the point, what I am trying to say is that otherwise we need to do it in [this](https://talks.golang.org/2014/testing.slide#23) way, which might be a bit convoluted..
 >@surajssd Yeah I got the point, what I am trying to say is that otherwise we need to do it in this way, which might be a bit convoluted.

@procrypt  `this` is self pointing here..
 @kadel taking this up!.
 FYI: I have done some work at #462 

Also, I will be using the github.com/pkg/errors package to wrap and push the errors up the call stack.

Just keeping everyone in the loop..
 "
,,415,"Fix a small spelling error.
 s/service/Service/g.
 "
,,414,"Adds mem_limit support for conversion.
 This commit adds mem_limit support. Taking the value from
docker-compose.yaml and converting it to it's associative value in
Kubernetes artifacts.

Closes (half) of
https://github.com/kubernetes-incubator/kompose/issues/267.
 You can check this out if you wish @containscafeine .
 Docs remaining specifying what this is gonna do exactly in kubernetes like this will be only limits and for k8s requests folks could do it by hand.

or start using docker-compose v3. Because it has a way to define what is request and what is limit. But kompose has no support for v3 yet. source https://docs.docker.com/compose/compose-file/#/deploy.
 @surajssd 

Yeah, we need docs that outline what is supported when converting from docker compose to kubernetes and *how* it's converted. 

I don't think we should use v3 just yet, let's wait until libcompose supports it. Most people are just on v1/v2 right now :).
 The doc can come in a different PR..
 IMO doc should go in same PR otherwise it's hard to track later what is documented and what is not..
 @kadel Can't comment on your other comment for some reason, but the reasoning for ` yaml.MemStringorInt` is it that libcompsose has a built-in function for converting the values already which works *beautifully*.

For example: 10Mb, 10MB, 1e+7 or 100000 are all valid entries in docker-compose for mem_limit. These values automatically convert to Kubernetes without an issue. Hence the `intOrString`..
 @kadel https://github.com/docker/libcompose/blob/master/yaml/types_yaml.go#L43 <== the awesome sauce in libcompose.
 Hey @kadel we're you able to look at this again?.
 Ahh, sorry @cdrage I somehow missed your comments :-(

:+1: OK than it makes sense.

LGTM

.
 there are conflicts  in compose.go :-( @surajssd updated it recently in https://github.com/kubernetes-incubator/kompose/pull/428.
 @kadel Yeah, I'm working on the Google doc in regards to conversion, so that'll come up soon :) 

Yup! I'll rebase and ping you again..
 Rebased, ready for another quick look-over / review! @kadel @surajssd @containscafeine .
 I've created issue so we doesn't forget to document this. https://github.com/kubernetes-incubator/kompose/issues/435.
 "
,,413,"add BuildConfig support to kompose down.
 ``` 
kompose --provider openshift up
INFO Successfully created Service: foo            
INFO Successfully created DeploymentConfig: foo   
INFO Successfully created ImageStream: foo        
INFO Successfully created BuildConfig: foo 
```
```
kompose --provider openshift down
INFO Buildconfig using https://github.com/kubernetes-incubator/kompose.git::master as source. 
INFO Successfully deleted service: foo            
INFO Successfully deleted DeploymentConfig: foo   
INFO Successfully deleted ImageStream: foo        
INFO Successfully deleted BuildConfig: foo   
```
docker-compose file used is [docker-compose.yml](https://github.com/kubernetes-incubator/kompose/tree/master/examples/buildconfig)

@kadel @cdrage @containscafeine Review please.
Fixes #382  .
 @procrypt mind adding unit tests for this?.
 > @procrypt mind adding unit tests for this?

I'm afraid that we still don't have a way how to test this. :-(
As it will require running or mocking cluster :-(


.
 @kadel I'm trying something don't know if it the right thing to do, will update the WIP later today..
 @procrypt - @kadel is correct, we will need to mock out the entire OpenShift client for this :(

I can think of a couple of ways to go about this -

- mock out just the parts we are testing?
- see in openshift/origin upstream about how are they mocking out the client, and if possible just use that?
- not unit test the deploy bits at all, and rely on functional tests to deploy on the cluster?

I don't know what is the right way forward, but yep, mocking out the entire client might take a sprint or two :)

Thoughts on this? - @surajssd @kadel @cdrage @rtnpro .
 I would recommend either mock required bits of API or see if we can use/reuse bits from openshift..
 @pradeepto @containscafeine no need to ""mock"" it, you can run an Openshift cluster within TravisCI..
 > @pradeepto @containscafeine no need to ""mock"" it, you can run an Openshift cluster within TravisCI.

@cdrage then that won't be called unit tests right? If we are planning on doing complete e2e test with kompose in golang, which involves bringing up clusters then that should be a complete new thing.
So that will also require writing all the harness code of bringing up clusters..
 @cdrage What @surajssd said. If we are bringing up oc cluster, then we are adding a dependency on the unit tests which doesn't sound right to me.  If the cluster doesn't come up anytime, then the tests will fail which is technically not a test failure but an infrastructure failure..
 @pradeepto Using versioned containers, it's unlikely to fail coming up (from my experience ""mocking"" the cluster).
 I think that we can discuss this elsewhere. 

I don't think we have block this PR  on tests.
We currently don't have any solution for testing this and this is not adding any new functionality  just fixing what was missing so I would say we can merge this. What do you think?.
 @kadel +1
.
 "
,,412,"Error to parse docker-compose v3 format.
 ## Problem
When trying to create named volumes that can be reused across multiple services (without relying on volumes_from due to ""[PersistentVolumeClaim is not bound](http://stackoverflow.com/questions/41738374/kubernestes-persistentvolumeclaim-is-not-bound)""), kompose is unable to parse docker-compose.yml version 3 format. 

See: https://docs.docker.com/compose/compose-file/#/volume-configuration-reference

## How To Recreate
1. Create file:`touch docker-compose.yml`
1. Copy/paste:

    ```    
    version: ""3""
    services:
      db:
        image: db
        volumes:
          - data-volume:/var/lib/db
      backup:
        image: backup-service
        volumes:
          - data-volume:/var/lib/backup/data

      volumes:
        data-volume:
    ```
1. Run: `kompose up -f docker-compose.yml`

## Actual Result
```
ERRO Could not parse config for project test : yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService
FATA Failed to load compose file: yaml: unmarshal errors:
  line 1: cannot unmarshal !!str `3` into config.RawService
```
## Expected Result
docker-compose.yml should successfully be converted and deployed..
 @pivulic `Kompose` does not support docker-compose version 3 yet..
 when will it be available? (roundabout).
 @surajssd Hey man, do you know if this will be updated upstream in libcompose?.
 Ahhhh, just found the issue: https://github.com/docker/libcompose/issues/421

We'll have to wait for this to be updated upstream @michaelharrer @pivulic .
 yeah v3 is still WIP in upstream and I guess once that is done we can move to it..
 @michaelharrer @pivulic 

The best way to ""workaround"" this is simply removing the ""deploy"" section of your V3 file and changing the `v3` value to `v2` and it'll work fine. Luckily there aren't any *too* major changes between the versions :).
 What ""deploy"" section? :) The reason why I'm trying the `v2` version, is to be able to use [named volumes](https://docs.docker.com/compose/compose-file/#/volume-configuration-reference), instead of using [volumes_from](https://docs.docker.com/compose/compose-file/#/volumesfrom), trying to get around the ""[PersistentVolumeClaim is not bound](http://stackoverflow.com/questions/41738374/kubernestes-persistentvolumeclaim-is-not-bound)"") issue.
But I'm going to try and create the Persistent Volume in my cluster before running `kompose up` (using a `v2` docker-compose.yml), as you recommend in https://github.com/kubernetes-incubator/kompose/issues/411#issuecomment-277693584 :).
 @pivulic Ahhhhh. I got my facts wrong. I thought the only large difference was the `deploy` section of v3. They added named volumes too! We'll see what we can do to fix it. Funny enough, another issue was just opened in regards to using underscores and such in volume names (bug), we could possibly fix two issues with one PR :).
 I'm labeling this as a bug with libcompose as this will need to be supported upstream as well as downstream within Kompose..
 @surajssd @kadel , can you please add `compose v3` label here ?.
 @surajnarwade done.
 @pivulic #600 has now been merged! :tada: :tada: :tada: .
 Wohoo!.
 "
,,411,"Wrong version (0.1.2) in ""kompose versione"" (instead of 0.2.0).
 ## Problem
I'm having the same issue as http://stackoverflow.com/questions/41738374/kubernestes-persistentvolumeclaim-is-not-bound, but thought I should upgrade from 0.1.2 to 0.2.0. 

However, running `kompose version` displays **0.1.2 (HEAD)** instead of **0.2.0**

## How To Recreate
Following the Mac OS steps:
```curl -L https://github.com/kubernetes-incubator/kompose/releases/download/v0.2.0/kompose-darwin-amd64 -o kompose
chmod +x kompose
sudo mv ./kompose /usr/local/bin/kompose
kompose version
```

Same result if I run:
```
cd /usr/local/bin/
./kompose version
```
## Actual Result
`0.1.2 (HEAD)`

## Expected Result
`0.2.0`.
 Regarding your issue, you should have created persistent volume before claiming, for reference: https://kubernetes.io/docs/user-guide/persistent-volumes/ 

this works for me:
$ kompose version
0.2.0 (64433fd)
.
 @surajnarwade @pivulic 

Looks like I created the binaries incorrectly (did not sync with master before release, boo on me!).

I'll update them so it *actually* shows 0.2.0 as the expected result on `kompose version`.

In regards to volumes, @surajnarwade is correct that you need to create a Persistent Volume before using PersistentVolumeClaim..
 @pivulic Release has been updated to include the proper `kompose version` output.

Mind checking it again? :).
 Going to close this for now as I was able to confirm that the version works with the new binary!.
 Thanks @cdrage! (and sorry for the late reply) Works perfectly! 👍 

Regarding creating a Persistent Volume, I looked through the [guide](https://kubernetes.io/docs/user-guide/persistent-volumes/), but isn't `kompose up` supposed to take care of it, if my `docker-compose.yml` file already has the volumes configured? 

Let me know if I should create a separate issue for this, or if you can refer me somewhere else :).
 @pivulic thanks for the issue and about kompose generating PVs by default:

it might feel like kompose should take care of this but the problem here is that `PV` can only be created by user with `system:admin` privileges, and there are multiple ways to create PV with various backends, now kompose might not know beforehand what is the type of cluster(minikube where hostPath can be used, multi-node cluster with admin access, cluster with only nfs, openshift online, etc.) a user is gonna deploy application on. So a generated PV might not always work, with different clusters. 

Kompose tries to generate configs which are cluster neutral, I mean they will work on any cluster. But generating configs which need cluster info can be little hard to do.

But in case anyone has better way of doing that it would be awesome, I cannot think of any as of now..
 Yeah, we're going to improve how we convert volumes in terms of logging as well as documentation, it's the biggest thorn when converting at the moment as they don't exactly translate 1-1 with Kubernetes..
 "
,,410,"Cannot unmarshal float environment values..
 When passing in a float value through `env:` seems to fail:

Ex:
```
  environment:
    TEST: 4
    BAR: 0.3
    FOO: 0.3
```

```
ERRO Could not parse config for project foobar : Cannot unmarshal '0.3' of type float64 into a string value 
FATA Failed to load compose file: Cannot unmarshal '0.3' of type float64 into a string value 
```.
 @cdrage , I was working on this issue, I found that, this error occurs due to libcompose, so I raised an issue https://github.com/docker/libcompose/issues/435 
(if you passed float value in quotes, it works).
 Is this working with docker-compose ?.
 @surajssd , yeah, it works with docker-compose but not with libcompose.
 @surajnarwade As a work-around, should we update in our code to convert it to a string before being passed in?.
 @cdrage , sounds good actually, I would like to work on it then.
 @cdrage , I tried to work on this, this error occurs due to libcompose, hence as a work around, we can tell user that if you want to put float value, put it in quotes..
 @surajnarwade That wouldn't be a great work-around, our code should automatically detect that the environment variables are *not* in quotes and put them in converts / convert to string before passing to libcompose.

I did however take a quick look through the libcompose code and it doesn't seem too daunting to fix it upstream..
 @cdrage, I tested kompose with your PR on libcompose, https://github.com/docker/libcompose/pull/437
its working..
 Closing. Fixed in #425 .
 "
,,409,"Update the example to include NodePort and accessability.
 This updates the example we have on the website to include NodePort in
the ""labels"" section as well as instructions on how to access the
service..
 ping @ngtuna @sebgoa @kadel .
 Going to merge for now since the index page is the main page people are hitting and this is a common problem (how do I access the example?).

Let me know if there are any outstanding issues / problems!.
 Hmm, I'm not sure if we should encourage people to use nodePort. Using LoadBalancer would be much better..
 @kadel Only problem is that LoadBalancer is not supported in Minikube and those who want to try it would have to use a cloud provider with that supported :-1: 

What if I leave a note though on what the label is (reference to the document we have) as well as outlining that if you're on GCE / AWS / etc use LoadBalancer instead?.
 @cdrage actually even if you convert the service as `LoadBalancer` it is still exposed as `NodePort`, so it's upto the user to provision a `LoadBalancer` and the values of it's IP address to be populated, but even if it's values are not populated the service should do just fine..
 If you are using  minikube and you have LoadBalancer service you can access it using `minikube service <service name>` 

This is basically same think that @surajssd is talking about it is taking advantage of NodePort, but user doesn't have to know about it.

I don't like using NodeBalancer for accessing services directly from ""outside"", it won't work on most production clusters..
 @kadel 

Okay. So basically, switch to LoadBalancer in the example and in the tutorial tell them to simply check `kubectl get svc` for IP?.
 Yes.
I think that  switching to LoadBalancer would be better.
Than  for minikube keeping `minikube service frontend` and for other cases `kubectl get svc ....`.
 @kadel Okay, #409 opened..
 btw. one useful, but ugly command 😉 :

`kubectl get svc frontend -o template --template ""{{(index .status.loadBalancer.ingress 0).ip}}:{{(index .spec.ports 0).port}}""`

this is will display public ip and port for frontend service. Tested on GKE
.
 "
,,408,"Add kompose to .gitignore, remove binary.
 "
,,407,"Update the setup page for Linux/MacOS/Windows on Kompose.io.
 "
,,406,"environment variables not being set in buildConfig.
 relevant dockerfile snippet: https://github.com/arcolife/sarjitsu/blob/master/lib/datasource/Dockerfile#L26

https://github.com/arcolife/sarjitsu/blob/master/docker-compose.yml#L21
This is the environment variable, whose value I expect to be picked from the env file (based off of docker-composed env file) https://github.com/arcolife/sarjitsu/blob/master/.env file and set in the generated buildconfig file (per se: datasource-buildconfig.yaml), as illustrated below:

```yaml
...
  source:
    contextDir: lib/datasource
    git:
      ref: komposed
      uri: https://github.com/arcolife/sarjitsu.git
    type: Git
  strategy:
    dockerStrategy:
      env:
        - name: ES_PORT
          value: ""9200""
    type: Docker
...
```

Currently no env variables are being set in the build config..
 So right now I don't think we support automatic looking / importing of `.env` files. But it is something that we *should* support!

Thanks for pointing this out..
 @cdrage , kompose does support automatic looking/ importing of .env files, but it's supporting only for deploymentconfig but not for buildconfig..
 @surajnarwade Wanna open an issue detailing as to what works vs. doesn't and close this one? Outlining exactly what issues occur..
 @cdrage yeah and I would like to work on this issue..
 "
,,405,"Unit tests for error out if controller object is specified with restart: on-failure.
 Fixes #404 
This is a WIP PR, need review to proceed further.
cc: @kadel @cdrage .
 Just one thing, as this is quite unusual way to do test, can you please add some comments explaining why we are doing it like this? Otherwise LGTM.
 @kadel Sure thing :).
 @procrypt @kadel Would it be better to fix #416 before we merge this in? Reason being is that all the awesome code that @procrypt contributed would be deleted after the fix was added :(.
 > @procrypt @kadel Would it be better to fix #416 before we merge this in? Reason being is that all the awesome code that @procrypt contributed would be deleted after the fix was added :(

It depends how log is #416 going to take :-).
 @kadel I have added some comments to explain why we are doing it like this.
@cdrage I guess it will take some time to fix #416 and by that time we can use this code..
 @procrypt Yeah :( Saves you having to rip out the code later when #416 is fixed (in particular, the part you're blocked on).
 I think that we can merged it, what do you say @cdrage. 
It might take some time until #416 is merged. .
 @kadel Good from me. LGTM..
 "
,,404,"unit tests for error out if controller object is specified with restart: on-failure..
 Add units tests for #354 
.
 "
,,403,"Adds favicons to the website.
 Going to merge this in! If there are any areas / comments for improvement, feel free to comment!.
 "
,,402,"Update website with user guide + updated setup.
 Copies over the user guide document from the `/docs` directory to display on the website.
 Going to merge this in! If there are any areas / comments for improvement, feel free to comment!.
 "
,,401,"Update vendoring + add Docker client packages.
 "
,,400,"Tagging for 0.2.1 release.
 Hey all,

I've closed the milestones for the 0.2.1 and 0.3.0 release since both were completed to 100%. Makes sense to go straight to a 0.2.0 release rather than arbitrarily skipping a major release number.

Should we tag all new bugs as part of the 0.2.1 release and all major changes as part of the 0.3.0 release?  .
 ping @kubernetes-incubator/maintainers-kompose .
 I don't know if I understand :-(

Does is make sense to plan like this if we are doing time based releases?.
 I'm not *too* sure. But yeah, you are correct though. Since we are doing time-based releases, tagging wouldn't be necessary / as well as milestones.

How should we keep our progress instead / future features?.
 I was thinking that maybe just priorities might be enough. But I'm not sure about that, just an idea..
 Closing this for now as we've just had a successful 0.3.0 release as well as we're going forward with time-based releases :).
 "
,,399,"Update the README.md with new installation instructions.
 Updates the README corresponding with binaries now in within our release
page..
 "
,,398,"Add quickstart guide to docs.
 This doc is a direct copy from the one used on Kompose.io

Eventually, we will sync the documents in the /docs/ directory of this
repo to the gh-pages branch (as well as the Kubernetes page)..
 Would it make sense to add information on how to access deployed application?.
 @kadel do you mean `kubectl` or `oc` commands?.
 @surajssd I think he means curl'ing the application or checking http://localhost:80 for it..
 > @surajssd I think he means curl'ing the application or checking http://localhost:80 for it.

That would be one of the options.
It would be nice to tell user how/where the application can be accessed.
.
 @kadel I've updated it in https://github.com/kubernetes-incubator/kompose/pull/409 so once that is merged, i'll update this PR..
 Closing for now.
 "
,,397,"Updates the cross compiling commands.
 Removed 32-Bit support, and pushes to the ""bin"" folder instead of
""bundles"".
 "
,,396,"Update the release script.
 This updates the release script to add the changelog gem as well as
clean up some of the scripts.

This also updates the binaries being uploaded and the messages being
passed onto the tag description on GitHub..
 "
,,395,"0.2.0 Release.
 Merging in order to do the release! :).
 "
,,394,"Removes the TCP output on the Kubernetes / OpenShift artifacts.
 If TCP is passed in as the protocol, by default, we add TCP as the
protocol within the Kubernetes or OpenShift artifacts.

By default, TCP is already selected within Kubernetes and thus having
the TCP output is redundant.

This commit checks to see if TCP has already been selected, and if it
has, ignores adding it to the list of ports.

Closes https://github.com/kubernetes-incubator/kompose/issues/392.
 Tests are gunna fail.

Ignore tests for now (I'll need to fix them as they test if TCP is included in the conversion). Will work on this..
 Tests pass now! :+1: Had to go through _each and every JSON file_ to update it to not include TCP...

Ready for review!.
 Ping @surajssd @containscafeine @procrypt @kadel @rtnpro for review!.
 "
,,393,"Add support for host:port:port.
 This adds support for supplying for example:
""127.0.0.1:80:80/tcp"" to docker-compose.yaml and converting it to it's
corresponding Kubernetes / OpenShift hostIP.

This commit also refactors the loadPorts function of compose.go.
 1 test doesn't pass, going to fix that :).
 There was a typo with a test parameter, all good now :+1: 

Ready for review! @surajssd @procrypt @kadel @ngtuna .
 Ping @surajssd @containscafeine @procrypt @kadel @rtnpro for review!.
 Can this be covered by unit tests?

otherwise LGTM.
 @cdrage LGTM .
 @kadel @cdrage Can I write the unit tests for this..
 @procrypt Sure why not! :).
 Rebased ^^.
 @cdrage fix in tests and docs with all the supported ports type will help! code LGTM :+1: .
 @surajssd @kadel Tests *should* pass this time (was related to my TCP PR being merged)

Regards for docs, like my other PR, I'm going to push a 1-1 document regarding what we convert between docker-compose => kubernetes/openshift all-in-one-go. Rather than including a tiny doc in here :).
 All green :tada: .
 I meant if you can add go unit tests, instead of shell test to this pr 👼 

I think is  is better to cover as much as we can using proper go tests.
 @kadel Np, I'll update that :).
 @kadel Your wish is granted! Unit tests added..
 Sweet 👍 thank you.

""Coverage increased (+2.3%) to 51.987%"" 🎉 🥇 
.
 "
,,392,"By default, remove protocol: TCP in conversion to artifacts.
 By default, TCP is selected.

https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_serviceport

We should not include `protocol: tcp` in the resulting yaml / json conversion since it's already set by default..
 "
,,391,"Container Port and Node Port mapping default to open.
 When mapping a port, for example:
```
- ""80:80""
```

in the Docker Compose file. It's the same as simply doing

```
- ""80""
```

Is this normal? Exposing the ports by default when converting them to a service?.
 I think so this is normal, because if you don't create a service name resolution wont happen from other pods. And it's safe because services are by default exposed as `clusterIP` which is not accessible from outside cluster..
 Yeah, kind of realized that this issue was me just being a Kubernetes noob :) Closing! Thanks @surajssd .
 "
,,390,"Docker DAB support does not currently work (still in experimental).
 Converting the current example we have produces this error:
```
▶ ./kompose convert -f examples/docker-compose-bundle.dab
ERRO Could not parse config for project examples : yaml: unmarshal errors:
  line 24: cannot unmarshal !!str `0.1` into config.RawService 
FATA Failed to load compose file: yaml: unmarshal errors:
  line 24: cannot unmarshal !!str `0.1` into config.RawService 
```.
 @ngtuna Any idea why this may be happening? I'm assuming problems with floating values not being converted..
 I am proposing a GSoC project to improve the dab support:
https://github.com/cncf/soc
.
 @sebgoa Should we deprecate this feature since it's still experimental within Docker and at the moment doesn't work with Kompose?.
 if it does not work, it is a regression that we should fix.

.
 Is DAB actually used somewhere? Do we know if someone is using dab even with docker?.
 Honestly I have not kept up with the dab development. but I will check..
 Please, I am interested in working on this project for the Google Summer of Code. I am very comfortable working with programming languages like Java, C/C++, Python and Go. I am very passionate about cloud and container technologies, and I would like to get some help that would enable me better familiarizing myself with the project. I am already familiar with Docker and Docker compose and I am currently familiarizing myself with Kubernetes..
 I believe this link: https://github.com/docker/docker/issues/26876 would be the best in terms of keeping track *IF* DAB comes out of being experimental.

It *has* happened in the past that an experimental feature wasn't accepted into Docker. So it'd be best to keep track of this while we continue to support development / improvements..
 I'm closing this for now until Docker figures out DAB's role..
 "
,,389,"Update documentation removing [0000] timestamp outputs.
 Updates the README as well as user_guide.md to remove the timestamp
outputs (as well as the random : that was added to the README.md).
 "
,,388,"error: Could not unmarshal '<nil>' to type <nil>.
 Platform:
  os: OS X Yosemite - 10.10.5 (14F2109)
  kompose: version 0.1.2 (92ea047)
compose-file:
```
version: '2'
services:
  <project>:
    build:
      context: .
      args:
        GIT_TOKEN:
    image: <private-img>
    links:
      - db_live
    depends_on:
      - db_live
    ports:
      - 28090:80
    environment:
      DB_HOST: db_live
  db_live:
    image: mysql:5.6
    ports:
      - 23306:3306
    environment:
      MYSQL_ROOT_PASSWORD: <passwd>
      MYSQL_DATABASE: <project>
      MYSQL_USER: <project>
      MYSQL_PASSWORD: <passwd>
```
Angular brackets are indicative of replacement text.

Command:
 - `kompose -f docker-compose.yml convert`

Error Output:
 - `ERRO[0000] Could not parse config for project <project> : Cannot unmarshal '<nil>' to type <nil> into a string value`.
 @kadel Could it be because GIT_TOKEN is passed as `GIT_TOKEN:` ?.
 @kadel @Hashfyre 

Yup.. Seems that a blank `GIT_TOKEN:` is the cause of the issue, removing it I don't have an error:

```
    MYSQL_USER: foo                                                                                                                                                                                                                                                         [0/49]
  image: mysql:5.6
  ports:
  - 23306:3306
foo:
  build:
    args:
      GIT_TOKEN: null
    context: .
  depends_on:
  - db_live
  environment:
    DB_HOST: db_live
  image: foo
  links:
  - db_live
  ports:
  - 28090:80
 
ERRO Could not parse config for project wikus : Cannot unmarshal '<nil>' to type <nil> into a string value 
FATA Failed to load compose file: Cannot unmarshal '<nil>' to type <nil> into a string value 

~                                                                                                                                                                                                                                                                               ⍉
▶ vim docker-compose.yml

~                                                                                                                                                                                                                                                                                
▶ kompose convert       
WARN Unsupported depends_on key - ignoring        
WARN Kubernetes provider doesn't support build key - ignoring 
INFO file ""db_live-service.yaml"" created          
INFO file ""foo-service.yaml"" created              
INFO file ""db_live-deployment.yaml"" created       
INFO file ""foo-deployment.yaml"" created         
```.
 @Hashfyre 

Could you change your docker-compose file to use this instead?

```
args:
  - GIT_TOKEN
```

instead of 

```
args:
 GIT_TOKEN:
```
.
 I have yet to check this deeper, but it looks like that that error message is coming from libcompose. We should check if libcompose has the same problem parsing it..
 The same syntax works as per docker-compose. As in, the compose file works with:
`docker-compose up -d --build`
once I have  exported `GIT_TOKEN` to my shell.

Currently, the following syntax works with `kompose -f docker-compose.yml convert`:

```
      args:
        - GIT_TOKEN
```
with output,
```
WARN[0000] Unsupported key build - ignoring
WARN[0000] Unsupported key depends_on - ignoring
INFO[0000] file ""db_live-service.json"" created
INFO[0000] file ""app-service.json"" created
INFO[0000] file ""db_live-deployment.json"" created
INFO[0000] file ""app-deployment.json"" created
```
If docker-compose supports the initial syntax of
```
      args:
        GIT_TOKEN:
```

shouldn't kompose also support it?
Also, from the output's `WARN` messages, we see `build` and `depends_on` keys seem to be unsupported, which could be because `k8s` doen't support builds.

I think this solves my issue, but do look into whether you could support a syntax already supported by `docker-compose` to retain `1:1` correspondence..
 @Hashfyre thanks for the feedback, build support for k8s is WIP and @rtnpro is looking at it right now in https://github.com/kubernetes-incubator/kompose/issues/97.
 "
,,387,"Ignores :z or :Z when passed in as a volume string.
 We're going to ignore :z / :Z for labeling aka SELinux when being passed
in via Docker Compose.

Closes https://github.com/kubernetes-incubator/kompose/issues/176.
 Not too sure if this was the most-correct way of doing this @kadel but here's a try at it :).
 Note that the modes can be a comma-separated list: https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems says 
```
-v, --volume=[host-src:]container-dest[:<options>]: Bind mount a volume.
The comma-delimited `options` are [rw|ro], [z|Z],
[[r]shared|[r]slave|[r]private], and [nocopy].
```.
 "
,,386,"Update to use YAML instead of json.
 ping @surajssd thanks for noticing this :).
 "
,,385,"Container for running tests and Makefile cleanup.
 This adds Dockerfile that can be used to run all Kompose tests locally.

`make test` will run exactly the same tests as travis-ci but running locally in docker image.
This can be used to tests everything before commiting or submitting PR.
Image is automatically  build in docker hub - https://hub.docker.com/r/kompose/tests/ or it can be build locally using `make test-image`.

Automatic build at docker hub is NOT triggered automatically on push. Only time when rebuild is needed is when Dockerfile is changed.


This PR also includes Makefile and `/script/` cleanup.
I've removed all the shell scripts that were just one single command and put those commands directly to Makefile. It is much more easier to figure out what is doing what.






.
 Just a note though, I feel as though these tests run a lot slower than the original ones? I think it's because there's no cache being passed through?

The part that's *reallyyyy* taking it's time is here:
```
# First install packages that are dependencies of the test. 
go test -i -race -cover ./cmd/... ./pkg/... .
```

Another being that what if I wanted to *just* run cmd or *just* run integration?.
 > Just a note though, I feel as though these tests run a lot slower than the original ones? I think it's because there's no cache being passed through?

Yes, no cache being passed through. 
I'll look at it in separate PR.

> 
> The part that's reallyyyy taking it's time is here:
> 
> ```
> # First install packages that are dependencies of the test. 
> go test -i -race -cover ./cmd/... ./pkg/... .
> ```

This pre-compiles all the dependencies for test. So it can take some time, but it will speed up running all the `go test`.  
Calculating coverage  for whole project requires running `go test` separately for every package. If you do it without running `go test -i` first it takes really long time (20+mins) :-D.

> Another being that what if I wanted to just run cmd or just run integration?

Yes, I was thinking about it. I would like to do it in separate PR.

I have some other ideas how to speed this up. But than it will run slightly different commands and tests from what is run in travis-ci. I wanted to replicated same thing that travis is doing first, and than add options to run faster but not complete test later.


.
 I like how you keep the current tests in as well. But perhaps we can do it so that it's ""test-container"" or something?

Would be easier for using it on travis, etc and for those who choose to run the container vs traditional..
 There is `make test-all` that runs all the tests outside container and `make test` that runs it inside container. 
My idea was that ""humans"" will run tests in container so i wanted to make command shorter, hence `make test` :-) 

So you are suggesting changing it so `make test` runs everything without container and creating  `make test-container` that doesn't what `make test` is doing right now (running it it all inside container)?
.
 @kadel 
Yup. That's what I'm suggesting. `make test` runs it traditionally. `make test-container` runs it in a container..
 > @kadel
> Yup. That's what I'm suggesting. make test runs it traditionally. make test-container runs it in a container.

done ;-)

There is just one small catch with `make test` and that it expects that you have $GOPATH/bin in $PATH.
Otherwise test-cmd might fail or  run against older binary.
.
 "
,,384,"Add Kompose site.
 Phew.

After messing around with git for an hour, I finally got this to work.

This branch is tiny tim'd (--orphaned).

@kadel Whenever you're ready push that giant green button above ^^.
 @cdrage  great! :wink: 

But that giant button is bellow :arrow_down: :rofl: .
 "
,,383,"Update logging for logrus.
 This commit disables the timestamp when outputting logs in order to be
more clean / concise.

One of the reasons being that the kompose up / convert / down commands
are *too fast* and thus output's all [0000].

For example, the output will look like this:
INFO I'm a little teapot

Instead of:
INFO[0000] I'm a little teapot.
 This also updates vendoring in order to import https://github.com/sirupsen/logrus/pull/400.
 "
,,382,"kompose down with openshift doesn't delete  BuildConfig.
 I tried running `kompose down` with the buildconfig example here: https://github.com/kubernetes-incubator/kompose/tree/master/examples/buildconfig

It doesn't delete the buildconfig. 

```bash
$ kompose --provider=openshift -f docker-compose.yml down
WARN[0000] [foo] Service cannot be created because of missing port. 
INFO[0000] Buildconfig using https://github.com/skippbox/kompose2.git::master as source. 
INFO[0001] Successfully deleted DeploymentConfig: foo   
INFO[0001] Successfully deleted ImageStream: foo
```
```bash
$ oc get bc
NAME      TYPE      FROM         LATEST
foo       Docker    Git@master   1
```.
 @ashetty1 `buildconfig` support was not present when `kompose down` for openshift got merged. Thanks for reporting the issue.
@kadel @cdrage I'm working on it..
 Correct me if I am wrong, but it appears in my testing that this issue hasn't been fixed yet:

Before running `kompose down`:

`NAME          READY     STATUS      RESTARTS   AGE`
`foo-1-build   0/1       Completed   0          1m`
`foo-1-lv0q5   1/1       Running     0          29s`

Running `kompose down`:
INFO Buildconfig using https://github.com/kubernetes-incubator/kompose.git::HEAD as source. 
INFO Successfully deleted Service: foo            
INFO Successfully deleted DeploymentConfig: foo   
INFO Successfully deleted ImageStream: foo        
INFO Successfully deleted BuildConfig: foo        


Looks like the build pod doesn't get deleted: Output of `oc get pods`:

`NAME          READY     STATUS      RESTARTS   AGE`
`foo-1-build   0/1       Completed   0          2m`
.
 @ashetty1 I think this https://github.com/kubernetes-incubator/kompose/pull/483 will solve the problem!.
 meanwhile keeping this open since this problem is not completelt solved!.
 "
,,381,"Adds Kompose.io website.
 This commit adds the kompose.io website including introduction and setup
instructions..
 Some notes:

- This is pushed to the gh-pages branch (for GitHub pages)
- I have parked the domain kompose.io and will update A records / etc once this PR has been merged
- This will add a website for Kompose with a basic introduction and setup page.
- In the future, blog post(s) can be added, more information pushed. As of right now, it's a quick ""30-second"" spiel to get the person's attention.
- This is not meant to replace any documentation on here and is meant as an alternative landing page for Kompose. In the future, syncing the `/docs` directory to the site would be the most ideal
- If you want to test it out, simply run `jekyll serve .`

Here's an included preview of what it looks like:
![image](http://i.imgur.com/53z1Sq8.png).
 ping @kubernetes-incubator/maintainers-kompose.
 It looks great. Thanks @cdrage . I did test it on my machine. But I think we should display another better example: guestbook or voting app ?.
 @ngtuna I feel as though an example like that is too overly-complex to be on a simple introduction page. Having a quick ""understand in 30 seconds"" page is the best answer.

Once I add new pages, I believe we should have a more elaborate example such as the voting app or guestbook application..
 I agree with tuna there should be a better 30 seconds example. Something that does not ask people to download a random image from a guy called ""tuna"" :).
 @sebgoa @ngtuna 

Added the Guestbook example! Feel free to have a look :) Once this is merged I can modify this repo to have the kompose.io domain point here..
 It looks like step 2.1 is not correctly formatted. 

![screenshot from 2017-01-19 16-14-27](https://cloud.githubusercontent.com/assets/57206/22112218/6e56b976-de62-11e6-90b3-5406c6dcaa54.png)
.
 @kadel You're right xD http://charliedrage.com/kompose/

Fixed! Thank you..
 One more thing. :angel: 
Couldn't you use `git checkout --orphan ... ` to create new empty branch? Than you don't have to delete all the files from master. .
 "
,,380,"Fixed warnings related to user type in tests.
 Fixes #343

Type of user is not string and that's what was being provided
in tests so fixed it and now tests output is cleaner..
 LGTM.
 @cdrage thanks :).
 "
,,379,"Converting docker-compose file on mac: `panic: runtime error`.
 Hey guys, first post. If I need anymore info, just let me know. First time use, trying to follow your README but this is what I got. I used the `go get` method of installation


Details:
Mac OSX El Capitan 10.11.6

```
jono@JonosMacbookPro:~/p/portal3|⚡*?                                                                           
➤ echo $GOPATH
/Users/jono/golang
jono@JonosMacbookPro:~/p/portal3|⚡*?                                                                           
➤ echo $GOROOT
/usr/local/opt/go/libexec
jono@JonosMacbookPro:~/p/portal3|⚡*?                                                                           
# First I tried Go version 1.6.x and it had the same thing, this is run with 1.7
➤ go version
go version go1.7.4 darwin/amd64
jono@JonosMacbookPro:~/p/portal3⚡*?                                                                           
➤ kompose -f docker-compose.yml convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x18 pc=0xb454f0]

goroutine 1 [running]:
panic(0x1f0dd80, 0xc8200100d0)
        /usr/local/opt/go/libexec/src/runtime/panic.go:481 +0x3e6
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).handleVolumeConfig(0xc8200d0700)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:319 +0x430
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc8200d0700, 0x7fff5fbffa73, 0x12, 0xc820282000, 0x3a5, 0x5a5, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:235 +0x649
github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc8200d0700, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/docker/libcompose/project/project.go:112 +0x335
github.com/kubernetes-incubator/kompose/pkg/loader/compose.(*Compose).LoadFile(0x3512d68, 0xc8202732a0, 0x1, 0x1, 0x0, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:262 +0x555
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1, 0xc8202732a0, 0x1, 0x1, ...)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:195 +0x1d2
github.com/kubernetes-incubator/kompose/cmd.glob.func2(0x34e0960, 0xc8200f6460, 0x0, 0x2)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:80 +0x27
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x34e0960, 0xc8200f6300, 0x2, 0x2, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:603 +0x896
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x34e0da0, 0x34e0960, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:689 +0x55c
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x34e0da0, 0x0, 0x0)
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:648 +0x2d
github.com/kubernetes-incubator/kompose/cmd.Execute()
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/cmd/root.go:86 +0x27
main.main()
        /Users/jono/golang/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x14
```

My docker-compose file:

```
➤ cat docker-compose.yml
version: '2'
services:
  web:
    command: /sbin/my_init
    build:
      context: .
      dockerfile: Dockerfile.dev
    volumes:
      - .:/home/app
      - ./certs/production/:/etc/ssl/certs:ro
      - ./certs/dhparam.pem:/etc/ssl/private/dhparam.pem:ro
      - ./certs/private/wildcard.com.key:/etc/ssl/private/wildcard.com.key:ro
      - ./staging.conf:/etc/nginx/sites-enabled/portal.conf
    env_file: ./config/environments/development.env
    ports:
      - ""80:80""
      - ""443:443""
    depends_on:
      - db
      - memcached
      - redis
      - mailcatcher
  db:
    image: sandbox-psql
    volumes:
      - data:/var/lib/postgresql/data
  memcached:
    image: memcached:1.4.28-alpine
  redis:
    image: redis:3.2-alpine
  mailcatcher:
    image: schickling/mailcatcher
    ports:
      - ""1080:1080""
volumes:
  data:
```.
 @jonathanstiansen thanks for reporting this issue! Tracked at https://github.com/docker/libcompose/issues/430 in upstream..
 @surajssd Thanks! I appreciate that..
 As https://github.com/docker/libcompose/issues/430 now, issue has been resolved, we can close this issue.
 it should be resolved, closing.

@jonathanstiansen if you still have same problem feel free to comment and reopen it.
 Nope! It's solved :-).
 "
,,378,"change strategy to recreate if volumes present, fix #264.
 .
 @containscafeine are you still working on this?.
 @surajssd yep.
 @kadel @surajssd @cdrage up for review, PTAL!.
 code LGTM, but wanna give it a try once by running it against application!.
 @containscafeine also title says 'no test' 

*change strategy to recreate if volumes present, no tests, fix #264*

but you seem to have added tests?.
 @containscafeine tested with etherpad application from fixtures and it works! would like to have this behavior documented then we are good to merge this..
 @surajssd thanks for pointing that out, added docs..
 @surajssd good to go now?.
 "
,,377,"bump libcompose to v0.4.0.
 bumping libcompose to their latest release v0.4.0

CC: @kadel @cdrage @surajssd .
 LGTM (if tests pass).
 "
,,376,"Should we not generate PVC's by default?.
 The current default is to generate a PVC with *only* 100Mb of available memory.

Ex:
```
WARN[0000] Unsupported depends_on key - ignoring
WARN[0000] Unsupported network_mode key - ignoring
WARN[0000] Volume mount on the host ""./media"" isn't supported - ignoring path on the host
WARN[0000] Volume mount on the host ""./media"" isn't supported - ignoring path on the host
```

Yet it still build PVC's. 

Should we (by default) NOT generate volume mounts? 
.
 I'm not sure if I understand :-( 
What are you proposing to do with volumes instead? 

We already had this discussion in some other issue. I still think that PVC is right approach here. 
And if for some reason you want to avoid that you can use `--emptyvols` option.

But I agree that 100Mb default is bad. We need to make this configurable for user.

.
 @kadel I find it odd that we have a default to 100Mb and the volumes are inherently not working correctly since it's ignored on the host..
 The host part will always be a problem as we don't have easy way how to copy data from the machine to the cluster :-(.
 > @kadel I find it odd that we have a default to 100Mb and the volumes are inherently not working correctly since it's ignored on the host.

@cdrage can you elaborate what do you mean here?.
 @surajssd We default to 100Mb in PVC's and if PV's aren't setup on the cluster Kompose won't warn the user / fail since PVC's will be stuck in a pending state the entire duration..
 @cdrage yes PVCs will fail when PV is not provisioned, but then kompose right now generates configs that are cluster agnostic with little extra setup needed.

We can expect PV to be setup already..
 @surajssd, @cdrage is right. PVC will stay in Pending state if there is no matching PV. I'm not aware of any timeout setting for this so it will be probably stuck in Pending forever.

Reason for this is to allow PVC to be created before PV, PVC is waiting for someone to create PV.

.
 @kadel , @surajssd , @cdrage , as of now, should we add warning in kompose such as, 
for example, 

```
WARN[0000] volume ""data-volume"" of size ""100 Mi"" created
```  .
 @surajnarwade IMO, INFO instead of WARN may be better..
 yeh, this shouldn't be WARN.
And message should probably mention something about PVC requiring PV. But I don't know how to explain it in one or two sentences :disappointed:  .
 okay @kadel @cdrage  I would like to work on it then.
 @surajnarwade assigned!
.
 @surajnarwade https://github.com/kubernetes-incubator/kompose/pull/519#issue-217506525 says that the PR fixes this issue partially, what is the current state? Should we re-open this issue?.
 @surajssd , no need to reopen the issue.
 "
,,375,"[WIP] add support for mem_limit.
 .
 @containscafeine What's left to be done in this PR? Tests? Defaults? Just wondering so I can pick up on it :).
 @cdrage IIRC, removing `template.Spec.Containers[0].Resources.Requests` and adding tests was remaining from this..
 Replaced by https://github.com/kubernetes-incubator/kompose/pull/414 thank you @containscafeine for the work! :+1: .
 "
,,374,"[WIP] bump libcompose to v0.4.0.
 .
 @containscafeine this is duplicate, @cdrage is already doing it here https://github.com/kubernetes-incubator/kompose/pull/356.
 Closin' :).
 Not a dup, reopened at #377 .
 "
,,373,"error out if controller object is specified with ""restart: on-failure"".
 Fixes #354 
CC: @kadel @surajssd .
 
[![Coverage Status](https://coveralls.io/builds/9618445/badge)](https://coveralls.io/builds/9618445)

Coverage decreased (-0.02%) to 46.983% when pulling **83723f88bf02fb45b95e5e639601554dbe0f17f9 on procrypt:error_should_be_displayed** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9618472/badge)](https://coveralls.io/builds/9618472)

Coverage decreased (-0.02%) to 46.983% when pulling **83723f88bf02fb45b95e5e639601554dbe0f17f9 on procrypt:error_should_be_displayed** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 @kadel @surajssd please review..
 Thanks for the comments. This LGTM :) All green from me..
 ![Image](http://cultofthepartyparrot.com/parrots/stableparrot.gif).
 @procrypt Thanks for the awesome work! Merging away :).
 "
,,372,"[WIP] Support local container builds for k8s/openshift.
 This implements support for local container builds for k8s/openshift and pushing it to the specified registry. The user needs to setup the Docker client so that it can access to the target registry..
 Are we sure this is in scope of the kompose tool?.
 sorry, I just read the discussion in #97..
 @rtnpro this PR is doing two things, 
- refactoring the way we do, exec
- adding build support

can we break those two atomic pieces?.
 Let's get the exec thing better and then come back to this again? It will be easier to see what is happening behind with this!.
 @surajssd I agree. Let's have the execute functionality minimal necessary for this feature. We'll visit it later..
 @rtnpro Any progress on this? .
 @rtnpro Can you post the error you're getting here so everyone can see what's happening with the authentication?.
 @rtnpro I'm having difficulty reviewing everything due to the multitude of commits. Is it possible to squash all the commits? (one for vendoring, the other for the actual implementation)? We'd have to do this anyways before mergin' in the future..
 @cdrage I have squashed the commits, like you asked.

I have a kind of should-work implementation of pushing a Docker image to registry at https://github.com/rtnpro/kompose/blob/a24edf5cdfd78a2af36daf0ba9a5a5995001807e/pkg/utils/docker/push.go and you can run the example as follows:

```
cd pkg/utils
go build main.go
sudo DOCKER_USERNAME=rtnpro DOCKER_PASSWORD=<my password> ./main ../../examples/buildconfig/build/ docker.io/rtnpro/foo
```
However, I am not able to push the image due to authentication error. The implementation is according to https://godoc.org/github.com/docker/docker/client#Client.ImagePush. The error is pasted below:

``` shell
[vagrant@localhost utils]$ sudo DOCKER_USERNAME=rtnpro DOCKER_PASSWORD=<my password> ./main ../../examples/
buildconfig/build/ docker.io/rtnpro/foo                                                                   
Abs dir /home/vagrant/go/src/github.com/kubernetes-incubator/kompose/examples/buildconfig/build
Header name 
Header name Dockerfile
{""stream"":""Step 1 : FROM busybox\n""}
{""stream"":"" ---\u003e 7968321274dc\n""}
{""stream"":""Step 2 : RUN touch /test\n""}
{""stream"":"" ---\u003e Using cache\n""}
{""stream"":"" ---\u003e f3cef57c8ca0\n""}
{""stream"":""Successfully built f3cef57c8ca0\n""}
Username:  rtnpro Password:  <my password>
Registry auth <my access token, same as that in ~/.docker/config.json>
INFO[0000] Pushing Docker image: docker.io/rtnpro/foo   
{""status"":""The push refers to a repository [docker.io/rtnpro/foo]""}
{""status"":""Preparing"",""progressDetail"":{},""id"":""4d064515e729""}
{""status"":""Preparing"",""progressDetail"":{},""id"":""38ac8d0f5bb3""}
{""errorDetail"":{""message"":""unauthorized: authentication required""},""error"":""unauthorized: authentication required""}
```.
 @rtnpro From this issue: https://github.com/docker/hub-feedback/issues/645

Shouldn't it be using https://index.docker.io/v1/ as the registry auth?.
 Are you making sure it's included when doing the image push? .
 @rtnpro maybe this can help with parsing the docker auth:
https://github.com/projectatomic/skopeo/blob/master/cmd/skopeo/utils.go#L33

I haven't seen code in depth but maybe this can help.

the above is called from https://github.com/projectatomic/skopeo/blob/master/cmd/skopeo/inspect.go#L28.
 Hey @rtnpro 
I'm unable to build your PR at the moment:
```
github.com/kubernetes-incubator/kompose  pr_372 ✔                                                                                                                                                                                                                          37d  ⍉
▶ make bin
go build -ldflags=""-w -X github.com/kubernetes-incubator/kompose/version.GITCOMMIT=3d81d60"" -o kompose main.go
pkg/transformer/utils.go:30:2: found packages utils (cmd.go) and main (main.go) in /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/pkg/utils
Makefile:29: recipe for target 'bin' failed
make: *** [bin] Error 1
```.
 Also needs rebasing + updates to vendoring :+1: .
 @kadel @rtnpro Funny enough, after searching, we already use github.com/fsouza/go-dockerclient deep within our vendoring as the Kubernetes project seems to use it (as well as OpenShift)!

Considering all the problems that @rtnpro was running into, would it be viable to use this library instead (if it's easier?), would need some investigation however. .
 if it's already vendored why not use it, :+1: for using it than doing it ourselves..
 I'm going to close this for now as I've taken over nad continued progress here: #521 .
 "
,,371,"updated pods example in user guide.
 earlier example has mariadb updated with more sensible example that users can try out, since it also simulates a job like behavior..
 
[![Coverage Status](https://coveralls.io/builds/9596682/badge)](https://coveralls.io/builds/9596682)

Coverage remained the same at 47.007% when pulling **97d82470479169e4f98c23ebe5796d6cc6249061 on surajssd:update_pod_example** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 "
,,370,"Add bash auto completion support.
 Adds auto completion support that's generated via:
```
$ kompose complete
```

This file is added to /etc/bash_completion.d/kompose.sh.
 Closes https://github.com/kubernetes-incubator/kompose/issues/37.
 
[![Coverage Status](https://coveralls.io/builds/9584441/badge)](https://coveralls.io/builds/9584441)

Coverage remained the same at 47.007% when pulling **15a1946fd7becabf2ec8f31a64b2cc10a53ee63b on cdrage:add-autocompletion** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 @ngtuna It should. Doesn't look like you're running as sudo / have user permission to /etc/bash_completion.d/

Try `sudo ./kompose completion`.
 Ah see it now... It doesn't work on Mac. Could we add this support to darwin ?.
 works on fedora for me :+1: .
 Can we do it like `kubectl` or `oc`? Print to stdout instead to file? (https://kubernetes.io/docs/user-guide/kubectl/kubectl_completion/) or at least have option for it.

I don't think that it is no nice write to `/etc` by default without any warning.

I really like that stdout option, because if you put `source <(kubectl completion bash)` to you `bashrc`,
completion is always up to date, you don't have to remember regenerate it with new kubectl version 


.
 And one more. Some people are using ZSH (like me for example :wink: ).
 @kadel Alright :) I'll do these three things:

1. Output to stdout
2. Add the ZSH option (btw @kadel zsh > bash. #zshmasterrace)
3. Add support for Darwin.
 @ngtuna @kadel 

Ready for another review!

It now does:

1. Outputs to stdout :+1: 
2. Added bash support :+1: 
3. For the users who use a laptop with a magical touchbar that removes the ESC key, you can simple source it with `source <(kompose completion bash)`. :+1: .
 @kadel 

Tests should be all green now (validate error with some unreachable code). 

I've also updated the README with the appropriate instructions on how to use this!

Merge when you're ready :+1: .
 LGTM @ngtuna can you confirm?.
 Yes. Confirmed.
 "
,,369,"panic on using --build-branch and default docker-compose file given.
 ```bash
✔ ~/go/src/github.com/kubernetes-incubator/kompose/examples/buildconfig [master L|✔] 
11:11 $ kompose --provider openshift convert --build-repo https://github.com/kubernetes-incubator/kompose
panic: runtime error: index out of range

goroutine 1 [running]:
panic(0x19e8000, 0xc4200101a0)
        /usr/local/go/src/runtime/panic.go:500 +0x1a1
github.com/kubernetes-incubator/kompose/pkg/transformer/openshift.getComposeFileDir(0x29e2610, 0x0, 0x0, 0x1, 0x2, 0xc420188a80, 0x1)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/pkg/transformer/openshift/openshift.go:118 +0x198
github.com/kubernetes-incubator/kompose/pkg/transformer/openshift.(*OpenShift).Transform(0xc4201d0d90, 0xc4201ebce0, 0x1c08af8, 0x7, 0x100000000, 0x7ffd10d112c1, 0x2f, 0x0, 0x0, 0x0, ...)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/pkg/transformer/openshift/openshift.go:338 +0xf82
github.com/kubernetes-incubator/kompose/pkg/app.Convert(0x100000000, 0x7ffd10d112c1, 0x2f, 0x0, 0x0, 0x0, 0x1, 0x29e2610, 0x0, 0x0, ...)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/pkg/app/app.go:201 +0x22d
github.com/kubernetes-incubator/kompose/cmd.glob..func2(0x29b4380, 0xc4200a8100, 0x0, 0x4)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/cmd/convert.go:80 +0x3f
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).execute(0x29b4380, 0xc4200a80c0, 0x4, 0x4, 0x29b4380, 0xc4200a80c0)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:636 +0x443
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x29b47c0, 0xc42000c118, 0x0, 0xc4204dfed0)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:722 +0x367
github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra.(*Command).Execute(0x29b47c0, 0x0, 0x0)
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/vendor/github.com/spf13/cobra/command.go:681 +0x2b
github.com/kubernetes-incubator/kompose/cmd.Execute()
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/cmd/root.go:86 +0x31
main.main()
        /home/hummer/go/src/github.com/kubernetes-incubator/kompose/main.go:22 +0x14
```

but if given a file with `-f` flag as following everything works fine

```bash
✘-2 ~/go/src/github.com/kubernetes-incubator/kompose/examples/buildconfig [master L|✔] 
11:12 $ kompose --provider openshift -f docker-compose.yml convert --build-repo https://github.com/kubernetes-incubator/kompose
WARN[0000] [foo] Service cannot be created because of missing port. 
INFO[0000] Buildconfig using https://github.com/kubernetes-incubator/kompose::master as source. 
INFO[0000] file ""foo-deploymentconfig.yaml"" created     
INFO[0000] file ""foo-imagestream.yaml"" created          
INFO[0000] file ""foo-buildconfig.yaml"" created          
```.
 @kadel this should be fixed before release..
 I think this is fixed with #368 so closing it..
 "
,,368,"added support for docker-compose.yaml besides docker-compose.yml.
 Now `kompose` will look for `docker-compose.yml` as well as `docker-compose.yaml` in the current directory, when `-f` or `--file` flag in not given .
```console
$ ls
docker-compose.yml
$ kompose convert
INFO[0000] file ""mlbparks-service.yaml"" created         
INFO[0000] file ""mongodb-service.yaml"" created          
INFO[0000] file ""mlbparks-deployment.yaml"" created      
INFO[0000] file ""mongodb-deployment.yaml"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.yaml"" created
```

```console
$ ls
docker-compose.yaml
$ kompose convert
INFO[0000] file ""mlbparks-service.yaml"" created         
INFO[0000] file ""mongodb-service.yaml"" created          
INFO[0000] file ""mlbparks-deployment.yaml"" created      
INFO[0000] file ""mongodb-deployment.yaml"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.yaml"" created
```
cc. @containscafeine @surajssd @kadel
Fixes #352 and #369 includes functional tests
I think we can now close #367 .
 
[![Coverage Status](https://coveralls.io/builds/9577222/badge)](https://coveralls.io/builds/9577222)

Coverage decreased (-0.08%) to 46.597% when pulling **4bc88cbcbd9c2fc0afd817f0c632ee8fabcb6d48 on procrypt:yaml_and_yml** into **4b3094d8acb5af5c676b92cdcd7530c925372841 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9577227/badge)](https://coveralls.io/builds/9577227)

Coverage decreased (-0.08%) to 46.597% when pulling **4bc88cbcbd9c2fc0afd817f0c632ee8fabcb6d48 on procrypt:yaml_and_yml** into **4b3094d8acb5af5c676b92cdcd7530c925372841 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9579655/badge)](https://coveralls.io/builds/9579655)

Coverage decreased (-0.08%) to 46.924% when pulling **6829e6f09393aa17db99b9dcde24226554b5886f on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9579704/badge)](https://coveralls.io/builds/9579704)

Coverage decreased (-0.08%) to 46.924% when pulling **6829e6f09393aa17db99b9dcde24226554b5886f on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9579717/badge)](https://coveralls.io/builds/9579717)

Coverage decreased (-0.08%) to 46.924% when pulling **6829e6f09393aa17db99b9dcde24226554b5886f on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 This will be broken by #367.

It would be better to decide between `docker-compose.yml` and `docker-compose.yaml` somewhere else,  outside compose loader.

.
 @kadel yes true!.
 
[![Coverage Status](https://coveralls.io/builds/9597841/badge)](https://coveralls.io/builds/9597841)

Coverage decreased (-0.1%) to 46.897% when pulling **57638ec45e931179c06a016f0f1b82ea76acad9b on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9597863/badge)](https://coveralls.io/builds/9597863)

Coverage increased (+0.08%) to 47.09% when pulling **57638ec45e931179c06a016f0f1b82ea76acad9b on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9598160/badge)](https://coveralls.io/builds/9598160)

Coverage increased (+0.08%) to 47.09% when pulling **0ba501a80ba7d14c7e0278775780812335dc5e63 on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9598200/badge)](https://coveralls.io/builds/9598200)

Coverage increased (+0.08%) to 47.09% when pulling **0ba501a80ba7d14c7e0278775780812335dc5e63 on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9598360/badge)](https://coveralls.io/builds/9598360)

Coverage increased (+0.08%) to 47.09% when pulling **ce72313828b9aad03f829fec1aa76aa48ab9a73b on procrypt:yaml_and_yml** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 @kadel do you think it's the right place to handle default files?.
 
[![Coverage Status](https://coveralls.io/builds/9615111/badge)](https://coveralls.io/builds/9615111)

Coverage increased (+0.08%) to 47.09% when pulling **a13549b790ec6823c57696b0d21223a297f1654c on procrypt:yaml_and_yml** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 @procrypt this breaks `kompose up` and `kompose down` for me, can you check that out?
.
 verified it indeed breaks `up` and `down` this is because `ValidateFlags` is called only when doing `convert`.
It needs deeper investigation .
 @kadel @containscafeine @surajssd Please review..
 @kadel @cdrage Please review..
 @procrypt LGTM! .
 ![Example](http://i.giphy.com/10v0l8aVLyLJ5e.gif).
 All green :+1: Merging away!.
 "
,,367,"Added default input file as docker-compose.yml.
 There was missing default docker-compose.yml so added it.

Fixes https://github.com/kubernetes-incubator/kompose/issues/369.
 
[![Coverage Status](https://coveralls.io/builds/9571803/badge)](https://coveralls.io/builds/9571803)

Coverage remained the same at 46.678% when pulling **583670cfe14c99d6038c64f582701503f24ffe01 on surajssd:default-inputfile** into **4b3094d8acb5af5c676b92cdcd7530c925372841 on kubernetes-incubator:master**.
.
 @rtnpro @procrypt is there a better way to do it? Because @procrypt is also working on https://github.com/kubernetes-incubator/kompose/pull/368 so want it to be easy in both places..
 @surajssd this looks good to me :+1: .
 LGTM :+1: .
 In the way how  #368  is right now implemented, change in this PR will break #368.
 @kadel @rtnpro closing this one since https://github.com/kubernetes-incubator/kompose/pull/368 solves it..
 "
,,366,"Preference file implementation using viper.
 now user can provider a prefernce file where s(he) can mention
what controllers to generate..
 
[![Coverage Status](https://coveralls.io/builds/9554386/badge)](https://coveralls.io/builds/9554386)

Coverage remained the same at 46.678% when pulling **ab1b83e67afb8634f9046331364d79c04017e811 on surajssd:preferencefile_viper** into **4b3094d8acb5af5c676b92cdcd7530c925372841 on kubernetes-incubator:master**.
.
 This will need an update to docs for this to be merged in. No idea what's happening here.

A better commit message too please detailing the new command-line function being added..
 In regards to 'GlobalProfile' I haven't seen this feature other than https://github.com/kubernetes-incubator/kompose/pull/155

Can an issue be opened giving an outline as to why we need this feature as well as a tutorial, documentation, examples on how to use it?

As well as a [WIP] tag being added to this PR? I'm not too sure that we've ironed out all the features here for a global profile..
 I feel as though this feature is over-engineering something simple. Why would we need both a `yaml` file for converting docker-compose as well as a separate viper-specific file for conversion?

Seems like a hack to fix something that needs to be refactored within `kompose`. Specifically, something like adding `labels` as to what @kadel did. Or introducing better conversion methods..
 
[![Coverage Status](https://coveralls.io/builds/9577532/badge)](https://coveralls.io/builds/9577532)

Coverage remained the same at 47.007% when pulling **cc944f42b9578e20b558638038587aa167cca427 on surajssd:preferencefile_viper** into **2ba88312e169634f71d4aedf910c8dba888ea003 on kubernetes-incubator:master**.
.
 >I feel as though this feature is over-engineering something simple. Why would we need both a yaml file for converting docker-compose as well as a separate viper-specific file for conversion?

this is basically to do somthing similar to `.kube/config`. See full discussion at https://github.com/kubernetes-incubator/kompose/issues/39

>Seems like a hack to fix something that needs to be refactored within kompose. Specifically, something like adding labels as to what @kadel did. Or introducing better conversion methods.

Labels in kompose is to overcome what docker-compose lacks but this is more of influence functionality of kompose. The things that can happen from command line can be influenced from another file.

So you can see this is only under `kompose convert`. `kompose up` and `down` are still done using defaults..
 I'd suggest @ngtuna to do a little review since the issue was originally his.

Personally I think we should try and keep Kompose as simple / straight-forward as possible and adding global profiles may make everything a bit too complex. But that's just me. 

In regards to the changes I've updated my comments ^^. Thanks for being patient @surajssd !.
 This preference file still confuses me a lot :-( 
I think that we should outline how it should work before jumping more into implementation. 
.
 The way this behaves is also strange :-(

If i set `KOMPOSE_CONFIG` where I have 'default' section I would expect that it will be use as default if I don't set any profile. 

.
 @kadel I totally agree, docs + spec for a good foundation before any sort of implementation..
 Lets go back to discussion in #39, so we have everything in one place and figure out what we wan't to do.

Than we can go back to this PR with clear goal..
 Let's close this PR for now until it's a WIP again :).
 "
,,365,"Unsupported root level networks key despite no networks.
 The warning could be a bit more descriptive, but upon converting:
```
▶ cat script/test/fixtures/tty-true/docker-compose.yml 
version: ""2""
services:
  client:
    image: registry.centos.org/centos/centos:7
    ports:
    - ""1337""
    tty: true
```

It appears to output a warning in regards to a root level network, despite none being defined.

```
github.com/kubernetes-incubator/kompose  update-vendoring ✔                                                                                                                                                                                                                  2d
▶ kompose -f /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/tty-true/docker-compose.yml convert --stdout -j
WARN[0000] Unsupported root level networks key - ignoring
{                            
  ""kind"": ""List"",
  ""apiVersion"": ""v1"",
  ""metadata"": {},          
  ""items"": [      
    {                            
      ""kind"": ""Service"",                                       
      ""apiVersion"": ""v1"",     
      ""metadata"": {      
```.
 @cdrage , I tried same docker compose file, there's no warning, I think issue is resolved now, we can close this,

output is: 
```
$ kompose -f docker-compose.yml convert --stdout -j
{
  ""kind"": ""List"",
  ""apiVersion"": ""v1"",
  ""metadata"": {
```.
 @surajnarwade You're right, this is no longer an issue. Closing! :+1: .
 "
,,364,"add support for mem_limit in kompose.
 It would be great to have support for [mem_limit](https://docs.docker.com/compose/compose-file/#/cpushares-cpuquota-cpuset-domainname-hostname-ipc-macaddress-memlimit-memswaplimit-oomscoreadj-privileged-readonly-restart-shmsize-stdinopen-tty-user-workingdir) which should translate to a pod's spec like -

```yaml
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: nginx
    resources:
      limits:
        memory: 200Mi
    terminationMessagePath: /dev/termination-log
    volumeMounts:
```.
 there already is issue for that #267 

closing as duplicate
.
 "
,,363,"add deploy/undeploy pod only.
 ref: #342

Ping @surajssd @kadel .
 
[![Coverage Status](https://coveralls.io/builds/9544418/badge)](https://coveralls.io/builds/9544418)

Coverage decreased (-0.5%) to 46.163% when pulling **162ae3ef07aea52106fee248090b1a8a16189fac on ngtuna:up-down-pod** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 @surajssd @kadel Do you have idea why my PR pulling down the coveralls ? :-(.
 @ngtuna because you added new lines that are not covered by tests :-).
 @kadel oh now I got it. Test is coming up..
 @ngtuna I'm not sure if this can be currently tested properly without mocking kubernetes :-( or starting cluster. 
But it would be great if you have any idea how to do it.
Otherwise I wouldn't worry about in this PR. We will have to figure out a way how to test up for everything later.
.
 @kadel Right. I made this commit last night but then came up with no idea how to add a test. Will investigate it more late today..
 
[![Coverage Status](https://coveralls.io/builds/9604034/badge)](https://coveralls.io/builds/9604034)

Coverage decreased (-0.4%) to 46.57% when pulling **fa8157a555dacf301c325338c11de0b8f0602bca on ngtuna:up-down-pod** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9604216/badge)](https://coveralls.io/builds/9604216)

Coverage decreased (-0.9%) to 46.141% when pulling **5e59400345b5b370f14669642ba8def5c2a2f5d1 on ngtuna:up-down-pod** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 @kadel I added commit for OpenShift.
 "
,,362,"Fixing functional tests for checking generated artifacts.
 Earlier any test written after check_file_exist would
fail, so fixed it with new function.

Fixes https://github.com/kubernetes-incubator/kompose/issues/361.
 @containscafeine would like your review on this one..
 
[![Coverage Status](https://coveralls.io/builds/9540010/badge)](https://coveralls.io/builds/9540010)

Coverage remained the same at 46.617% when pulling **26e348e73172c1ef9063fc88f98b6fae018fd080 on surajssd:cmd_tests_fix** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 @surajssd LGTM, works even when I'm adding tests after this. Solves the issue, confirmed..
 @kadel @containscafeine thanks :).
 "
,,361,"cmd tests written after `convert::files_exist` does not pass.
 In cmd functional tests in `script/test/cmd/tests.sh` after function `convert::files_exist:` is called any other function like `convert::expect_success` does not pass..
 "
,,360,"Small simplification of kubernetes.PrintList.
 Use reflect instead of big type switch that was prone to errors.

This should prevent future errors, where we forgot add new type to that git  switch..
 
[![Coverage Status](https://coveralls.io/builds/9553218/badge)](https://coveralls.io/builds/9553218)

Coverage increased (+0.3%) to 47.007% when pulling **3cf6866dd0301a88568fe5c43822c360e36fc2ec on kadel:simplify-printlist** into **4b3094d8acb5af5c676b92cdcd7530c925372841 on kubernetes-incubator:master**.
.
 "
,,359,"update roadmap.
 info about monthly releases.
 
[![Coverage Status](https://coveralls.io/builds/9533350/badge)](https://coveralls.io/builds/9533350)

Coverage remained the same at 46.617% when pulling **de8136579e4a2befe9d5bdafd32795325911ed58 on kadel-patch-2** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9537044/badge)](https://coveralls.io/builds/9537044)

Coverage remained the same at 46.617% when pulling **5e188b3950b5345622e43169e1061e59d0f201a4 on kadel-patch-2** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on master**.
.
 Thank you @cdrage..
 "
,,358,"disable coveralls.io comments.
 It is starting get a little bit annoying that coveralls comments to for every push to PR.

Maybe we should consider disabling coveralls comments (this can be done in coveralls.io settings). Increase or decrease of coverage for PR can be still seen in status checks.

I think that only one who has permission to change coveralls.io settings are repository admins (@sebgoa)

.
 disabled ;-)

If someone wan't that enabled. let me know. we can turn that on if there is a reason for it..
 "
,,357,"""Failed to unmarshal MaporSlice"" attempt to convert Sentry quick start.
 I attempted to use the Fedora `kompose` package to convert https://github.com/getsentry/onpremise to Kubernetes/OpenShift and got the following error:

```
ERRO[0000] Could not parse config for project sentryonopenshift : Failed to unmarshal MaporSlice 
FATA[0000] Failed to load compose file: Failed to unmarshal MaporSlice 
```

The Fedora package was last updated in October though, so I'm going to try building from source and see if that works:

```
$ rpm -qa kompose
kompose-0.1.2-0.1.git92ea047.fc25.x86_64
```
.
 Building from source gives exactly the same error..
 @ncoghlan tracked in library used by kompose called libcompose https://github.com/docker/libcompose/issues/428.
 @ncoghlan I applied following diff and kompose worked for me:
Ideally this should be solved in kompose/libcompose, but this could be short term solution for you to move forward:

```diff
$ git diff
diff --git a/docker-compose.yml b/docker-compose.yml
index ba5d198..8c42f6c 100644
--- a/docker-compose.yml
+++ b/docker-compose.yml
@@ -36,7 +36,8 @@ services:
       - ./data/postgres:/var/lib/postgresql/data
 
   web:
-    extends: base
+    extends:
+      service: base
     links:
       - redis
       - postgres
@@ -46,7 +47,8 @@ services:
       - '9000:9000'
 
   cron:
-    extends: base
+    extends:
+      service: base
     command: run cron
     links:
       - redis
@@ -55,7 +57,8 @@ services:
       - smtp
 
   worker:
-    extends: base
+    extends:
+      service: base
     command: run worker
     links:
       - redis

```.
 @kadel @surajssd @ncoghlan  , I have raised PR for this issue in libcompose which can be tracked here https://github.com/docker/libcompose/pull/457.
 @kadel @surajssd @ncoghlan , PR for issue https://github.com/docker/libcompose/pull/457 in libcompose is merged now, I updated vendoring in PR https://github.com/kubernetes-incubator/kompose/pull/562, once that gets merged, this issue will be resolved..
 we can close this now as https://github.com/kubernetes-incubator/kompose/pull/454 is merged now.
 original issue is fixed, but deploying Sentry from https://github.com/getsentry/onpremise/ without modification will be tricky, as it heavily depends on `build`.
 "
,,356,"Update vendoring as well as libcompose.
 This commit updates libcompose in order to merge in
https://github.com/docker/libcompose/pull/423 which affected
https://github.com/kubernetes-incubator/kompose/issues/92 by not
erroring out when an image name wasn't provided.

Closes https://github.com/kubernetes-incubator/kompose/issues/92

As well as knocks out the last required milestone for a 0.2.1 release
https://github.com/kubernetes-incubator/kompose/milestone/2.
 ping @ngtuna as this closes your issue. 

With this PR, we will have completed all milestones for 0.2.1 which unblocks us for releasing a new version of kompose. https://github.com/kubernetes-incubator/kompose/milestone/2.
 
[![Coverage Status](https://coveralls.io/builds/9505533/badge)](https://coveralls.io/builds/9505533)

Coverage remained the same at 46.617% when pulling **63f44be5e0d85cd1c7e62db9b042c01ffb5b8bf5 on cdrage:update-vendoring** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 +1 @cdrage. 

I was inserting a manual check for image while libcompose has not been updated, but your PR is here so we will work on this. Now I'm considering the test cases failing..
 
[![Coverage Status](https://coveralls.io/builds/9521786/badge)](https://coveralls.io/builds/9521786)

Coverage remained the same at 46.617% when pulling **57039425b6e7c01b3367a065c5e07f45990246a5 on cdrage:update-vendoring** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 @ngtuna @kadel So this seems to be failing due to:
```
▶ kompose --provider openshift -f /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/tty-true/docker-compose.yml convert --stdout -j                                                                                                     
etes-incubator/kompose/script/test/fixtures/tty-true/output-oc.json                                                                                                                                                                                                               
WARN[0000] Unsupported root level networks key - ignoring                                                                                                          
{                                                                                                                         
  ""kind"": ""List"",                         
  ""apiVersion"": ""v1"",                
  ""metadata"": {},                                                                                                                                                                                                                                                                 
  ""items"": [                                                                                                                                                                                                                                                                      
    {                               
```

appearing..

Going to investigate this more.. But looks like an update to libcompose added that warning..
 @cdrage 

There is a check that was testing root level networks before 
https://github.com/kubernetes-incubator/kompose/blob/4f176b847ec75f61ab69bcc03f2b759a178df991/pkg/loader/compose/compose.go#L87

It looks like new libcompose version is doing something little bit different with networks :-(
.
 @kadel yeah :( i saw, seems that it's something putting something into the file even though a network isn't there. I'll open up a separate PR for this to unblock this PR..
 I don't think that we should merge this  if it is giving warning about root level network even there is none in docker-compose file. We should include fix in this pr..
 @kadel Done. I've added another commit to this PR that fixes the test..
 
[![Coverage Status](https://coveralls.io/builds/9553335/badge)](https://coveralls.io/builds/9553335)

Coverage increased (+0.1%) to 46.744% when pulling **7cc78248a631d2983d7c1905bc9944019bd39fef on cdrage:update-vendoring** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 @ngtuna @surajssd can we get a quick review? :).
 
[![Coverage Status](https://coveralls.io/builds/9602766/badge)](https://coveralls.io/builds/9602766)

Coverage increased (+0.03%) to 47.042% when pulling **39fbc4ab9c435c09bd6af22aef099372b94bc9a7 on cdrage:update-vendoring** into **7dbf00c18e167878a4ecc05325c54027326b4e1c on kubernetes-incubator:master**.
.
 @cdrage LGTM.
 @surajssd 

Done. Have a quick look and give me the LGTM :+1: Then we can merge!.
 @containscafeine I'll have to open up a separate PR in regards to updating libcompose as for some odd reason you can't do `glide update --strip-vendor` in a detached HEAD state when you do a git rebase.

Mind doing a quick LGTM so I can press that merge button?.
 @cdrage sure, lookin' gooood to me!!!.
 "
,,355,"kompose binary per merge? (add nightlies).
 Hi team,

We are merging PRs to master which result from the issues we face during deployments everyday. This code goes into master and we can build it locally after pulling it.

Is there any way we can host the kompose binary somewhere, resulting from the current state of master?

This would help in making the conversion and deployment automated by simply downloading the binary and running it instead of building the code locally from master and then do the deployments.

Some place where maybe Travis can push the binary after each merge, like AWS S3 or Dropbox or Google Drive?

Thoughts?.
 Long time ago, I created something like this for Henge:
https://github.com/kadel/henge/blob/travis-deploy/hack/upload-master-builds-to-dropbox.sh.
 Throwing this in the ring. https://docs.travis-ci.com/user/deployment/releases/ Basically, uploading the binary to GH releases via Travis..
 > Throwing this in the ring. https://docs.travis-ci.com/user/deployment/releases/ Basically, uploading the binary to GH releases via Travis.

Looks good. This would be better than dropbox/drive... If we plan to keep only latest binary (nigtly).

But if we want keep history of binaries (for every PR), than I think other place would be better, as github releases page might become chaotic..
 this has been added!.
 "
,,354,"error should be displayed If controller object is specified  and `restart: on-failure` .
 ```yaml
version: ""2""

services:
  foo:
    image: ""busybox""
    restart: ""on-failure""
    command: [""sleep"", ""30s""]
```

```
./kompose convert --deployment
INFO[0000] file ""foo-pod.json"" created
```

I would expect error or at least warning..
 @kadel can you assign it to me..
 "
,,353,"Add support for s2i in buildconfigs for OpenShift.
 right now the build startegy is Docker only, it would be great if s2i is also supported..
 I don't think it makes sense to add support for S2I to Kompose.
It defies purpose of Kompose. Kompose is tool that helps docker-compose users move to Kubernetes.

S2I is replacement for Dockerfiles. And everyone who is using docker-compose with `build` is building images using Dockerfiles. 

I just don't see a way how we can support s2i builds and also making sure that same docker-compose.yml file with same build directory will still work with `docker-compose` tool.

On the other side, supporting s2i builds is great usecase for https://github.com/redhat-developer/opencompose


.
 What about in effect generating an s2i builder image given a Dockerfile?  Or if the base image in the Dockerfile is a builder image, then the rest of the Dockerfile takes the place of the assemble and run scripts of the builder image?

.
 @stephanosbacon AFAIK builder images are generic enough to have things needed to run code, and people using docker-compose generally do have steps in Dockerfile where code is copied from local repo into the image, so I don't think using that Dockerfile to generate builder image makes sense.

>Or if the base image in the Dockerfile is a builder image, then the rest of the Dockerfile takes the place of the assemble and run scripts of the builder image?

I don't understand this part can you explain it?.
 @surajssd Sure, they can be generic, but why not generate one on the fly?  Take a generic node.js builder image for example - it's assemble script will likely copy all the subdirectories under . (as the ones that I've seen do), but suppose I don't want that and in my Dockerfile I control exactly what I want copied (e.g. my unit tests).  I may want my unit test code built into a separate container, for example.  What I was thinking was that given a Dockerfile, one has a lot of the information one needs to generate a builder on the fly so to speak.

re the second part - as I mentioned above, in some sense a Dockerfile does what the assemble script does in a Dockerfile, doesn't it?  Why not generate the assemble script from it then, thereby giving the developer a bit more control over what gets put into the container. .
 > What I was thinking was that given a Dockerfile, one has a lot of the information one needs to generate a builder on the fly so to speak.

What are benefits of this over building finished image directly from Dockerfile? 
If i understand it correctly, `docker build` will have to be used to build builder image, and that builder image will be specific only for this one case. .
 On OpenShift Online and OpenShift Dedicated, one cannot run docker builds (because as I understand it the docker socket is a security hole), and writing one's own builder image is more involved than writing a Dockerfile..
 Yes. And for the same reason builder image will have to be build outside of the OpenShift cluster and resulting build image will be specific  for given project.

Than why not build image directly from Dockerfile outside OpenShift and import it to OpenShift as ImageStream?

For me it all sounds like a lot of complicated thinks, with some stuff that I'm not even sure is possible to do,  without any benefits.


Maybe I'm still not getting it. That is also quite possible :blush:  .
 It's entirely likely I'm out in left field, but the builder image would only have to be built once outside of openshift, then imported and re-used to build the project itself multiple times.

What this gets me as a developer is the ability to use my Dockerfile (which presumably isn't going to be changing as frequently as my code) to build a custom builder image for my project (yes, this would have to be built outside of openshift).  This will let me take advantage of s2i builds and build pipelines running entirely in openshift - which I can't do if I'm doing docker builds at least on OpenShift online and dedicated, and I don't have to learn how to create builder images which are kind of arcane and OpenShift-specific.

Ideally kompose would also have flags that tell it to generate build pipelines as well.
.
 > What this gets me as a developer is the ability to use my Dockerfile (which presumably isn't going to be changing as frequently as my code) to build a custom builder image for my project (yes, this would have to be built outside of openshift). This will let me take advantage of s2i builds and build pipelines running entirely in openshift - which I can't do if I'm doing docker builds at least on OpenShift online and dedicated, and I don't have to learn how to create builder images which are kind of arcane and OpenShift-specific.

OK, I can see your point. 

Only problem that I can see with this is that it will depend on how well is Dockerfile written. I'm afraid that it won't be possible to do it for any Dockerfile and Dockerfile will have to be written in specific way.
I'll try look into it. It might be interesting.


.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 As what @kadel I don't believe it makes sense to add this to Kompose. Since there hasn't been much discussion on this, let's close this issue and re-open if there is some interest..
 "
,,352,"add support for docker-compose.yaml besides docker-compose.yml.
 It would be great if kompose would also look for `docker-compose.yaml` besides `docker-compose.yml` in the current directory..
 I guess default should always be one value..
 @surajssd IIRC, docker-compose supports both, should we or not?.
 i guess we should!.
 @containscafeine @surajssd can any one of you assign it to me..
 "
,,351,"Improve logging messages in unit tests.
 If would be great if unit tests throw better log messages while bring run, this would help in better troubleshooting which tests are failing and which are passing..
 @surajssd , we can close this..
 Yup, This is merged..
 I don't think this is fixed, #350 was not for this issue..
 @containscafeine @surajssd can we close this?.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,350,"add stdin_open, tty support, add tests, fix #344.
 This adds supports for stdin_open: bool and
tty: bool support for kubernetes and openshift
providers in kompose. This maps to the
template.Spec.Containers[0].Stdin and
template.Spec.Containers[0].TTY in Kubernets
world.

Also, added tests.

Fixes #344.
 
[![Coverage Status](https://coveralls.io/builds/9434835/badge)](https://coveralls.io/builds/9434835)

Coverage increased (+0.2%) to 45.953% when pulling **21a44213e0fa9854601dfde43cdaef1c1dfe5590 on containscafeine:stdin_tty** into **73418310ac1e607b41d0af2588ed7a808a3c85fa on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9436378/badge)](https://coveralls.io/builds/9436378)

Coverage decreased (-0.06%) to 45.682% when pulling **f219cbdb1f9727cbeec3cb0fa8cea1113b3905b8 on containscafeine:stdin_tty** into **0370d66357ca3198f492457355b093356ba7d522 on kubernetes-incubator:master**.
.
 apart from those two comments LGTM!.
 
[![Coverage Status](https://coveralls.io/builds/9445088/badge)](https://coveralls.io/builds/9445088)

Coverage decreased (-0.06%) to 45.682% when pulling **6a151c6267204e9d2e990e7bace170b6dd38c0ec on containscafeine:stdin_tty** into **0370d66357ca3198f492457355b093356ba7d522 on kubernetes-incubator:master**.
.
 @containscafeine awesome work :+1: .
 "
,,349,"Tests before merge.
 After a maintainer does merge, tests should run with PR rebased with master, and if all tests pass then only merge should happen. I think this can be implemented with travis. .
 @surajssd I've gone ahead and enabled this within GitHub. Tests are now required to pass before merging in (can't merge in without travis being :green_heart: ).
 @cdrage awesome thing! .
 "
,,348,"Abstract out api.PodSpec in kubernetes.go.
 `api.PodSpec` is being used 4 times in `kubernetes.go` for RC, Deployment, DS and Pod generation.

Just putting it out there that this can be abstracted out..
 :+1: .
 @containscafeine taking this..
 "
,,347,"Flag validation called on up and down.
 On kompose up and kompose down flag validation
was done which is validating flags that are not there
in kompose up and kompose down.
 
[![Coverage Status](https://coveralls.io/builds/9434212/badge)](https://coveralls.io/builds/9434212)

Coverage remained the same at 45.739% when pulling **5625a978333a5b7f8bd3dc03948d9e21dbc4c250 on surajssd:up_down_no_validation_needed** into **73418310ac1e607b41d0af2588ed7a808a3c85fa on kubernetes-incubator:master**.
.
 @pradeepto thanks :+1: .
 "
,,346,"kubernetes_test.go and openshift_test.go follow different patterns.
 It would be great if `openshift_test.go` follows the same pattern as `kubernetes_test.go`. Currently the way the tests are written vary very differently, and I don't see the need for them to vary..
 What do you mean by very differently? 
They test different things, but otherwise they follow similar pattern in how they are written..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 "
,,345,"Show ""next steps"" after kompose convert.
 It would be great if we output a message relaying the ""what next"" information after `kompose convert` is run.

For e.g.
- If a `pvc` object is created, we should display something like ""you need to have a `pv` ready to use this object""
- In case of a missing port, ""you might want to expose this service manually since kompose could not detect a port""

Thoughts?.
 I agree with this, @surajnarwade has updated this in https://github.com/cdrage/kompose/commit/f88d48961d1a9db3a6173249f504c8412e2264ea however, I still think there could be some improvement. 

Tools such as Helm have *a lot* of logging output that describes all the steps after launching / using Helm..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,344,"support for stdin_open and tty keys.
 Hi,

My docker-compose.yml looks something like - 

```yaml
version: ""2""
services:
  client:
     image: registry.centos.org/centos/centos:7
     stdin_open: true
     tty: true
```

`kompose up` gives me -
```bash
WARN[0000] Unsupported stdin_open key - ignoring        
WARN[0000] Unsupported tty key - ignoring               
WARN[0000] [client] Service cannot be created because of missing port. 
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created Deployment: client      

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

Since these keys are unsupported, the pod goes from Running to Completed to CrashLoopBackOff

```bash
$ kubectl get pods -w
NAME                      READY     STATUS              RESTARTS   AGE
client-2474090665-o7wdc   0/1       ContainerCreating   0          1s
NAME                      READY     STATUS      RESTARTS   AGE
client-2474090665-o7wdc   0/1       Completed   0          1s
client-2474090665-o7wdc   0/1       Completed   1         2s
client-2474090665-o7wdc   0/1       CrashLoopBackOff   1         3s
client-2474090665-o7wdc   0/1       Completed   2         16s
```

It would be great if `stdin_open` and `tty` could be supported.

Here is the equivalent in Kubernetes world - 

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
...
spec:
...
  template:
    metadata:
    ...
    spec:
      containers:
      - stdin: true
        tty: true
        image: registry.centos.org/centos/centos:7
```.
 "
,,343,"fix unit tests that cause warnings.
 There are some unit tests that cause warnings which clutters the unit test output

```bash
✔ ~/go/src/github.com/kubernetes-incubator/kompose [master L|✔]
17:36 $ make test-unit
./script/make.sh test-unit
---> Making bundle: test-unit (in .)
?       github.com/kubernetes-incubator/kompose [no test files]
<snip>
       kubernetes_test.go:215: Test case: Convert to Ingress: label set to example.com
=== RUN   TestKomposeConvert
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
time=""2016-12-23T17:37:27+05:30"" level=warning msg=""Ignoring user directive. User to be specified as a UID (numeric).""
<snip>
```

.
 "
,,342,"kompose up/down not creating/deleting POD object generated with convert.
 .
 Hey @surajssd do you mind giving a test example? I'm trying to replicate this..
 what this is about?.
 @surajssd 
Is this issue about this?

```yaml
version: ""2""

services:
  foo:
    image: ""busybox""
    restart: ""on-failure""
    command: [""sleep"", ""30s""]
```

```
▶ kompose up       
WARN[0000] [foo] Service cannot be created because of missing port. 
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

FATA[0000] Error while deploying application: Deployment.extensions ""foo"" is invalid: spec.template.spec.restartPolicy: Unsupported value: ""OnFailure"": supported values: Always 
```
.
 here is the docker-compose file i am using
```yaml
$ cat docker-compose.yml 
version: ""2""

services:
  mariadb:
    image: centos/mariadb
    restart: ""no""
```


when doing convert
```bash
$ kompose convert
INFO[0000] file ""mariadb-pod.json"" created
```

when doing up nothing is created
```bash
$ kompose up                                                                                                                                                               
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 


Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods,pvc' for details.
```

sorry for incomplete info above..
 fixed in #363 .
 "
,,341,"updated dev docs with latest instructions.
 cleaned up development docs to have latest changes.
 
[![Coverage Status](https://coveralls.io/builds/9318300/badge)](https://coveralls.io/builds/9318300)

Coverage remained the same at 35.491% when pulling **cc493058f3496d1569a0c999c210d987401f6f60 on surajssd:build_instructions_update** into **7bda85707976cbbfe16b5d4b0e349e0e47608c6c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9515538/badge)](https://coveralls.io/builds/9515538)

Coverage remained the same at 46.617% when pulling **3decdd7fc9dfda0215c6905dee144c1ea6180c43 on surajssd:build_instructions_update** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 "
,,340,"update vendored dependencies.
 .
 
[![Coverage Status](https://coveralls.io/builds/9312916/badge)](https://coveralls.io/builds/9312916)

Coverage remained the same at 35.491% when pulling **10299eb5dc619d48c24ff103e391a851c1e73ba1 on surajssd:update_broken_master** into **4dd31da6e4a262f7c333e975bb3ccfad8ccf86d4 on kubernetes-incubator:master**.
.
 Tested! .
 "
,,339,"make YAML the default kompose conversion .
 FIX #306 

cc @kadel @surajssd 

```bash
$ kompose convert
INFO[0000] file ""mlbparks-service.yaml"" created         
INFO[0000] file ""mongodb-service.yaml"" created          
INFO[0000] file ""mlbparks-deployment.yaml"" created      
INFO[0000] file ""mongodb-deployment.yaml"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.yaml"" created 
```

```bash
$ kompose convert -j
INFO[0000] file ""mlbparks-service.json"" created         
INFO[0000] file ""mongodb-service.json"" created          
INFO[0000] file ""mlbparks-deployment.json"" created      
INFO[0000] file ""mongodb-deployment.json"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.json"" created
```.
 Still waiting for https://github.com/kubernetes-incubator/kompose/pull/304 to be merged too :(.
 @cdrage How long do we have to wait for #304 to get merged. I have to update this PR once #304 gets merged :).
 @procrypt no idea, depending on the reviews, if you can review it too + test it, that'll speed up the process  :).
 @cdrage I'm on it 😃 .
 @procrypt so we don't remove a flag, we will add another flag for json output, default output to yaml and also there is a way in cmdline framework to mention what flag is gonna be deprecated. Remove flag of yaml right away might break things..
 @surajssd @containscafeine @cdrage @pradeepto I have updated the PR. Please review.
```bash
$ kompose convert
INFO[0000] file ""mlbparks-service.yaml"" created         
INFO[0000] file ""mongodb-service.yaml"" created          
INFO[0000] file ""mlbparks-deployment.yaml"" created      
INFO[0000] file ""mongodb-deployment.yaml"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.yaml"" created
```
```bash
$kompose convert -j
Flag --json has been deprecated, use --yaml or -y
INFO[0000] file ""mlbparks-service.json"" created         
INFO[0000] file ""mongodb-service.json"" created          
INFO[0000] file ""mlbparks-deployment.json"" created      
INFO[0000] file ""mongodb-deployment.json"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.json"" created
```.
 
[![Coverage Status](https://coveralls.io/builds/9445641/badge)](https://coveralls.io/builds/9445641)

Coverage remained the same at 45.682% when pulling **fa36f31852650744f6391e08c2a2ad2b8ab3522a on procrypt:default_yaml** into **c80735c1a597d10cb8d5126484b1ef6dfb5d84a0 on kubernetes-incubator:master**.
.
 @procrypt for making tests work you will have to add `-j` flag in all the cmd tests. Right now it creates default json so there was no flag, with your changes you will have to add that to all the tests..
 @surajssd Since we want the default conversion to be in `yaml` and the output of all the tests is in `json` format. I was thinking to replace all the test output from `json` to `yaml`, instead of adding the `-j` flag.
WDYT ?.
 
[![Coverage Status](https://coveralls.io/builds/9457179/badge)](https://coveralls.io/builds/9457179)

Coverage remained the same at 46.582% when pulling **b102e1a44bf3f276baf91e17e87a49502889c42a on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9457284/badge)](https://coveralls.io/builds/9457284)

Coverage remained the same at 46.582% when pulling **fe800ab8032019d8bcf052154cf33f1495a2e760 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9457314/badge)](https://coveralls.io/builds/9457314)

Coverage remained the same at 46.582% when pulling **fe800ab8032019d8bcf052154cf33f1495a2e760 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 Just to be sure check if user is not giving -y and -j simultaneously..
 @surajssd Added the check for not providing -y and -j simultaneously..
 
[![Coverage Status](https://coveralls.io/builds/9489079/badge)](https://coveralls.io/builds/9489079)

Coverage remained the same at 46.582% when pulling **88c87a302230c9ea16cbad7ae63a86d4a7589420 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495239/badge)](https://coveralls.io/builds/9495239)

Coverage remained the same at 46.582% when pulling **dddc533cfed2d6e491c84e489d068d5c8c0cfde3 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9496196/badge)](https://coveralls.io/builds/9496196)

Coverage remained the same at 46.582% when pulling **92bb3b80184dbd6c72359e00b0074e416a60c4ad on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9496214/badge)](https://coveralls.io/builds/9496214)

Coverage remained the same at 46.582% when pulling **92bb3b80184dbd6c72359e00b0074e416a60c4ad on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9496267/badge)](https://coveralls.io/builds/9496267)

Coverage remained the same at 46.582% when pulling **d8ae85a654657e875ce70e5231c13f53e5e8962e on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9496305/badge)](https://coveralls.io/builds/9496305)

Coverage remained the same at 46.582% when pulling **6c5174b5f78bc126c2b872bc653cc5f94580b3f3 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9497258/badge)](https://coveralls.io/builds/9497258)

Coverage remained the same at 46.582% when pulling **eb08a34d22a324680181551e1ef0733551ef5bb7 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9497387/badge)](https://coveralls.io/builds/9497387)

Coverage remained the same at 46.582% when pulling **a1af9dc2cb1c3295afa102934f82b75bc29d712f on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9497648/badge)](https://coveralls.io/builds/9497648)

Coverage remained the same at 46.582% when pulling **6995a695283b1a0356b8330fb962f75d53eae1c5 on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9498693/badge)](https://coveralls.io/builds/9498693)

Coverage remained the same at 46.582% when pulling **f49b93d91dd4e1288435b5b4c5d6c353dee97f7c on procrypt:default_yaml** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 @procrypt  code LGTM, one last bit of update docs: https://github.com/kubernetes-incubator/kompose/blob/master/docs/user-guide.md and https://github.com/kubernetes-incubator/kompose#use-case.
 
[![Coverage Status](https://coveralls.io/builds/9499721/badge)](https://coveralls.io/builds/9499721)

Coverage remained the same at 46.617% when pulling **4ab3303468877f9edc6d9f75f5bbf6c92014f2a2 on procrypt:default_yaml** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 @procrypt Tests need to be converted to check against yaml instead..
 
[![Coverage Status](https://coveralls.io/builds/9511452/badge)](https://coveralls.io/builds/9511452)

Coverage remained the same at 46.617% when pulling **d17edbb8b65abdbff4f74edf9c19fa68c658fe25 on procrypt:default_yaml** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9512394/badge)](https://coveralls.io/builds/9512394)

Coverage remained the same at 46.617% when pulling **cfcbfa8c6d52b57fceb011ee4a198efd0733f28e on procrypt:default_yaml** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 @procrypt thanks for awesome work :+1: :tada: .
 "
,,338,"#231 Invoking kompose --bundle X.dab convert --stdout will produce tw….
 …o differently ordered results.
 
[![Coverage Status](https://coveralls.io/builds/9285935/badge)](https://coveralls.io/builds/9285935)

Coverage increased (+0.4%) to 35.387% when pulling **39488b910eca1fc5a42b572bc78fa0aa688f6b19 on cab105:dab-ordering** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 Whoopsie.  Knew I needed another cup of coffee before pushing..
 
[![Coverage Status](https://coveralls.io/builds/9304057/badge)](https://coveralls.io/builds/9304057)

Coverage increased (+0.4%) to 35.891% when pulling **24cbd52475088e888e6e345895eede3c5f659b0e on cab105:dab-ordering** into **78845d3954aa93f9a5dc36f76f12bb08d7bdba4f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9304759/badge)](https://coveralls.io/builds/9304759)

Coverage increased (+0.4%) to 35.891% when pulling **01f7e8903e280acb168cf08e057f3c8e84704aed on cab105:dab-ordering** into **78845d3954aa93f9a5dc36f76f12bb08d7bdba4f on kubernetes-incubator:master**.
.
 Normally yes, however this bug was the result of adding in unit tests for dab/dsb support (See #241).
 @cab105 ah k, merge away then? :+1: .
 @cdrage.  Unfortunately blocked.  Will need @ngtuna to bless this..
 @cab105 Done. Go ahead man :-).
 Thanks @ngtuna!.
 "
,,337,"implement storing to directory or file, add functional tests.
 Fix #209 
.
 wow Travis has still not started build, its more than hour now!.
 
[![Coverage Status](https://coveralls.io/builds/9284516/badge)](https://coveralls.io/builds/9284516)

Coverage decreased (-0.7%) to 34.208% when pulling **be1efb2719b56b8d10fe73485f76c16eeed36b4c on containscafeine:output_file_dir** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9298008/badge)](https://coveralls.io/builds/9298008)

Coverage increased (+0.5%) to 36.009% when pulling **f1e3a7f9f8fa2870abc65250571e4fc84eb386fc on containscafeine:output_file_dir** into **78845d3954aa93f9a5dc36f76f12bb08d7bdba4f on kubernetes-incubator:master**.
.
 It looks like the commit message is empty? I only see a title in there..
 @cdrage, whoops, fixed!.
 
[![Coverage Status](https://coveralls.io/builds/9303664/badge)](https://coveralls.io/builds/9303664)

Coverage increased (+0.5%) to 36.009% when pulling **dac70d8efde633435b106ebe61e500bcd801e1d8 on containscafeine:output_file_dir** into **78845d3954aa93f9a5dc36f76f12bb08d7bdba4f on kubernetes-incubator:master**.
.
 LGTM!.
 Code LGTM, however @containscafeine mind explaining a little bit on the usage (how to use?). Seeing if we need to update the docs for this change :).
 
[![Coverage Status](https://coveralls.io/builds/9361035/badge)](https://coveralls.io/builds/9361035)

Coverage increased (+0.5%) to 38.939% when pulling **a782a5eda4b98bc61c81af7f0d0b784196144f4e on containscafeine:output_file_dir** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @surajssd @cdrage updated the usage for the flag -o. Should be good to go now?.
 
[![Coverage Status](https://coveralls.io/builds/9376994/badge)](https://coveralls.io/builds/9376994)

Coverage increased (+0.5%) to 38.939% when pulling **365fe819877ec56e26a63aa09630dd524dddb90b on containscafeine:output_file_dir** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @containscafeine thanks merging it! .
 "
,,336,"yml support.
 Do you guys plan to bring support for yaml files. Currently `kompose` generates JSON files only..
 Hi @vasil-moneybird 

Kompose already supports conversion to YAML format. Use the `-y` switch to the commandline and  read more about it in the user [guide](https://github.com/kubernetes-incubator/kompose/blob/master/docs/user-guide.md). 

And here's the [issue]( https://github.com/kubernetes-incubator/kompose/issues/306) for converting to YAML as default.
.
 Cool thanks, I guess I didn't search enough :).
 "
,,335,"Support for host:container:protocol.
 Marked as fixed in #158 but I still get the same error.

Definition in docker-compose file:
ports:
  - 127.0.0.1:15000:15000/tcp
  - 127.0.0.1:15001:15001/udp

FATA[0000] ""agent"" failed to load ports from compose file: invalid host port ""127.0.0.1:15000:15000/tcp""

root@350035d7afc9:/compose# kompose -v
kompose version 0.1.2 (92ea047)

Let me know if I'm missing something..
 @OguzPastirmaci 

Yup. This looks like an error, we're testing against:

```
- ""5000:5000/tcp""
```

but
```
- ""127.0.0.1:5000:5000/tcp""
```

doesn't work and this:

```
test/fixtures/ports-with-proto  master ✗                                                                                                                                                                                                                                4h34m ⚑  
▶ kompose convert
FATA[0000] ""web"" failed to load ports from compose file: invalid host port ""127.0.0.1:5000:5000/tcp"" 
```

errors out.

I'll see what we can do for a fix..
 Hey @ngtuna @kadel 

Adding IP mapping via the port makes the *most* sense in regards to mapping to ClusterIP / LoadBalancerIP.

Would make things *awesome* in regards to scenarios of specifying certain IP addressing for each service.

Here's an example:

```
services:                                                                                                                                                                                                                                                                         
    web:                                                                                                                                                                                                                                                                          
      image: tuna/docker-counter23                                                                                                                                                                                                                                                
      ports:                                                                                                                                                                                                                                                                      
        - ""10.10.10.1:5000:5000/tcp""                                                                                                                                                                                                                                               
      links:                                                                                                                                                                                                                                                                      
        - redis                                                                                                                                                                                                                                                                   
      networks:                                                                                                                                                                                                                                                                   
        - default  
```

Converts to:

```
    {                                                                                                                                                                                                                                                                             
      ""kind"": ""Service"",                                                                                                                                                                                                                                                          
      ""apiVersion"": ""v1"",                                                                                                                                                                                                                                                         
      ""metadata"": {                                                                                                                                                                                                                                                               
        ""name"": ""web"",                                                                                                                                                                                                                                                            
        ""creationTimestamp"": null,                                                                                                                                                                                                                                                
        ""labels"": {                                                                                                                                                                                                                                                               
          ""service"": ""web""                                                                                                                                                                                                                                                        
        }                                                                                                                                                                                                                                                                         
      },                                                                                                                                                                                                                                                                          
      ""spec"": {                                                                                                                                                                                                                                                                   
        ""ports"": [                                                                                                                                                                                                                                                                
          {                                                                                                                                                                                                                                                                       
            ""name"": ""5000"",                                                                                                                                                                                                                                                       
            ""protocol"": ""TCP"",                                                                                                                                                                                                                                                    
            ""port"": 5000,                                                                                                                                                                                                                                                         
            ""targetPort"": 5000                                                                                                                                                                                                                                                    
          }                                                                                                                                                                                                                                                                       
        ],
       ""clusterIP"": ""10.10.10.1"",                                                                                                                                                                                                                                                                        
        ""selector"": {                                                                                                                                                                                                                                                             
          ""service"": ""web""                                                                                                                                                                                                                                                        
        }                                                                                                                                                                                                                                                                         
      },                                                                                                                                                                                                                                                                          
      ""status"": {                                                                                                                                                                                                                                                                 
        ""loadBalancer"": {}                                                                                                                                                                                                                                                        
      }                                                                                                                                                                                                                                                                           
    },   
```

See __10.10.10.1__

Does this make sense?

Or should we warn the user instead that it's not supported?.
 @cdrage Does docker-compose have that kind of port format ? And is that a real use-case user want to have a fixed IP address for k8s service clusterIP ?.
 @ngtuna Yes, the definition in a Docker-Compose file uses the ip:port:port format. Fixed IP address in a cluster is necessary if you have a pool of IP addresses and want to use them. This suggestion would be the easiest way to have 1-1 conversion between compose and k8s..
 Yeah I didn't notice that format. Can we warranty reusing that IP address for k8s clusterIP will work ? I remember when setting up k8s cluster, a clusterIP range is defined. I would suggest while accepting that port format we shouldn't set the clusterIP address..
 > I would suggest while accepting that port format we shouldn't set the clusterIP address.

@ngtuna :+1: .
 Shouldn't this IP address map to `hostIP` in [ContainerPort](https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_containerport)?.
 @kadel You're right. That'd be a better place to put it..
 "
,,334,"support for raw pod output without controller.
 if a user specifies a docker-compose service with restart value as ""no"" or ""on-failure"" then normal pod will be created as against to a controller and a pod..
 
[![Coverage Status](https://coveralls.io/builds/9235971/badge)](https://coveralls.io/builds/9235971)

Coverage decreased (-0.8%) to 34.256% when pulling **66ce7c141d9011afb6bba46125cd940933491df5 on surajssd:create_pod** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9239806/badge)](https://coveralls.io/builds/9239806)

Coverage decreased (-0.8%) to 34.256% when pulling **921d9368d3c74bc1cf4e30fedcacf61d7281968a on surajssd:create_pod** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9242522/badge)](https://coveralls.io/builds/9242522)

Coverage increased (+1.9%) to 36.812% when pulling **905be2605266ff6008af50b61c7ab1d3d4f50a54 on surajssd:create_pod** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 ping @ngtuna @sebgoa .
 
[![Coverage Status](https://coveralls.io/builds/9256110/badge)](https://coveralls.io/builds/9256110)

Coverage increased (+1.9%) to 36.812% when pulling **ca0bd9082cafc1bfbc5a6f3c34f549cf403fcb82 on surajssd:create_pod** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 @surajssd LGTM. Just notice github provided `Reviewers` button for requesting a review from specific person(s)..
 
[![Coverage Status](https://coveralls.io/builds/9257576/badge)](https://coveralls.io/builds/9257576)

Coverage increased (+1.9%) to 36.812% when pulling **6ea5f72e40b70df94a81e0ccb7967080c2347ef2 on surajssd:create_pod** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 @ngtuna thanks for review, yes will use that reviewers button next time..
 @ngtuna thanks fore review, merging :+1: .
 "
,,333,"Fix container_name incorrectly being generated.
 Checks to see if ""container_name"" is used correctly in a docker-compose
file conversion and updates the changes respectively in the outputted
artifact files.

For example with container_name set as myfoobarname, the change will
correctly update the ""containerNames"" portion of the deployment-config
for OpenShift.

""imageChangeParams"": {
  ""automatic"": true,
  ""containerNames"": [
    ""myfoobarname""
  ],
  ""from"": {
    ""kind"": ""ImageStreamTag"",
    ""name"": ""rabbit:3.6.1""
  }
}

Closes https://github.com/kubernetes-incubator/kompose/issues/301.
 
[![Coverage Status](https://coveralls.io/builds/9194265/badge)](https://coveralls.io/builds/9194265)

Coverage decreased (-0.06%) to 34.954% when pulling **ee2946c810082be662b59b91b8245f8fae3717a5 on cdrage:namespace-bug** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 @surajssd @kadel Can you guys have a look at this one?.
 LGTM, @cdrage but need to satisfy coveralls :(.
 Coveralls is OK, don't trust that number.  ;-)

It decreased because there were no tests before ;-).
 @kadel but merging is blocked !.
 @surajssd as part of your review, you have to approve changes. see  https://help.github.com/articles/about-pull-request-reviews/.
 "
,,332,"Update RPM instalaion instructions in README.md.
 .
 LGTM.
 
[![Coverage Status](https://coveralls.io/builds/9174870/badge)](https://coveralls.io/builds/9174870)

Coverage remained the same at 35.01% when pulling **25200cf418df8b10de1a887703cefeb09632a4ef on kadel-patch-1** into **862419b8366e15caf3d43d051b18bc024242c063 on master**.
.
 Someone has to approve review, It won't let me to merge it :-).
 "
,,331,"Removing unconventional two letter flags + adding dashes in-between two letter words..
 Using multi-two-letter flags is unconventional and against common CLI usages.

For example:

```
   --replicationcontroller, --rc        Generate a Kubernetes replication controller object
```

Should either be JUST `--rc` or `--replicationcontroller`.

Ideally, flags with two names should have dashes in between them, such as `--replication-controller`.

Common CLI tools such as `kubectl` and `oc` use these conventions and considering most of the users are coming from these tools, we should follow suit.

PR is available here with these changes: #304 .
 Kubectl example using two-letter words with dashes:
```
      --dry-run=false: If true, only print the object that would be sent, without sending it.
      --generator='deployment-basic/v1beta1': The name of the API generator to use.
      --image=[]: Image name to run.
      --no-headers=false: When using the default or custom-column output format, don't print headers.
  -o, --output='': Output format. One of: json|yaml|wide|name|custom-columns=...|custom-columns-file=...|go-template=...|go-template-file=...|jsonpath=...|jsonpath-file=... See custom columns [http://kubernetes.io/docs/user-guide/kubectl-overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [http://kubernetes.io/docs/user-guide/jsonpath].
      --output-version='': Output the formatted object with the given group version (for ex: 'extensions/v1beta1').
      --save-config=false: If true, the configuration of current object will be saved in its annotation. This is useful when you want to perform kubectl apply on this object in the future.
      --schema-cache-dir='~/.kube/schema': If non-empty, load/store cached API schemas in this directory, default is '$HOME/.kube/schema'
  -a, --show-all=false: When printing, show all resources (default hide terminated pods.)
      --show-labels=false: When printing, show all labels as the last column (default hide labels column)
      --sort-by='': If non-empty, sort list types using this field specification.  The field specification is expressed as a JSONPath expression (e.g. '{.metadata.name}'). The field in the API resource specified by this JSONPath expression must be an integer or a string.
      --template='': Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
      --validate=true: If true, use a schema to validate the input before sending it
```

And when referencing replication controller, it's conventionally used with a dash in-between the words:

```
SubobjectPath	Reason			Message
  Thu, 24 Sep 2015 10:38:20 -0700	Thu, 24 Sep 2015 10:38:20 -0700	1
{replication-controller }			SuccessfulCreate	Created pod: nginx-qrm3m
  Thu, 24 Sep 2015 10:38:20 -0700	Thu, 24 Sep 2015 10:38:20 -0700	1
{replication-controller }			SuccessfulCreate	Created pod: nginx-3ntk0
  Thu, 24 Sep 2015 10:38:20 -0700	Thu, 24 Sep 2015 10:38:20 -0700	1
{replication-controller }			SuccessfulCreate	Created pod: nginx-4ok8v
```.
 Okay since #304 was merged, this can be closed..
 "
,,330,"Improve coveralls.io reporting.
 Packages that don't have any tests are not included in coveralls report.

We should find a way how to include them in reports, so we have accurate coverage number.

.
 Workaround might be creating one empty *_test.go file in every package.
 .
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,329,"Report code coverage to coveralls.
 quick fix for Coveralls problem 
#287 .
 LGTM.
 lets wait untill travis job finishes.

I only tested this on my fork..
 
[![Coverage Status](https://coveralls.io/builds/9170350/badge)](https://coveralls.io/builds/9170350)

Changes Unknown when pulling **373ab369469141bb96eb72761f756d80ee6c498b on kadel:coveralls-fix** into ** on kubernetes-incubator:master**.
.
 Wheeee, it works ;-)

Only down side is that number it reports is  coverage of lines from files that have tests.
So packages without any tests are not included in this.



.
 This was quickest solution that I could think of. 
It would be great to get something little bit cleaner..
 "
,,328,"Get kompose in kubernetes repo.
 kubeadm can be installed via:

```
# cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://yum.kubernetes.io/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
       https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
# setenforce 0
# yum install -y docker kubelet kubeadm kubectl kubernetes-cni
# systemctl enable docker && systemctl start docker
# systemctl enable kubelet && systemctl start kubelet
```

We need to get kompose in the pipeline to get added there.

.
 @dustymabe is kompose in main EPEL repo now ?.
 Probably after incubator graduation?.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 @dustymabe is kompose in main EPEL repo now ?

yes it is in epel.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,327,"Determine group membership.
 Currently it seems that I cannot add folks to the contributor group.

We need a group that can attache labels, and assign tickets to themselves.

+ determine who gets write access to the repo.

There is no incubator wide rules on this afaik..
 @sebgoa As team maintainer, you can add team members, you just can't add org members -- only org owners can do that.

Related:
https://github.com/kubernetes/community/issues/142

Any ideas, @philips?.
 https://help.github.com/articles/adding-organization-members-to-a-team/.
 I always feel stupid with these...but, since I am not an org owner I cannot send an invite to a non-org member. Even if I am the team maintainer, I can only invite org members.

we are trying to add @cdrage , ideally to just give permissions to add labels and assign issues to himself. But I don't think there is that granularity in teams.


.
 cc @grodrigues3 @fejta.
 Sorry about that missed clicking.
 Invited @cdrage to org..
 "
,,326,"Add ROADMAP.md move current road map information.
 Adds ROADMAP.md to the root directory with milestone links to all
upcoming major releases.

Closes https://github.com/kubernetes-incubator/kompose/issues/250.
 "
,,325,"[WIP] Mapping for docker-compose to k8s and openshift conversion.
 WIP for #82 

cc @kadel .
 @procrypt Should we close this for now or are you still working on it?.
 @cdrage Yes we can close this..
 "
,,324,"Unsupported keys per provider.
 Separate unsupported keys based on provider..
 #206 is blocked on this..
 Can we have unit tests for this, please ?.
 @sebgoa for sure. It is not going to be merged without it..
 
[![Coverage Status](https://coveralls.io/builds/9211647/badge)](https://coveralls.io/builds/9211647)

Changes Unknown when pulling **fcb8352a4e99b6b6c618e6927ba3e2963fe52bc8 on rtnpro:unsupported-keys-per-provider** into ** on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9238681/badge)](https://coveralls.io/builds/9238681)

Changes Unknown when pulling **e1d88f737e0698bb4f649092f69974e8b4fdeac0 on rtnpro:unsupported-keys-per-provider** into ** on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9240231/badge)](https://coveralls.io/builds/9240231)

Coverage increased (+3.2%) to 38.242% when pulling **1e5d5e3465812a370b5085590bb44d708551dc63 on rtnpro:unsupported-keys-per-provider** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 @ngtuna your say here will be appreciated!.
 
[![Coverage Status](https://coveralls.io/builds/9301746/badge)](https://coveralls.io/builds/9301746)

Coverage increased (+2.5%) to 38.005% when pulling **2e40f45b192ff169e3ba94cda40548ccf1fc87e4 on rtnpro:unsupported-keys-per-provider** into **78845d3954aa93f9a5dc36f76f12bb08d7bdba4f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9354571/badge)](https://coveralls.io/builds/9354571)

Coverage increased (+0.7%) to 39.184% when pulling **e3ef7480f59d3b058ceb6127d0aa18da2a7158a2 on rtnpro:unsupported-keys-per-provider** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9357742/badge)](https://coveralls.io/builds/9357742)

Coverage increased (+2.006%) to 40.492% when pulling **3419ae7fe17e7ff2d8e4fb79d0a9d9b560c7bb35 on rtnpro:unsupported-keys-per-provider** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @surajssd rebased and ready for merging..
 @rtnpro @kadel  Thanks :+1: .
 "
,,323,"Functional tests for OpenShift down.
 Need functional tests for #280 .
 Shouldn't this be addressed in the PR? Why the extra issue?.
 Almost all code in this touches OpenShift cluster.
To test this, it will require setting up OpenShift cluster or mocking its api.

The same situation is with up/down for k8s. We will have to figure out how we will test all this.

We don't want to block PR on that. So @procrypt  created this separate issue..
 @cdrage @kadel, we can close this issue as functional tests are being added for `kompose down` by @ashetty1 .
 "
,,322,"Added installation instructions of rpm.
 kompose is packaged for CentOS and Fedora, so added easy installation
instructions..
 I see this was merged, but I disagree with it.

We cannot ask people to add an openshift repo to install a kubernetes tool. It is confusing to users.

We should:

* either point to standard EPEL if it is there
* or put kompose in the k8s repo like kubeadm
* then put the openshift repo as an alternative install strategies.
.
 @sebgoa OK, I see your point.

I did't realize that kompose is in EPEL.
@surajssd  Why did you use centos-release-openshift-origin and not epel-release?

.
 "
,,321,"IntelliJ IDE .gitignore.
 added .gitignore for IntelliJ IDE files.
 "
,,320,"kompose errors identifying string in docker-compose.
 when using docker-compose file 
```yaml
version: ""2"" 
services:
  mariadb:
    image: centos/mariadb
    restart: no
```

failed saying val should be string
```bash
$ kompose convert --stdout > /dev/null 
ERRO[0000] Could not parse config for project onfailure : Service 'mariadb' configuration key 'restart' contains an invalid type, it should be a string. 
FATA[0000] Failed to load compose file: Service 'mariadb' configuration key 'restart' contains an invalid type, it should be a string. 
$ echo $?
1
```

but this works fine

```yaml
version: ""2"" 
services:
  mariadb:
    image: centos/mariadb
    restart: on-failure
```

```bash
$ kompose convert --stdout > /dev/null 
WARN[0000] [mariadb] Service cannot be created because of missing port.
$ echo $?
0
```


also this works fine

```yaml
version: ""2"" 
services:
  mariadb:
    image: centos/mariadb
    restart: ""no""
```
.
 I think that this might be an issue with libcompose.  
Does `restart: no` works with `docker-compose`?.
 @kadel found the issue, it reads `no` as boolean this is inherent to `yaml`

>A Boolean represents a true/false value. Booleans are formatted as English words (“true”/“false”, “yes”/“no” or “on”/“off”) for readability and may be abbreviated as a single character “y”/“n” or “Y”/“N”.

Source: http://yaml.org/type/bool.html.
 Closing since we cannot do anything with the yaml spec..
 "
,,319,"Switch from godep to glide.
 fixed #314

I tried to use Glide instead of Godep, setting up was surprisingly easy.
With only one catch: You need to run `glide update` with `--strip-vendor` otherwise glide keeps vendor directories inside kompose vendor dir (`/vendor/.../vendor/...`) In some project this can be useful, but kompose can't be build whit this.
Overall I really like glide.

**But** (there is always but :sunglasses: )
It looks like glide is not striping unused code from vendored dependencies , like godep does.
with glide vendor is **277M** :-(
with godep it was **52M**

https://github.com/sgotti/glide-vc might help with that. (haven't tried yet)
Or we can remove vendor from git as @ngtuna suggested [here](https://github.com/kubernetes-incubator/kompose/pull/297#issuecomment-263586556). But I expressed my view there. I think it is better to keep vendor in project repo..
 I am +1 on keeping `vendor` dir as it is and not removing it from kompose..
 So with this PR should we delete the PR #297 ?.
 So there is a reason why glide doesn't strip dependencies. 
It is explained here http://engineeredweb.com/blog/2016/go-why-not-strip-unused-pkgs/
But I don't know if that is valid point or not.

Maybe @sebgoa has opinion on that?.
 updated this PR with glide-vc cleanup.
vendor is now 32M.
 I will add some docs to this PR explaining how to add and update dependencies .
 you'll probably want to squash those commits, or git will still track the removed objects..
 @ericchiang yes that is the plan, I will definitely squash this before merge.

@ngtuna I'll add short docs and probably scripts that will wrap glide and glide-vc. Than I'll ping you for another review. :wink: .
 I've added docs and scripts that validate if vendor is clean.

It is ready for another review.
ping @ngtuna 

.
 @technosophos could you advise us with this ?.
 
[![Coverage Status](https://coveralls.io/builds/9174841/badge)](https://coveralls.io/builds/9174841)

Coverage remained the same at 35.01% when pulling **a0ba435efb6686e945682bd5cae049c26cc0169a on kadel:glide** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 /cc @mattfarina (who volunteered to look at this on SIG-Apps).

This looks good to me. If you're checking in vendor, then glide-vc is a great way to manage that. And everything else looks great..
 @technosophos so can we go ahead with merging this?.
 I have no reason to object to merging this, though I'm not a core maintainer on this project..
 @surajssd I think we can let it passed now. @kadel can you merge?.
 @ngtuna He's away until after the new year, so you'll have to merge or we could wait until he's back :).
 @technosophos @ngtuna @cdrage thank you merging this in..
 oh I see. So could you also take a look into #317 @surajssd @cdrage ?.
 "
,,318,"restart: Unsupported value: ""OnFailure"": supported values: Always .
 Using this docker-compose file

```yaml
$ cat docker-compose.yml 
version: ""2""
services:
  mariadb:
    image: centos/mariadb
    restart: on-failure
```

which fails as
```bash
$ kompose up
WARN[0000] [mariadb] Service cannot be created because of missing port. 
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

FATA[0000] Error while deploying application: Deployment.extensions ""mariadb"" is invalid: spec.template.spec.restartPolicy: Unsupported value: ""OnFailure"": supported values: Always 
```

when converted it looks like this:

```yaml
$ cat mariadb.yml 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  name: mariadb
spec:
  replicas: 1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        service: mariadb
    spec:
      containers:
      - image: centos/mariadb
        name: mariadb
        resources: {}
      restartPolicy: OnFailure
status: {}
```

so this cannot be `OnFailure` it always has to be `Always` which stops us from using `docker-compose`'s `restart: on-failure` to simulate kubernetes jobs..
 So I tried this in continuation with discussion at https://github.com/kubernetes-incubator/kompose/issues/236#issuecomment-262592263.
 But this is perfectly valid thing 
```yaml
$ cat pod-maria.yml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  name: mariadb
spec:
  containers:
  - image: centos/mariadb
    name: mariadb
  restartPolicy: OnFailure
```

a pod without controller can have `restartPolicy` as `OnFailure`.
 I'm afraid that this doesn't have easy solution.
I don't think that we can create just pod if there is `restartPolicy: on-failure` in docker-file.

But we could get away with just ignoring it, and showing warning explaining that this is ignored and `Always` will be used instead)




.
 >But we could get away with just ignoring it, and showing warning explaining that this is ignored and Always will be used instead)

@kadel but then this is not solving our original problem of how do we simulate k8s-job like workflow with kompose and docker-compose?.
 I'm not even sure if we should simulate Kubernetes job workflow with kompose and docker-compose.

You are proposing creating Job if there is `restart: on-failure`?.
 so with #334 pod will be created instead of Job if there is `restart: on-failure`..
 @ngtuna yes you are right!.
 With https://github.com/kubernetes-incubator/kompose/pull/334 merged this issue is solved..
 "
,,317,"support parse key-only environment variable.
 fix #303 
.
 :+1: 
But can you please also add unit test for this?.
 yeah, let's blocked everything until we get in the habit of making sure we have unit tests....
 ok so @kadel I added the unit test. Please take a look..
 
[![Coverage Status](https://coveralls.io/builds/9287543/badge)](https://coveralls.io/builds/9287543)

Coverage increased (+2.1%) to 37.093% when pulling **fdc47a4d6f5ddc85332264e633401bea068cfa0c on ngtuna:env-key-only** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9287670/badge)](https://coveralls.io/builds/9287670)

Coverage increased (+2.1%) to 37.093% when pulling **fdc47a4d6f5ddc85332264e633401bea068cfa0c on ngtuna:env-key-only** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 Tks @cdrage Rebased!.
 
[![Coverage Status](https://coveralls.io/builds/9315078/badge)](https://coveralls.io/builds/9315078)

Coverage increased (+2.0%) to 37.481% when pulling **8253805a14dfa156b10ada72898fda4bc28f972e on ngtuna:env-key-only** into **7bda85707976cbbfe16b5d4b0e349e0e47608c6c on kubernetes-incubator:master**.
.
 LGTM :+1: .
 @cdrage please approve again then I can merge it..
 @ngtuna I can approve, but since I still don't have access to @kubernetes-incubator it wont appear as :+1: / green..
 @cdrage I see :-(.
 @ngtuna  Also three more conditions that are not tested: 

```bash
env: ""foo:bar=foobar""     name: ""foo"" val: ""bar=foobar""
env: ""foo=foo:bar""        name: ""foo"" val: ""foo:bar""

env: ""foo:""               name: ""foo"" val: """"
```

otherwise LGTM.
 @surajssd Added and rebased. Please take a look and approve if it's okay for you..
 
[![Coverage Status](https://coveralls.io/builds/9338507/badge)](https://coveralls.io/builds/9338507)

Coverage increased (+2.6%) to 38.485% when pulling **7556f6f9fa4e4ac47a4f2bbe984796e34a0abb8d on ngtuna:env-key-only** into **072d4815ee48b31aeb7261e4d5c08dd506e91a3e on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9338512/badge)](https://coveralls.io/builds/9338512)

Coverage increased (+2.6%) to 38.485% when pulling **7556f6f9fa4e4ac47a4f2bbe984796e34a0abb8d on ngtuna:env-key-only** into **072d4815ee48b31aeb7261e4d5c08dd506e91a3e on kubernetes-incubator:master**.
.
 "
,,316,"Add release script.
 This adds a release script automating the changelog, notes as well as
release (to GitHub) via the CLI / a simple script.

The caveat is the next release will have to have `v` removed from the
title in order for `changelog()` function to work correctly.

Some changes to all upcoming releases are:
 - Using `git shortlog` instead of
   https://github.com/skywinder/Github-Changelog-Generator.
 @ngtuna This will change a lot in regards to releases:

- faster (people can just `cd script` and run `./release.sh`
- using `git shortlog` instead of https://github.com/skywinder/Github-Changelog-Generator
- removing `v` from versions. instead of `v1.0.0` it'd be just `1.0.0` this can be changed to include `v` if you wish, it's just a developer preference.
- can do release from the `cli` only
- gpg signed releases with .asc key.
 @cdrage sounds great. Thanks. I will try it..
 > removing v from versions. instead of v1.0.0 it'd be just 1.0.0 this can be changed to include v if you wish, it's just a developer preference.

I would vote for keeping 'v' as we already started doing that..
 @kadel @ngtuna 

Updated with the changes. Removed the `sudo` parts as well as add `v` prefix for each release ex. `v1.0.0`.
 @cdrage overall I am curious, did you write this script from scratch ? it seems to me this has been used in a different environment..
 @sebgoa I wrote it from scratch for multiple projects.

See:
https://github.com/projectatomic/atomicapp/blob/master/script/release.sh
https://github.com/cdrage/kubeshift/blob/master/script/release.sh
https://github.com/streamlink/streamlink/blob/master/script/release.sh.
 @sebgoa updated with your requested changes..
 "
,,315,"Update roadmap / split into ROADMAP.md with relevant information.
 So a few things look out of date / completed in the road map within README.md.

I say we split this into ROADMAP.md and have a more up-to-date / future plan. Including listing all past ""accomplishments""..
 Can we use just Issues and Milestones for roadmap and planing?.
 @kadel One of my reasonings is in regards to being accepted into the Kubernetes repo. It was noted to have a clear roadmap for the future in regards to release / features / implementations.

So having a ROADMAP.md in the readme similar to: https://github.com/coreos/rkt/blob/master/ROADMAP.md (just an example).
 > So having a ROADMAP.md in the readme similar to: https://github.com/coreos/rkt/blob/master/ROADMAP.md (just an example)

ok, that looks good. It just links to Milestones I like that ;-).
 I am going to close this in favor of #250 which talks about removing the roadmap items in the README.

So feel free to send a PR for this, I had said I would do it...

For the record, the simple bullet list roadmap was just to get a few ideas for the incubator proposal..
 "
,,314,"Replace godep with glide.
 We had a lot of issues with `godep` it is time to switch to `glide`.
If we use `glide` we can get rid of ugly [godep-restore.sh](https://github.com/kubernetes-incubator/kompose/blob/master/script/godep-restore.sh).
 "
,,313,"godeps: remove quotes from one entry.
 .
 @kadel @ngtuna can we edit godeps.json manually ?.
 @surajssd you shouldn't edit it manually, i don't have idea how that happend :-(

But this will be also solved by https://github.com/kubernetes-incubator/kompose/pull/297.
 @sebgoa yes we can but it doesn't recommend..
 ok feel free to close when this is resolved by the other issue/PR then.
 @dustymabe thanks, this is resolved in other PR!.
 "
,,312,"added support for multiple-compose files.
 Fix #275 

```bash
$ kompose -f docker-compose.yml,docker-guestbook.yml convert
INFO[0000] file ""redis-master-service.json"" created     
INFO[0000] file ""redis-slave-service.json"" created      
INFO[0000] file ""redis-service.json"" created            
INFO[0000] file ""web-service.json"" created              
INFO[0000] file ""frontend-service.json"" created         
INFO[0000] file ""redis-master-deployment.json"" created  
INFO[0000] file ""redis-slave-deployment.json"" created   
INFO[0000] file ""redis-deployment.json"" created         
INFO[0000] file ""web-deployment.json"" created           
INFO[0000] file ""frontend-deployment.json"" created 
```
cc @kadel @surajssd.
 I'm not sure if comma separated list is right here :-(
With docker-compose it looks like this - `docker-compose -f docker-compose.yml -f docker-guestbook.yml up`
I think that we should do it in the same way as docker-compose does it.

@cdrage how would this work with https://github.com/kubernetes-incubator/kompose/pull/304 ?
Comma separated or multiple -f arguments?.
 @kadel would be easy to implement via #304 once it's merged. But yes, multiple -f arguments would work with it..
 Lets wait for #304. Thank we can revisit this..
 
[![Coverage Status](https://coveralls.io/builds/9443221/badge)](https://coveralls.io/builds/9443221)

Coverage increased (+0.03%) to 45.768% when pulling **68a3361392bef6b2e22379d21e13772222bfa752 on procrypt:multiple_files** into **0370d66357ca3198f492457355b093356ba7d522 on kubernetes-incubator:master**.
.
 @procrypt unit tests, docs needed as well! 

Also I thought we are trying to implement this the docker-compose cli way which is 

```
docker-compose -f foo.yml -f bar.yml up
```
in our case 

```
kompose -f foo.yml -f bar.yml up
```

as opposed to

```
kompose -f foo.yml,bar.yml up
```.
 
[![Coverage Status](https://coveralls.io/builds/9467981/badge)](https://coveralls.io/builds/9467981)

Coverage increased (+1.8%) to 48.38% when pulling **1ff9136107495e1e8ee7e7eb90c0d249c26bca56 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9467997/badge)](https://coveralls.io/builds/9467997)

Coverage increased (+1.8%) to 48.38% when pulling **1ff9136107495e1e8ee7e7eb90c0d249c26bca56 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 @surajssd @containscafeine I have updated the PR. Please review
```bash
$ kompose -f docker-compose.yml -f docker-guestbook.yml convert 
INFO[0000] file ""frontend-service.json"" created         
INFO[0000] file ""mlbparks-service.json"" created         
INFO[0000] file ""mongodb-service.json"" created          
INFO[0000] file ""redis-master-service.json"" created     
INFO[0000] file ""redis-slave-service.json"" created      
INFO[0000] file ""frontend-deployment.json"" created      
INFO[0000] file ""mlbparks-deployment.json"" created      
INFO[0000] file ""mongodb-deployment.json"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.json"" created 
INFO[0000] file ""redis-master-deployment.json"" created  
INFO[0000] file ""redis-slave-deployment.json"" created 
```
```bash
$ kompose -f docker-compose.yml -f docker-guestbook.yml convert 
INFO[0000] file ""mlbparks-service.json"" created         
INFO[0000] file ""frontend-service.json"" created         
INFO[0000] file ""mongodb-service.json"" created          
INFO[0000] file ""redis-master-service.json"" created     
INFO[0000] file ""redis-slave-service.json"" created      
INFO[0000] file ""frontend-deployment.json"" created      
INFO[0000] file ""mlbparks-deployment.json"" created      
INFO[0000] file ""mongodb-deployment.json"" created       
INFO[0000] file ""mongodb-claim0-persistentvolumeclaim.json"" created 
INFO[0000] file ""redis-master-deployment.json"" created  
INFO[0000] file ""redis-slave-deployment.json"" created 
```
The test are failing for this particular feature because the artifacts created are not in any particular order. When we run the `kompose convert` command sometimes `mlbparks-service.json` will be crated first and sometimes `frontend-service.json`and this makes it difficult to match the output in the tests for this feature. We need to think of a different testing strategy to test this rather than matching the output. .
 
[![Coverage Status](https://coveralls.io/builds/9468089/badge)](https://coveralls.io/builds/9468089)

Coverage increased (+1.8%) to 48.38% when pulling **f91837ecd936fd660317648832c2333cf568c998 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 @procrypt even if the order is upside down, it should not cause any problems, because that is what happens for other conversion also, the order may not be same and still `jq` does the matching..
 @surajssd Thanks for the explanation, I'll recheck my work on the tests..
 
[![Coverage Status](https://coveralls.io/builds/9495381/badge)](https://coveralls.io/builds/9495381)

Coverage increased (+1.8%) to 48.38% when pulling **04a281106550437aedd202a1c6a74f3313feaf7c on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495436/badge)](https://coveralls.io/builds/9495436)

Coverage increased (+1.8%) to 48.38% when pulling **8e7bb176b548f6437812fe6121b36d016bb27d70 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495444/badge)](https://coveralls.io/builds/9495444)

Coverage increased (+1.8%) to 48.38% when pulling **8e7bb176b548f6437812fe6121b36d016bb27d70 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495566/badge)](https://coveralls.io/builds/9495566)

Coverage increased (+1.8%) to 48.38% when pulling **07fbe013802a6007afbfd552f0f14572105d9d1f on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495642/badge)](https://coveralls.io/builds/9495642)

Coverage increased (+0.03%) to 46.617% when pulling **8ea7c9728d268117b0c2bf8226334a291979550d on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9495673/badge)](https://coveralls.io/builds/9495673)

Coverage increased (+0.03%) to 46.617% when pulling **8ea7c9728d268117b0c2bf8226334a291979550d on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 @procrypt one last bit, add info about this awesome fetaure to docs! Rest LGTM.
 
[![Coverage Status](https://coveralls.io/builds/9495821/badge)](https://coveralls.io/builds/9495821)

Coverage increased (+0.03%) to 46.617% when pulling **e8af6f15cdebbe517ee67c0cc2a3bb87329a4ca0 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9497512/badge)](https://coveralls.io/builds/9497512)

Coverage increased (+0.03%) to 46.617% when pulling **de2b448b2f8346c0f7ed5c916b763079f2a9f89c on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9498776/badge)](https://coveralls.io/builds/9498776)

Coverage increased (+0.03%) to 46.617% when pulling **a5a3805760737f52c363635257c1ee991be8ce70 on procrypt:multiple_files** into **9c3fdaa48d5e871ab83a3cad95b27fb13dc1f98c on kubernetes-incubator:master**.
.
 @procrypt thanks for awesome work, code + tests + docs :+1: :tada: .
 @surajssd Thank you all your help 😄 .
 "
,,311,"added support for cpu_shares.
 .
 "
,,310,"Multiple compose file support  .
 Fix #275 
cc @kadel @surajssd @aaronlevy .
 "
,,309,"Unable to run cmd tests under Debian..
 Weird issue running the `cmd` tests under Debian. Getting a weird ""convert"" issue running `make cmd-test`

```
===> Starting test <===
convert::expect_success: Running: 'kompose --bundle /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/bundles/dab/docker-compose-bundle.dab convert --stdout' expected_output: '/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/bundles/dab/output-k8s.json'
error: too many arguments to post_recurse (expected 0 but got 1)
def post_recurse(f): def r: (f | select(. != null) | r), .; r; def post_recurse: post_recurse(.[]?); ($a | (post_recurse | arrays) |= sort) as $a | ($b | (post_recurse | arrays) |= sort) as $b | $a == $b                                                                                 1 compile error
FAIL: converted output does not match


===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose --bundle /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/bundles/dsb/docker-voting-bundle.dsb convert --stdout' expected_output: '/home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/bundles/dsb/output-k8s.json' expected_warning: 'Service cannot be created because of missing port.'
error: too many arguments to post_recurse (expected 0 but got 1)
def post_recurse(f): def r: (f | select(. != null) | r), .; r; def post_recurse: post_recurse(.[]?); ($a | (post_recurse | arrays) |= sort) as $a | ($b | (post_recurse | arrays) |= sort) as $b | $a == $b                                                                                 1 compile error
FAIL: converted output does not match
Makefile:31: recipe for target 'test-cmd' failed
make: *** [test-cmd] Error 1
```.
 @cdrage what is version of jq you have installed? Cause [here](https://github.com/kubernetes-incubator/kompose/tree/master/script/test#requirements) it says `jq 1.5` is required..
 @surajssd thanks man, that'd do it:
```
jq - commandline JSON processor [version 1.4-1-e73951f]
Usage: jq [options] <jq filter> [file...]
```.
 "
,,308,"Convert docker-compose env files into configmaps.
 # Convert docker-compose env files

## Context

When it comes to application development, our dev teams tend to want to use docker-compose for its simplicity. However we deploy to kuberentes as our runtime environment of choice.

kompose seems to be the right tool for the job. It is fast, clean, and comprehensive.

## Problem Statement

At current out dev teams have not taken to minikube and so we need a solution to handle conversion.

We are using a combination of tools like github.com/kelseyhightower/compose2kube and github.com/dhoer/k8s-env-gen. It would be great to leverage a tool like kompose to handle all of these things in a single package.

Looking for a cleaner solution, something comprehensive and not custom managed. I tried to convert an existing project that contains docker compose env files and received the following warning. 

![image](https://cloud.githubusercontent.com/assets/1334469/20560684/aff36f74-b148-11e6-9acc-07b45911c2f9.png)

I also found issue #30 which would relate to the scope of this request as well.

## Solution

I'm proposing adding support for docker-compose env file translation..
 @johnt337 How would one determine if env-file was a secret or not? I would think all env-files would have to be a configmap..
 Agreed. I think we can do this with a default configmap.

Dealing with secrets would be a different issue, especially that proper secret mgt is coming in Docker..
 When https://github.com/kubernetes/kubernetes/pull/37295 is released (k8s v1.6 release?), it would be nice for [env_file](https://docs.docker.com/compose/compose-file/#/envfile) entries to get converted to configmaps, and deployment yaml to get updated with `envFrom` configMap entries.

.
 @sebgoa OK make sense. @dhoer yea I agree since docker does not have this in functional form.
I see docker is incubating the idea https://github.com/docker/docker/issues/13490 so this might help outline how kompose could deduce the difference (down the road).

Also see https://github.com/docker/compose/issues/1534#issuecomment-110880137.

Would a flag specifying what file(s) or regex to use for scanning/rendering secrets be allowable in the short term?.
 @johnt337 Should this issue be broken into 2 issues?  One for `env_file` entries and the other on handling secrets?.
 > At current out dev teams have not taken to minikube and so we need a solution to handle conversion

Do you see an evolution towards using Minikube locally? We're still at a stage where dev teams haven't adopted anything right now. I was playing with the idea of skipping the compose step and use Minikube as suggested.. We are using Helm Charts for everything and this would mean a Helm chart that takes parameters to run on a single-node Minikube install as well as a fine-tuned Prod install... and it just doesn't make sense to me.

Makes more sense to have a simplified stack in compose and a hand crafted Helm Chart for deployment to the cluster (something Kompose can't help with at all, btw)  .
 @so0k what are you trying to suggest here? Something where kompose can improve?.
 Hi @johnt337 I've gone ahead and changed the title to ConfigMaps since we have another issue opened in regards to secrets #296 .

This is something we'd like to have on the Kompose roadmap and I've gone ahead and marked it as a milestone for a future release..
 With #799 merged in, this can be *finally* closed! `env_file` has been added to Kompose.

We've also coincided this with the release of Kompose 1.3.0

Feel free to check it out @johnt337 @so0k and @dhoer .
 @cdrage Thanks!! Will do!.
 "
,,307,"add golint check to travis-ci.
 This adds [golint](https://github.com/golang/lint) check to travis.

Golint checks coding standart rules from [Effective Go](https://golang.org/doc/effective_go.html) and the [CodeReviewComments wiki page](https://golang.org/wiki/CodeReviewComments).

Sometimes it can be quite strict and annoying, but I think that we should try it, and see how it goes.

This PR also fixes all the golint errors in the current code.

 


.
 ping us when this is ready..
 it will take a while :-(.
 
[![Coverage Status](https://coveralls.io/builds/9531555/badge)](https://coveralls.io/builds/9531555)

Coverage increased (+0.06%) to 46.678% when pulling **4f176b847ec75f61ab69bcc03f2b759a178df991 on kadel:golint** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 @kadel cool LGTM.
 "
,,306,"Default to YAML output.
 As per the ""[best practices](http://kubernetes.io/docs/user-guide/config-best-practices/)"":
> Write your configuration files using YAML rather than JSON. They can be used interchangeably in almost all scenarios, but YAML tends to be more user-friendly for config.

I've not followed that advice when I used kompose to convert my docker-compose files, and now need to reconvert+reapply adjustments (or convert via JSON->YAML converter).

Arguments for YAML:
* YAML allows comments
* All examples in kubernetes documentation are YAML

.
 +1.
 Totally agree on my part..
 I can implement this after #304 is added since this involves changing a few of the CLI parameters..
 @ngtuna @sebgoa Can I be added to the repo so I can self-assign / labels?.
 I don't think that we should block this on #304 
This will be easy fix and it would be great to get it finally in.

My proposal for this is:
 - add new `--json -j` option to `convert` command, that will export to JSON only if set.
 - change  default  format to yaml if no option is specified
 - when user sets `--yaml` show warning that this option is deprecated and that yaml format is default.

I would even consider dropping JSON support all together. I don't know if it is something that anyone will use.


.
 "
,,305,"Remove trailing slash.
 "
,,304,"Switch to spf13/cobra from urfave/cli.
 There's A LOT happening in this commit, so here's an outline:

- First off, urfave/cli has been removed in favour of spf13/cobra. With
  this, comes changes to the formatting as well as the help page for
  Kompose.

- Upon converting, I noticed a CLI flag was NOT appearing for OpenShift.
  Specifically, `--deploymentconfig`. This has been added with a note
  that says it is OpenShift only.

- Exit codes have been fixed. If the conversion / down / up fails for
  any reason, Kompose will exit with Code 1.

- `--verbose` as well as `--suppress-warnings` can now be set at the
  same time.

- `app_test.go` in the cli directory has been moved to `pkg/transformer`
  to better reflect the testing coverage.

- `version.go` has been removed and converted to it's own CLI command in
  conjuction with (most) Go software. A new CLI command has been
  created. `kompose version`

- `--dab` isn't a conventional way for short-form CLI paramters. This
  has been shortened to `-b` for bundle.

- CLI flags consisting of only two/three letters have been removed due to
  it being unconventional for CLI. For example, `--dc` was removed in preference
  for `--deploymentconfig`

- `--replicas` has been added as an option when using `kompose down` or
  `kompose up`. This has been added as previously in `app.go` the
  replica amount was hard-coded as `1`.

- Differentiating names have been used for flags. For example,
  persistent flags use the name Global (ex. GlobalOut). Command-specific
  flags have their own names (ex. UpOpt).

Closes https://github.com/kubernetes-incubator/kompose/issues/239 https://github.com/kubernetes-incubator/kompose/issues/253.
 @kadel I'll need some help in regards to vendoring in `spf13/cobra` if you can help me with the commands :).
 @kadel @ngtuna 
Would need some help regarding the failing bash / cmd tests:

I don't touch anything regarding the ""conversion"". Despite having the *exact* same output at before the conversion:
```
▶ ./kompose --provider=openshift -f $GOPATH/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad/docker-compose.yml convert --stdout
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
WARN[0000] The DB_USER variable is not set. Substituting a blank string. 
WARN[0000] The DB_HOST variable is not set. Substituting a blank string. 
WARN[0000] The DB_NAME variable is not set. Substituting a blank string. 
WARN[0000] The DB_PASS variable is not set. Substituting a blank string. 
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
WARN[0000] The DB_NAME variable is not set. Substituting a blank string. 
WARN[0000] The DB_PASS variable is not set. Substituting a blank string. 
WARN[0000] The DB_USER variable is not set. Substituting a blank string. 
WARN[0000] The ROOT_PASS variable is not set. Substituting a blank string. 
ERRO[0000] Could not parse config for project etherpad : Service 'mariadb' configuration key 0 value Does not match format 'ports' 
FATA[0000] Failed to load compose file: Service 'mariadb' configuration key 0 value Does not match format 'ports' 
```

It still fails with the 
```
convert::expect_success_and_warning ""kompose --provider=openshift -f $KOMPOSE_ROOT/script/test/fixtures/etherpad/docker-compose.yml convert --stdout"" ""$KOMPOSE_ROOT/script/test/fixtures/etherpad/output-os.json"" ""Unsupported key depends_on - ignoring""
```

test.


Did something change?.
 @cdrage export envs before you run kompose 

```bash
✔ ~/git/gowork/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad [master ↑·307|…1] 
09:49 $ export $(cat envs )    

✔ ~/git/gowork/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad [master ↑·307|…1] 
09:51 $ kompose --provider openshift up
WARN[0000] Unsupported key depends_on - ignoring        
We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO[0000] Successfully created Service: etherpad       
INFO[0000] Successfully created Service: mariadb        
INFO[0000] Successfully created DeploymentConfig: etherpad 
INFO[0000] Successfully created ImageStream: etherpad   
INFO[0000] Successfully created DeploymentConfig: mariadb 
INFO[0000] Successfully created ImageStream: mariadb    
INFO[0000] Successfully created PersistentVolumeClaim: mariadb-claim0 

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.
```.
 @surajssd not quite sure what you mean when exporting envs.

Isn't this already in the testing suite / shouldn't fail?

edit: it also looks like you're testing against master not PR #304 
edit2: also, I'm testing the failures of `convert` in the testing, not `up`.
 @cdrage this is what i did and found out it works with openshift
```bash
✔ ~/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad [switch-to-cobra|✔] 
19:14 $ ll
total 36
-rw-rw-r--. 1 hummer hummer  102 Oct 24 16:11 docker-compose-no-image.yml
-rw-rw-r--. 1 hummer hummer   61 Oct 24 16:11 docker-compose-no-ports.yml
-rw-rw-r--. 1 hummer hummer  509 Nov 24 19:06 docker-compose.yml
-rw-rw-r--. 1 hummer hummer   99 Oct 24 16:11 envs
-rw-rw-r--. 1 hummer hummer 4852 Nov 24 19:06 output-k8s.json
-rw-rw-r--. 1 hummer hummer 7119 Nov 24 19:06 output-os.json
-rw-rw-r--. 1 hummer hummer  180 Oct 24 16:11 README.md
✔ ~/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad [switch-to-cobra|✔] 
19:14 $ export $(cat envs)                                                                                                                                                                                        
✔ ~/go/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad [switch-to-cobra|✔] 
19:14 $ kompose --provider openshift convert --stdout                                                                                                                                                              
WARN[0000] Unsupported key depends_on - ignoring        
{
  ""kind"": ""List"",
  ""apiVersion"": ""v1"",
  ""metadata"": {},
  ""items"": [
    {
      ""kind"": ""Service"",
      ""apiVersion"": ""v1"",

```.
 @surajssd thanks! so it looks like an issue reading the env's, i'm going to update the PR and see what happens.

edit: how I feel right now trying to get these tests to pass:

![image](https://i.imgur.com/JL1aW25.gif)

opened up issue #309 as I'm getting a weird error running the cmd tests on my local machine..
 @cdrage also `-y` is not working for some reason

```bash
$ kompose convert --stdout -y
Error: unknown shorthand flag: 'y' in -y
<snip>
```.
 @surajssd updated, should work now. added `-y` to yaml. had forgotten to add it..
 @surajssd @kadel I've been trying to resolve the test scenarios but I'm having issues making them pass :( Even though the output is the *exact* same as before this PR, it doesn't seem to ""match"" correctly. Any ideas?.
 For example: Here's a test that *should* pass even after doing `export $(cat envs)`. It's the desired output:
```
test/fixtures/etherpad  switch-to-cobra ✔                                                                                                                                                                                                                                    3d  
▶ export $(cat envs)                                                                                                                                   

test/fixtures/etherpad  switch-to-cobra ✔                                                                                                                                                                                                                                    3d  
▶ kompose --provider=openshift -f $GOPATH/src/github.com/kubernetes-incubator/kompose/script/test/fixtures/etherpad/docker-compose.yml convert --stdout
WARN[0000] Unsupported key depends_on - ignoring        
{
  ""kind"": ""List"",
  ""apiVersion"": ""v1"",
  ""metadata"": {},
  ""items"": [
    {
```.
 @cdrage so looking closely it seems it's generating `deployment` and `deploymentconfigs` both, so with openshift we only generate `deploymentconfig` as default controller object..
 @surajssd 

I see, so in: https://github.com/kubernetes-incubator/kompose/blob/6033025c058e44f00d78c42149a09be025ba6a31/cli/command/command.go

We actually have different flags depending on the provider (which I think is a big no-no since suddenly flags disappear if a different provider is provided). 

So what essentially happens is that by default ""deployment"" is false since it's not implied. Got it. I'll fix this :).
 If anyone else has a different opinion / way to implement, that'd be great.

Another option for ""splitting"" the flags is simply having a validation (if you pass in --chart for OpenShift it'll simply error out as not compatible / usable)..
 @cdrage that was purposeful **changing controller flags depending on provider** user mentions..
 All tests pass now :+1: .
 @cdrage I see flags which are not for provider `openshift` ? It will confuse users actually, this was the argument behind changing flags on changing providers. Ref: https://github.com/kubernetes-incubator/kompose/pull/182#discussion_r81815659
```bash
$ ./kompose --provider openshift convert --help
A longer description that spans multiple lines and likely contains examples

Usage:
  kompose convert [file] [flags]

Flags:
  -c, --chart                   Create a Helm chart for converted objects **Kubernetes only**
      --daemonset               Generate a Kubernetes daemonset object **Kubernetes only**
  -d, --deployment              Generate a Kubernetes deployment object **OpenShift only**
      --deploymentconfig        Generate a deployment config object. **OpenShift only*
      --emptyvols               Use Empty Volumes. Do not generate PVCs
  -o, --out string              Specify a file name to save objects to
      --replicas int            Specify the number of repliaces in the generate resource spec (default 1)
      --replicationcontroller   Generate a Kubernetes replication controller object **Kubernetes only**
      --stdout                  Print converted objects to stdout
  -y, --yaml                    Generate resource files into yaml format

Global Flags:
  -b, --bundle string       Specify a Distributed Application GlobalBundle (DAB) file
      --error-on-warning    Treat any warning as an error
  -f, --file string         Specify an alternative compose file (default ""docker-compose.yml"")
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```.
 following do not work
```
kompose convert --ds
kompose convert --rc
kompose --provider openshift convert --dc

kompose --dab file convert
```

following should error out but it still continues execution
```
kompose --provider openshift convert -d
```

You can set provider using env var `PROVIDER` but now it is not taking effect. Similarly for `dab` file and `compose` file and output file.



Good job with having replicas under sub-command `up`..
 @surajssd 
```
kompose convert --ds
kompose convert --rc
kompose --provider openshift convert --dc

kompose --dab file convert
```

Those errors are intentional...

`-rc`, etc is unconventional for CLI. it should either be a full name `--replicationcontroller` or one letter, ex. `-r`. 

```
kompose --provider openshift convert -d
```

For this I will fix ^^.

From your comment, I will split off the CLI flags based on provider so they do not appear. Thanks for another review!
.
 @surajssd 

Output now looks like this:
```
▶ ./kompose convert -h
Usage:
  kompose convert [file] [flags]

Kubernetes Flags:
  -c, --chart                   Create a Helm chart for converted objects
      --daemonset               Generate a Kubernetes daemonset object
      --replicationcontroller   Generate a Kubernetes replication controller object

OpenShift Flags:
  -d, --deployment         Generate an OpenShift deployment object
      --deploymentconfig   Generate an OpenShift deploymentconfig object

Flags:
      --emptyvols      Use Empty Volumes. Do not generate PVCs
  -o, --out string     Specify a file name to save objects to
      --replicas int   Specify the number of repliaces in the generate resource spec (default 1)
      --stdout         Print converted objects to stdout
  -y, --yaml           Generate resource files into yaml format

Global Flags:
  -b, --bundle string       Specify a Distributed Application GlobalBundle (DAB) file
      --error-on-warning    Treat any warning as an error
  -f, --file string         Specify an alternative compose file (default ""docker-compose.yml"")
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```

Which (IMO) is much more intuitive instead of having hidden flags all the time.

.
 deployment are k8s resources.

We should see Global Flags first, the Flags, and I would group the resource specific ones under a single heading (Resource flags).

If a user tries to use deploymentconfig without a provider=openshit, then it should error out..
 @sebgoa I disagree with having Global Flags first, it makes sense to have Flags first. This is what's default on cobra as well as other large projects using the CLI tool.

However, I took your suggestion and differentiated the flags to one rather than separating k8s + openshift:

```
Usage:
  kompose convert [file] [flags]

Resource Flags:
  -c, --chart                   Create a Helm chart for converted objects
      --daemonset               Generate a daemonset object
  -d, --deployment              Generate a deployment object
      --deploymentconfig        Generate a deployment config object
      --replicationcontroller   Generate a replication controller object

Flags:
      --emptyvols      Use Empty Volumes. Do not generate PVCs
  -o, --out string     Specify a file name to save objects to
      --replicas int   Specify the number of repliaces in the generate resource spec (default 1)
      --stdout         Print converted objects to stdout
  -y, --yaml           Generate resource files into yaml format

Global Flags:
  -b, --bundle string       Specify a Distributed Application GlobalBundle (DAB) file
      --error-on-warning    Treat any warning as an error
  -f, --file string         Specify an alternative compose file (default ""docker-compose.yml"")
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```.
 This PR is ready for another review if anyone want to take another shot at it @surajssd @kadel @sebgoa @ngtuna .
 #275 .
 Reminder to myself: See what we can do in the future for #275 .
 So a major change to this would be removing some of the unconventional 2-letter flag parameters. As well as adding dashing between two-letter words as common in tools such as `oc` and `kubectl`.

For example:

```
   --replicationcontroller, --rc        Generate a Kubernetes replication controller object
```

is replaced with

```
      --replication-controller   Generate a replication controller object
```

The full output being:
```
▶ ./kompose convert -h
Usage:
  kompose convert [file] [flags]

Resource Flags:
  -c, --chart                    Create a Helm chart for converted objects
      --daemon-set               Generate a daemonset object
  -d, --deployment               Generate a deployment object
      --deployment-config        Generate a deployment config object
      --replication-controller   Generate a replication controller object
```
.
 
[![Coverage Status](https://coveralls.io/builds/9174701/badge)](https://coveralls.io/builds/9174701)

Coverage increased (+5.7%) to 40.689% when pulling **8e00724336b997ace9f2a861ccdef3178f3c2bbd on cdrage:switch-to-cobra** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 @sebgoa Ayyy, coveralls seems to work now! :).
 
[![Coverage Status](https://coveralls.io/builds/9176239/badge)](https://coveralls.io/builds/9176239)

Coverage increased (+5.7%) to 40.689% when pulling **8716c282f697694248cdcff4ec64fd55849ad749 on cdrage:switch-to-cobra** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9176284/badge)](https://coveralls.io/builds/9176284)

Coverage increased (+5.7%) to 40.689% when pulling **8716c282f697694248cdcff4ec64fd55849ad749 on cdrage:switch-to-cobra** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 `$ kompose convert --deployment-config --stdout` worked without errors, it created `deployment` and `services`..
 "
,,303,"kompose 0.1.2 fails to parse key-only variables in environment section, does work with lists but generates invalid k8s resources.
 `kompose version 0.1.2 (92ea047)`

I was exciting to try out kompose to help my colleague migrate to k8s, but I could not find any of our dock-compose files that kompose could parse. They all reported errors for the 'environment' section, such as:

```
ERRO[0000] Could not parse config for project project : yaml: line 88: could not find expected ':'
```
or
```
FATA[0000] Failed to load compose file: Service 'mysql' configuration key 'environment' contains an invalid type, it should be an array or object
Service 'phpmyadmin' configuration key 'environment' contains an invalid type, it should be an array or object
Unsupported config option for phpmyadmin service: 'PMA_HOST'
```

It looks like the kompose parser doesn't support the full docker-compose spec for environment variables. If you want to pass your build environment value into the same-named environment variable in your container, you just need to name the variable in the environment section of the docker-compose file, e.g.

```
    environment:
      MYSQL_HOST
      MYSQL_DATABASE
      MYSQL_USER
      MYSQL_PASSWORD
```

This is documented in the docker-compose spec page for environment variables here:

https://docs.docker.com/compose/compose-file/#/environment
**""Environment variables with only a key are resolved to their values on the machine Compose is running on, which can be helpful for secret or host-specific values.""**

I was able to work around this for the kompose parser by adding colons to each item, but I think that might break docker-compose as all the variables will get blank/empty values.
```
    environment:
      MYSQL_HOST:
      MYSQL_DATABASE:
      MYSQL_USER:
      MYSQL_PASSWORD:
```

Converting the environment section to a sequence also helped kompose parse it, though again not sure if docker-compose will support this form?
```
    environment:
      - MYSQL_HOST
      - MYSQL_DATABASE
      - MYSQL_USER
      - MYSQL_PASSWORD
```

But even with both those work-arounds kompose generated only name fields for kubernetes, with no value, which isn't going to work when sent to a cluster. 

```
                ""env"": [
                  {
                    ""name"": ""MYSQL_DATABASE""
                  },
                  {
                    ""name"": ""MYSQL_USER""
                  },
                  {
                    ""name"": ""MYSQL_PASSWORD""
                  },
                  {
                    ""name"": ""MYSQL_ROOT_PASSWORD""
                  }
                ],
```

I think kompose should generate value properties with the actual value of the environment variables (from the kompose environment).

When we manually convert docker-compose file some of those environment fields become Secret or ConfigMap entries, but probably injecting the value is best default behavior for kompose is order to allow `kompose up` to work?



.
 Hi, thanks for reporting this.
Docker compose reads the environment variable and uses the same as key. which we don't do (checking on it now)

For kompose, this should work:

```
environment:
  - MYSQL_HOST: $MYSQL_HOST
  - MYSQL_DATABASE: $MYSQL_DATABASE
  - MYSQL_USER: $MYSQL_USER
```

We will check it carefully and patch kompose to support the case you mentioned.

.
 Thanks @whereisaaron I submitted a patch above for your case..
 Hi, @whereisaaron 

Does this work for you with docker-compose?
```
    environment:
      MYSQL_HOST
      MYSQL_DATABASE
      MYSQL_USER
      MYSQL_PASSWORD
```

I've tried that and I got
```
ERROR: The Compose file './docker-compose.yml' is invalid because:
services.foo.environment contains an invalid type, it should be an object, or an array
```

I think that  that only possible options for this even with docker-compose are
```
    environment:
      MYSQL_HOST:
```
or
```
    environment:
      - MYSQL_HOST
``` 
.
 @kadel Yes you're correct. it doesn't work on docker-compose. Tested with latest docker-compose 1.9.0.
 "
,,302,"Switch to 'make bin' instead of 'make binary'.
 I keep mistyping this when creating the binary as per other projects
that use it commonly (it's usually `make bin` instead of `make binary`)..
 @sebgoa do we really need to put a license header in *every* file? Not even Docker has that (and it's pretty much the largest Go project out there: https://github.com/docker/docker/blob/master/Makefile).
 @sebgoa 
Updated the PR and to answer your questions:
make already builds binary by default
binary-cross switched to just cross
yeah... validation tests should be added, i'll add this once gofmt + go lint has been added here: https://github.com/kubernetes-incubator/kompose/pull/259/files.
 > yeah... validation tests should be added, i'll add this once gofmt + go lint has been added here: https://github.com/kubernetes-incubator/kompose/pull/259/files

added ;-).
 @kadel thanks :)

@sebgoa updated with *all* your suggestions now! Good for review :+1: .
 @cdrage don't forget to update [.travis.yml](https://github.com/kubernetes-incubator/kompose/blob/master/.travis.yml) :wink: .
 @cdrage and yes we need the license header. I don't care what Docker does. Any file that does not have the license header is not properly licensed.. that's how you apply an ASL license throughout your code base..
 @sebgoa done. added license and updated readme..
 well, lots of travis errors.
 @sebgoa Travis passes now. Forgot to update `.travis.yml`.
 "
,,301,"When using `container_name` in docker-compose problems with dc and imagestreams.
 docker-compose file i am using:
```yaml
$ cat docker-compose.yml 
version: ""2""
services:
  rabbit:
    image: rabbitmq:3.6.1
    container_name: myfavrabbit
    ports:
     - ""5672:5672""
```

deloying app
```bash
$ oc new-project rabbit
$ kompose --provider openshift up
We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO[0000] Successfully created Service: rabbit         
INFO[0000] Successfully created DeploymentConfig: rabbit 
INFO[0000] Successfully created ImageStream: rabbit     

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.
```

nothing happens

```bash
$ oc get dc
NAME      REVISION   DESIRED   CURRENT   TRIGGERED BY
rabbit    0          1         0         config,image(rabbit:3.6.1)
```

manually trigger the deployment from GUI

```bash
$ oc get events -w
LASTSEEN   FIRSTSEEN   COUNT     NAME      KIND      SUBOBJECT   TYPE      REASON    SOURCE    MESSAGE
LASTSEEN                        FIRSTSEEN                       COUNT     NAME      KIND               SUBOBJECT   TYPE      REASON              SOURCE                           MESSAGE
2016-11-21 15:16:27 +0000 UTC   2016-11-21 15:16:27 +0000 UTC   1         rabbit    DeploymentConfig               Normal    DeploymentCreated   {deploymentconfig-controller }   Created new replication controller ""rabbit-1"" for version 1
2016-11-21 15:16:27 +0000 UTC   2016-11-21 15:16:27 +0000 UTC   1         rabbit-1-deploy   Pod                 Normal    Scheduled   {default-scheduler }   Successfully assigned rabbit-1-deploy to 192.168.121.251
2016-11-21 15:16:29 +0000 UTC   2016-11-21 15:16:29 +0000 UTC   1         rabbit-1-deploy   Pod       spec.containers{deployment}   Normal    Pulled    {kubelet 192.168.121.251}   Container image ""openshift/origin-deployer:v1.4.0-alpha.1"" already present on machine
2016-11-21 15:16:29 +0000 UTC   2016-11-21 15:16:29 +0000 UTC   1         rabbit-1-deploy   Pod       spec.containers{deployment}   Normal    Created   {kubelet 192.168.121.251}   Created container with docker id 62ddc990d5c9; Security:[seccomp=unconfined]
2016-11-21 15:16:29 +0000 UTC   2016-11-21 15:16:29 +0000 UTC   1         rabbit-1-deploy   Pod       spec.containers{deployment}   Normal    Started   {kubelet 192.168.121.251}   Started container with docker id 62ddc990d5c9
2016-11-21 15:16:30 +0000 UTC   2016-11-21 15:16:30 +0000 UTC   1         rabbit-1-mmz6z   Pod                 Normal    Scheduled   {default-scheduler }   Successfully assigned rabbit-1-mmz6z to 192.168.121.251
2016-11-21 15:16:30 +0000 UTC   2016-11-21 15:16:30 +0000 UTC   1         rabbit-1   ReplicationController             Normal    SuccessfulCreate   {replication-controller }   Created pod: rabbit-1-mmz6z
2016-11-21 15:16:31 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   1         rabbit-1-mmz6z   Pod       spec.containers{myfavrabbit}   Normal    Pulling   {kubelet 192.168.121.251}   pulling image "" ""
2016-11-21 15:16:31 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   1         rabbit-1-mmz6z   Pod       spec.containers{myfavrabbit}   Warning   Failed    {kubelet 192.168.121.251}   Failed to pull image "" "": couldn't parse image reference "" "": invalid reference format
2016-11-21 15:16:31 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   1         rabbit-1-mmz6z   Pod                 Warning   FailedSync   {kubelet 192.168.121.251}   Error syncing pod, skipping: failed to ""StartContainer"" for ""myfavrabbit"" with ErrImagePull: ""couldn't parse image
reference \"" \"": invalid reference format""

2016-11-21 15:16:32 +0000 UTC   2016-11-21 15:16:32 +0000 UTC   1         rabbit-1-mmz6z   Pod       spec.containers{myfavrabbit}   Normal    BackOff   {kubelet 192.168.121.251}   Back-off pulling image "" ""
2016-11-21 15:16:32 +0000 UTC   2016-11-21 15:16:32 +0000 UTC   1         rabbit-1-mmz6z   Pod                 Warning   FailedSync   {kubelet 192.168.121.251}   Error syncing pod, skipping: failed to ""StartContainer"" for ""myfavrabbit"" with ImagePullBackOff: ""Back-off pulling image
\"" \""""

2016-11-21 15:16:45 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   2         rabbit-1-mmz6z   Pod                 Warning   FailedSync   {kubelet 192.168.121.251}   Error syncing pod, skipping: failed to ""StartContainer"" for ""myfavrabbit"" with ErrImagePull: ""couldn't parse image
reference \"" \"": invalid reference format""

2016-11-21 15:16:45 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   2         rabbit-1-mmz6z   Pod       spec.containers{myfavrabbit}   Normal    Pulling   {kubelet 192.168.121.251}   pulling image "" ""
2016-11-21 15:16:45 +0000 UTC   2016-11-21 15:16:31 +0000 UTC   2         rabbit-1-mmz6z   Pod       spec.containers{myfavrabbit}   Warning   Failed    {kubelet 192.168.121.251}   Failed to pull image "" "": couldn't parse image reference "" "": invalid reference format
[SNIP]
```

But when `container_name` is not used everything runs fine..
 Problem is that ConfigChange trigger in DeploymentConfig is using wrong containerName (rabbit instad of myfavrabbit). It has to match container name in spec.template.spec.containers[0].name

this gets generated 
```json
        ""triggers"": [
          {
            ""type"": ""ConfigChange""
          },
          {
            ""type"": ""ImageChange"",
            ""imageChangeParams"": {
              ""automatic"": true,
              ""containerNames"": [
                ""rabbit""
              ],
              ""from"": {
                ""kind"": ""ImageStreamTag"",
                ""name"": ""rabbit:3.6.1""
              }
            }
          }
        ],
```
it should look like this:

```json
""triggers"": [
          {
            ""type"": ""ConfigChange""
          },
          {
            ""type"": ""ImageChange"",
            ""imageChangeParams"": {
              ""automatic"": true,
              ""containerNames"": [
                ""myfavrabbit""
              ],
              ""from"": {
                ""kind"": ""ImageStreamTag"",
                ""name"": ""rabbit:3.6.1""
              }
            }
          }
        ],
```
.
 "
,,300,"make `script/godep-restore.sh` more verbose.
 Hi,

It would be of great help if `script/godep-restore.sh` would return more verbose output, since restoring the godeps takes quite some time, and getting a verbose output of what is happening when will be of great help..
 @containscafeine since #314 is closed, should we close this too?.
 @cdrage yessir!.
 "
,,299,"no test/check for Godeps.json health.
 Hi,

There are fair chances that `Godeps.json` might grow stale in due time due to changes in upstream (stale commits, change in git history). This could cause issues whenever some PR requires to add entries to Godeps.json, but `godep restore` fails due to broken upstream dependencies.

Does it make sense to add a CI step or a functional test for this?

Thoughts?.
 Since we have moved away from godep, closing this..
 "
,,298,"`script/godep-restore.sh` is failing on master.
 Hi,

Running `script/godep-restore.sh` on a fresh `$GOPATH` fails with the following output -

<details>

<summary>
$ script/godep-restore.sh
</summary>

```bash
[concaf@containscafeine kompose]$ script/godep-restore.sh
Preloading some dependencies
remote: Counting objects: 6704, done.
remote: Compressing objects: 100% (527/527), done.
remote: Total 6704 (delta 3623), reused 3318 (delta 3318), pack-reused 2859
Receiving objects: 100% (6704/6704), 3.43 MiB | 744.00 KiB/s, done.
Resolving deltas: 100% (5036/5036), completed with 1436 local objects.
From https://github.com/openshift/kubernetes
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      openshift-1.3 -> github.com/openshift-remote/openshift-1.3
 * [new branch]      openshift-1.4 -> github.com/openshift-remote/openshift-1.4
 * [new branch]      rebase-20160831 -> github.com/openshift-remote/rebase-20160831
 * [new branch]      release-1.0 -> github.com/openshift-remote/release-1.0
 * [new branch]      release-1.1 -> github.com/openshift-remote/release-1.1
 * [new branch]      release-1.2 -> github.com/openshift-remote/release-1.2
 * [new branch]      release-1.2-stable-20160309 -> github.com/openshift-remote/release-1.2-stable-20160309
 * [new branch]      release-1.2-stable-20160312 -> github.com/openshift-remote/release-1.2-stable-20160312
 * [new branch]      release-1.2-stable-20160316 -> github.com/openshift-remote/release-1.2-stable-20160316
 * [new branch]      stable     -> github.com/openshift-remote/stable
 * [new branch]      stable-20160127 -> github.com/openshift-remote/stable-20160127
 * [new branch]      stable-20160211 -> github.com/openshift-remote/stable-20160211
 * [new branch]      stable-20160309 -> github.com/openshift-remote/stable-20160309
 * [new branch]      stable-20160411 -> github.com/openshift-remote/stable-20160411
 * [new branch]      stable-20160510 -> github.com/openshift-remote/stable-20160510
 * [new branch]      stable-20160615 -> github.com/openshift-remote/stable-20160615
 * [new branch]      stable-20160624 -> github.com/openshift-remote/stable-20160624
 * [new branch]      stable-20160804 -> github.com/openshift-remote/stable-20160804
 * [new branch]      stable-20160831 -> github.com/openshift-remote/stable-20160831
 * [new branch]      stable-9da202e -> github.com/openshift-remote/stable-9da202e
 * [new tag]         v1.1.0-origin -> v1.1.0-origin
 * [new tag]         v1.2.0-origin -> v1.2.0-origin
remote: Counting objects: 3, done.
remote: Total 3 (delta 2), reused 2 (delta 2), pack-reused 1
Unpacking objects: 100% (3/3), done.
From https://github.com/openshift/glog
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      stable     -> github.com/openshift-remote/stable
Starting to download all godeps. This takes a while
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/apis/federation): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/apis/federation/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/apis/federation/v1beta1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/client/clientset_generated/federation_internalclientset): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/client/clientset_generated/federation_internalclientset/typed/core/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/client/clientset_generated/federation_internalclientset/typed/extensions/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/federation/client/clientset_generated/federation_internalclientset/typed/federation/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/annotations): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/endpoints): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/errors): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/meta): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/meta/metatypes): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/pod): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/resource): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/rest): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/service): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/unversioned/validation): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/v1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/api/validation): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apimachinery): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apimachinery/registered): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/apps): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/apps/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/apps/v1alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authentication): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authentication/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authentication/v1beta1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authorization): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authorization/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/authorization/v1beta1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/autoscaling): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/autoscaling/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/autoscaling/v1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/batch): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/batch/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/batch/v1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/batch/v2alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/certificates): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/certificates/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/certificates/v1alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/componentconfig): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/componentconfig/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/componentconfig/v1alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/extensions): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/extensions/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/extensions/v1beta1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/extensions/validation): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/policy): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/policy/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/policy/v1alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/rbac): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/rbac/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/rbac/v1alpha1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/storage): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/storage/install): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/apis/storage/v1beta1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/auth/authenticator): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/auth/user): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/capabilities): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/cache): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/authentication/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/authorization/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/autoscaling/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/batch/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/certificates/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/core/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/extensions/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/rbac/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/storage/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/metrics): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/record): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/restclient): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/transport): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/typed/discovery): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/typed/dynamic): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/adapters/internalclientset): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/auth): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/clientcmd): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/clientcmd/api): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/clientcmd/api/latest): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/client/unversioned/clientcmd/api/v1): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/controller): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/controller/deployment/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/controller/framework): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/controller/framework/informers): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/controller/replication): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/conversion): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/conversion/queryparams): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/credentialprovider): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/fieldpath): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/fields): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/kubectl): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/kubectl/cmd/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/kubectl/resource): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/kubelet/qos): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/kubelet/types): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/labels): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/master/ports): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/registry/generic): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/registry/thirdpartyresourcedata): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer/json): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer/protobuf): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer/recognizer): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer/streaming): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/runtime/serializer/versioning): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/security/apparmor): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/security/podsecuritypolicy/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/securitycontextconstraints/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/selection): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/serviceaccount): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/etcd): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/etcd/metrics): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/etcd/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/etcd3): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/storagebackend): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/storage/storagebackend/factory): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/types): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/cache): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/certificates): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/clock): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/config): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/crypto): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/diff): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/errors): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/exec): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/flag): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/flowcontrol): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/framer): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/hash): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/homedir): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/integer): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/interrupt): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/intstr): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/json): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/jsonpath): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/labels): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/metrics): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/net): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/net/sets): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/parsers): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/pod): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/rand): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/replicaset): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/runtime): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/sets): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/slice): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/strategicpatch): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/term): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/uuid): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/validation): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/validation/field): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/wait): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/workqueue): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/util/yaml): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/version): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/watch): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/pkg/watch/versioned): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/plugin/pkg/client/auth): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/plugin/pkg/client/auth/gcp): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/plugin/pkg/client/auth/oidc): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/third_party/forked/golang/json): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/third_party/forked/golang/netutil): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/third_party/forked/golang/reflect): exit status 128
# cd /home/concaf/godep_kompose/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error restoring dep (k8s.io/kubernetes/third_party/forked/golang/template): exit status 128
godep: Error restoring some deps. Aborting check.
Download finished into /home/concaf/godep_kompose

[concaf@containscafeine kompose]$
```
</details>


Now since `godep restore` does a `git checkout` at a given commit in a detached state, I tried the following -

```bash
[concaf@containscafeine]$ cd $GOPATH/src/k8s.io/

[concaf@containscafeine k8s.io]$ ls
client-go  kubernetes

[concaf@containscafeine k8s.io]$ rm -rf kubernetes/

[concaf@containscafeine k8s.io]$ git clone https://github.com/kubernetes/kubernetes
Cloning into 'kubernetes'...
remote: Counting objects: 379523, done.
remote: Compressing objects: 100% (1531/1531), done.
remote: Total 379523 (delta 903), reused 2 (delta 2), pack-reused 377982
Receiving objects: 100% (379523/379523), 345.68 MiB | 873.00 KiB/s, done.
Resolving deltas: 100% (249419/249419), done.
Checking connectivity... done.

[concaf@containscafeine k8s.io]$ cd kubernetes

[concaf@containscafeine kubernetes]$ git remote add github.com/openshift-remote https://github.com/openshift/kubernetes

[concaf@containscafeine kubernetes]$ git remote update
Fetching origin
Fetching github.com/openshift-remote
remote: Counting objects: 6704, done.
remote: Compressing objects: 100% (527/527), done.
remote: Total 6704 (delta 3623), reused 3318 (delta 3318), pack-reused 2859
Receiving objects: 100% (6704/6704), 3.43 MiB | 703.00 KiB/s, done.
Resolving deltas: 100% (5036/5036), completed with 1436 local objects.
From https://github.com/openshift/kubernetes
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      openshift-1.3 -> github.com/openshift-remote/openshift-1.3
 * [new branch]      openshift-1.4 -> github.com/openshift-remote/openshift-1.4
 * [new branch]      rebase-20160831 -> github.com/openshift-remote/rebase-20160831
 * [new branch]      release-1.0 -> github.com/openshift-remote/release-1.0
 * [new branch]      release-1.1 -> github.com/openshift-remote/release-1.1
 * [new branch]      release-1.2 -> github.com/openshift-remote/release-1.2
 * [new branch]      release-1.2-stable-20160309 -> github.com/openshift-remote/release-1.2-stable-20160309
 * [new branch]      release-1.2-stable-20160312 -> github.com/openshift-remote/release-1.2-stable-20160312
 * [new branch]      release-1.2-stable-20160316 -> github.com/openshift-remote/release-1.2-stable-20160316
 * [new branch]      stable     -> github.com/openshift-remote/stable
 * [new branch]      stable-20160127 -> github.com/openshift-remote/stable-20160127
 * [new branch]      stable-20160211 -> github.com/openshift-remote/stable-20160211
 * [new branch]      stable-20160309 -> github.com/openshift-remote/stable-20160309
 * [new branch]      stable-20160411 -> github.com/openshift-remote/stable-20160411
 * [new branch]      stable-20160510 -> github.com/openshift-remote/stable-20160510
 * [new branch]      stable-20160615 -> github.com/openshift-remote/stable-20160615
 * [new branch]      stable-20160624 -> github.com/openshift-remote/stable-20160624
 * [new branch]      stable-20160804 -> github.com/openshift-remote/stable-20160804
 * [new branch]      stable-20160831 -> github.com/openshift-remote/stable-20160831
 * [new branch]      stable-9da202e -> github.com/openshift-remote/stable-9da202e
 * [new tag]         v1.1.0-origin -> v1.1.0-origin
 * [new tag]         v1.2.0-origin -> v1.2.0-origin

[concaf@containscafeine kubernetes]$ git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4

[concaf@containscafeine kubernetes]$ git branch -r --contains d19513fe86f3e0769dd5c4674c093a88a5adb8b4
error: no such commit d19513fe86f3e0769dd5c4674c093a88a5adb8b4
usage: git branch [<options>] [-r | -a] [--merged | --no-merged]
...
...
```

Here, git cannot find the given commit in any of the branches.

Now, I have tried checking out multiple commits and releases of Kubernetes, but have not been able to fix this.

This is the first time I am dealing with godep and vendoring issues, so any help is much appreciated.

CC: @surajssd @rtnpro @kadel .
 ```
$ export GOPATH=$( mktemp -d )
$ go get github.com/kubernetes-incubator/kompose
$ go get github.com/tools/godep
$ cd $GOPATH/src/github.com/kubernetes-incubator/kompose
$ $GOPATH/bin/godep restore -v
...
godep: Downloading dependency (if needed): github.com/golang/glog
# cd /tmp/tmp.RlrPOID081/src/github.com/golang/glog; git checkout 335da9dda11408a34b64344f82e9c03779b71673
fatal: reference is not a tree: 335da9dda11408a34b64344f82e9c03779b71673
godep: error downloading dep (github.com/golang/glog): exit status 128
...
godep: Downloading dependency (if needed): k8s.io/kubernetes/federation/apis/federation
# cd /tmp/tmp.RlrPOID081/src/k8s.io/kubernetes; git checkout d19513fe86f3e0769dd5c4674c093a88a5adb8b4
fatal: reference is not a tree: d19513fe86f3e0769dd5c4674c093a88a5adb8b4
godep: error downloading dep (k8s.io/kubernetes/federation/apis/federation): exit status 128
...
```

Also I just downloaded all of Kubernetes, the Kubernetes go client, Docker and OpenShift ¯\\\_(ツ)\_/¯

Fyi, I tried this out with glide and it also complains about missing SHAs

```
$ glide import
$ rm -rf vendor
$ glide up -v
...
[ERROR]	Failed to set version on github.com/golang/glog to 335da9dda11408a34b64344f82e9c03779b71673: Unable to update checked out version
...
[ERROR]	Failed to set version on k8s.io/kubernetes to d19513fe86f3e0769dd5c4674c093a88a5adb8b4: Unable to update checked out version
```

cc @sebgoa this is probably a pretty high priority if you can't update dependencies..
 agreed, cleaning this and tests are two top priorities. Will discuss today at the meeting..
 @sebgoa @ericchiang 
running just `godep restore` will fail. There is `./script/godep-restore.sh` that should be used instead of this.
Reason for this is that openshift is using its own glog and kubernetes forks (github.com/openshift/glog and github.com/openshift/kubernetes). `script/godep-restore.sh` solves this by adding openshift/glog and openshift/kubernetes remotes to original repositories.  godep than can find revisions from those forks.
I don't see any other solution with godeps. As I understand glide supports aliasing so we could get rid of that ugly shell script if we switch to glide.


.
 > Reason for this is that openshift is using its own glog and kubernetes forks (github.com/openshift/glog and github.com/openshift/kubernetes). script/godep-restore.sh solves this by adding openshift/glog and openshift/kubernetes remotes to original repositories. godep than can find revisions from those forks.

What features does kompose depend on that require the forked kubernetes/glog?.
 > What features does kompose depend on that require the forked kubernetes/glog?

Is not direct kompose dependency, some part of OpenShift that we are using requires it..
 @kadel similar to how kubernetes split their go-client to a separate repo, if OpenShift does something similar, could we *theoretically* remove these dependencies / restore issues?.
 Yes and that would be best solution it would make kompose much lighter..
 @containscafeine closing this since we moved to glide this is irrelevant..
 "
,,297,"Update openshift, openshift k8s deps in Godeps and vendors..
 Steps followed to update Godeps:

``` bash
cd $GOPATH/src/github.com/openshift/origin; git checkout v1.4.0-rc1; ./hack/godep-restore.sh
cd $GOPATH/src/github.com/docker/docker; git checkout 601004e1a714d77d3a43e957b8ae8adbc867b280 # from existing Godeps.json
cd $GOPATH/src/github.com/docker/engine-api; git checkout 1d247454d4307fb1ddf10d09fd2996394b085904 # from Godeps.json
cd $GOPATH/src/github.com/kubernetes-incubator/kompose
# To avoid errors during saving dependencies
rm -rf Godeps
godep save ./... 
``` .
 @rtnpro, running `script/godep-restore.sh` fails with this -

```bash
<snip>
Starting to download all godeps. This takes a while
# cd /home/concaf/rtn_pr_godep/src/google.golang.org/cloud; git checkout eb47ba841d53d93506cfbfbc03927daf9cc48f88
godep: error restoring dep (google.golang.org/cloud/compute/metadata): chdir /home/concaf/rtn_pr_godep/src/google.golang.org/cloud: no such file or directory
# cd /home/concaf/rtn_pr_godep/src/google.golang.org/cloud; git checkout eb47ba841d53d93506cfbfbc03927daf9cc48f88
godep: error restoring dep (google.golang.org/cloud/internal): chdir /home/concaf/rtn_pr_godep/src/google.golang.org/cloud: no such file or directory
godep: Error restoring some deps. Aborting check.
```.
 @containscafeine this was in a clean GOPATH ?.
 @surajssd Yessir!.
 @kadel should have a look at this. I believe there is an issue with our dependencies, we seem to be pulling way more than we need..
 I got this:
```
Starting to download all godeps. This takes a while
godep: error restoring dep (google.golang.org/cloud/compute/metadata): cannot find package ""google.golang.org/cloud/compute/metadata"" in any of:
	/usr/lib/go/src/google.golang.org/cloud/compute/metadata (from $GOROOT)
	/home/tomas/tmp/kompose/src/google.golang.org/cloud/compute/metadata (from $GOPATH)
godep: error restoring dep (google.golang.org/cloud/internal): cannot find package ""google.golang.org/cloud/internal"" in any of:
	/usr/lib/go/src/google.golang.org/cloud/internal (from $GOROOT)
	/home/tomas/tmp/kompose/src/google.golang.org/cloud/internal (from $GOPATH)
godep: Error restoring some deps. Aborting check.
Download finished into /home/tomas/tmp/kompose
```.
 I'm fairly confused about this. If i do `godep restore` again after i get that error, everything works fine .
 @kadel @surajssd I found a related issue with godeps here: https://github.com/tools/godep/issues/186

It seems like ``godep`` complains if it's not able to download or find the package. However, on the second run, it works. I am not sure how to work around this issue..
 @rtnpro this worked for me on a clean GOPATH..
 @rtnpro @containscafeine @surajssd 
can you please check https://github.com/kadel/kompose/tree/update-godeps-openshift-k8s?
It is modified godep-restore.sh (more in comments) and it should fix this.

Right now I don't see any other way how to fix this :-(

Will do more testing tomorrow..
 @kadel did try your script and it worked without problems.

```bash
[vagrant@fedora ~]$ ll
total 12
drwxrwxr-x. 2 vagrant vagrant 4096 Nov 24 06:12 Downloads
drwxrwxr-x. 5 vagrant vagrant 4096 Nov 24 12:40 go
-rwxrwxr-x. 1 vagrant vagrant 3152 Nov 24 06:31 installer_go.sh
[vagrant@fedora ~]$ rm -rf $GOPATH/src

[vagrant@fedora ~]$ mkdir -p $GOPATH/src/github.com/kubernetes-incubator
[vagrant@fedora ~]$ cd $GOPATH/src/github.com/kubernetes-incubator

[vagrant@fedora kubernetes-incubator]$ git clone https://github.com/kadel/kompose
Cloning into 'kompose'...
remote: Counting objects: 8992, done.
remote: Compressing objects: 100% (6/6), done.
remote: Total 8992 (delta 0), reused 0 (delta 0), pack-reused 8986
Receiving objects: 100% (8992/8992), 7.67 MiB | 1.75 MiB/s, done.
Resolving deltas: 100% (3954/3954), done.
Checking connectivity... done.


[vagrant@fedora kubernetes-incubator]$ cd kompose/
✔ ~/go/src/github.com/kubernetes-incubator/kompose [master|✔]
18:11 $ git checkout update-godeps-openshift-k8s 
Branch update-godeps-openshift-k8s set up to track remote branch update-godeps-openshift-k8s from origin.
Switched to a new branch 'update-godeps-openshift-k8s'

✔ ~/go/src/github.com/kubernetes-incubator/kompose [update-godeps-openshift-k8s|✔] 
18:12 $ ./script/godep-restore.sh 
Preloading some dependencies
remote: Counting objects: 6704, done.
remote: Total 6704 (delta 3386), reused 3386 (delta 3386), pack-reused 3318
Receiving objects: 100% (6704/6704), 3.36 MiB | 1.40 MiB/s, done.
Resolving deltas: 100% (5103/5103), completed with 1444 local objects.
From https://github.com/openshift/kubernetes
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      openshift-1.3 -> github.com/openshift-remote/openshift-1.3
 * [new branch]      openshift-1.4 -> github.com/openshift-remote/openshift-1.4
 * [new branch]      rebase-20160831 -> github.com/openshift-remote/rebase-20160831
 * [new branch]      release-1.0 -> github.com/openshift-remote/release-1.0
 * [new branch]      release-1.1 -> github.com/openshift-remote/release-1.1
 * [new branch]      release-1.2 -> github.com/openshift-remote/release-1.2
 * [new branch]      release-1.2-stable-20160309 -> github.com/openshift-remote/release-1.2-stable-20160309
 * [new branch]      release-1.2-stable-20160312 -> github.com/openshift-remote/release-1.2-stable-20160312
 * [new branch]      release-1.2-stable-20160316 -> github.com/openshift-remote/release-1.2-stable-20160316
 * [new branch]      stable     -> github.com/openshift-remote/stable
 * [new branch]      stable-20160127 -> github.com/openshift-remote/stable-20160127
 * [new branch]      stable-20160211 -> github.com/openshift-remote/stable-20160211
 * [new branch]      stable-20160309 -> github.com/openshift-remote/stable-20160309
 * [new branch]      stable-20160411 -> github.com/openshift-remote/stable-20160411
 * [new branch]      stable-20160510 -> github.com/openshift-remote/stable-20160510
 * [new branch]      stable-20160615 -> github.com/openshift-remote/stable-20160615
 * [new branch]      stable-20160624 -> github.com/openshift-remote/stable-20160624
 * [new branch]      stable-20160804 -> github.com/openshift-remote/stable-20160804
 * [new branch]      stable-20160831 -> github.com/openshift-remote/stable-20160831
 * [new branch]      stable-9da202e -> github.com/openshift-remote/stable-9da202e
 * [new tag]         v1.1.0-origin -> v1.1.0-origin
 * [new tag]         v1.2.0-origin -> v1.2.0-origin
remote: Counting objects: 3, done.
remote: Total 3 (delta 2), reused 2 (delta 2), pack-reused 1
Unpacking objects: 100% (3/3), done.
From https://github.com/openshift/glog
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      stable     -> github.com/openshift-remote/stable
Note: checking out 'eb47ba8'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again. Example:

  git checkout -b <new-branch-name>

HEAD is now at eb47ba8... metadata: use ctxhttp to support cancelation in Go 1.4
Starting to download all godeps. This takes a while
Download finished into /home/vagrant/go

✔ ~/go/src/github.com/kubernetes-incubator/kompose [update-godeps-openshift-k8s|✔] 
18:27 $ 
```.
 I've added my changes to godep-restore.sh to this PR.
 Can we get more reviews on this?
This is quite big.

fixes #297 


As soon as we fix current state with `godeps` we can start working on switching to `glide` ( #314)

cc: @rtnpro @surajssd @ngtuna @janetkuo 

.
 Hi @kadel I have another approach for this. Let's not try to fix the current Godeps, just remove vendor and Godeps folders and start building glide. We should list out here dependencies and theirs version that Kompose relies on and then build glide.yaml file. Focusing on main packages, others we could use latest version. So here we have:

- libcompose v0.3.0-68-gfbdac0a (could be upgraded to v0.3.0)
- kubernetes/openshift 1.3 (probably we should upgrade to 1.4)
- spf13/cobra master

Once having the fixed dependencies, we will test the current codebase and make changes if it's needed..
 Problem is that it is broken now, and until we make glide work, we can't do restore and work with dependencies.

 I think that we should fix this first. Especially when we already have fix.

Than we can work on making it work with glide.
.
 So, let's merge it :).
 Okay. So I just tested this PR in a separate folder and it worked. Didn't look into files.

```
Tunas-MacBook-Pro:kompose tuna$ git branch
  master
* rtnpro-update-godeps-openshift-k8s
Tunas-MacBook-Pro:kompose tuna$ go build -o kompose main.go 

Tunas-MacBook-Pro:kompose tuna$ pwd
/tmp/gocode/kompose/src/github.com/kubernetes-incubator/kompose

Tunas-MacBook-Pro:kompose tuna$ script/godep-restore.sh 
Preloading some dependencies
remote: Counting objects: 6704, done.
remote: Total 6704 (delta 3383), reused 3383 (delta 3383), pack-reused 3321
Receiving objects: 100% (6704/6704), 3.39 MiB | 963.00 KiB/s, done.
Resolving deltas: 100% (5102/5102), completed with 1443 local objects.
From https://github.com/openshift/kubernetes
 * [new branch]      master        -> github.com/openshift-remote/master
 * [new branch]      openshift-1.3 -> github.com/openshift-remote/openshift-1.3
 * [new branch]      openshift-1.4 -> github.com/openshift-remote/openshift-1.4
 * [new branch]      rebase-20160831 -> github.com/openshift-remote/rebase-20160831
 * [new branch]      release-1.0   -> github.com/openshift-remote/release-1.0
 * [new branch]      release-1.1   -> github.com/openshift-remote/release-1.1
 * [new branch]      release-1.2   -> github.com/openshift-remote/release-1.2
 * [new branch]      release-1.2-stable-20160309 -> github.com/openshift-remote/release-1.2-stable-20160309
 * [new branch]      release-1.2-stable-20160312 -> github.com/openshift-remote/release-1.2-stable-20160312
 * [new branch]      release-1.2-stable-20160316 -> github.com/openshift-remote/release-1.2-stable-20160316
 * [new branch]      stable        -> github.com/openshift-remote/stable
 * [new branch]      stable-20160127 -> github.com/openshift-remote/stable-20160127
 * [new branch]      stable-20160211 -> github.com/openshift-remote/stable-20160211
 * [new branch]      stable-20160309 -> github.com/openshift-remote/stable-20160309
 * [new branch]      stable-20160411 -> github.com/openshift-remote/stable-20160411
 * [new branch]      stable-20160510 -> github.com/openshift-remote/stable-20160510
 * [new branch]      stable-20160615 -> github.com/openshift-remote/stable-20160615
 * [new branch]      stable-20160624 -> github.com/openshift-remote/stable-20160624
 * [new branch]      stable-20160804 -> github.com/openshift-remote/stable-20160804
 * [new branch]      stable-20160831 -> github.com/openshift-remote/stable-20160831
 * [new branch]      stable-9da202e -> github.com/openshift-remote/stable-9da202e
 * [new tag]         v1.1.0-origin -> v1.1.0-origin
 * [new tag]         v1.2.0-origin -> v1.2.0-origin
remote: Counting objects: 3, done.
remote: Total 3 (delta 2), reused 2 (delta 2), pack-reused 1
Unpacking objects: 100% (3/3), done.
From https://github.com/openshift/glog
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      stable     -> github.com/openshift-remote/stable
Note: checking out 'eb47ba8'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again. Example:

  git checkout -b <new-branch-name>

HEAD is now at eb47ba8... metadata: use ctxhttp to support cancelation in Go 1.4
Starting to download all godeps. This takes a while
Download finished into /tmp/gocode/kompose
```.
 Before we merge this, can we have a discussion on whether we really need all these dependencies. I have not spend much time with Godeps...but it looks like the project is getting bigger and bigger with dependencies going down the rabbit hole...

Like do we really need all of openshift and all of Kubernetes (plus a ton of other things) to compile ?.
 @sebgoa that's also what I wanted to mention on above suggestion. Like what I did with Glide, I listed out mandatory packages relating directly to our code and build Glide file from the scratch. The pain of dependency problem is that these packages will require other packages. But that's fine. Maintaining only packages relating directly to kompose code would be a good approach. And we should not upload vendor folder, let's users install deps on their own machine..
 > And we should not upload vendor folder, let's users install deps on their own machine.

Please don't do that.

We should upload vendor folder, it is intended to be included in project repo.
If you don't include vendor in your project git repository, it is easy to break build.
If someone deletes library that you depend on you can still build your project because that code is in your vendor dir.
.
 > Like do we really need all of openshift and all of Kubernetes (plus a ton of other things) to compile ?

Kompose just imports bunch of pkgs  from:
 - k8s.io/kubernetes
 - gitub.com/openshif/origin
 - github.com/docker/libcompose

Problem is that those brings their dependencies, dependencies of those dependencies ...  it gets complicated especially with OpenShift and Kubernetes in one project.

List of actual dependencies is generated by godep.
I wouldn't be surprised if there is a lot of dependencies that are not required, but godeps includes them for some reason. Glide might be better in this.  But right now, this is what we get with godep.

I will try to do this again to verify that i get same result as rtnpro got.





.
 @sebgoa  I did fresh `godep-restore.sh` and `godep save ./...` and I got less dependencies than @rtnpro  got.
I don't understand how it is possible :confused: but somehow it is, and everything seems to be working.

Now this PR removes more lines that it adds..
 > We should upload vendor folder, it is intended to be included in project repo.
If you don't include vendor in your project git repository, it is easy to break build.

Yeah that's also correct. We could probably make travis pulling deps on every build but yes it will slow down the build process. .
 I think this is not required any more. @rtnpro closing it..
 "
,,296,"Support for secrets.
 Right now there is no way I can specify secrets from docker-compose which then maps to kubernetes. This would be great thing to have. 

For using this feature I had to manually create secret object and then add it to container spec in deployment..
 Docker does not yet have a concept of secrets, does it ? I think they are working on it , but it is not there yet and not in compose AFAIK..
 So one instance that would be supported now would be in use of environmental variables.  the docker compose for my project i just converted sets stuff like the username and pass for a database as env variables. ill convert them over to using secrets.
 @jamstar yeah that needs to be done manually!.
 Secrets are able to be defined in Docker Compose Version 3: https://docs.docker.com/compose/compose-file/#secrets-configuration-reference and thus we can map this to Kubernetes much easier than expected..
 Since Docker Compose now has secrets, the best way (from my research) would be to use secrets as well as the `file` option of import. Unfortunately using `external` will not work as secrets stored within swarm are encrypted Raft variables (no idea what they mean by that in the documentation).

See: https://stackoverflow.com/questions/42139605/how-do-you-manage-secret-values-with-docker-compose-v3-1 for some context.

.
 FYI, `secrets` is supported in docker-compose version 3.1.
 I just had a look at things and it appears as though the mapping is doable, with the exception of _uid_ and _gid_ when projecting the secret into `/run/secrets/` - this may be something to raise as an in Kubernetes if it hasn't been already.

The rest of this post is really just a summary of the documentation and links to things that I think are relevant for whoever takes this on, which I found from a quick poke around (I'm not familiar with the codebases).

## Creating secrets
_[compose documentation](https://docs.docker.com/compose/compose-file/#secrets-configuration-reference)_
The documentation shows the 3 ways secrets can be specified:
```yaml
secrets:
  my_first_secret:
    file: ""./secret_data""
  my_second_secret:
    external: true
  my_third_secret:
    external:
      name: ""name_externally""
```
I'm not sure we can use the values of external secrets (I think what @cdrage was saying), even if we could I think maintaining the separation in environments that comes with the externals is beneficial.

In Kubernetes I think this would revolve around [Secret](https://github.com/kubernetes/kubernetes/blob/v1.9.0/staging/src/k8s.io/api/core/v1/types.go#L4766) objects.

## Using secrets
_[compose documentation](https://docs.docker.com/compose/compose-file/#secrets)_
When a secret is shared with a container it is mapped into it, by default to `/run/secrets/$name`. The following are configurable:
 * _source_ - the name of the secret in Docker
 * _target_ - the name to use within `/run/secrets/`
 * _uid_ - the UID to use for the secret in the container
 * _gid_ - the GID to use for the secret in the container
 * _mode_ - the file mode to use for the secret in the container

In Kubernetes I think this would revolve around [SecretProjection](https://github.com/kubernetes/kubernetes/blob/v1.9.0/staging/src/k8s.io/api/core/v1/types.go#L1192)s to project the secrets into `/run/secrets/`. [example](https://kubernetes.io/docs/concepts/storage/volumes/#projected).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 I see this has been marked as stale now. It would be _really_ nice to get this into kompose (along with support for docker 'configs'!), as these are perhaps the trickiest bits to understand and get right for a k8s noob.

Not sure what the etiquette is with the bot and `/remove-lifecycle stale` - is this meant just for repo owners, or anyone who is interested in the feature?.
 This is a big feature, i can start working on it !.
 The `file` secret seems pretty straightforward.  The `external` secret  data seems can be retrieved from the docker api ( docker inspect <secret-name>). But seems we don't connect to docker when do `kompose convert`, this is tricky.  I think I can start trying to add the `file` part first..
 +1.
 /remove-lifecycle stale.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 "
,,295,"Stdout shouldn't output warning / logging messages..
 When doing `--stdout`. I don't think is should be outputting. `--surpress-warnings` should be set by default if passing in `--stdout`
```
WARN[0000] Unsupported key network_mode - ignoring      
WARN[0000] Unsupported key build - ignoring             
WARN[0000] Unsupported key depends_on - ignoring        
WARN[0000] Unsupported key tty - ignoring               
WARN[0000] [anitya-postgres] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./lib/cucoslib:/usr/lib/python3.5/site-packages/cucoslib:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./server/bayesian:/usr/lib/python3.5/site-packages/bayesian:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./server/kerberos/keytab:/mnt:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./server/coreapi-httpd.conf:/etc/httpd/conf.d/coreapi-httpd.conf:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./server/:/coreapi/:ro,z 
WARN[0000] [redis-populate] Service cannot be created because of missing port. 
WARN[0000] [beat-scheduler] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./lib/cucoslib:/usr/lib/python2.7/site-packages/cucoslib:ro,z 
WARN[0000] [worker] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./lib/cucoslib:/usr/lib/python3.5/site-packages/cucoslib:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./mercator/mercator:/usr/lib/python3.5/site-packages/mercator:ro,z 
WARN[0000] Failed to configure container volume: invalid volume format: ./lib/hack/secrets.yaml:/var/lib/secrets/secrets.yaml:ro,z 
```.
 Those warning are on stderr. So it shouldn't cause  any problems. Some of the warning are quite important as they are informing about things that can make application non working properly (like missing port, or skipped volumes).
 agreed with kadel.

```
$ ./kompose -f ./examples/docker-voting.yml convert --stdout > foobar
WARN[0000] [worker] Service cannot be created because of missing port. 
sebair: kompose (preference)$ cat foobar | more
{
  ""kind"": ""List"",
  ""apiVersion"": ""v1"",
```.
 "
,,294,"added support for cpu_shares.
 [WIP] for #267 
How can we convert `cpu_share` defined in [docker](https://docs.docker.com/engine/reference/run/#cpu-share-constraint) to `cpu` defined in [Kubernetes](http://kubernetes.io/docs/user-guide/compute-resources/) as there is no one to one mapping for it. 

**Docker** by default gives all containers get the same proportion of CPU cycles and by using `cpu_share` we can give a percentage of CPU to each container.
 
In **Kubernetes** world, cpu are measured in unit. The expression `0.1` is equivalent to the expression `100m`, which can be read as “one hundred millicpu”. CPU is always requested as an absolute quantity, never as a relative quantity; `0.1` is the same amount of `cpu` on a single core, dual core, or 48 core machine.

Thoughts ? @surajssd @kadel @ngtuna.
 I would suggest finding the kubelet code that does this translation. since docker is used as runtime, kubernetes must pass its limits to docker...somehow....
 Hey @procrypt any status on this? I'm trying to find the kubelet code, so I was wondering if you happened to have found it already or not..
 I did find some information on `millicpu` though. https://github.com/kubernetes/kubernetes/search?utf8=%E2%9C%93&q=millicpu.
 @cdrage I'm not working on this currently, this is not on the priority list so I picked up some other issue. .
 @cdrage this PR is more of communication starter of how do you map CPU in docker and k8s world, which talk different language. 

Docker talks in terms of CPU shares which is certain percent of CPU of total CPU. While k8s talks in terms of no. of cores. Now converting CPU shares to amount of core is hard unless you know how many cores a cluster has available. So I am not sure if we should use cpu_shares to support it..
 @procrypt I'm going to close this PR for now and move the discussion back to https://github.com/kubernetes-incubator/kompose/issues/267 until we've come up with a fix for implementing cpu_limit.
 "
,,293,"Added volume to mariadb in etherpad fixture.
 Volume constraint is missing in mariadb service in etherpad example, so added that so that it mariadb container does not fail in environments where creating container in `/var/lib/mysql` is not allowed for non-root process..
 LGTM.
 "
,,292,"Interactive / work-through-each-step mode..
 So at the moment you simply run `kompose convert` and that's it. Sometimes you can pass in:
```
   --chart, -c                          Create a Helm chart for converted objects
   --deployment, -d                     Generate a Kubernetes deployment object (default on)
   --daemonset, --ds                    Generate a Kubernetes daemonset object
   --replicationcontroller, --rc        Generate a Kubernetes replication controller object
```

However, I'd be **awesome** to add an interactive mode where it will walk you through each step.

For example, when encountering a service *without* a port within `docker-compose.yml`, `kompose` should output the implicit section and ask the user what port that service is using. This is required for Kubernetes conversion.

The same goes for volumes which are binded to the host within `docker-compose.yml` but cannot be converted to an equivalent Kubernetes artifact. .
 Yeah this used to be discussed during summer. We should keep it in mind and for some special cases need interactive mode we will discuss (probably on kompose call). Also, in those special cases, I would suggest we should provide both (for example, adding `--silent` flag for non-interactive mode).
 @cdrage @ngtuna how do we proceed with this?

Instead of a `--silent` flag, should be instead have `-i, --interactive` flag?

Also, the possibilities of going interactive for a particular option/behavior are quite a few, so should we do this iteratively instead? e.g., let's start with adding one for when the ports are not found, and keep on sending PRs as and when we go?

Thoughts?
CC: @kadel @surajssd .
 What would be use cases for interactive mode? What question would like to ask?

Ports are solved and we don't need interactive mode for that.


.
 @kadel - umm..., something like - 

- no value set for environment variable $image, enter now :
- build specified, but no git repo initialized, enter now:

There can be more cases as and when we go, WDYT?.
 We first need to create a layer around the way data comes in. With this addition data will be coming in from cmd line flags, defaults and interactive mode.

this will help us do validation from one place only..
 I'm going to close this for now. .
 "
,,291,"A better missing port warning message.
 When encountering the warning from: https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/k8sutils.go#L232 I don't know what it specifically means when it says that ""port"" is missing.

What am I missing here? I don't believe I need to explicitly supply the port, correct?.
 Discussion on similar lines happened about detecting ports exposed from image itself at https://github.com/kubernetes-incubator/kompose/issues/146

I am +1 for better warning message or something like that.
.
 https://github.com/kubernetes-incubator/kompose/pull/157 should solve this. .
 Yes, I am closing. I will get back to #157 .
 "
,,290,"Update .dsb to .dab.
 "
,,289,"Clean up the logging output for unknown provider.
 "
,,288,"`--output`, or specify folder to output converted files to.
 Missing command for `--output` as I'd like to output the converted files to a different folder than current folder. .
 @containscafeine created similar issue sometime back https://github.com/kubernetes-incubator/kompose/issues/209
.
 closing, this can be covered in #209.
 "
,,287,"Update TRAVIS CI to add coveralls.
 Updates travis to enable coveralls support.

Fixes https://github.com/kubernetes-incubator/kompose/issues/281.
 I have access to coveralls via incubator. I will test this today..
 @sebgoa done. now let's see if these tests pass :).
 Currently this isn't working for some odd-reason (timing out). I'll be looking at an alternative fix..
 ok, I am going to merge it and fix it.
 Why merge it if its not working?
It looks like it is missing token https://coveralls.zendesk.com/hc/en-us/articles/201342809-Go

.
 because I was tired of seeing this PR pending and seeing our code coverage on the front page will be good motivation to improve unit tests.

afaik, you don't need a token for public repos...

but yeah it is failing..
 To be honestly I don't see reason why it couldn't be fixed in this PR.

Now front page shows no coverage and failed tests.

I've done some digging around, and it is timeouting because it runs all unit test again for every package as separate `go test` run.
like this:
```
for package in all_packages:
   go test package
```
it takes a long time to start go test and travis-ci jobs has 15min timeout.

Root cause for this is that for some reason `go test ` can't collect coverage profile for multiple packages.
So you have to run it for every package again :-(


We could run tests and collect all coverageprofiles into one file  and than call `goveralls` with `-coverprofile` to only submit results to coveralls.io  as described here https://gist.github.com/rjeczalik/6f01430e8554bf59b88e

But it still requires to run `go test` for every package separately. 
.
 this is how kubernetes is dealing with this https://github.com/kubernetes/kubernetes/blob/master/hack/make-rules/test.sh#L228.
 "
,,286,"Minor doc fix.
 .
 @containscafeine please sign linux foundation cla, otherwise fix LGTM
.
 @surajssd just did!
.
 @sebgoa seems this was merged before the trailing `/` was removed. opened up https://github.com/kubernetes-incubator/kompose/pull/305.
 what's wrong with the trailing / ?.
 @sebgoa nothing, just OCD, not ""unix-like"": http://unix.stackexchange.com/questions/212805/should-i-use-a-slash-at-the-end-of-path-variables-in-shell-script-or-not.
 "
,,285,"expose service to outside, fix #140.
 .
 i think this needs rebasing, you've got some README.md changes in here. 
.
 @cdrage yeah, it's a WIP right now, things are going to get worse before it gets any better :)
.
 @containscafeine I tested the example you have created and it seems to work correctly. I also had a look at the code. It looks good, overall..
 
[![Coverage Status](https://coveralls.io/builds/9174852/badge)](https://coveralls.io/builds/9174852)

Coverage decreased (-0.1%) to 34.872% when pulling **f1406673800a5a6b2d62d812916dc855996570ce on containscafeine:expose_service** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9189747/badge)](https://coveralls.io/builds/9189747)

Coverage decreased (-2.0%) to 33.024% when pulling **9a52fa65917f249133431bd795176ada76d58efe on containscafeine:expose_service** into **862419b8366e15caf3d43d051b18bc024242c063 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9191901/badge)](https://coveralls.io/builds/9191901)

Coverage decreased (-2.0%) to 33.024% when pulling **1a6946a60cb00cb92b48fd2da96c66ad0b874409 on containscafeine:expose_service** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9194448/badge)](https://coveralls.io/builds/9194448)

Coverage decreased (-1.4%) to 33.617% when pulling **179c1afa9452aa177d356c049e627522c748fc04 on containscafeine:expose_service** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9207199/badge)](https://coveralls.io/builds/9207199)

Coverage decreased (-1.4%) to 33.617% when pulling **4c224669ca9736d3a634a93641bad4741b9ee378 on containscafeine:expose_service** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9242294/badge)](https://coveralls.io/builds/9242294)

Coverage decreased (-2.2%) to 32.707% when pulling **87f88840ac18b9df1a8185be36a72986028d46b4 on containscafeine:expose_service** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9275479/badge)](https://coveralls.io/builds/9275479)

Coverage increased (+3.6%) to 38.576% when pulling **d40fd99a19f06f35b124a1c6e12a84fe8e52d5f6 on containscafeine:expose_service** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9275678/badge)](https://coveralls.io/builds/9275678)

Coverage increased (+3.6%) to 38.576% when pulling **35302eff3e66057e441ddec0641d095bae21172a on containscafeine:expose_service** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 @containscafeine please send docs with this, we don't want user to miss out on this cool feature due to lack of docs.
 
[![Coverage Status](https://coveralls.io/builds/9358635/badge)](https://coveralls.io/builds/9358635)

Coverage increased (+2.7%) to 41.155% when pulling **190cf791b580437e5a5d12f180e37fdb390d81ca on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9358662/badge)](https://coveralls.io/builds/9358662)

Coverage increased (+2.7%) to 41.155% when pulling **190cf791b580437e5a5d12f180e37fdb390d81ca on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9359302/badge)](https://coveralls.io/builds/9359302)

Coverage increased (+1.7%) to 40.157% when pulling **0c1fd729236e684aa34b23d2fde3f664575b764b on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @containscafeine tests seem to fail since `glide-vc --only-code --no-tests` needs to be ran again in the directory for vendoring. missing one odd file..
 
[![Coverage Status](https://coveralls.io/builds/9360093/badge)](https://coveralls.io/builds/9360093)

Coverage increased (+1.7%) to 40.157% when pulling **861f0168d09ac14ddd4cc6db236f08cd9ed1eb36 on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 commits need to be squashed and then LGTM from me :).
 
[![Coverage Status](https://coveralls.io/builds/9374870/badge)](https://coveralls.io/builds/9374870)

Coverage increased (+1.7%) to 40.157% when pulling **667f3592c9e8173b2231d29b534ec84b2d73e64e on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9375784/badge)](https://coveralls.io/builds/9375784)

Coverage increased (+1.7%) to 40.157% when pulling **d14802f692a83968409ccc852e4693daefecf689 on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9375839/badge)](https://coveralls.io/builds/9375839)

Coverage increased (+1.7%) to 40.157% when pulling **d14802f692a83968409ccc852e4693daefecf689 on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @cdrage @surajssd - added docs, squashed the commits, refactored the ingress unit test since last review. Should be good to go now..
 
[![Coverage Status](https://coveralls.io/builds/9376087/badge)](https://coveralls.io/builds/9376087)

Coverage increased (+1.7%) to 40.157% when pulling **9654f28e13f43136249b4de57df1228ea5a9a431 on containscafeine:expose_service** into **c485a870d8856c20133ae0f4a9fca7440a90a00f on kubernetes-incubator:master**.
.
 @containscafeine just conflicting right now :).
 
[![Coverage Status](https://coveralls.io/builds/9378595/badge)](https://coveralls.io/builds/9378595)

Coverage increased (+1.2%) to 42.083% when pulling **7e378cd54669b60ebdab329e42ef4dcbaf55ac58 on containscafeine:expose_service** into **48e3ba88cd6154617215e43cb3fea88d86b82535 on kubernetes-incubator:master**.
.
 @cdrage fixed.
 LGTM!.
 "
,,284,"Organize the README..
 This updates the README with some small changes such as titles as well
as rewording a few sentences..
 @cdrage only a minor comment otherwise LGTM
.
 @kadel @ericchiang rebased ^^.
 "
,,283,"Update building instructions.
 @kadel @sebgoa rebased..
 @kadel @sebgoa @ngtuna is it possible for me to get access to add / remove labels?.
 @cdrage I will check about labels....
 @sebgoa another review on this? :).
 and you will need to rebase after editing that requirements list to what it was..
 Going to close this for now ^^.
 "
,,282,"Update README since Kompose is now Go gettable.
 Since You're now able to install Kompose via `go get`. Update the README
accordingly..
 "
,,281,"Add coveralls.
 to track our unit test coverage, we should setup coveralls.io, it is used in the main repo.

then we need to work on the unit-tests.
 @sebgoa someone will have to login to coveralls.io to enable it, but I've created #287 
.
 @sarahnovotny sorry to ping you directly, but do you know how we can enable `coveralls` for kompose. I am assuming there is a kubernetes project account..
 In the meantime, I logged into coveralls and requested access for kubernetes-incubator, no clue to whom the request went. Will see..
 @sebgoa @sarahnovotny thank you both. Yeah, the PR (https://github.com/kubernetes-incubator/kompose/pull/287) failed due to no access (timeout to coveralls).
 "
,,280,"added support for OpenShift down.
 Fix #208 
cc @kadel @surajssd @sebgoa @ngtuna .
 @surajssd I have updated the PR. .
 We need tests for this PR to go in..
 @surajssd Working on tests..
 @kadel Updated the PR.
 @kadel Updated the PR.
Please review :).
 @kadel I think it will be a heavy job, to bring up the OpenShift cluster for unit testing of the code. What we can do is, open a separate issue for the testing part and not block this PR for unit tests.

Thoughts ?.
 @kadel added comments..
 @procrypt gofmt :wink: .
 
[![Coverage Status](https://coveralls.io/builds/9235959/badge)](https://coveralls.io/builds/9235959)

Coverage decreased (-0.03%) to 34.975% when pulling **27dc5dcd819d72dda34de34602fc37e3ed154e4f on procrypt:down** into **04a3131834cddfb1af42b63b21641fbbf84a4a9d on kubernetes-incubator:master**.
.
 @surajssd Good catch. When you resolve those issues with @procrypt. Feel free to merge it..
 
[![Coverage Status](https://coveralls.io/builds/9291409/badge)](https://coveralls.io/builds/9291409)

Coverage decreased (-1.3%) to 33.656% when pulling **6ad54a36e2392b1c46dc853af53e017013c69d28 on procrypt:down** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9291444/badge)](https://coveralls.io/builds/9291444)

Coverage decreased (-1.3%) to 33.656% when pulling **6ad54a36e2392b1c46dc853af53e017013c69d28 on procrypt:down** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9291526/badge)](https://coveralls.io/builds/9291526)

Coverage decreased (-1.3%) to 33.656% when pulling **6ad54a36e2392b1c46dc853af53e017013c69d28 on procrypt:down** into **65e19e31054f53aa6f5d7c2ad32dd5a6839fff38 on kubernetes-incubator:master**.
.
 @procrypt thanks merging!.
 "
,,279,"Added flag definitions for kompose #37.
 .
 @cab105 I'm gonna refuse this PR because you was doing it in the keynote.
.
 At least I'm doing something productive while paying attention.
.
 So tell me what Kelsey was talking at his keynote section? :trollface:
.
 What is kubeadm for 100 @ngtuna?
.
 Tested. LGTM
.
 "
,,278,"Add initial support for bringing up a kubernetes cluster using miniku….
 …be #156.
 Per my comment here (https://github.com/kubernetes-incubator/kompose/issues/156#issuecomment-259847395) I think that this doesn't belong in kompose. I'll let an owner have the finial say though. 
.
 "
,,277,"Generic service type handler for kompose.
 Moved label handling code from Transformer to loader, to make it generic to handle creating service types.

Added new attribute to ServiceConfig which gets populated in loader.

Fixes #273.
 @cdrage I would like your view on the test function being modified and moved to new place, with less checks? Jump to https://github.com/kubernetes-incubator/kompose/pull/277/files#diff-8aba3d6a079386eaab47ed176d32d43cR23
.
 @cdrage addressed all your concerns!
.
 @ngtuna @kadel need your say on this PR as well to merge it!
.
 @kadel thanks :+1: .
 "
,,276,"support adding kompose label for bundle file.
 $title.
 @ngtuna can you please assign it to me.
.
 Thanks @pradeepto 
.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 @cdrage If I'm not mistaken support for Docker bundle format was removed from Kompose. Is that true @cdrage? .
 @kadel yeah, *way* too many issues with bundling and it's still an experimental feature. We all agreed that we would stop development on it until Docker accepts it as mainline. See: https://docs.docker.com/compose/bundles/.
 /lifecycle frozen.
 Although I believe we should keep this open :+1: .
 "
,,275,"Support multiple compose files.
 In my environment I have multiple docker-compose files: one ""base"", and then some more to enable additional services/options. These additional docker-compose files override/modify the base image settings.

It would be nice if kompose supported this natively: `kompose -f base.yml -f mod.yml -f other-mod.yml convert`.

Currently it simply ignores all but the last-mentioned file..
 > Currently it simply ignores all but the last-mentioned file.

This probably counts as ""input argument validation"", i.e. https://github.com/kubernetes-incubator/kompose/issues/87 is related.
.
 @ankon or this could also look like 

```
kompose -f base.yml,mod.yml,other-mod.yml convert
```
.
 In principle, yes. But I think it would be good to stay consistent with docker-compose's behavior here. Also note that ',' is a regular character that can appear in file names, so one needs to think about escaping; additionally it breaks at least my shell's tab completion logic :)
.
 I can work on this once #304 is merged :) Add supported for multiple file import..
 "
,,274,"kompose logo.
 It would be great to have a logo for kompose project!.
 If recommend holding off on this until kompose either graduates from the incubator or finds a different home. If it becomes an official kubernetes project I'm sure some of the kubernetes design folks will have opinions about a logo.
.
 @surajssd I was just browsing through the issues, does Kompose has a logo now? If it doesn't, good time to get one as its now an official Kubernetes project and has graduated :).
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,273,"specifying service type right now is very docker-compose specific.
 We use `labels` from docker-compose to specify type of service (e.g. `kompose.service.type: nodeport`) that gets created and this gets mapped to [`annotatations`](https://github.com/kubernetes-incubator/kompose/blob/a3495b1d6bf73dba0fd6f3af44d68f2f910e3df0/pkg/kobject/kobject.go#L135) internally but then we can do this cleanly by adding one more directive in [`ServiceConfig`](https://github.com/kubernetes-incubator/kompose/blob/a3495b1d6bf73dba0fd6f3af44d68f2f910e3df0/pkg/kobject/kobject.go#L124) named `ServiceType string` so that at [loader stage](https://github.com/kubernetes-incubator/kompose/blob/a3495b1d6bf73dba0fd6f3af44d68f2f910e3df0/pkg/loader/compose/compose.go#L127) itself we load this variable and [in transformation](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/k8sutils.go#L247) we don't need to do annotation checking!

So basically now we add one vairable to `ServiceConfig` and move code from [`CreateService`](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/k8sutils.go#L239) to respective loaders..
 +1. I think that makes sense.
.
 "
,,272,"CPUSet is read and but do not map to k8s.
 We do read the `CPUSet` from docker-compose file and do not map it to any kubernetes constructs. So either add support for it or add it to unsupported keys..
 Hmm. Seems that a limit range must be added in order to add this to Kubernetes! 

http://kubernetes.io/docs/admin/limitrange/

I'm assuming we should warn the user if CPUSet is set?.
 @surajssd @cdrage as CPUset is mapped to any k8s key, shall we add it to unsupported keys..
 @surajnarwade yes SGTM, go ahead with it!.
 "
,,271,"Update docker-gitlab example.
 Latest docker-gitlab example in compose v2 format. Registering new user works well..
 "
,,270,"Make kompose keep trying its job.
 I would suggest to make kompose keep trying its job when an error occurs. Currently we throw the error and stop doing convert/up/down immediately. I would prefer a better behavior like this:

```console
$ kompose --file kadel.yml up 
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead.

INFO[0001] Successfully created Service: frontend       
INFO[0002] Successfully created Service: mongodb        
INFO[0002] Successfully created Service: backend        
INFO[0002] Successfully created Deployment: frontend    
INFO[0003] Successfully created Deployment: mongodb     
FATA[0003] Error while deploying application: persistentvolumeclaims ""mongodb-claim0"" already exists . We will keep deploying application.
INFO[0003] Successfully created Deployment: backend

$ kompose --file kadel.yml down
INFO[0002] Successfully deleted Service: backend        
INFO[0002] Successfully deleted Service: frontend       
INFO[0003] Successfully deleted Service: mongodb        
FATA[0003] Error while deleting application: deployments.extensions ""backend"" not found. We will keep deleting resources.
INFO[0002] Successfully deleted Service: frontend       
INFO[0003] Successfully deleted Service: mongodb
```

Probably it's okay to stop the `kompose up` immediately at the time of error happening, but keep the `kompose down` working will help to clean the resources better..
 Probably add `--force` flag
.
 > Probably it's okay to stop the kompose up immediately at the time of error happening, but keep the kompose down working will help to clean the resources better.

+1

I agreed for `down` it should continue cleaning even after unsuccessful deletion of one object.

For `up` it doesn't make sense  to continue because you will end up with application that is not completely deployed. But instead  if there is and error during `up` we should clean up objects that were already created..
 @kadel Totally agree..
 Hey @ngtuna, are you working on this?.
 "
,,269,"correct display when using --emptyvols.
 Fix #268 .
 "
,,268,"Tiny issue on kompose up --emptyvols displaying.
 ```console
$ kompose --file docker-compose.yml up --emptyvols
We are going to create Kubernetes Deployments, Services and PersistentVolumeClaims for your Dockerized application.
```.
 "
,,267,"Support for cpu_shares.
 It would be nice to have resources limits for cpu_shares and mem_limits..
 It would be great to have support for [mem_limit](https://docs.docker.com/compose/compose-file/#/cpushares-cpuquota-cpuset-domainname-hostname-ipc-macaddress-memlimit-memswaplimit-oomscoreadj-privileged-readonly-restart-shmsize-stdinopen-tty-user-workingdir) which should translate to a pod's spec like -

```yaml
spec:
  containers:
  - image: nginx
    imagePullPolicy: Always
    name: nginx
    resources:
      limits:
        memory: 200Mi
    terminationMessagePath: /dev/termination-log
    volumeMounts:
```

@kadel imo, mem_limit can be mapped directly, not sure about cpu_shares..
 @containscafeine :+1: .
 I'll start working on this. I'll assign myself to this issue!.
 Assigning to @containscafeine instead..
 Sigh, okay, so taking a look at the `mem_limit` part, and having implemented it, turns out that if the docker-compose.yaml looks like -
```yaml
web:
  image: tuna/docker-counter23
  ports:
    - ""5000:5000""
  links:
    - redis
  mem_limit: 500m
```

i.e., has a non integer value, then, `kompose convert` fails with -

```shell
ERRO[0000] Could not parse config for project tmp : strconv.ParseInt: parsing ""500m"": invalid syntax 
FATA[0000] Failed to load compose file: strconv.ParseInt: parsing ""500m"": invalid syntax 
```

Tracking this down further, this is a libcompose issue and `libcompose up` fails with -

```shell
ERRO[0000] Failed to unmarshall: strconv.ParseInt: parsing ""500m"": invalid syntax
web:
  image: tuna/docker-counter23
  links:
  - redis
  mem_limit: 500m
  ports:
  - 5000:5000 
ERRO[0000] Could not parse config for project tmp : strconv.ParseInt: parsing ""500m"": invalid syntax 
FATA[0000] Failed to read project: strconv.ParseInt: parsing ""500m"": invalid syntax 
```

However, trying `libcompose up` with the [latest release](https://github.com/docker/libcompose/releases/tag/v0.4.0) works fine.

So, for this to work fine, libcompose version has to be bumped, which is being tracked at https://github.com/kubernetes-incubator/kompose/pull/374.
 @containscafeine can you test it with  https://github.com/kubernetes-incubator/kompose/pull/356?.
 @cdrage just tried this with #356, and mem_limit fails. This is fixed in the latest release of [`libcompose`](https://github.com/docker/libcompose/releases/tag/v0.4.0), can we upgrade to that?.
 @cdrage @surajssd we can close this issue, as mem_limit is now supported.
 @surajnarwade cpu_shares is still an issue. So let's leave this open..
 @cdrage oh my bad, got it.
 @cdrage `mem_limit` is supported right now so edited the title.
 @cdrage @surajnarwade we can officially declare that we don't support `cpu_shares` becasue there is no way we can map it to anything in k8s.

`cpu_shares` talks in terms of percentage of cpu to give to any container, this is feasible on a single machine but does not make sense on multi-node cluster where we dont know the entire cpu number.

TLDR: this is not easy to map to k8s cpu resources.

more info about cpu shares: https://docs.docker.com/engine/admin/resource_constraints/#cpu.
 So the PR that closes this issue should remove all the code which tries to read this info from docker compose file and adds it to `ServiceConfig` and also give warning as this is unsupported..
 @surajssd Adding this to unsupportedkeys sounds like the best viable option considering the complexity of implementing cpu_shares. I agree..
 @surajssd @cdrage , I am onto this..
 we can close this now.
 Hope not to be pedantic here, but I think for `cpu_shares` and `cpu_quota` there are highly relevant concepts in Kubernetes: [see](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#how-pods-with-resource-limits-are-run).
These two keys in compose file are analogous to `docker run` counterpart, while in k8s `requests.cpu` maps to `docker run --cpu-shares` and `limits.cpu` maps to `--cpu-quota`(involving simple computations and pre-condition that `--cpu-period=100000` though)
A user case I can come up with is that we may use daemonset or pod affinity to run one instance on every node and keep dedicated share/quota of CPU for it.
As for `cpuset` key I agree that it is pointless in a cluster environment as we usually don't care which cpu is used.
WDYT? @surajssd @cdrage @surajnarwade .
 @gitlawr , but there is no direct mapping for `cpu_shares` and `quotas`.
 @surajnarwade For example,setting cpu resource such as:
```
apiVersion: v1
kind: Pod
metadata:
  name: one
spec:
  volumes:
  containers:
  - name: busysleep
    image: busybox
    command: [""sleep"",""3000""]
    resources:
      requests:
        cpu: 100m
      limits:
        cpu: 0.5
```
Then the container will be run with CpuShares==102(which is 0.1*1024) and CpuQuota=50000(which is half of CpuPeriod given CpuPeriod= 100000). Is it kind of direct mapping I think?.
 "
,,266,"Update main.go path.
 Fix #265 
cc @kadel .
 lgtm
.
 "
,,265,"Update README .
 Since we no longer have `main.go` file in `cli/main/` folder, we need to update the README because README still says to [build](https://github.com/kubernetes-incubator/kompose#building) using 
`$ go build -o kompose ./cli/main`

cc @kadel .
 "
,,264,"Change strategy for Deployments/DeployementConfigs.
 When Kompose creates Deployments there is no strategy specified -  RollingUpdate is default.

This might cause problems with some applications using volumes, like databases.

We should consider changing strategy to Recreate, this should be safer option.
.
 Yes agree @kadel. That's something we thought about. Ref #17 
.
 I'm seeing there are more and more specific options coming like deployment strategy, volume size, and so on. And we are fixing these options in code. Should we make a flexible configuration strategy like putting them into profile in the preference file, or adding kompose-specific labels. They should not be declared in flags as user doesn't want to remember all of these details in a single command.
.
 Also consider some applications take time to start, so having Recreate by default might cause problems there. I think the default of RollingUpdate is there for a reason.
.
 @ngtuna 

> Should we make a flexible configuration strategy like putting them into profile in the preference file, or adding kompose-specific labels. They should not be declared in flags as user doesn't want to remember all of these details in a single command

Agreed, I think that we already started with labels, so those thinks should be configurable via labels.

@surajssd 

> Also consider some applications take time to start, so having Recreate by default might cause problems there. I think the default of RollingUpdate is there for a reason.

I don't know. I would rather have small interruption then corrupting my database, and potentially loosing all my data :wink:  
If we do it configurable via labels, RollingUpdate should be default (that i agree), but if we have to choose one without allowing user to change it , than it should be Recreate.
.
 I just thought how we can do it ""in between"" ;-) If docker-compose service doesn't have volumes we can safely use RollingUpdate and only if service has volume we will default to Recreate. 

Thoughts? :-)
.
 @kadel taking this up!.
 "
,,263,"Improve test times by removing ""-race"".
 Improve test times by removing the -race condition on running the unit
tests.
 Please see my comment here https://github.com/kubernetes-incubator/kompose/issues/247#issuecomment-257672539

The race detector isn't your issue, its the fact the unit test script doesn't cache builds combined with kompose having a _huge_ number of dependencies.
.
 "
,,262,"Fix license headers, This closes #223.
 As the person having signed the Corporate CLA between skippbox and CNCF and thus donated kompose, I am switching the copyright of kompose to the ""Kubernetes Authors"".

This was referenced in #223 .
 One file still has old copyright - `pkg/transformer/kubernetes/k8sutils.go`
.
 "
,,261,"Modify command in initializing unit tests.
 This cleans up the current script we have to a simple one-liner to test
unit tests..
 @kadel updated!
.
 "
,,260,"update CHANGELOG.
 .
 @ngtuna can you rebase....
 @sebgoa Rebased..
 "
,,259,"Add `go vet`,  and `gofmt` tests..
 fixes #215 

Add `go vet`, `golint` and `gofmt` tests.

Travis now runs `make validate` as first target.
`make validate` includes all validate tests (go vet, golint, gofmt)


#### TODO:
 - [x] fix gofmt errors
 - [x] fix go vet errors
 - [x] ~~fix golint errors~~ #307
.
 Might be reasonable to turn on golint in a separate PR since govet and gofmt would be good to have on their own.
.
 I've removed golint from this PR.

as suggested by @ericchiang  I'll turn it back on in separate PR with fixing all golint errors. (#307)

This is ready for review and merge.

ping @surajssd @ngtuna @cdrage .
 LGTM my end!.
 "
,,258,"v0.1.2.
 change version to v0.1.2.
 "
,,257,"binary-cross build.
 fix #256
.
 @kadel Appreciate a small review on it today as it's holding the release.
.
 "
,,256,"can't `make binary-cross` at HEAD.
 ``` console
Tunas-MacBook-Pro:kompose tuna$ make binary-cross
CGO_ENABLED=1 ./script/make.sh binary-cross
---> Making bundle: binary-cross (in .)
Number of parallel builds: 3

-->      darwin/386: command-line-arguments
-->       linux/386: command-line-arguments
-->     linux/amd64: command-line-arguments
-->   windows/amd64: command-line-arguments
-->     windows/386: command-line-arguments
-->    darwin/amd64: command-line-arguments

6 errors occurred:
--> linux/amd64 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

--> darwin/386 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

--> linux/386 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

--> windows/386 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

--> darwin/amd64 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

--> windows/amd64 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /Users/tuna/Workspace/gocode/kompose/src/command-line-arguments (from $GOPATH)

make: *** [binary-cross] Error 1
```
.
 "
,,255,"Improving `down` to handle Volumes.
 In 7349dc9 i'm proposing adding --emptyvols to the up/down operations. This raises a bigger question on whether we should enable passing the other **convert** options so that they can be used with up/down - this can be useful, but maybe not something we want to do.
.
 @dustymabe I think `kompose down` doesn't need to have --emptyvols option

``` console
$ $ kompose down --help
NAME:
   kompose down - Delete instantiated services/deployments from kubernetes

USAGE:
   kompose down [command options] [arguments...]

OPTIONS:
   --emptyvols  Use Empty Volumes. Don't generate PVCs
```
.
 There is a bigger question.
If you are deleting object for `kompose down`, how you know what objects should deleted?

If user deployed using `kompose up` that there is  PersisntentVolumeClaim and if `--emptyvols` was used than there is no PVC.

Easiest solution in the case of PVC might be to always try delete PVC (basicaly always assume `down --emptyvol`)  and don't report error if there is no PVC. But this assumes that user won't create PVC with same name convention that is Kompose using, otherwise we delete PVC that wasn't created by Kompose.
.
 Right. It's because there is no clue in docker-compose file that lets us know if pvc was created or not. From UX perspective `kompose down --emptyvols` looks a bit of weird. 

Should we automatically/transparently add a kompose label for pvc to the original docker-compose file once user chooses to create pvc object ? OR should we update the strategy of generating pvc by adding label ?
.
 > From UX perspective kompose down --emptyvols looks a bit of weird.

Agreed it is weird. We should force user to think about such things.

> Should we automatically/transparently add a kompose label for pvc to the original docker-compose file once user chooses to create pvc object ? OR should we update the strategy of generating pvc by adding label ?

Annotating controller with additional information about what was used for conversion might be in general great idea. Other think that we could do is to actually inspect controller object and find out if it uses PVC or not. But i don't know how complicated this might be
.
 for `kompose down` we could use labels that were applied to each element that was created during ""up"" to bring the application down. so it's possible we don't have to do a ""conversion"" at all, just inspect for labels and delete everything that has that label 
.
 > for kompose down we could use labels that were applied to each element that was created during ""up"" to bring the application down. so it's possible we don't have to do a ""conversion"" at all, just inspect for labels and delete everything that has that label

I was thinking about this also, but what if user deploys two different application (docker-compose.yml files) to one namespace?
.
 we could:

1 - try to use a unique name
2 - collision avoidance - if you try to ""up"" and there is a label conflict with the label you are going to use and a label that already exists, then error out and tell the user. 
.
 to improve doing down, we should label artifacts at creation time saying that those artifacts were created using kompose, then while deleting we only delete things that has those label?

that label could look like this:

`kompose-project-name: <project_name>`
or something better than above label so that we can query things that were created using kompose and we delete only artifacts for current project and not other project kompose generated objects..
 @surajssd what is `<project_name>`?


How about we do it like this:
Lets use `io.kompose.service: <service_name>` label to label all objects that are related to given service.
Use this also for PVC.
During down, delete all object related to given service using this label as selector..
 @kadel I agree on using `io.kompose.service: <service_name>` and then we delete the object using that `label`. There is cli command for doing that `kubectl delete <object> --selector=io.kompose.label=<service_name>`, still need to figure out the api calls.
.
 @kadel with `<project_name>` I was thinking of having a single label on all resources. As opposed to labeling service wise. So that we can delete everything in one go!

With each service having different labels we will have to loop over the service names to delete the artifacts..
 Had a discussion with @kadel and we found out that there is a function `SelectorFromSet()`
in kubernetes which returns a `Selector (or Label)` which will match exactly the given Set (in our case it is `io.kompose.service`), making use of that we can find all the objects associated with the given `Selector (or Label)` and can further do the delete operation..
 Was going to type this in the PR but here goes:

@kadel @procrypt 

So I think this is *awesome* and amazing code @procrypt 

What I'd like to discuss though, is should we really be putting these labels in when we `convert`?

Honestly, most of our users simply convert, look at the conversion and then `kubectl create/apply` it..

With this PR, we're adding selectors as well as a metadata section that includes `creationTimeStamp` as well as a label, making an already-long Kubernetes yaml file even longer.

The point of this PR is to implement `kompose down` so it deletes based on the label. 

What I'm getting at is should we ""hide"" these labels and implement them ONLY when the user `kompose up`'s?.
 "
,,254,"Match case with API objects when printing to terminal.
 .
 @janetkuo Could you merge it ? as @dustymabe doesn't have write access.
.
 "
,,253,"Issues regarding CLI. Perhaps switching to Cobra?.
 Recently I've been digging through urfave trying to find a solution for  #239 (https://github.com/urfave/cli/pull/399 was the fix).

Most of these edge-cases have already been proven and used in another CLI library called Cobra. I recently found it _very_ useful and much cleaner than urfave when adding new commands and improving the UX. 

Lot's of major projects using it as well as the lead developer recently joining the Golang team :) 

Given a PR, would people be willing to switch? 

https://github.com/spf13/cobra
.
 +1 for cobra, but we need to make sure we don't introduce new bugs.
.
 +1 for cobra also. It looks like it is more powerful. Plus we already have it in Kompose codebase as Kubernetes dependency. 
.
 +1 Cobra is great. The original kompose was a fork of libcompose that's why it's using urfave/cli.
.
 #304 .
 closing as #304 was merged.
 "
,,252,"Add documentation on recent labels feature.
 This adds some documentation to the user guide regarding the new labels
feature that's been added to Kompose.
.
 Let me know if this is appropriate / is actually correct @procrypt 
.
  LGTM 
Thank you @cdrage :) 
cc @kadel @surajssd @sebgoa @dustymabe 
.
 LGTM
.
 "
,,251,"reporting deployment when it should be deploymentConfig.
 In the below scenario we are creating DeploymentConfigs and not Deployments. It's a bit misleading to report that we are creating deployments so we should fix that. 

```
$ kompose --provider openshift up 
We are going to create OpenShift DeploymentConfigs, Services and PersistentVolumeClaims for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO[0005] Successfully created service: mlbparks       
INFO[0005] Successfully created service: mongodb        
INFO[0005] Successfully created deployment: mlbparks    
INFO[0005] Successfully created ImageStream: mlbparks   
INFO[0005] Successfully created deployment: mongodb     
INFO[0005] Successfully created ImageStream: mongodb    
INFO[0005] Successfully created persistentVolumeClaim: mongodb-claim0

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is,pvc' for details.
$ oc get dc
NAME       REVISION   REPLICAS   TRIGGERED BY
mlbparks   1          1          config,image(mlbparks:latest)
mongodb    1          1          config,image(mongodb:latest)
```
.
 "
,,250,"Track release goals with GitHub milestones.
 Part of being in the kubernetes-incubator is regular releases and conveying the development roadmap. While the README has a section about this, it's pretty out of date, and only addresses extremely high level goals.

As discussed on the #kompose slack channel, consider using GitHub milestones to address this.

cc @dustymabe @sebgoa 
.
 great idea Eric, @sebgoa can we come up with a list of things that can be achieved via a F2F meeting at kubecon? coming up with a list of milestones would be a good thing to do there when a part of the team is meeting face to face. 
.
 yes, I will remove the roadmap in the README in a small PR.

I created 2 milestones and labels....now we need to tag the issues properly to fill up the milestone.

Still need criteria that trigger the actual release...
.
 @sebgoa thanks! Couple of follow up todo's before I close this issue.
- Someone should update the README to refer to the milestones.
- It seems odd to have a point release milestone since kompose only has one branch. How would you release 0.2.1 features without 0.3.0 features commit to master getting in.
- There need to be more high level feature issues. As @dustymabe pointed out kubecon might be a good place to spec some of these out. 
.
 no need to close. This was just a five minute thing.

We need a release process and and write up about how to tag issues and create milestone.
.
 cc #315 .
 "
,,249,"CreatePVC: correct setting of read/only access.
 Fixes #237
.
 Except for the nit this LGTM
.
 @janetkuo sorry about the delay. Have been away from the computer mostly since Friday. 
.
 "
,,248,"Adding support for choosing empty volumes.
 Fixes #226
.
 This PR depends on #240 - it is rebased on top of that PR 
.
 tested and it works great
.
 @kadel I added two more commits. 7e4c68b is self explanatory. 301b5c2 is because I'd like to be able to run `kompose up --emptyvols`.

Should we reconsider allowing people to pass in the ""convert options"" for up/down? 
.
 @dustymabe Code LGTM. I will step forward to approve this PR. If @kadel doesn't have any more feedback then I will merge it if you want.
.
 @kadel Could you merge it? It should be great to have it in the release
.
 "
,,247,"Why do tests take so long to run?.
 I'm trying to figure out why the tests take so long to run, even though we only have one test file: `kubernetes_test.go`.

When I run `htop` during the test build, it's showing a lot of vendor tests being ran, is this normal?
.
 yes that is a big one. I noticed the same thing.

We need to fix this asap.
.
 > When I run htop during the test build, it's showing a lot of vendor tests being ran, is this normal?

`go test ./...` will run test files in the `vendor` directory. Are you not filtering those packages out properly?
.
 Times on my laptop:

| go test arguments | duration |
| --- | --- |
| `-cover -race` | 208.25s |
| `-cover` | 14.48s |
| no args | 14.35s |

I run it like this
`time go test  -v $( go list github.com/kubernetes-incubator/kompose/... | grep -v '/vendor/' )`

So it looks like race condition detector is to blame. 
I don't think that we need it in automated tests.
.
 @kadel 

Create a PR for this :) #263 
.
 @kadel that's because you're not caching the build assets and need to rebuild every time.

```
$ pkgs=$( go list github.com/kubernetes-incubator/kompose/... | grep -v '/vendor/' )
$ # install test dependencies
$ go test -v -i -race $pkgs
$ time go test -race $pkgs
?       github.com/kubernetes-incubator/kompose [no test files]
ok      github.com/kubernetes-incubator/kompose/cli/app 1.062s
?       github.com/kubernetes-incubator/kompose/cli/command [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/kobject [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader  [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader/bundle   [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader/compose  [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/transformer [no test files]
ok      github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes  1.070s
?       github.com/kubernetes-incubator/kompose/pkg/transformer/openshift   [no test files]
?       github.com/kubernetes-incubator/kompose/version [no test files]

real    0m6.592s
user    0m15.668s
sys 0m2.012s
```

Please please please keep the race detector enabled. It's a critical tool for finding race bugs.
.
 OK lets keep `-race`.

I don't know that much about Go testing, I'll have to do more reading.

What is `-i` doing?
.
 > What is -i doing?

Installing test dependencies. Similar to `go build` vs `go install`: http://dave.cheney.net/2014/06/04/what-does-go-build-build

Since the race detector requires recompiling dependencies, you're noticing the lack of this flag more.
.
 I'm going to close this for now. The length of the tests is negligible since the main blocker of this is the time it takes to initially compile.

While watching `htop` I see that it's compiling files from the `vendor` directory. Specifically Kubernetes.

Once Kompose has compiled, tests are ran in less than 5 seconds..
 "
,,246,"Tests for CreateService and annotations.
 Adds some tests for CreateService, specifically the initial generation
as well as providing an edge case when specifying ""kompose.service.type""
.
 Fixes 1/2 of https://github.com/kubernetes-incubator/kompose/issues/242
.
 Still newbish to Go, so let me know what things I can improve on to make this more idiomatic!
.
 @kadel me neither for the tests, I updated it to check that information is generated. I tried doing a comparison between port numbers (passing 123 and making sure we get 123 back). But I'm having a bit of difficulty digging through k8s code to find the correct way of doing it. Hopefully this update to the PR is sufficient!
.
 there already is a function for comparing ports in [kubernetes_test.go](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/kubernetes_test.go#L93)
.
 you commited vim swap file ;-) -  `pkg/transformer/kubernetes/.k8sutils_test.go.swp`
.
 @kadel ~~boo, that's why I added the .gitignore PR earlier xD okay, so i've updated this PR again with new code, although I'm not sure why the tests are erroring.~~

Updated the PR, passes now! Ready for another review.
.
 @kadel updated with your code :) thanks man!
.
 > @kadel updated with your code :) thanks man!

thanks ;-)
Sorry for confusion, sometimes it is easier for me to express myself in code than in english :laughing: 
.
 @kadel 

01101110 01101111 00100000 01110000 01110010 01101111 01100010 01101100 01100101 01101101

:)
.
 00111010 01000100
.
 "
,,245,"Add support for user directive.
 This is little a bit user unfriendly :-(

Issue is that in docker-compose you can set `user` by user name or uid. But K8S allows you to set user only by its uid (has to be int).

This is why I added warning that tells user that `user` directive will be ignored if its not a number.
Here is user unfriendly part, in docker-compose even if you set user by it uid, it has to be string. (user: ""2324"") If you set it as int (user: 2324) libcompose parser will complain about this not being string.

So now Kompose requires `user` to be number but written as string :-(

fixes #244 
.
 Failing tests?
.
 > Failing tests?

yeah :-( It adds empty security context for every container (`""securityContext"": {}`) I have to change that or update tests
.
 fixed and rebased
.
 unit tests?
.
 rebased and added  test.
 @kadel It needs rebase again.
 rebased.
 "
,,244,"User directive from docker-compose is siletly ignored.
 .
 "
,,243,"Add VIM git ignore information.
 "
,,242,"Add missing tests and documentations for ""Service type"" PR.
 Add missing tests and docs for https://github.com/kubernetes-incubator/kompose/pull/189
.
 Closing since #246 is merged..
 "
,,241,"Add tests converting dab files.
 Resubmitting to work around conflict with tests.sh
.
 @ngtuna Is it possible I could get a quick +1?
.
 @cab105 👍 LGTM
.
 Thanks!
.
 "
,,240,"Make OpenShift inherit from Kubernetes.
 .
 This is just a first stab and not ready yet. @kadel we really need to refactor k8sutils.go and pull out some of those functions into a separate file I think. Help me find out which functions should go in what file. 
.
 this is probably a change that needs 2 reviewers. @janetkuo, can you review? 
.
 > this is probably a change that needs 2 reviewers. @janetkuo, can you review?

Agreed, second pair of eyes would be great.
.
 LGTM. Thanks @dustymabe :+1: 
.
 "
,,239,"CLI exit code on error.
 When running `kompose -f file` for any invalid file or any invalid command I would expect a shell return code of non-zero.
.
 Thank for reporting it. You are right we have to fix that
.
 @kadel @sstarcher I think this is normal behavior (with regards to not doing anything). The problem is that there's no **default** behaviour when just using ./kompose

Even I just realized that there was the ""Incorrect Usage."" message on the top, go figure!

```
github.com/kubernetes-incubator/kompose  master ✗                                                                            23h39m ⚑  
▶ kompose -f foobar        
NAME:
   kompose - A tool helping Docker Compose users move to Kubernetes.

USAGE:
   kompose [global options] command [command options] [arguments...]

VERSION:
   0.1.0 (8227684)

AUTHOR(S):
   Skippbox Kompose Contributors <https://github.com/skippbox/kompose> 

COMMANDS:
    convert     Convert Docker Compose file (e.g. docker-compose.yml) to Kubernetes objects
    up          Deploy your Dockerized application to Kubernetes (default: creating Kubernetes deployment and service)
    down        Delete instantiated services/deployments from kubernetes

GLOBAL OPTIONS:
   --file, -f ""docker-compose.yml""      Specify an alternative compose file (default: docker-compose.yml) [$COMPOSE_FILE]
   --help, -h                           show help
   --generate-bash-completion
   --version, -v                        print the version


github.com/kubernetes-incubator/kompose  master ✗                                                                            23h39m ⚑  
▶ echo $?
0
```

Like what @sstarcher mentioned, it's suppose to be 1 :) I'll work up a patch for this. 
.
 I'm trying to figure where to fix this with the most recent work in https://github.com/urfave/cli/pull/399
.
 Fixed in #304 which exits correctly with a proper error code.

```
github.com/kubernetes-incubator/kompose  switch-to-cobra ✔                                                                                                                                                                                                                   0m  
▶ ./kompose convert
ERRO[0000] Failed to find the compose file: docker-compose.yml 
FATA[0000] Failed to load compose file: open docker-compose.yml: no such file or directory 

github.com/kubernetes-incubator/kompose  switch-to-cobra ✔                                                                                                                                                                                                                  4m  ⍉
▶ echo $?
1
```
.
 "
,,238,"added support for kompose down.
 .
 "
,,237,"ReadWriteOnce set even when volume is ""ro"".
 I'm guess that ""ro"" should mean read only: 

https://github.com/kubernetes-incubator/kompose/blob/7435f822ed17837a4d6f472f9a0f800abe1adc95/pkg/transformer/kubernetes/kubernetes.go#L178

Should we change this to be: 

``` diff
diff --git a/pkg/transformer/kubernetes/kubernetes.go b/pkg/transformer/kubernetes/kubernetes.go
index 6f47bdb..1ba7f38 100644
--- a/pkg/transformer/kubernetes/kubernetes.go
+++ b/pkg/transformer/kubernetes/kubernetes.go
@@ -175,7 +175,7 @@ func CreatePVC(name string, mode string) *api.PersistentVolumeClaim {
        }

        if mode == ""ro"" {
-               pvc.Spec.AccessModes = []api.PersistentVolumeAccessMode{""ReadWriteOnce""}
+               pvc.Spec.AccessModes = []api.PersistentVolumeAccessMode{""ReadOnlyMany""}
        } else {
                pvc.Spec.AccessModes = []api.PersistentVolumeAccessMode{""ReadWriteOnce""}
        }
```
.
 @dustymabe yes sure!
.
 "
,,236,"Support for Job objects.
 Feature request to support Job objects
.
 Interesting idea. I haven't played with Kubernetes jobs  yet. 
How would Job map to docker-compose?
.
 I was under the incorrect assumption that values that were outside of docker-compose were flags, but after closer inspection it looks like the only flag is --replicas.

The values in the Job spec that are outside of the realm of docker-compose would be 
completions, parallelism , activeDeadlineSeconds

I'll close this if you think it's out of scope for kompose.
.
 Lets keep this open. We can maybe do something with Jobs in the future.
.
 @kadel I think this can be done using docker-compose labels to define service type, if a user defines label `kompose.service.type: job` and no ports specified then we create a job controller type than service and deployment? WDYT?

Inspired by: https://github.com/redhat-developer/opencompose/issues/50
.
 Currently we have couple of choices for preferences: kompose-specific
labels, flags and preference file. We need to structure them correctly and
make sure they are not overlapping.

Preference file: We are seeing it as a way to define profiles to be
used including cluster info, default objects, probably user authentication
(if we don't intend to rely on kubectl anymore). IMO It should
only defines high-level properties. Somehow we should support 'kompose
config profile' command.

Flags: for declaration at runtime like output format (chart/yml/json),
additional objects (in this case job object should be declared here),
output location. But IMO we should not define too many flags.

Kompose-specific label: we are using it for post-deploy action but I
think it's really powerful and it makes kompose to be more specific.
Lets discuss more to define its scope.

On Monday, November 7, 2016, Suraj Deshmukh notifications@github.com
wrote:

> @kadel https://github.com/kadel I think this can be done using
> docker-compose labels to define service type, if a user defines label kompose.service.type:
> job and no ports specified then we create a job controller type than
> service and deployment? WDYT?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/kubernetes-incubator/kompose/issues/236#issuecomment-258764776,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AB31x1AMM57qGCNfQHewqp43CJjhNslZks5q7tNwgaJpZM4KgW_5
> .

## 

Regards,
Tu Nguyen
Sent from mobile
.
 So for creating jobs we can use docker-compose's `restart` for this, it's just we define some constraints like
- default value of `restart` is `always`: where we create normal `deployments` or `deploymentconfigs` and services
- if `restart` is `on-failure` we create `job` which restarts on failure
- if `restart` is `no` we create `job` which does not restart on failure

e.g. about docker-compose restart https://github.com/docker/compose/blob/50faddb683d76567d64c8ef7dd1a09358f68a779/tests/fixtures/restart/docker-compose.yml
.
 > default value of restart is always

From what I've seen the default value of `restart` seems to be `no`, i.e. the service is not restarted on exit (success / failure).
.
 @jpopelka, yes `restart` is `no` by default for docker-compose, I was suggesting how we go about interpreting this in kompose!
.
 Does docker-compose really have semantics for batch jobs ?
I don't think we should try to ""hack"" k8s semantics on top of docker-compose ones.
the restart is really about the pods being restarted by the kubelet or not..
 @sebgoa there is no direct way to define batch jobs in docker-compose. But you can get behavior of jobs if you define docker-compose service with `restart: ""no""`, it will act as job.

>the restart is really about the pods being restarted by the kubelet or not.

I didn't understand what you are trying to say here?.
 `restart: ""no""` in a docker-compose is meant to tell docker to not restart the containers if they fail.

In k8s, a Pod has a `restartPolicy`. This is the clear one to one match.

If we start using a docker-compose semantic to do something in k8s that is not a one to one match, it will get confusing really quickly.

So my question is ""how do you do batch processing in Docker swarm ?"".
 > If we start using a docker-compose semantic to do something in k8s that is not a one to one match, it will get confusing really quickly.

+1

.
 > So for creating jobs we can use docker-compose's restart for this, it's just we define some constraints like
> 
> default value of restart is always: where we create normal deployments or deploymentconfigs and services
> if restart is on-failure we create job which restarts on failure
> if restart is no we create job which does not restart on failure
> e.g. about docker-compose restart https://github.com/docker/compose/blob/50faddb683d76567d64c8ef7dd1a09358f68a779/tests/fixtures/restart/docker-compose.yml

restart from docker-compose should map to restartPolicy in PodSpec.
 I think the confusion between the above discussions comes down to the restartPolicy vs `kubectl run`

For version >= 1.3
Always creates a Deployment
OnFailure creates a Job
Never creates a Pod

From http://kubernetes.io/docs/user-guide/kubectl/kubectl_run/
```
 --generator string           The name of the API generator to use.  Default is 'deployment/v1beta1' if --restart=Always, 'job/v1' for OnFailure and 'run-pod/v1' for Never.  This will happen only for cluster version at least 1.3, for 1.2 we will fallback to 'deployment/v1beta1' for --restart=Always, 'job/v1' for others, for olders we will fallback to 'run/v1' for --restart=Always, 'run-pod/v1' for others.
```.
 okay so i understand here is that we map `docker-compose` 's `restart` to PodSpec's restartPolicy, but it's done already in code..
 > - default value of `restart` is `always`: where we create normal `deployments` or `deploymentconfigs` and services
> - if `restart` is `on-failure` we create `job` which restarts on failure
> - if `restart` is `no` we create `job` which does not restart on failure

@surajssd In [`kubectl run`](http://kubernetes.io/docs/user-guide/kubectl/kubectl_run/), we share the same pattern (see `--restart` flag), except that when `restart` is `no`, a `pod` will be created, instead of a `job`.
 There is also another thing that we should be aware. 
We are assuming different default value for `restart` than docker-compose does.
If you don't specify restart docker uses `no` as default.
But kompose is creating controller objects (Deployments, ReplicationSets..) and they all have `restartPolicy: Always` (podSpec in those objects can't have different restartPolicy)
.
 So what I understand from @janetkuo  and @surajssd comments there is a proposal to handle restart values like this:

docker-compose restart value | object created by kompose |  |
-----------------------|----------------------|----------------
no restart specified |  controller object
`always`  |  controller object
`no`  |  Pod
` on-failure`  |  Job | can have max-retires argument:  `on-failure[:max-retries]`
`unless-stopped` | controller object  

Docker documentation regarding restart values https://docs.docker.com/engine/reference/run/#restart-policies---restart (this is same for docker-compose)

.
 ok fine with me, but Pods can have restart policies as well, and Jobs are much more than just Pods that restart..
 small modification to this.
Lets start implementing this but when `restart: on-failure` than convert to Pod with restartPolicy= OnFailure.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 /lifecycle frozen.
 "
,,235,"allow for setting size of persistent volume.
 Would be nice to be able to set a size of a volume other than having it hardcoded to [100Mi](https://github.com/kubernetes-incubator/kompose/blob/7435f822ed17837a4d6f472f9a0f800abe1adc95/pkg/transformer/kubernetes/kubernetes.go#L155)

Here is an example of how it is done in docker compose now. I don't think we have to do it this way, just showing an example:

```
# From https://github.com/docker/docker/issues/24318#issuecomment-230410196
version: ""2""

services:
  myservice:
    # […]

volumes:
  wangdk2:
    driver: driver-plugin
    driver_opts:
      size: 1G
```
.
 Yes we should start thinking how to set volume size. 
Hardcoded 100Mi was just temporary solution.
.
 @cdrage @kadel @surajssd , can we have something like this:

```
$ kompose convert --pvc=300
```

which allow us to set pvc size.

thoughts ?.
 Perhaps --volume-size ? @surajnarwade .
 Maybe label per service?

    labels: 
      kompose.volume.size: 1Ti.
 @abitrolly what about both?.
 @cdrage how to select which resource volume needs to be increased with command line parameter? Different resources come with different requirements..
 > @cdrage how to select which resource volume needs to be increased with command line parameter? Different resources come with different requirements.

The same problem will be even with labels. Labels are per service, but one service can have multiple volumes with different requirements.


It looks like it is possible to label volumes. [source](https://docs.docker.com/compose/compose-file/#labels-3) If that is true that the best way would be to use the same label as @abitrolly  suggested but on volumes. The volume would have to be defined using top-level volumes key, but I think that this is a reasonable requirement.




.
 I implemented volume size with service level labels. It keeps simple `docker-compose.yml` files short. If volume labels will be added in future, they could take the priority..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale
.
 close by #867 .
 "
,,234,"Raw Pod output.
 Feature request for supporting the output of a raw Pod definition.  
.
 can you elaborate a little more on what exactly you want? 
.
 Kompose currently supports

```
  --chart, -c               Create a Helm chart for converted objects
   --deployment, -d         Generate a Kubernetes deployment object (default on)
   --daemonset, --ds            Generate a Kubernetes daemonset object
   --replicationcontroller, --rc    Generate a Kubernetes replication controller object
```

The request is for a --pod that will output a pod definition without any controller.

```
kind: Pod
```
.
 @ngtuna that one should be pretty straightforward.
 this could be solved with `restart:no` if implement as discussed  in https://github.com/kubernetes-incubator/kompose/issues/236.
 @sstarcher you want all docker services to be in a Single Pod, or a Pod per docker services ?.
 I would say all in one pod would be preferable. .
 Is this for constructing your own jobs or something? It seems odd to have kompose generate invalid manifests, particularly when you can just use jq to filter the output already..
 Invalid manifests? A pod is a valid manifest. .
 Ah, right. Sorry, brain fart..
 @sstarcher this is not what kompose would do, but if you want pod per docker-compose service and not have a controller, you can use docker-compose's `restart` construct, read about it here https://github.com/kubernetes-incubator/kompose/blob/master/docs/user-guide.md#restart.
 @surajssd that's exactly what I wanted.  #334 .
 @sstarcher that solves it then :+1: .
 "
,,233,"Add tests converting dab files #167.
 Updated pull request to make use of a new branch as per @surajssd's suggestion.
.
 "
,,232,"Add tests converting dab files #167.
 .
 @cab105 you are committing changes from your `master` please consider creating a new branch, it will enable you to work irrespective of changes being done on master. 
.
 Updated, and recreated PR.
.
 "
,,231,"Invoking kompose --bundle X.dab convert --stdout will produce two differently ordered results.
 The current kompose testing framework relies on dumping the results of the command to stdout and comparing it against a known baseline.  While doing the same thing for converting bundles, kompose will alter the order of the output such that no two invocations will result in the same output (see test1.txt and test2.txt).

While this doesn't pose an issue for normal operations, this will result in the tests failing occasionally.  The primary question is whether the tests should be altered to compare the resulting file output, or of dumping via stdout should be consistent?

[test1.txt](https://github.com/kubernetes-incubator/kompose/files/545981/test1.txt)
[test2.txt](https://github.com/kubernetes-incubator/kompose/files/545982/test2.txt)
.
 @cab105 see if this helps https://github.com/kubernetes-incubator/kompose/blob/master/script/test/cmd/lib.sh#L70 

It can match json even if the order changes. Also you can use functions like `convert::match_output` directly. 
.
 @cab105 see the usage here https://github.com/kubernetes-incubator/kompose/blob/master/script/test/cmd/tests.sh#L15
.
 Thanks for the guideline, but the thing is that I'm running this through 
convert::expect_success and convert::expect_success_and_warning so 
convert::match_output is being called.

Then again, I need to debug if this is my environment or a bug with the 
test scripts.

On 10/22/2016 09:57 PM, Suraj Deshmukh wrote:

> @cab105 https://github.com/cab105 see the usage here
> https://github.com/kubernetes-incubator/kompose/blob/master/script/test/cmd/tests.sh#L15
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/kubernetes-incubator/kompose/issues/231#issuecomment-255569876,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAmHpnplRf9GO4P59sYKcMhpOBHMtHusks5q2ulAgaJpZM4Kd8dl.
.
 @cab105 can we close this ?.
 I'd say not yet.  Haven't had a chance to delve into it, but will take ownership..
 https://github.com/kubernetes-incubator/kompose/pull/338 has been merged. This is safe to be closed..
 "
,,230,"update unsupported key list.
 fix #207 
.
 "
,,229,"remove tag experimental.
 Fix #228 

Follow up discussion at #216 , it's good to remove tag experimental of bundlefile at this moment. By copying its structs and loadFile() function, we can also shorten the vendor list.
.
 Sort out the vendor list will be added in a separate PR. I just tried doing that but there was a problem with godep restore again. Spend time figure it out tomorrow.
.
 > Follow up discussion at #226,

I think you have the wrong number 
.
 Correct. It should be #216 
.
 "
,,228,"Remove experimental tag.
 Creating for tracking purpose although it was suggested in #216 
.
 "
,,227,"make kompose go get-able.
 Fix #216 
.
 I was implying the CLI be go-getable in #216
.
 @ericchiang  you mean `go get github.com/kubernetes-incubator/kompose/cli` ?
.
 @ngtuna I was implying renaming the package `main` to `kompose` so go get would install the binary correctly. For users familiar with Go this is what they expect for most CLI go projects.

So at minimum

```
go get github.com/kubernetes-incubator/kompose/cli/kompose
```
.
 It's obviously not critical. But it's pretty standard for Go projects :)
.
 Okay thanks @ericchiang for pointing it out. It's pretty easy to rename the package. I will consider more on removing experimental tag of bundlefile.
.
 @ericchiang I see it would be better to move main/main.go to the parent directory but not sure if it violates the standard of kubenertes-incubator or not. That is a bit of weird in path of the package when doing `go get github.com/kubernetes-incubator/kompose/cli/kompose`. It would be better with:

``` console
$ go get github.com/kubernetes-incubator/kompose
```
.
 > $ go get github.com/kubernetes-incubator/kompose

I'm for this (but that's just a preference).
.
 Works for me but I can't officially review so it's not worth much. 
.
 ping @ericchiang @kadel Could you add your review on this ?
.
 lgtm but I'll let @kadel add the review.
.
 I found that `make binary` doesn't work on HEAD (not broken by this PR)

``` console
$ make binary
CGO_ENABLED=1 ./script/make.sh binary
---> Making bundle: binary (in .)
# command-line-arguments
./main.go:35: cannot use command.BeforeApp (type func(*""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Context) error) as type func(*""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Context) error in assignment
./main.go:36: cannot use append(command.CommonFlags()) (type []""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Flag) as type []""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Flag in assignment
./main.go:40: cannot use command.ConvertCommandDummy() (type ""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Command) as type ""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Command in array or slice literal
./main.go:44: cannot use command.UpCommand() (type ""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Command) as type ""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Command in array or slice literal
./main.go:45: cannot use command.DownCommand() (type ""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Command) as type ""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Command in array or slice literal
make: *** [binary] Error 2
```
.
 > I found that make binary doesn't work on HEAD (not broken by this PR)

Could you re-run it ? I just run `make binary` successfully on HEAD.
.
 > > I found that make binary doesn't work on HEAD (not broken by this PR)
> 
> Could you re-run it ? I just run make binary successfully on HEAD.

From the error log it seems that it's because I'm still using skippbox/kompose/

```
./main.go:35: cannot use command.BeforeApp (type func(*""github.com/kubernetes-incubator/kompose/vendor/github.com/urfave/cli"".Context) error) as type func(*""github.com/skippbox/kompose/vendor/github.com/urfave/cli"".Context) error in assignment
```

`make binary` works after I change my local directory from skippbox/kompose to kubernetes-incubator/kompose. 
.
 Merging
.
 "
,,226,"provide easy option for users in setup without PVs.
 If a user is targeting an env without PVs it would be great if we gave them an easy option for getting up and running. Rather than having them create PVs (which can be complicated or maybe even not allowed if they don't control their environment) I think we should give them the option `--volume=empty`  to substitute in a `emptyDir` for a PVC. The --volume option would could default to `--volume=pvc`. 

This would allow them to get going without having to have it all set up, but would keep sane defaults for people who have real environments with appropriate volume setups. 

More information on `emptyDir` [here](http://kubernetes.io/docs/user-guide/volumes/#emptydir)
.
 alternatively we could default to `emptyDir` and warn the user that if they want persistence they should provide `--volume=pvc`. 
.
 This is another thing that we might want to put in a preference file as well. 
.
 This is great idea. But I would keep `--volume=pvc` as default, because I  think that `emptyDir` is dangerous for users that don't know how ti works.
.
 cool - I assume we can plan on doing this then, unless someone else objects
.
 "
,,225,"readme: update slack info.
 fixes #222
.
 LGTM
.
 "
,,224,"New slack channel link update.
 Updated link of slack channel in README to http://slack.k8s.io/

Fixes #222
.
 "
,,223,"Switch Copyright.
 Currently still with Skippbox, I am checking a few things with CNCF to see if we move to ""Kubernetes Authors""
.
 I am working on this, I just need a green light. should be coming quickly.
.
 @sarahnovotny Hi, could you confirm that we can switch the copyright to ""The Kubernetes Authors"" and not to ""Cloud Native Computing Foundation"" even though the software was donated to CNCF in the skippbox CCLA. 
.
 ack ""The Kubernetes Authors"" for consistency sake. 
.
 "
,,222,"Switch slack channel to official kubernetes slack.
 .
 yes, we need to get a #kompose channel created in k8s slack then switch over.
.
 @sebgoa thanks updated the issue. I'll ask around and see who can make this happen.
.
 maybe if we just ping @sarahnovotny she will create a #kompose channel for us on k8s slack ?
.
 done.

(after a brief foray on the wrong slack)

On Thu, Oct 20, 2016 at 8:55 AM, sebgoa notifications@github.com wrote:

> maybe if we just ping @sarahnovotny https://github.com/sarahnovotny she
> will create a #kompose channel for us on k8s slack ?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/kubernetes-incubator/kompose/issues/222#issuecomment-255148038,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAHxirpC8kq65YWlbZ5BZzwLlqHD_N6Nks5q148LgaJpZM4KbjiU
> .
.
 "
,,221,"wrong global --bundle/--dab input #198.
 Modified email address.
.
 @kadel can you review this simple change ? 
.
 Ah, I didn't noticed that this is PR was recreated.
.
 "
,,220,"kompose up/down create and delete pvc.
 pvc will be parsed when passing objects via kube client to create various objects. Also while deleting pvc will be deleted.

Fixes #218
.
 was trying to test this for openshift but seems like this change is only for kube - should we update both at the same time? 
.
 also managed to get this error - but not sure where it came from: 

```
[dustymabe@media examples (dusty-mlbparks)]$ ../kompose up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created service: redis          
INFO[0000] Successfully created service: web            
INFO[0000] Successfully created deployment: redis       
INFO[0000] Successfully created deployment: web         

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods' for details.
[dustymabe@media examples (dusty-mlbparks)]$ ../kompose down 
INFO[0000] Successfully deleted service: redis          
INFO[0003] Successfully deleted deployment: redis       
FATA[0003] Error while deleting application: no reaper has been implemented for { PersistentVolumeClaim}
```
.
 @dustymabe sorry for not labeling it, so creating a PVC was easy thing to do, but looking at how can I delete it, it's not straightforward like other objects, so stuck on it right now, so mostly following code from `kubectl`
.
 So I need some review here with respect to how `Undeploy` is implemented, I feel even for undeploy we should get converted objects iterate on those and then type switch on it and delete objects, cleanly. The problem here is that with komposeObject there is no way to identify how many PVCs were created? And since the names of PVC follow index starting from 0. There is no easy way to understand their names. So I propose here to change current implementation to implementation similar to `Deploy` its just that instead of create we call delete.
.
 hey suraj - this is working for openshift now :) - one thing though. should we modify the following line to include `pvc`  for both kube and openshift? 

```
Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.
```
.
 @dustymabe sure done for k8s as well! That's nice catch!

Never mind https://github.com/kubernetes-incubator/kompose/pull/220#issuecomment-255124733 check latest changes!
.
 > Never mind #220 (comment) check latest changes!

so you figured out how to go about doing the undeploy? 
.
 @dustymabe yes with @kadel 's help got some pointers earlier today from old code that once @ngtuna did here https://github.com/kubernetes-incubator/kompose/blob/e08ab06f2c1dacf2bae477bb5faace2feb387c90/pkg/transformer/kubernetes/kubernetes.go#L298
.
 up/down seems to be working for me now. I'm good with this - just need a maintainer to review. 
.
 ping @ngtuna @janetkuo @kadel 
.
 Code LGTM. Haven't tested yet but @dustymabe did it.
.
 @kadel done! https://github.com/kubernetes-incubator/kompose/pull/220/files#diff-08d4e6a1922a157aca193e75416bbb9cR48

Also merging :) Thanks @dustymabe @kadel and @ngtuna for reviewing!
.
 "
,,219,"Support converting OpenShift json <-> Kubernetes json/yaml.
 As a user I'd like to use OpenShift json files or Kubernetes yaml files to convert manifests from one environment to the other. This seems like it would be easier to support than docker-compose files but currently is a manual process (as far as I've found).

Maybe I missed an existing issue or PR (I searched) but this would be a great addition for both communities.
.
 just to confirm, instead of transforming from docker formats to k8s/openshift, you would like to transform from openshift to k8s ?
.
 Correct. That is my initial goal, but I could also see a use case to switch from k8s manifests -> openshift
.
 Hi,
regarding k8s->openshift you don't need any conversion, everything that works on k8s should work on OpenShift by default.

Other way is problematic. OpenShift is superset of k8s. For most objects it will be ok (because they are same in openshift and k8s), but there are objects in OpenShift that cannot be easily mapped to Kubernetes, for example BuildConfig. 

Theoretically it can be done (to some degree), but I don't think that it is something that is in scope for Kompose.
.
 If it's out of scope that is fine (we can close this issue) I just think it may be a use case for some people. Me being one of those people where I often translate OpenShift -> Kubernetes manifests manually. It could help broaden available applications for both OpenShift and vanilla Kubernetes
.
 @rothgar this has come up a few times in OpenShift as well.  Even if we don't want to do it here, I'd be open to implementing it in the OpenShift CLI or another command.  I agree the idea of:

deployment config -> deployment
route -> ingress

and vice versa would be very useful.
.
 I assumed kompose would be the tool to do the conversions. It'd be nice if I didn't need `oc` or multiple conversion tools for each scenario.
.
 @rothgar let's definitely keep this issue open. We talked about supporting other input formats (like nomad Jobs) for example, so we could add openshift -> k8s conversion.

And I agree that having only one conversion tool would be better.
.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 @fejta-bot @fejta How do I remove / whitelist the Kompose repo from this bot?.
 Move it out of the kubernetes org.
 @cdrage I think that this bot will be useful.
 @fejta Okay, we'll keep it around :+1: .
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 Since there's been no activity since December and this has (mainly) been used as a Docker Compose to Kubernetes / OpenShift tool, I'm going to close this (for now)..
 "
,,218,"PVCs are not created when calling `kompose up`.
 .
 Yes I think this is because there is no case for creating a PVC here https://github.com/kubernetes-incubator/kompose/blob/master/pkg/transformer/kubernetes/kubernetes.go#L357
.
 @surajssd yes this is the reason for this, and same think in `openshift.go`
.
 this breaks kompose for docker-compose files that are using volumes so I'm giving this P0
.
 "
,,217,"example: add mlbparks example.
 .
 maybe we should add volume to mongodb for this to work on OpenShift online:

```
    volumes:
      - /var/lib/mongodb/data
```

more info about why this is required https://bugzilla.redhat.com/show_bug.cgi?id=1318542
.
 I had a volume in there but I took it out because if you don't have persistent volumes set up on your test cluster then the thing will fail to come up. I can add it back. 
.
 @dustymabe hmm, that is good point. So now we have to choose if it should by default work on OpenShift online or on single node test cluster.

Can we maybe have volumes there but commented out?
.
 will probably need to organize examples better.

But for this, if it works on minikube, I saw we merge.  I will test it right now.
.
 Ok I tested this and it works fine on minikube.

However the image mlbparks is really big ~1GB and I am not sure what it brings more than the guestbook app.
.
 hey @sebgoa - I actually didn't realize it was so big. it is based on the `openshift/wildfly-100-centos7` image that is pretty large. I like this app because it is flashy but we don't have to include it as it is a large example.

If we do decide to include it I added the volume as tkral suggested. Let me know what you want to do. 
.
 @dustymabe yeah, I think the image is too big...we should only include examples that we can do during a talk. Also the map has a large ""openshift"" statement in it. I'd rather see _kubernetes_.
 closing.
 "
,,216,"Make go get'able (or at least go installable).
 It's odd that kompose's main package is named `main` rather than `kompose` like most Go projects Additionally, since there's no top level package it seems like it'd be reasonable to enable `go get github.com/kubernetes-incubator/kompose` to work.

Additionally there's a dependence on `-tags experimental` due to a docker dependency[0]. Removing that import here[1], (say by copying the structs) would also break the dependency on github.com/docker/docker and remove 19 direct imports from vendor.

```
$ cat Godeps/Godeps.json | jq .Deps[].ImportPath | grep '""github.com/docker/docker'
""github.com/docker/docker/api/types""
""github.com/docker/docker/api/types/blkiodev""
""github.com/docker/docker/api/types/container""
""github.com/docker/docker/api/types/filters""
""github.com/docker/docker/api/types/mount""
""github.com/docker/docker/api/types/network""
""github.com/docker/docker/api/types/registry""
""github.com/docker/docker/api/types/strslice""
""github.com/docker/docker/api/types/swarm""
""github.com/docker/docker/api/types/versions""
""github.com/docker/docker/cli/command/bundlefile""
""github.com/docker/docker/opts""
""github.com/docker/docker/pkg/mount""
""github.com/docker/docker/pkg/signal""
""github.com/docker/docker/pkg/system""
""github.com/docker/docker/pkg/term""
""github.com/docker/docker/pkg/term/windows""
""github.com/docker/docker/pkg/urlutil""
""github.com/docker/docker/runconfig/opts""
```

[0] https://github.com/docker/docker/blob/15ea28f6db7339f8a44078f3ef70484c96eebce7/cli/command/bundlefile/bundlefile.go
[1] https://github.com/kubernetes-incubator/kompose/blob/d9899b788d0e2051221e1b993f5a48268f9f3758/pkg/loader/bundle/bundle.go#L26
.
 @ngtuna can you take this ?
.
 @ericchiang I added package.go at #227 for making `kompose` go get-able. IMHO main package named `main` is okay. There are a lot of Go projects doing like that.

Yes removing `-tags experimental` is a good point. However it's not only copy structs but kompose also depends on [bundlefile's loadFile](https://github.com/kubernetes-incubator/kompose/blob/master/pkg/loader/bundle/bundle.go#L112) I am afraid that will need a ""big"" effort to completely remove importing bundlefile at this moment.
.
 @ngtuna 

> There are a lot of Go projects doing like that.

Sure, but Kubernetes isn't one of those projects. And almost all other kubernetes-incubator repos use the `cmd/( binary name )` structure used by the Go project (see: https://godoc.org/golang.org/x/tools/cmd)

> However it's not only copy structs but kompose also depends on bundlefile's loadFile I am afraid that will need a ""big"" effort to completely remove importing bundlefile at this moment.

LoadFile is just calling `json.Decoder(r).Decode(bundle)`.

https://github.com/docker/docker/blob/2c620d0aa24c5f774a9115449a86b158b005bba8/cli/command/bundlefile/bundlefile.go#L37-L59
.
 > LoadFile is just calling json.Decoder(r).Decode(bundle).

Oh you're right... My mistake didn't take a look into the function's detail. The thing is not simple like that with compose file parsing function.
.
 @ngtuna I'm assuming it'll get rid of this error when you `go get` then?

```
▶ go get github.com/kubernetes-incubator/kompose
package github.com/kubernetes-incubator/kompose: no buildable Go source files in /home/wikus/dropbox/dev/go/src/github.com/kubernetes-incubator/kompose
```
.
 @cdrage at least it will yes, and we expect to get the binary as well.
.
 "
,,215,"Add `go vet`.
 Tests that are run in travis-ci for every PR should include `go vet` to check for suspicious constructs and formatting errors.

we can create `make test` target that will run all tests (vet,unit,cmd)

current state:

```
$ for f in `find . -path ./vendor -prune -o -name '*.go' -print `; do go vet $f; done
cli/app/app_test.go:109: missing argument for Errorf(""%s""): format reads arg 3, have only 2 args
cli/app/app_test.go:112: missing argument for Errorf(""%s""): format reads arg 3, have only 2 args
cli/app/app_test.go:115: missing argument for Errorf(""%s""): format reads arg 3, have only 2 args
cli/app/app_test.go:118: missing argument for Errorf(""%s""): format reads arg 3, have only 2 args
pkg/loader/bundle/bundle.go:109: no formatting directive in Fatalf call
pkg/loader/bundle/bundle.go:114: no formatting directive in Fatalf call
```
.
 We can also use tools like [Go Meta Linter ](https://github.com/alecthomas/gometalinter) 
.
 > We can also use tools like Go Meta Linter

The regular `golint` tool already finds a lot of issues. Might want to tackle that first.

```
$ for pkg in $( go list github.com/kubernetes-incubator/kompose/... | grep -v '/vendor/' ); do golint $pkg; done
/home/eric/src/github.com/kubernetes-incubator/kompose/cli/app/app.go:42:2: exported const DefaultComposeFile should have comment (or a comment on this block) or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/cli/command/command.go:67:1: comment on exported function ConvertCommandDummy should be of the form ""ConvertCommandDummy ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/kobject/kobject.go:108:6: exported type ConvertOptions should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/kobject/kobject.go:161:1: exported function CheckUnsupportedKey should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/loader.go:28:6: exported type Loader should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/loader.go:42:15: should replace errors.New(fmt.Sprintf(...)) with fmt.Errorf(...)
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/bundle/bundle.go:32:6: exported type Bundle should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/bundle/bundle.go:128:1: comment on exported method Bundle.LoadFile should be of the form ""LoadFile ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:35:6: exported type Compose should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/loader/compose/compose.go:126:1: comment on exported method Compose.LoadFile should be of the form ""LoadFile ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/transformer.go:24:6: exported type Transformer should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:31:1: comment on exported function CreateOutFile should be of the form ""CreateOutFile ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:44:1: comment on exported function ParseVolume should be of the form ""ParseVolume ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:80:1: comment on exported function ConfigLabels should be of the form ""ConfigLabels ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:85:1: comment on exported function ConfigAnnotations should be of the form ""ConfigAnnotations ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:95:1: comment on exported function TransformData should be of the form ""TransformData ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/utils.go:117:1: comment on exported function Print should be of the form ""Print ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:230:1: exported method Kubernetes.PortsExist should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:234:9: if block ends with a return statement, so drop this else and outdent its block
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:239:1: comment on exported method Kubernetes.CreateService should be of the form ""CreateService ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:269:1: comment on exported method Kubernetes.UpdateKubernetesObjects should be of the form ""UpdateKubernetesObjects ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:334:1: comment on exported method Kubernetes.SortServicesFirst should be of the form ""SortServicesFirst ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/k8sutils.go:366:1: exported method Kubernetes.VolumesFrom should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:31:2: a blank import should be only in a main or test package, or have a comment justifying it
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:35:2: a blank import should be only in a main or test package, or have a comment justifying it
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:45:6: exported type Kubernetes should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:50:1: comment on exported const TIMEOUT should be of the form ""TIMEOUT ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:54:1: comment on exported method Kubernetes.InitRC should be of the form ""InitRC ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:84:1: comment on exported method Kubernetes.InitSvc should be of the form ""InitSvc ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:102:1: comment on exported method Kubernetes.InitD should be of the form ""InitD ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:129:1: comment on exported method Kubernetes.InitDS should be of the form ""InitDS ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:155:1: comment on exported method Kubernetes.CreatePVC should be of the form ""CreatePVC ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:187:1: comment on exported method Kubernetes.ConfigPorts should be of the form ""ConfigPorts ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:200:1: comment on exported method Kubernetes.ConfigServicePorts should be of the form ""ConfigServicePorts ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:220:1: comment on exported method Kubernetes.ConfigVolumes should be of the form ""ConfigVolumes ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:282:1: comment on exported method Kubernetes.ConfigEmptyVolumeSource should be of the form ""ConfigEmptyVolumeSource ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:289:1: comment on exported method Kubernetes.ConfigPVCVolumeSource should be of the form ""ConfigPVCVolumeSource ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:299:1: comment on exported method Kubernetes.ConfigEnvs should be of the form ""ConfigEnvs ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:312:1: comment on exported method Kubernetes.CreateKubernetesObjects should be of the form ""CreateKubernetesObjects ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:355:1: comment on exported method Kubernetes.UpdateController should be of the form ""UpdateController ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:376:1: comment on exported method Kubernetes.Deploy should be of the form ""Deploy ...""
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:422:1: exported method Kubernetes.Undeploy should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:449:11: if block ends with a return statement, so drop this else and outdent its block
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:462:11: if block ends with a return statement, so drop this else and outdent its block
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes.go:470:11: if block ends with a return statement, so drop this else and outdent its block
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes_test.go:75:15: don't use leading k in Go names; func parameter kEnvs should be envs
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes_test.go:79:9: don't use leading k in Go names; range var kEnv should be env
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes_test.go:93:17: don't use leading k in Go names; func parameter kPorts should be ports
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes/kubernetes_test.go:97:9: don't use leading k in Go names; range var kPort should be port
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/openshift/openshift.go:44:6: exported type OpenShift should have comment or be unexported
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/openshift/openshift.go:57:9: if block ends with a return statement, so drop this else and outdent its block
/home/eric/src/github.com/kubernetes-incubator/kompose/pkg/transformer/openshift/openshift.go:174:1: exported method OpenShift.Deploy should have comment or be unexported
```
.
 "
,,214,"wrong global --bundle/--dab input.
 An immediate fix to resolve the use of --bundle/--dab in order to resume work with adding test support for bundles.
.
 @cab105 's commit LGTM
.
 @cab105 can you please rebase?
otherwise LGTM
.
 Fixed rebase issue.
.
 that's going to be a lot of work for this change :) but see my email to get the CLA checker happy....
.
 Will need to close and resubmit the PR to account for the updated email identity.
.
 "
,,213,"remove skippbox reference in usage.
 just a small tweak to the usage due to the move.
.
 LGTM - but it doesn't count :) 
.
 @sebgoa needs CLA :) 
.
 "
,,212,"Update imports to reflect move to kubernetes-incubator.
 .
 LGTM! Press that magic green button!
.
 one sec:

```
$ grep -R skippbox | head -n 3
script/.validate:       VALIDATE_REPO='https://github.com/skippbox/kompose.git'
script/.build:BUILD_FLAGS=(-tags experimental -ldflags=""-w -X github.com/skippbox/kompose/version.GITCOMMIT=${GITCOMMIT}"")
Godeps/Godeps.json:     ""ImportPath"": ""github.com/skippbox/kompose"",
```
.
 @dustymabe Good catch. I checked just *.go files.
.
 I've updated original commit to include files that I've missed.
I've also added new commit updating links in docs and readme.
.
 LGTM
.
 +1 LGTM

let's merge it , I am testing the build right now, so we can fix quickly if there are remaining issues.
.
 @kadel your write privileges should have transferred....you should try to merge it so we can test that as well ...
.
 merging for tomas, because he is not in front of his computer and we need a working build after the move.
.
 "
,,211,"remove unknown args and added tests.
 Fix #193 
cc @kadel @dustymabe @sebgoa @surajssd
.
 can you rebase now that the rename has happened? 
.
 @dustymabe rebase done.
.
 @procrypt - can you ""sign the cla""?  basically create a [linuxfoundation account](https://www.linuxfoundation.org/caslogin)  with your redhat email address and then visit [this link](https://identity.linuxfoundation.org/projects/cncf) and ""sign up as an employee"".
.
 Just one thing. Have you consider putting that check to  `validateFlags` instead of adding it to every command?
`validateFlags` is already doing some validation and it is already called in every command.

I'm not saying that you should change it like this. I'm just interested why you did it like this. Valid answer can be that you think that it makes more sense the way you did it. :wink: 

I tested your code and it works great. :+1: 
.
 @kadel I didn't know about the function `validateFlags` we have for doing the validation thing, so I went ahead and wrote a new function which does the validation :)
I can update the PR if you want to use `validateFlags` instead of the `CheckForUnknownArgs`.
.
 I think that would be better to have all the validation on one place ;-)
.
 @kadel I'll update the PR :)
.
 Oh and one more think. It looks like your commit has some weird Author.
`Author: Abhishek <abhishek@dhcp35-217.lab.eng.blr.redhat.com>` so even if you already signed CLA it will still fail because it cannot associate this commit with your github account.
.
 I'll check and make sure it will be correct this time.
.
 @kadel @sebgoa I have update the PR, can you please review it.
.
 @kadel :)
.
 looks like merge conflict - need to resolve it. 
.
 Is this merge able now? cc @dustymabe  @procrypt @kadel @ngtuna 
.
 @pradeepto Yes it is. 
Some time ago we established workflow where everyone is merging his/her own PR after LGTM, so I left this for @procrypt  to merge it himself.
.
 @kadel I was not aware of that sorry my bad.
.
 Ah, no don't worry.
We should probably talk about this and document PR review process, and change it, because this cant' work for someone who doesn't have write access to repo. 
.
 Ah, no don't worry.
We should probably  talk about this and document PR review process.

On Wed, Oct 26, 2016 at 2:25 PM, Abhishek Pratap Singh <
notifications@github.com> wrote:

> @kadel https://github.com/kadel I was not aware of that sorry my bad.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/kubernetes-incubator/kompose/pull/211#issuecomment-256331714,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AADfdnLb7DojF9MP4w1rc9Mx_5hR-z_jks5q30amgaJpZM4KYaxb
> .
.
 "
,,210,"Remove unknown args.
 Fix #193 
CC @kadel @dustymabe @sebgoa @surajssd 
.
 "
,,209,"being able to store artifacts separately in a specific directory.
 Hi,

It would be great if I could store the generated provider artifacts to a specific directory other than the current working directory without having to bundling them into a single file (which `kompose convert -o ...`  currently does.

So, when `kompose convert -o artifacts` is run, if `artifacts` is a directory, then kompose should store all the resulting files inside it, and if it's not, then it should store the artifacts in a single file.

Thoughts?
.
 I totally could use this bit. @surajssd  and I were discussing earlier this week about exactly this. 
.
 I think this makes sense +1 from me. 
.
 @containscafeine I would like to work on it, if no one else is working on it.
.
 @procrypt I just assigned this to you and put it for v0.3 release.

this has been requested at least by one user..
 Hey @sebgoa, I think @containscafeine is already working on the issue..
 "
,,208,"kompose down for OpenShift.
 #200 implements only `up` we also need `down` for OpenShift
.
 @kadel I want to give it a try :)
.
 "
,,207,"compose constructs we support are still there in unsupportedKey.
 We do support things like `CPUSet`, `CPUShares`, etc. as seen in code [here](https://github.com/skippbox/kompose/blob/master/pkg/loader/compose/compose.go#L187) but we still have them in [`unsupportedKey` map](https://github.com/skippbox/kompose/blob/master/pkg/kobject/kobject.go#L29). So this is inconsistency, which should be fixed.
.
 Right. Unsupported keys hasn't been tracked for a while.
.
 "
,,206,"Generate buildconfig for Openshift.
 This implements support for generating buildconfig for services on Openshift.
.
 rebase please
.
 @dustymabe https://github.com/kubernetes-incubator/kompose/pull/206/commits/23536de83da59d329f8717a437f314b5edcd1267 fixes the issue you reported!
.
 @kadel @surajssd could you review this pull request once again? The generated artifacts now work with openshift as is. I am looking at how to replace doing system calls to `git`. I need `git` for 2 things:
- to find out the relative path of the compose file directory root dir of the project using `git rev-parse --show-prefix`. I don't have a way to work around this without `git` or `git2go`
-  to find the remote url of the project repository. It can be worked around by reading `.git/config`
.
 Would you like to bring this PR to the release ? @kadel @rtnpro @surajssd 
.
 @rtnpro Sorry, I didn't have much time latlely. But I'll will look at this as soon as I can.

@ngtuna I dont' think that we are going to make this to today's release
.
 @rtnpro so I tried to build on the latest branch today and saw that user can provide custom remote using `--repo https://github.com/rtnpro/kompose.git --branch buildconfig` but then how do you know what service's remote to change?

A docker-compose file can have multiple services and each service can be a project in itself!
.
 @rtnpro I tried this build on OpenShift online

Convert:

``` bash
$ kompose --provider openshift convert --stdout -y --bc > output.yml
WARN[0000] [foo] Service cannot be created because of missing port. 
```

and create objects in online

``` bash
$ oc new-project alm
$ oc create -f output.yml 
deploymentconfig ""foo"" created
imagestream ""foo"" created
Error from server: buildconfigs ""foo"" is forbidden: build strategy Docker is not allowed
```

It's not allowing build-strategy docker in openshift online.

Will give it one try on OpenShift running locally.
.
 Can you please rebase.
It looks like there are some govet errors. 
.
 Rebased!.
 @kadel what about deploying ``buildconfig`` to openshift with ``kompose up``?.
 @rtnpro tried today

```bash
vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ kompose --provider openshift convert -y --stdout > output.yml                                                                                       
WARN[0000] [foo] Service cannot be created because of missing port. 
INFO[0000] Buildconfig using https://github.com/rtnpro/kompose.git::master as source. 

vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc new-project kom
Already on project ""kom"" on server ""https://192.168.121.193:8443"".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.

vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc create -f output.yml 
deploymentconfig ""foo"" created
imagestream ""foo"" created
buildconfig ""foo"" created
vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc get pods
NAME          READY     STATUS    RESTARTS   AGE
foo-1-build   1/1       Running   0          26s

vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc logs foo-1-build
Cloning ""https://github.com/rtnpro/kompose.git"" ...
        Commit: 20a13d3eeff38a0af4faad3119ce6182a042c5fc (Merge pull request #254 from dustymabe/dusty-deployment-deploymentconfig)
        Author: Janet Kuo <chiachenk@google.com>
        Date:   Fri Oct 28 17:38:04 2016 -0700
error: build error: open /tmp/docker-build757686686/examples/buildconfig/build/Dockerfile: no such file or directory

```

now loooking at git log here is what i see

```bash
vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ git log | grep -A 10 -B 5 20a13d3eeff38a0af4faad3119ce6182a042c5fc

    Merge pull request #248 from dustymabe/dusty-empty-vols
    
    Adding support for choosing empty volumes

commit 20a13d3eeff38a0af4faad3119ce6182a042c5fc
Merge: 9c38e88 48aa4c7
Author: Janet Kuo <chiachenk@google.com>
Date:   Fri Oct 28 17:38:04 2016 -0700

    Merge pull request #254 from dustymabe/dusty-deployment-deploymentconfig
    
    Match case with API objects when printing to terminal

commit 6eb8c4ca76e27451881cf15e34a04bb22c892aa4
Author: Tuna <ng.tuna@gmail.com>
```

So it is pulling some old commit for some reason?.
 On Tue, Nov 29, 2016 at 3:59 PM, Suraj Deshmukh
<notifications@github.com> wrote:
>
> @rtnpro tried today
>
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ kompose --provider openshift convert -y --stdout > output.yml
> WARN[0000] [foo] Service cannot be created because of missing port.
> INFO[0000] Buildconfig using https://github.com/rtnpro/kompose.git::master as source.
>
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc new-project kom
> Already on project ""kom"" on server ""https://192.168.121.193:8443"".
>
> You can add applications to this project with the 'new-app' command. For example, try:
>
>     oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git
>
> to build a new example application in Ruby.
>
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc create -f output.yml
> deploymentconfig ""foo"" created
> imagestream ""foo"" created
> buildconfig ""foo"" created
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc get pods
> NAME          READY     STATUS    RESTARTS   AGE
> foo-1-build   1/1       Running   0          26s
>
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ oc logs foo-1-build
> Cloning ""https://github.com/rtnpro/kompose.git"" ...
>         Commit: 20a13d3eeff38a0af4faad3119ce6182a042c5fc (Merge pull request #254 from dustymabe/dusty-deployment-deploymentconfig)
>         Author: Janet Kuo <chiachenk@google.com>
>         Date:   Fri Oct 28 17:38:04 2016 -0700
> error: build error: open /tmp/docker-build757686686/examples/buildconfig/build/Dockerfile: no such file or directory
>
> now loooking at git log here is what i see
>
> vagrant@fedora:~/tmp/buildconfig/kompose/examples/buildconfig$ git log | grep -A 10 -B 5 20a13d3eeff38a0af4faad3119ce6182a042c5fc
>
>     Merge pull request #248 from dustymabe/dusty-empty-vols
>
>     Adding support for choosing empty volumes
>
> commit 20a13d3eeff38a0af4faad3119ce6182a042c5fc
> Merge: 9c38e88 48aa4c7
> Author: Janet Kuo <chiachenk@google.com>
> Date:   Fri Oct 28 17:38:04 2016 -0700
>
>     Merge pull request #254 from dustymabe/dusty-deployment-deploymentconfig
>
>     Match case with API objects when printing to terminal
>
> commit 6eb8c4ca76e27451881cf15e34a04bb22c892aa4
> Author: Tuna <ng.tuna@gmail.com>

This is perfectly OK :) My changes (along with the example app) are
not in master branch. It's in my fork. So you need to specify

``--build-repo https://github.com/rtnpro/kompose.git --build-branch
buildconfig``

in the ``kompose convert`` options.
.
 @rtnpro I think that branch should be detected in the similar way as you detect git remote. It is confusing that you get one from git repository automatically and other not.
`--build-branch` should be used only to overwrite that to something else..
 Functional tests will break till the time #324 is not merged..
 
[![Coverage Status](https://coveralls.io/builds/9424908/badge)](https://coveralls.io/builds/9424908)

Coverage increased (+1.07%) to 43.149% when pulling **9b17227d089408d981869dac759782073f0b8376 on rtnpro:buildconfig** into **240f15049238751d91037eee2a0c0fb86c65f17b on kubernetes-incubator:master**.
.
 @surajssd Resolved issues you reported on review!.
 
[![Coverage Status](https://coveralls.io/builds/9427440/badge)](https://coveralls.io/builds/9427440)

Coverage increased (+0.9%) to 46.636% when pulling **4894a49167f7e00feaafe4c918dc79adca3d4380 on rtnpro:buildconfig** into **73418310ac1e607b41d0af2588ed7a808a3c85fa on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9436351/badge)](https://coveralls.io/builds/9436351)

Coverage increased (+0.9%) to 46.636% when pulling **87f0464900461745ed8db16635dada3ef3470b91 on rtnpro:buildconfig** into **73418310ac1e607b41d0af2588ed7a808a3c85fa on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9445634/badge)](https://coveralls.io/builds/9445634)

Coverage increased (+0.9%) to 46.582% when pulling **8ed07fca52fee936c6ef6d3117aac661bfd085ab on rtnpro:buildconfig** into **c80735c1a597d10cb8d5126484b1ef6dfb5d84a0 on kubernetes-incubator:master**.
.
 @rtnpro two things now

```bash
$ kompose --provider openshift convert -o config/ --build-repo https://github.com/rtnpro/kompose 
WARN[0000] [foo] Service cannot be created because of missing port. 
INFO[0000] Buildconfig using https://github.com/rtnpro/kompose:: as source. 
<snip>
```
It is correctly reading the branch but then it is not showing up as you can see in last line.

It is still not pushing to internal registry! 

I see following things in status

```bash
$ oc status -v
In project simple on server https://192.168.121.103:8443

dc/foo deploys istag/foo:latest <- bc/foo docker builds https://github.com/rtnpro/kompose#buildconfig 
    build #1 failed 2 minutes ago - 8ed07fc: Fixed typos in openshift buildconfig. (Ratnadeep Debnath <rtnpro@gmail.com>)
  deployment #1 waiting on image or update

Errors:
  * build/foo-1 has failed.
    try: Inspect the build failure with 'oc logs -f bc/foo'
Warnings:
  * pod/foo-1-build has no liveness probe to verify pods are still running.
    try: oc set probe pod/foo-1-build --liveness ...
  * The image trigger for dc/foo will have no effect until istag/foo:latest is imported or created by a build.
  * dc/foo has no readiness probe to verify pods are ready to accept traffic or ensure deployment is successful.
    try: oc set probe dc/foo --readiness ...
  * dc/foo has no liveness probe to verify pods are still running.
    try: oc set probe dc/foo --liveness ...

View details with 'oc describe <resource>/<name>' or list everything with 'oc get all'.
```

and build container failed saying
```bash
$ oc logs foo-1-build
Cloning ""https://github.com/rtnpro/kompose"" ...
        Commit: 8ed07fca52fee936c6ef6d3117aac661bfd085ab (Fixed typos in openshift buildconfig.)
        Author: Ratnadeep Debnath <rtnpro@gmail.com>
        Date:   Wed Dec 28 16:58:52 2016 +0530
Step 1 : FROM busybox
 ---> 1efc1d465fd6
<snip>
Removing intermediate container 1fb8d9987023
Successfully built 4e0fdc19432e
Pushing image 172.30.240.241:5000/simple/foo:latest ...
error: build error: Failed to push image: unauthorized: authentication required
```
.
 
[![Coverage Status](https://coveralls.io/builds/9446377/badge)](https://coveralls.io/builds/9446377)

Coverage increased (+0.9%) to 46.582% when pulling **b10c0ad1a96c055c007a012b4169b7eac2f6619b on rtnpro:buildconfig** into **c80735c1a597d10cb8d5126484b1ef6dfb5d84a0 on kubernetes-incubator:master**.
.
 
[![Coverage Status](https://coveralls.io/builds/9446883/badge)](https://coveralls.io/builds/9446883)

Coverage increased (+0.9%) to 46.582% when pulling **0d86f3e08754e8165ef2ae6d0306156ef84fe4d0 on rtnpro:buildconfig** into **c80735c1a597d10cb8d5126484b1ef6dfb5d84a0 on kubernetes-incubator:master**.
.
 @rtnpro @kadel great work and thanks for all the patience :+1: .
 "
,,205,"Add tests based on current issues.
 That fail due to libcompose v2 support...

Add wiki page and keep track of tests.
.
 kompose could definitely use more unit test. I only see two on HEAD.

I've seen a ton of PRs be merged without unit tests. Most of the work of adding new features is proper testing to prevent regressions and help reviewers have confidence in changes. It might be a reasonable idea to start enforcing tests as part of PRs as well.

```
$ go test -race -cover -v $( go list github.com/kubernetes-incubator/kompose/... | grep -v '/vendor/' )
?       github.com/kubernetes-incubator/kompose [no test files]
=== RUN   TestParseVolume
--- PASS: TestParseVolume (0.00s)
PASS
coverage: 0.0% of statements
ok      github.com/kubernetes-incubator/kompose/cli/app 1.128s  coverage: 0.0% of statements
?       github.com/kubernetes-incubator/kompose/cli/command [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/kobject [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader  [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader/bundle   [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/loader/compose  [no test files]
?       github.com/kubernetes-incubator/kompose/pkg/transformer [no test files]
=== RUN   TestKomposeConvert
--- PASS: TestKomposeConvert (0.00s)
    kubernetes_test.go:215: Test case: Convert to Deployments (D)
    kubernetes_test.go:215: Test case: Convert to DaemonSets (DS)
    kubernetes_test.go:215: Test case: Convert to ReplicationController (RC)
    kubernetes_test.go:215: Test case: Convert to D, DS, and RC
PASS
coverage: 40.5% of statements
ok      github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes  1.095s  coverage: 40.5% of statements
?       github.com/kubernetes-incubator/kompose/pkg/transformer/openshift   [no test files]
?       github.com/kubernetes-incubator/kompose/version [no test files]
```
.
 @ericchiang That looks like a way better command to use to add to unit tests, perhaps we add this to the current `make test-unit` command we have?
.
 I created PR #261 for this ^^
.
 i think we are doing good on this, so closing it. Thanks @surajnarwade for bringing this to my notice!.
 "
,,204,"Meeting info to README.md.
 added link to agenda doc and meeting bluejeans link
.
 @sebgoa done! I missed that part, sorry about that :)
.
 LGTM, @surajssd go ahead and merge
.
 @sebgoa you will have to resolve it, right now merging is blocked!
.
 Oh now it shows resolved, merging
.
 "
,,203,"Update to 0.1.1 in README.
 "
,,202,"panic: runtime error: invalid memory address or nil pointer dereference.
 I am facing this issue when converting the docker-compose.yml file . It is a straighforward compose file with couple of volume mounts and no env variables.

Kompose version : kompose version 0.1.0 (8227684)
## Error:

panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x18 pc=0xbbff5c]

goroutine 1 [running]:
panic(0x15a9b60, 0xc82000e0e0)
        /usr/local/go/src/runtime/panic.go:481 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(_Project).handleNetworkConfig(0xc8201762a0)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:254 +0x26c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(_Project).load(0xc8201762a0, 0xc820355c40, 0x12, 0xc8201e4800, 0x4c3, 0x6c3, 0x0, 0x0)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:209 +0x638
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(_Project).Parse(0xc8201762a0, 0x0, 0x0)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:87 +0x335
github.com/skippbox/kompose/pkg/loader/compose.(_Compose).LoadFile(0x22db590, 0xc820355c40, 0x12, 0x0)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/pkg/loader/compose/compose.go:121 +0x52f
github.com/skippbox/kompose/cli/app.Convert(0xc8202e1400)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/cli/app/app.go:145 +0x4e8
github.com/skippbox/kompose/cli/command.ConvertCommand.func1(0xc8202e1400)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/cli/command/command.go:32 +0x21
github.com/skippbox/kompose/vendor/github.com/urfave/cli.Command.Run(0x1811338, 0x7, 0x0, 0x0, 0x0, 0x0, 0x0, 0xc8203947d0, 0x4b, 0x0, ...)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/command.go:179 +0x1399
github.com/skippbox/kompose/vendor/github.com/urfave/cli.(*App).Run(0xc8203c2840, 0xc82000a140, 0x4, 0x4, 0x0, 0x0)
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/app.go:196 +0x137c
main.main()
        /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/cli/main/main.go:47 +0x33b
.
 Hi @beravelli 
from trace you posted it looks like issue with libcompose, during parsing network definition. 

Can you please show docker-compose file that you used, or at least snippet of it with network definitions?
.
 Hi kadel,

networks:
           - incubator

networks:
  incubator:
.
 It works when I take out the networks and volumes section in the docker-compose.yml file. 
.
 @beravelli network definition was improved with this recent PR https://github.com/skippbox/kompose/pull/195. We will soon publish new release included this fix. Right now could you try getting kompose HEAD and test with your compose file?
.
 Similar issue: https://github.com/skippbox/kompose/issues/149
.
 close via #195 
.
 "
,,201,"update README with SIG-APPS and Champion.
 some clean up for incubation
.
 @kadel @ngtuna appreciate a review...simple readme edits...
.
 I am gonna make it merge-able by adding approved review. @sebgoa has the whole idea on the incubating progress.
.
 ok merging
.
 "
,,200,"Kompose up for OpenShift.
 `kompose --provider openshift up`
This has similar behavior as `kompose up` for k8s. It assumes that you already have `.kube/config` setup (you are logged using `oc login`). 
It converts docker-compose.yaml to DeploymentConfigs, Services and ImageStreams, those objects are then deployed to OpenShift cluster.

This PR also updates bunch of vendored libs.
Mainly  OpenShift 1.4.0-alpha.0 this is required to avoid collisions between Docker version that is required by OpenShift and version that Kompose requires for bundle support.
Upgrading OpenShift forced updates for a lots of other libs. Kubernetes is now in version v1.4.0-beta.3
#40

~~requires #199~~ - merged
#### Issues:

~~Can't update vendored libs :-(~~

~~godep save ./...
godep: Package (github.com/docker/docker/pkg/term/winconsole) not found~~

Solved in https://github.com/skippbox/kompose/pull/200/commits/2273436ed77e55b3632d340436e7792e6485576e - upgrading OpenShift to 1.4.0-apha.0 this version is using docker version that is compatible version that we require for bundle support.

~~is still not working (fails while creating deployment) :-(~~

All issues are solved, and it is ready for review
.
 > Can't update vendored libs :-(
> godep save ./...  
> godep: Package (github.com/docker/docker/pkg/term/winconsole) not found

Does it (g/docker/docker) conflict revision with one I upgraded at #174  ?
.
 It was in conflict even before that :-(
But it was OK, because we haven't been using parts of OpenShift that are calling this.

It his PR I'm using `github.com/openshift/origin/pkg/client` and `github.com/openshift/origin/pkg/cmd/util/clientcmd` and it looks like that they both have dependency on `github.com/docker/docker/pkg/term/winconsole`
.
 :tada: ,  now it is ready for testing and review
.
 Do you have tests in there for conversion to DeploymentConfigs and ImageStreams ? does not look like Travis run any.

Also if would be good to add a user-guide in /docs ....
.
 Yes, test for DeploymentConfigs are there (every conversion to OpenShift generates DeploymentConfig). Same for ImageStreams, every OpenShift conversion generates ImageStream, tests was updated in https://github.com/skippbox/kompose/pull/160
.
 I've added commit with updated user-guide.
.
 seems to be working for me - one of my imagestreams was not working right, but I think that might be another issue. 
.
 ok - i'm having some trouble with image streams in the example I am trying to do. This is the file: https://github.com/dustymabe/kompose/blob/dusty-foo-bar/examples/mlbparks.yml

When I create with openshift it doesn't work complaining about imagepullbackoff for the dustymabe/mlbparks image. Here is what I used to get into openshift:

```
$ ../kompose --provider openshift -f mlbparks.yml up                                                                                                                                              
We are going to create OpenShift DeploymentConfigs and Services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'oc create -f' commands instead. 

INFO[0000] Successfully created service: mlbparks       
INFO[0000] Successfully created service: mongodb        
INFO[0000] Successfully created deployment: mlbparks    
INFO[0000] Successfully created ImageStream: mlbparks   
INFO[0000] Successfully created deployment: mongodb     
INFO[0000] Successfully created ImageStream: mongodb    

Your application has been deployed to OpenShift. You can run 'oc get dc,svc,is' for details.

```

When I convert to ""pretend"" that I am kube by passing --rc then the image pulls fine and the application comes up. Here is that command:

```
$ ../kompose -f mlbparks.yml convert --stdout --rc | oc create -f -
service ""mlbparks"" created
service ""mongodb"" created
replicationcontroller ""mlbparks"" created
replicationcontroller ""mongodb"" created
```

The openshift environment I am targeting is: 

```
OpenShift Master:
    v3.2.1.15-8-gc402626
Kubernetes Master:
    v1.2.0-36-g4a3f9c5 
```
.
 hmm :-(
I've just tried your mlbparks.yml and it worked fine for me. 
Only difference is that I used OpenShift Origin 1.3.0. 

It complained only for dustymabe/mlbparks image? centos/mongodb-26-centos7 pulled successfully?
.
 > I've just tried your mlbparks.yml and it worked fine for me.

Then I wouldn't worry about it. Most likely my setup. 

> It complained only for dustymabe/mlbparks image?

yes. It only complained for one of the images. The onther one was fine. 
.
 Can we get this rebased? :) 
.
 Ah, It conflicted with my other PR :-)

Rebased.
.
 ping @surajssd @janetkuo @ngtuna @sebgoa - can we get this reviewed by a maintainer? 
.
 @dustymabe I think some of us don't have Openshift account for testing. But you guys made some tests already and user-guide was also added, it should be good to let it pass. We can always open issue later.
.
 @ngtuna If you would like to play with OpenShift in future you can use [minishift](https://github.com/jimmidyson/minishift) it is practically same as minikube but it starts vm with OpenShift ;-)
.
 Thanks @kadel for the reference :+1:

On Tuesday, October 18, 2016, Tomas Kral notifications@github.com wrote:

> @ngtuna https://github.com/ngtuna If you would like to play with
> OpenShift in future you can use minishift
> https://github.com/jimmidyson/minishift it is practically same as
> minikube but it starts vm with OpenShift ;-)
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/kubernetes-incubator/kompose/pull/200#issuecomment-254547582,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AB31xxMoSAu2_gZJum51UknzbAiRzxpkks5q1Of9gaJpZM4KTa-U
> .

## 

Regards,
Tu Nguyen
Sent from mobile
.
 @ngtuna also you can try out for free in openshift online: https://www.openshift.com/devpreview/
.
 @dustymabe @kadel so this worked for me when I tried it today with the docker-compose file in examples well.
.
 "
,,199,"fix golang.org/x/net vendoring.
 fixes golang.org/x/net vendoring
it  was vendored with reference to `2beffdc2e92c8a3027590f898fe88f69af48a3f8`
but this is not a reference to golang.org/x/net instead it is reference in fork https://github.com/tonistiigi/net.git

This was caused by libcompose.  (https://github.com/docker/libcompose/blob/master/hack/vendor.sh#L23)

cc: @ngtuna 
.
 "
,,198,"wrong global --bundle/--dab input.
 ``` console
$ kompose --bundle docker-voting-bundle.dsb convert
FATA[0000] Error: 'compose' file and 'dab' file cannot be specified at the same time
```

Figured out `opt.InputFile` received `docker-voting-bundle.dsb` instead of `docker-compose.yml` then the [if clause](https://github.com/ngtuna/kompose/blob/master/cli/app/app.go#L74) returned true.
.
 @ngtuna I have a fix for this along with my initial test.sh work for #167.
.
 close via #221 
.
 "
,,197,"support both : and = as compose envvar separators.
 fix #196 #173 
.
 could you check it? @surajssd 
.
 > But there is one think that this PR should include, and that is test for it.

Yes. I will add follow-up commit
.
 @ngtuna I have problem building this branch, can you guys tell me what am I missing?

``` bash
$ git remote show tuna
* remote tuna
  Fetch URL: https://github.com/ngtuna/kompose
  Push  URL: https://github.com/ngtuna/kompose
  HEAD branch: master
  Remote branches:
    clean-code        tracked
    envvar_colon      tracked
    global-flag       tracked
[SNIP]
    userguide         tracked
  Local branches configured for 'git pull':
    envvar_colon    merges with remote envvar_colon
    project-context merges with remote project-context
    update-objects  merges with remote update-objects
  Local refs configured for 'git push':
    envvar_colon    pushes to envvar_colon    (up to date)
    master          pushes to master          (fast-forwardable)
    project-context pushes to project-context (up to date)
    update-objects  pushes to update-objects  (up to date)
```

``` bash
$ git fetch tuna
```

``` bash
$ git checkout envvar_colon 
Switched to branch 'envvar_colon'
Your branch is up-to-date with 'tuna/envvar_colon'.

$ git pull
Already up-to-date.
```

``` bash
$ build-kompose 
+ cd /home/hummer/go/src/github.com/kubernetes-incubator/kompose
+ go build -tags experimental -o kompose ./cli/main/
# github.com/kubernetes-incubator/kompose/pkg/loader/bundle
pkg/loader/bundle/bundle.go:95: cannot use p (type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
# github.com/kubernetes-incubator/kompose/pkg/loader/compose
pkg/loader/compose/compose.go:101: cannot use proto (type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
pkg/loader/compose/compose.go:110: cannot use proto (type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
# github.com/kubernetes-incubator/kompose/pkg/transformer/kubernetes
pkg/transformer/kubernetes/k8sutils.go:248: cannot use service (type ""github.com/skippbox/kompose/pkg/kobject"".ServiceConfig) as type ""github.com/kubernetes-incubator/kompose/pkg/kobject"".ServiceConfig in argument to transformer.ConfigAnnotations
pkg/transformer/kubernetes/k8sutils.go:274: cannot use service (type ""github.com/skippbox/kompose/pkg/kobject"".ServiceConfig) as type ""github.com/kubernetes-incubator/kompose/pkg/kobject"".ServiceConfig in argument to transformer.ConfigAnnotations
pkg/transformer/kubernetes/kubernetes.go:188: cannot use port.Protocol (type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
pkg/transformer/kubernetes/kubernetes.go:207: cannot use port.Protocol (type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
# github.com/skippbox/kompose/pkg/transformer/kubernetes
../../skippbox/kompose/pkg/transformer/kubernetes/k8sutils.go:248: cannot use service (type ""github.com/kubernetes-incubator/kompose/pkg/kobject"".ServiceConfig) as type ""github.com/skippbox/kompose/pkg/kobject"".ServiceConfig in argument to transformer.ConfigAnnotations
../../skippbox/kompose/pkg/transformer/kubernetes/k8sutils.go:274: cannot use service (type ""github.com/kubernetes-incubator/kompose/pkg/kobject"".ServiceConfig) as type ""github.com/skippbox/kompose/pkg/kobject"".ServiceConfig in argument to transformer.ConfigAnnotations
../../skippbox/kompose/pkg/transformer/kubernetes/kubernetes.go:188: cannot use port.Protocol (type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
../../skippbox/kompose/pkg/transformer/kubernetes/kubernetes.go:207: cannot use port.Protocol (type ""github.com/kubernetes-incubator/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol) as type ""github.com/skippbox/kompose/vendor/k8s.io/kubernetes/pkg/api"".Protocol in field value
```
.
 @surajssd this is because @ngtuna's branch is not yet rebased to current master. It still uses old import path `github.com/skippbox/kompose`
.
 oh okay
.
 Hey @kadel @surajssd I made rebase and added test. Please take a look.
.
 @ngtuna I tried pulling and building it and it LGTM
.
 merging
.
 "
,,196,"Parsing environment variables with `:`.
 libcompose could support both separate characters `:` and `=` in envvar because docker config object accepted them. However, kompose doesn't rely on docker but libcompose config object. Thus, kompose can only support `=` at this moment.

Related issue: #173. In the [hygieia](https://raw.githubusercontent.com/capitalone/Hygieia/master/docker-compose.yml) example, there are envvars with `:` and kompose getting panic.
.
 "
,,195,"upgrade libcompose.
 I made an upgrade libcompose to its HEAD at https://github.com/docker/libcompose/commit/fbdac0a6a80837c63eb6c8f43514f7bb3f32df6c.
- Tested with all test cases we have `make test-cmd`.
- Need to enable CGO as required by vendor/github.com/opencontainers/runc/libcontainer/system/sysconfig.go
- Scanned vendor/ and removed all unused packages.
- Many packages also being upgraded accordingly as they harmonize with libcompose, but do not conflict with kompose. Such as:
  - github.com/docker/docker
  - github.com/docker/distribution
  - github.com/opencontainers/runc
  - etc

Fixed #149, #92, #80 
.
 #194 
.
 Merging. Thanks @kadel 
.
 "
,,194,"script/godep-restore.sh doesn't seem to work correctly.
 I tried running `script/godep-restore.sh` in a fresh $GOPATH, and then removed Godeps and vendor folders and then running `godep save ./...` in order to save them again. The new born Godeps.json looks quite different with the current one we have in upstream.
.
 However, building kompose with the new generated vendor/ run successfully. Many packages have been removed.
.
 This is not godep fault but ours. 
We let `vendor` get out of sync. Every time we add or remove import we should run `save`.
We don't do that so we have few unused libs in vendor.
.
 Right. So I am going to update vendor
.
 closed via https://github.com/skippbox/kompose/pull/195
.
 "
,,193,"error on extraneous/unexpected cli input.
 we should probably error out if we get extra arguments/input on the CLI that we don't expect or understand. One example of this is when I was trying to start the gitlab example but I was doing it wrong:

```
[vagrant@f24 examples (upstreammaster=)]$ ../kompose --version
kompose version 0.1.1 (5a37bf0)
[vagrant@f24 examples (upstreammaster=)]$ ../kompose up docker-gitlab.yml 
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created service: web            
INFO[0000] Successfully created service: redis          
INFO[0000] Successfully created deployment: web         
INFO[0000] Successfully created deployment: redis       

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods' for details.
```

So you can see I was trying to run gitlab, but I didn't specify things like I should have: `kompose -f docker-gitlab.yml up`. This means that it actually ignored the `docker-gitlab.yml` that I passed on the command line and used the default `docker-compose.yml` instead and it looks like the application is brought up (if you aren't paying attention too close). 

Now if instead it would error out when it detected extraneous input then I would have found out what was wrong sooner than later.
.
 @dustymabe can I work on it, if no one else working on it.
.
 @procrypt just assigned it to you.
.
 @sebgoa Thanks :)
.
 "
,,192,"establish release process - protect master branch.
 Hey hey!

I went to create the new rpm today for kompose 0.1.1 and see that the history is lost for the tag 0.1.1 from the master branch. According to the [release page](https://github.com/skippbox/kompose/releases/tag/v0.1.1) it was tagged from 534fa9b but that commit does not show up in the history for the master branch. I believe that means that the master branch was force pushed to in order to overwrite history. 

Can we possibly do the following: 
- establish a methodical release process to follow for a release
- protect the master branch from any force pushes ever (you can configure this in the settings in github so that it protects history from getting lost)
- always do work through pull requests and require at least one maintainer +1 before doing a merge
.
 Yes @dustymabe that was a mistake then I made a force push on https://github.com/skippbox/kompose/commit/534fa9ba1d46909ffb20004dbc75bc9bcc7eae2c.

> establish a methodical release process to follow for a release

Yes. I believe @sebgoa is working on it.

> protect the master branch from any force pushes ever (you can configure this in the settings in github so that it protects history from getting lost)

Done. I disabled force push on master and required to have one approved review prior to the PR is getting merged.

> always do work through pull requests and require at least one maintainer +1 before doing a merge

We are having this procedure.
.
 @ngtuna thanks! I guess once @sebgoa gets the docs for the release process published then we can close this issue.

for the record i think I'll wait for 0.1.2 to update the downstream rpm.
.
 closing this for #70 .
 "
,,191,"Add ""mkdocs"" generation for Kompose site.
 This commit adds ""mkdocs"" generation to push markdown documenation to
the Kompose website.

On each push to master, new documentation is automatically generated and
pushed to ""gh-pages""
.
 Before this is merged and tested upon, this guide needs to be followed:

https://blog.wyrihaximus.net/2015/09/github-auth-token-on-travis/

GITHUB_API_KEY needs to be added as an environment variable to the travis builds.

On completion of this, when this is merged, the documents in `docs/source` will automatically generate and be pushed to https://skippbox.github.io/kompose
.
 This will create https://skippbox.github.io/kompose with automatic doc generation on each master PR merge.
.
 @cdrage thanks, I will take this one.

Can you sign a CLA from https://github.com/skippbox/cla

Maybe check with @pradeepto or @dustymabe , I just want to keep track of CLAs so if we need to change the copyright it will be easy.
.
 @sebgoa ya sure, so what do i need to do? fill out out and send it to some email?
.
 @cdrage yes just sign, put your name and address, scan and send to: info at skippbox dot com
.
 @sebgoa sent
.
 @sebgoa updated with your changes!

Remember to login to Travis and add the API key via the guide before mergin'
.
 @cdrage I did not forget about this. But now that we moved to the incubator I am trying to do a few things first.

In any case, while you signed the skippbox CLA, now that we moved you need to sign the CNCF CLA.

maybe @dustymabe can help you with that.
.
 @cdrage it's pretty easy - just follow what I said here: https://github.com/kubernetes-incubator/kompose/pull/211#issuecomment-254308960
.
 Since we've moved to the kubernetes-incubator, I'm going to close this _for now_ until I figure out a good area to push the docs to (the kubernetes site, or some other area)
.
 "
,,190,"support for volumes_from docker-compose construct.
 Now a user can provide `volumes_from` to share `volumes` from other service so here the PVC created for that service will be shared by service calling `volumes_from`.
.
 PVC are created with AccessMode ""ReadWriteOnce"". So they can't be mounted to multiple containers :-(
.
 @kadel so I tried following in minikube, see if you can re-create it:

Start a minikube VM and ssh into it

``` bash
$ minikube start
$ minikube ssh
docker@minikube:~$ mkdir ~/data
```

And create a PV and PVC using following file:

``` yaml
$ cat vols.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: vol1
  labels:
    type: local
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: ""/home/docker/data""
---

kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: myclaim
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

and create pods that share same PVC

``` yaml
$ cat pods.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: httpd
spec:
  containers:
  - image: docker.io/centos/httpd
    name: httpd
    volumeMounts:
    - mountPath: /var/www/html
      name: httpd-volume
  volumes:
  - name: httpd-volume
    persistentVolumeClaim:
      claimName: myclaim
---

apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    volumeMounts:
    - mountPath: /mynginx
      name: nginx-volume
  volumes:
  - name: nginx-volume
    persistentVolumeClaim:
      claimName: myclaim
```

once all started 

``` bash
$ kubectl exec -it nginx bash
root@nginx:/# cat > mynginx/index.html
this file is created from nginx container and will be served by httpd
```

get IP addr of pod

``` bash
$ kubectl get pods -o wide
NAME      READY     STATUS    RESTARTS   AGE       IP           NODE
httpd     1/1       Running   0          14m       172.17.0.4   minikube
nginx     1/1       Running   0          14m       172.17.0.3   minikube
```

in minikube vm i could see httpd serving that file created from nginx container

``` bash
$ minikube ssh
docker@minikube:~$ curl 172.17.0.4
this file is created from nginx container and will be served by httpd
```
.
 OK, I followed your instruction and it worked. But according to [docs](http://kubernetes.io/docs/user-guide/persistent-volumes/#access-modes) it shouldn't have :-)

'ReadWriteOnce – the volume can be mounted as read-write by a single node'

Otherwise It doesn't make sense, or I don't get it :-(
.
 Ohhh, I get it now. (maybe :wink: ) it is by **single node** not single container. This will work on single node cluster. But not on multi-node. I'll have to test this.
.
 I tested this on multinode cluster and if pods are on different nodes it is not working :-(

```
▶ kubectl exec -it nginx bash        
root@nginx:/# echo ""asdf"" > /mynginx/index.html 
root@nginx:/# exit

▶ kubectl exec -it httpd bash
[root@httpd /]# ls /var/www/html/
[root@httpd /]# exit
```
.
 I have a 2 node 1 master k8s cluster and 1 more machine acting as NFS server out of k8s cluster.

these are the pods i am running

``` bash
$ kubectl get pods -o wide
NAME      READY     STATUS    RESTARTS   AGE       IP             NODE
httpd     1/1       Running   0          35m       10.246.93.2    kubernetes-node-2
httpd1    1/1       Running   0          4m        10.246.93.4    kubernetes-node-2
httpd2    1/1       Running   0          3m        10.246.93.7    kubernetes-node-2
httpd3    1/1       Running   0          3m        10.246.93.8    kubernetes-node-2
httpd4    1/1       Running   0          2m        10.246.48.3    kubernetes-node-1
httpd5    1/1       Running   0          1m        10.246.48.7    kubernetes-node-1
```

and here is the pv and pvc i have

``` bash
$ kubectl get pv
NAME      CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS    CLAIM             REASON    AGE
vol1      5Gi        RWO           Retain          Bound     default/myclaim             45m

$ kubectl get pvc
NAME      STATUS    VOLUME    CAPACITY   ACCESSMODES   AGE
myclaim   Bound     vol1      5Gi        RWO           42m
```

now on node1

``` bash
[vagrant@kubernetes-node-1 ~]$ curl 10.246.93.2
hey this should reflect everywhere
[vagrant@kubernetes-node-1 ~]$ curl 10.246.48.3
hey this should reflect everywhere
[vagrant@kubernetes-node-1 ~]$ curl 10.246.93.4
hey this should reflect everywhere
[vagrant@kubernetes-node-1 ~]$ curl 10.246.48.7
hey this should reflect everywhere
```

now on node2

``` bash
[vagrant@kubernetes-node-2 ~]$ curl 10.246.93.2
hey this should reflect everywhere
[vagrant@kubernetes-node-2 ~]$ 
[vagrant@kubernetes-node-2 ~]$ curl 10.246.48.3
hey this should reflect everywhere
[vagrant@kubernetes-node-2 ~]$ curl 10.246.93.4
hey this should reflect everywhere
[vagrant@kubernetes-node-2 ~]$ curl 10.246.48.7
hey this should reflect everywhere
```

The only difference is `pv` this time instead of `hostPath` it's `NFS`

``` yaml
$ cat pv.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: vol1
  labels:
    type: local
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  nfs:
    path: /shared/kubernetes/web
    server: 192.168.121.199
```

The `pvc` is as before pod definitions are also as before.

followed http://severalnines.com/blog/wordpress-application-clustering-using-kubernetes-haproxy-and-keepalived for the setup

all the pods are also same just having different names.
.
 Ok, it works with NFS on multi  node. I think that we can marge this, so more people can test it and we can improve later on.
.
 maybe wait for @ngtuna if he has any feedback on this.
.
 > Ok, it works with NFS on multi node. I think that we can marge this, so more people can test it and we can improve later on.

@kadel  so we had this discussion about the `accessModes` not being enforced, so I found similar information in video here[1] which says that kubernetes does best match against `accessModes` and `storage` capacity, these are not use to enforce storage characteristics in backend, you can go over a space requested.

Also in the end of talk some questions regarding this are asked at [2].

[0] Kubernetes Storage 101; KubeCon EU 2016 https://www.youtube.com/watch?v=ZqTHe6Xj0Ek
[1] https://youtu.be/ZqTHe6Xj0Ek?t=819
[2] https://youtu.be/ZqTHe6Xj0Ek?t=2051
.
 @ngtuna @kadel thanks for reviews and great points!
.
 "
,,189,"Configure service types.
 Fix #154 
cc @surajssd @kadel 
.
 Thank you @procrypt  for staring on this.

I have few notes regarding this:
Wouldn't be better to have something like `kompose.service.type` with different values representing k8s service types, rather than having bunch of true/false options and worrying about conflicts between them?

Another question is if labels should use k8s terminology like (LoadBalancer,NodePort,ClusterIP) or something different that is more general. Any thought on this @sebgoa ?

Examples:
k8s terminology
- `kompose.service.type: loadbalancer`
- `kompose.service.type: nodeport`
- `kompose.service.type: clusterip`

generic:
- `kompose.service.type: public` - (or `kompose.service.type: external`)  maps to LoadBalancer
- `kompose.service.type: local` - maps to ClusterIP
- `kompose.service.type:  node` - maps to NodePort
.
 I'd rather stick to k8s terminology than create a kompose specific one.

if some providers don't use that terminology, the onus should be on them to make the mapping ;)
.
 @kadel I agree with @sebgoa we should use the k8 terminology.
I'm updating the PR @dustymabe I'm also adding a check for invalid value.
.
 @procrypt you will have to update the unit tests and also add new functional tests for this kinda behavior.
.
 @kadel I have updated the PR as per your suggestion please take a look at it.
.
 Code looks good :+1:
Thank you @procrypt 

One last thing. Can you please add tests and docs?
.
 @kadel I'll add the tests and docs :)
.
 @kadel Thanks :)
.
 "
,,188,"fix param order in readme.
 tried the latest stable (mac os x) and I had to use `kompose convert docker-compose.yml`
.
 thanks for reporting the issue. There is a `-f` missing in the readme that's for sure.

But the order is correct for HEAD.

I suspect you download the 0.1.0 release ?

We will put a 0.1.1 release up to avoid this. I will keep the PR open until we fix it. Hopefully today.

@ngtuna, can you upload a 0.1.1 release in github releases page.
.
 ah yeah I downloaded 0.1.0. Thanks for the fast response :)
.
 @sharpner 0.1.1 is made for you https://github.com/skippbox/kompose/releases/tag/v0.1.1
.
 perfect thx
.
 "
,,187,"come up with a release schedule.
 It would be nice if we can come up with a release schedule so that we can get new features out to users and also give them some baseline to report issues against. Could we possibly come up with a release strategy (time based/feature based, etc) for the project?
.
 yeah, linked to #70 

I will close it as dupe if you don't mind, but label #70 as P0
.
 Sure - that works. Thanks!
.
 "
,,186,"Create PVC object for docker-compose volumes.
 Instead of creating emptydir, create PersistentVolumeClaim for docker-compose volumes by default

Fixes #150
.
 it would be great to test this on minikube, to make sure we know that this is now supported.
.
 thanks for including tests and fixtures.

LGTM
.
 @sebgoa The fixture I have added can be directly fed to a running k8s cluster or OpenShift cluster provided you have PV already available. I tried it on minikube and a single node OpenShift cluster, and the mounts work.
.
 I created PV in minikube VM, using following artifact

``` yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: vol1
  labels:
    type: local
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: ""/home/docker/data""
```

Need to try the dynamic provisioning though!
.
 LGTM and tests are visible so this should be in 0.1.1 as well. Merging.
.
 @surajssd there was a test run failed on this PR. I'm looking on it
https://travis-ci.org/skippbox/kompose/builds/165631060
.
 Got it. 

``` console
kompose -f /home/travis/gopath/src/github.com/skippbox/kompose/script/test/fixtures/volume-mounts/simple-vol-mounts/docker-compose.yml convert --stdout --dc
```

That should include the new born `--provider` flag to figure out OpenShift. Fixed at https://github.com/skippbox/kompose/commit/2d09b9567ecece33ddf99a4450841df5da133bac
.
 "
,,185,"Documentation site.
 Hey all,

In preparation for Kubecon next month, I'd like to add a documentation site for people to browse for easier viewing.

An outside contributor helped me recently created this via `Sphinx` documentation generation https://cdrage.github.io/kubeshift/

Which can be configured to either manually be generated each-time you want to update the site, or updated on each push to master via travis-ci.

Would this be something that skippbox is interested in?

The documentation would be generated to a `gh-pages` branch within this repo. It would be available @ https://skippbox.github.io/kompose
.
 @cdrage sure we can do this.
.
 I have created the gh-pages branch
.
 @sebgoa Awesome! I'll work on it this week and get a PR up and running :)
.
 Closing this for now since this documentation could perhaps be pushed to the kubernetes.io site instead.
.
 "
,,184,"Update .dsb references to .dab.
 Updates the new file extension for distributed application bundles.
.
 thank you :+1: 
if you are in it, can you also rename dsb files in examples? :wink: 
.
 @kadel i already did in https://github.com/skippbox/kompose/pull/183 :) needs to just be merged
.
 ahh, sorry,  I missed that
.
 +1

merging.
.
 "
,,183,"Update README + Docker Compose Bundle references.
 This commit updates a few sentences in the README that I thought would
need improving.

Bundles now end with the .dab extension and are named ""Distributed
Application Bundles"" now. I've updated the README as well as the example
accordingly.
.
 That is awesome clean up @cdrage Thanks for it :+1: 
.
 LGTM :+1: . But I definitely shouldn't be the one reviewing anything written English :smiley: 
.
 That's also lgtm. You might want to take a look @sebgoa 
.
 @sebgoa updated it with your changes!
.
 "
,,182,"--provider global flag for kompose.
 Now a user can select a provider using global flag `--provider=openshift` to select openshift provider
or `--provider-kubernetes` to select kubernetes provider if nothing is provided kubernetes is the default provider.

Fixes #179
.
 Today on train to Berlin I've worked on same thing as part of work on `kompose up` for openshift. :-)

Because I wanted `--help` to show only options that are valid for given provider, I've done this slightly differently.

I've used `app.Before` to add Commands depending on specified provider.
You can see my wip in branch openshift-up in my fork https://github.com/skippbox/kompose/compare/master...kadel:openshift-up 

I don't know how much time I'm going to have this week to clean it up and finish. But If you want to have provider flag sooner, look at my branch and you can use it ;-)
.
 @kadel thanks for pointers, this helps with the missing point I had!
.
 @kadel addressed the issues you mentioned!

Now output looks like this:

for openshift

``` bash
$ kompose --provider=openshift convert -h
NAME:
   kompose convert - Convert Docker Compose file (e.g. docker-compose.yml) to Kubernetes objects

USAGE:
   kompose convert [command options] [arguments...]

OPTIONS:
   --out, -o                    Specify file name in order to save objects into [$OUTPUT_FILE]
   --replicas ""1""               Specify the number of replicas in the generated resource spec (default 1)
   --chart, -c                  Create a chart deployment
   --yaml, -y                   Generate resource file in yaml format
   --stdout                     Print converted objects to stdout
   --deploymentconfig, --dc     Generate a DeploymentConfig for OpenShift
```

for k8s

``` bash
$ kompose convert -h
NAME:
   kompose convert - Convert Docker Compose file (e.g. docker-compose.yml) to Kubernetes objects

USAGE:
   kompose convert [command options] [arguments...]

OPTIONS:
   --out, -o                            Specify file name in order to save objects into [$OUTPUT_FILE]
   --replicas ""1""                       Specify the number of replicas in the generated resource spec (default 1)
   --chart, -c                          Create a chart deployment
   --yaml, -y                           Generate resource file in yaml format
   --stdout                             Print converted objects to stdout
   --deployment, -d                     Generate a deployment resource file (default on)
   --daemonset, --ds                    Generate a daemonset resource file
   --replicationcontroller, --rc        Generate a replication controller resource file

```
.
 Changed it now to have new `cli.Command` altogether, so usage is changed, added new function that returns common flags.

``` bash
$ kompose --provider=openshift convert -h
NAME:
    - Convert Docker Compose file (e.g. docker-compose.yml) to OpenShift objects

USAGE:
    [command options] [arguments...]

OPTIONS:
   --deploymentconfig, --dc     Generate a OpenShift DeploymentConfig object
   --out, -o                    Specify file name in order to save objects into [$OUTPUT_FILE]
   --replicas ""1""               Specify the number of replicas in the generated resource spec (default 1)
   --yaml, -y                   Generate resource file in yaml format
   --stdout                     Print converted objects to stdout
```
.
 @kadel sure will wait for @sebgoa or @ngtuna to try it out once! Thanks for reviews and pointers!
.
 Great work @surajssd  :+1: I will try it today. Thanks
.
 Hey @surajssd, at first test I see `$ kompose --help` lists out `up` and `down` command only. Convert is missing.

``` console
$ kompose --help
...
COMMANDS:
    up      Deploy your Dockerized application to Kubernetes (default: creating Kubernetes deployment and service)
    down    Delete instantiated services/deployments from kubernetes
...
```
.
 Otherwise LGTM. I like the idea of changing usage between providers :100: 
.
 Then provider owners have their own space to arrange outputs.
.
 @ngtuna nice catch about convert not being visible. Made changes accordingly here https://github.com/skippbox/kompose/pull/182/files#diff-3145698b159fb0a026984b4a017a8b24R67 also added note here https://github.com/skippbox/kompose/pull/182/files#diff-d9814220427d68b7f7ade416b1440032R38
.
 And also it shows up under help

``` bash
$ kompose -h
NAME:
[SNIP]
   Skippbox Kompose Contributors <https://github.com/skippbox/kompose> 

COMMANDS:
    convert     Convert Docker Compose file (e.g. docker-compose.yml) to Kubernetes/OpenShift objects
    up          Deploy your Dockerized application to Kubernetes (default: creating Kubernetes deployment and service)
    down        Delete instantiated services/deployments from kubernetes

GLOBAL OPTIONS:
[SNIP]
```
.
 Thanks @surajssd . Merging now for the release tonight.
.
 Thanks @ngtuna !
.
 "
,,181,"go 1.5 not building.
 just to confirm, we are now using go 1.6, and 1.5 does not work anymore.

travis runs 1.6

we need to update the readme
.
 You should be able to compile Kompose with go 1.5

on go1.5 I can build with `cgo` disabled it like this:

```
CGO_ENABLED=0 GO15VENDOREXPERIMENT=1 go build -o kompose -tags experimental ./cli/main
```

I don't know why, but if I try to build it with `cgo` it fails on:

```
# github.com/skippbox/kompose/vendor/github.com/opencontainers/runc/libcontainer/system
cannot load DWARF output from $WORK/github.com/skippbox/kompose/vendor/github.com/opencontainers/runc/libcontainer/system/_obj//_cgo_.o: decoding dwarf section info at offset 0x4: unsupported version 0
```

With go1.7  I can build it in both cases (with and without `cgo`).
It looks like that for go1.5 `cgo` has to be disabled. I don't know why :-( Maybe I'm doing something wrong. I don't know much about go compiler :-(
Maybe  @janetkuo has idea? 
.
 So I made a direct update to README accordingly for both cases. https://github.com/skippbox/kompose/commit/9cb74ed0231aa31771394d355c936aa88a2f2ce8
.
 "
,,180,"Changed version tag to reflect the tip of the branch.
 .
 merging
.
 Thanks @ngtuna 
.
 "
,,179,"`--provider` flag for kompose.
 The way, ""what artifacts to generate?"" is not handled consistently.
Having a provider flag will enable the further implementation of pref file, so that the way artifacts generation is handled is unified.

`convert` ->  

``` bash
validate: --provider and individual flags(--ds, --rs) cannot be together

if --provider given
    if provider is openshift
        generate dc, imagestreams, svc, routes, pvc(if needed)
    else if provider is foo
        generate x, y, z
    else
        default to k8s
        generate deployments, svc, pvc(if needed)

else if individual flags are given generate those artifacts
    deployments, svc, daemonsets, replicasets, rc can be generated for both providers
    but imagestreams, routes can be created for openshift only


else if --provider is not given and individual flags are not given
    if pref file given read artifacts from there
    else
        default to k8s
        generate deployments, svc, pvc(if needed)
```

`up` ->

individual flags not supported

``` bash
if --provider given
    if provider is openshift
        generate dc, imagestreams, svc, routes, pvc(if needed)
    else if provider is foo
        generate x, y, z
    else
        default to k8s
        generate deployments, svc, pvc(if needed)
else if --provider is not given
    if pref file given read artifacts from there
    else
        default to k8s
        generate deployments, svc, pvc(if needed)
```

Closing this unblocks #39
.
 @ngtuna @kadel do we need this flag?
.
 @surajssd If we see the preference file is mandatory, then we can restrict provider declared in profile inside the file. Otherwise, somehow user wanna skip the file and go directly with `--provider` flag, but I will see there are might be other flags need to be declared along with. Of course support both cases makes kompose more flexible, but also reduce simplicity. I go with the first option. Let's wait for @kadel comment.
.
 @ngtuna we don't want to restrict user to have preference file, that's for sure.

Or we can use other approach as, create a pref file if its not there alongside docker-compose file, with default profile of k8s and artifacts/objects to generate will be `deployments` and `svc`.

Also for `up` it makes sense to have a `--provider` and if nothing is provided we anyways default to k8s.
.
 Yes we can generate the file by default. And probably support a subcommand `kompose config` in order to keep user away from editing manually (probably lead to wrong configuration). Like `kubectl config`
.
 > @ngtuna @kadel do we need this flag?

I think that we should have global provider flag, that defaults to kubernetes)
We have global flags for specifying inputs (--bundle --file) we should also have global flag for output/provider

Provider flag can be still specified with --rc --rs ... options, but list of valid controller object will depend on provider flag.

This is how i think it could look like:

`kompose up` -  defaults to Kubernetes Deployments

`kompose --provider openshift up` - defaults to OpenShift DeploymentConfig

`kompose  convert --rc` - Kubernetes ReplicationController

`kompose --provider openshift convert --dc` -  OpenShift DeploymentConfig (it is same as default, but in future we might add another controller objects even for OpenShift)

`kompose convert --dc`  - This is invalid option as Kubernetes doesn't have DeploymentConfigs
`kompose --provider openshift  convert --rc` - Even this is technical valid, we don't currently support that. So right now this should also throw error (but we might add it in future)

`kompose --provider openshift convert -h` - this will display all valid options and controller objects (right now just --dc) but only for OpenShift and same for kubernetes `kompose convert -h` or `kompose --provider kubernetes convert -h` (this will show that --rc --rs --d ...)

Default flag can be also specified in preference file, but using --provider flag can always overwrite what is in preference file.

> Yes we can generate the file by default. And probably support a subcommand kompose config in order to keep user away from editing manually (probably lead to wrong configuration). Like kubectl config

I don't think that we should require  config file, even if it is auto generated. Kompose should be able to run even without any config files. 
I like the idea to have `kompose config` to set configuration options so user doesn't have to edit the that file. (Lets do that later, when we figure out rest of the this)
.
 "
,,178,"Add .gitignore for Go files + compiled Kompose file.
 Adds .gitignore for common Go-related files as well as ignoring the
binary generate via go build and/or `make binary`.
.
 fair enough.

merging
.
 "
,,177,"Fixtures directory has README.md that are incomplete or inconsistent.
 The test scripts from fixtures has README.md which has info of how to run those examples with `docker-compose` we can add info of using it with `kompose`.
- https://github.com/skippbox/kompose/tree/master/script/test/fixtures/etherpad
- https://github.com/skippbox/kompose/tree/master/script/test/fixtures/gitlab
- https://github.com/skippbox/kompose/tree/master/script/test/fixtures/ngnix-node-redis

These fixtures directories have no README.md at all.
- https://github.com/skippbox/kompose/tree/master/script/test/fixtures/entrypoint-command
- https://github.com/skippbox/kompose/tree/master/script/test/fixtures/ports-with-proto
.
 Is it necessary for test fixtures to have README?
entrypoint-commmand and ports-with-proto are not even meaningful applications
.
 I just wanted to make sure that these apps work when deployed so that end-to-end still works when we do `kompose up` on them!
.
 @surajssd I hear you.._but_ some of these docker-compose files will most likely break at some point.  The ether pad one for example uses a mariad db container without an image tag...so latest might change underneath you at some point.
- image tags are not immutable anyway.

So technically we should actually verify that the docker-compose files actually give a working app...
.
 i don't think this is required/valid so closing it..
 "
,,176,"docker-compose :Z not supported in volume mounts.
 Trying to convert docker-compose.yml file, kompose cannot parse a volume format that looks like ""HOSTPATH:CONTAINERPATH:Z"".

> To change the label in the container context, you can add either of two suffixes :z or :Z to the volume mount. These suffixes tell Docker to relabel file objects on the shared volumes. The z option tells Docker that two containers share the volume content. As a result, Docker labels the content with a shared content label. Shared volume labels allow all containers to read/write content. The Z option tells Docker to label the content with a private unshared label. Only the current container can use a private volume.

Above info source: https://docs.docker.com/engine/reference/commandline/run/#/mount-volumes-from-container-volumes-from
- docker-compose.yml can be found here: https://pagure.io/webauthinfra/raw/master/f/docker-compose.yml
- repo link of above docker-compose.yml https://pagure.io/webauthinfra (you can git clone on https://pagure.io/webauthinfra)

When converting kompose gives warnings like:

``` bash
$ kompose convert --stdout -y
WARN[0000] Unsupported key build - ignoring             
WARN[0000] Unsupported key domainname - ignoring        
WARN[0000] Unsupported key hostname - ignoring          
WARN[0000] Unsupported key stop_signal - ignoring       
WARN[0000] [www] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./www-data:/data:Z
WARN[0000] Volume mount on the host ""/sys/fs/cgroup"" isn't supported - ignoring path on the host 
WARN[0000] [app] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./app-data:/data:Z 
WARN[0000] Failed to configure container volume: invalid volume format: ./client-data:/data:Z 
WARN[0000] Volume mount on the host ""/sys/fs/cgroup"" isn't supported - ignoring path on the host 
WARN[0000] [ipa] Service cannot be created because of missing port. 
WARN[0000] Failed to configure container volume: invalid volume format: ./ipa-data:/data:Z 
WARN[0000] Volume mount on the host ""/sys/fs/cgroup"" isn't supported - ignoring path on the host 
apiVersion: v1
items:
- apiVersion: v1
[SNIP]
```

so warnings that show `:Z` is not supported are 

``` bash
WARN[0000] Failed to configure container volume: invalid volume format: ./www-data:/data:Z
```

Found this issue from https://github.com/openshift/origin/issues/10925
.
 I'm considering if `:z` and `:Z` are common cases. What are corresponding options in k8s ?
.
 These somehow would need to get mapped into security context-y things: http://kubernetes.io/docs/user-guide/security-context/

As that seems quite complex, maybe a first step could be to ignore the option with a warning? 

In my specific case: I'm trying to use kompose to do a migration from docker-compose to kubernetes, and my first goal is to get things running inside minikube, which doesn't seem to provide SELinux things anyways. I used sed now to drop the ':z', and at least the error message is a lot nicer now:
~~~~
WARN[0000] Volume mount on the host "".........."" isn't supported - ignoring path on the host 
~~~~.
 Agree with @ankon here.
First step here should be just ignoring `:z` and `:Z` and do same what we do with regular volume mounts without selinux.


.
 "
,,175,"[EPIC] Use kubernetes/client-go.
 It should be possible to use  [kubernetes/client-go](https://github.com/kubernetes/client-go) instead of digging through whole k8s.io/kubernetes.

As a result we might get smaller dependencies and it could  solve whole problem of conflicting kubernetes/kubernetes vs. openshift/kubernetes see: https://github.com/skippbox/kompose/pull/157#issuecomment-249858757
.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 I marked the title as [EPIC] but lets keep this issue open. Would massively reduce the size of the binary..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 Hi, I am curious as to the progress here.  While debugging an [issue](https://github.com/kubernetes-sigs/aws-iam-authenticator/issues/137) with someone trying to use kompose on EKS getting prompted for username and password I found the version of client-go vendored here is out of date and does not include the new exec based authentication type.

Does it make sense to open a new issue for just for client-go vendor upgrade or include it as part of this EPIC?

.
 @mattlandis 

To be honest, we don't have much development time to implement client-go (it's a huge task that involves refactoring a ton of code / libraries). However, we are more than open to PR's. We will most likely re-visit `client-go` in the future. .
 "
,,174,"upgrade libcompose revision.
 We haven't upgraded it for a little bit long time. Due to #149 and #173 , we should consider to do that.
.
 I can take this. 
I will also upgrade k8s and openshift dependencies.
.
 Closed via #195 
.
 "
,,173,"go panic when converting hygieia docker-compose.
 the file can be found here:
https://raw.githubusercontent.com/capitalone/Hygieia/master/docker-compose.yml
.
 @raffaelespazzoli can you copy the error you are getting in this issue.
thanks
.
 @raffaelespazzoli : The panic comes from libcompose parsing function. 

``` console
$ kompose --file hygieia.yml convert 
WARN[0000] Unsupported key volume_driver - ignoring     
panic: runtime error: index out of range

goroutine 1 [running]:
panic(0x15b1de0, 0xc82000e170)
    /usr/local/go/src/runtime/panic.go:481 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml.toMap(0xc8203a6720, 0x3, 0x3, 0x1814c78, 0x1, 0x40)
    /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml/types_yaml.go:223 +0x187
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml.(*MaporEqualSlice).ToMap(0xc8201b92d0, 0xc8201b9180)
    /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml/types_yaml.go:126 +0x4b
github.com/skippbox/kompose/pkg/loader/compose.(*Compose).LoadFile(0x24e87f0, 0xc8204cb150, 0xb, 0x0)

```

@sebgoa I also tested on HEAD's libcompose, it worked fine. It's another sample motivating us to upgrade libcompose. Like this one: #149 
.
 @raffaelespazzoli you got it passed on master branch now.
.
 "
,,172,"support -o - to stdout.
 fix #169
.
 LGTM
.
 "
,,171,"remove executable perms from docs.
 .
 having docs that are executable throws off some red flags in some downstream package management tools, this PR moves them to not be executable. 
.
 my bad.

I will merge as soon as the travis runs finishes
.
 > my bad.

no need to apologize at all :) 

> I will merge as soon as the travis runs finishes

+1 
.
 "
,,170,"kompose --version - print out dev tag .
 right now if you run `kompose --version` it will print out:

```
$ ../kompose --version
kompose version 0.1.0 (fa46376)
```

which is a bit misleading because tag `0.1.0` does not correlate to `fa46376` but rather to `8227684`. Could we have kompose print out a 'dev' tag or something when on a commit that doesn't have an associated tag? 
.
 @cab105 that's an easy one for you to get back to work on kompose :)
.
 Opps.. I made a wrong ref.
.
 @ngtuna Did you already beat me to the punch?
.
 @cab105 Haha just a reference mistake. Good to see you @cab105 
.
 Likewise.  BTW, @sebgoa PR is out to you.  Looks like the version is expected to be updated by hand.
.
 Correct. Version is being updated by hand. Any idea we can have it updated automatically ?
.
 Not from what I can tell.  We can take a known tag and derive its hash, but not the other way around, at least using git rev-parse.  At least given how the kompose build scripts are being used.  Even then, this technique still won't work if you use go build natively.
.
 https://github.com/skippbox/kompose/pull/180 is merged so this can be closed!

Result on current master:

``` bash
$ kompose --version
kompose version dev (HEAD)
```
.
 This is now a problem again after the last release. Any ideas for making this dynamic? 
.
 "
,,169,"suggestion: let `-` denote stdout for -o option.
 specifying `-` to the `-o` option creates a file named `-`. Could we let this actually mean stdout like it does for so many other applications. I know there is a `--stdout` flag but I think some people will probably not read that far (as I didn't) and go with `-o -` instead. 

```
$ ../kompose -f docker-compose.yml convert -o -
$ ls -l
total 28
-rw-rw-r--. 1 vagrant vagrant 2832 Sep 25 15:56 -
-rw-rw-r--. 1 vagrant vagrant  538 Sep  6 21:42 docker-compose-bundle.dsb
-rw-rw-r--. 1 vagrant vagrant  132 Sep  6 21:42 docker-compose.yml
-rw-rw-r--. 1 vagrant vagrant 1729 Sep  6 21:42 docker-gitlab.yml
-rw-rw-r--. 1 vagrant vagrant  379 Sep  6 21:42 docker-guestbook.yml
-rw-rw-r--. 1 vagrant vagrant 1486 Sep 25 15:54 docker-voting-bundle.dsb
-rw-rw-r--. 1 vagrant vagrant  485 Sep 25 15:54 docker-voting.yml
$ ../kompose --version
kompose version 0.1.0 (fa46376)
```
.
 @dustymabe you got it.
.
 "
,,168,"Make --dab/--bundle global flag.
 closes #161 
.
 "
,,167,"Add tests converting dab files.
 there is no test in [test.sh](https://github.com/skippbox/kompose/blob/master/script/test/cmd/tests.sh) that converts dab file.
.
 cc/ @cab105 that's another easy one for you.

We need some fixtures and modifications to test.sh to run the conversion of docker bundles

```
kompose --bundle docker-compose.dab convert
```
.
 @sebgoa Sure, I'll take a look at it this weekend.
.
 Can we close this issue ?
.
 Not yet, I have another changeset that addresses this.  Will also need to open up another issue to account for the failed test.
.
 "
,,166,"Prepare up/down for other providers.
 Small refactoring of Up and Down code to make space for implementing up/down with other providers (OpenShift).
It moves some provider/transfomer specific functionality (like creating client) to appropriate transformer package. It makes app.go more generic at this will make adding providers little bit easier.

related to #40
.
 LGTM. I like the idea to makes up/down to be generic functions in transformer package. Thanks @kadel 
.
 Thanks @ngtuna.
I've also more code readability improvements in stash ;-) PRs will be soon ;-)
.
 LGTM nothing is broken on doing up!
.
 "
,,165,"time-out errors while deleting deployments on openshift.
 I see time-out errors while deleting deployments. This is with openshift. Could someone tell me why I am seeing these warning messages when the deployments seem to be successfully deleted. 

```
$ kompose --file docker-guestbook.yml down
INFO[0000] Successfully deleted service: frontend       
WARN[0060] Can't delete deployment: frontend due to 'timed out waiting for the condition' 
INFO[0060] Successfully deleted service: redis-master   
WARN[0120] Can't delete deployment: redis-master due to 'timed out waiting for the condition' 
INFO[0120] Successfully deleted service: redis-slave    
WARN[0180] Can't delete deployment: redis-slave due to 'timed out waiting for the condition'
```
.
 @surajssd @kadel could you check it with an Openshift environment?
.
 @ashetty1 
- What is the version of openshift you are using?
- How did you deploy this particular example on openshift?
.
 @ashetty1 So I did this, with my openshift cluster running:

``` bash
$ kompose --file docker-guestbook.yml up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

INFO[0000] Successfully created service: frontend       
INFO[0000] Successfully created service: redis-master   
INFO[0000] Successfully created service: redis-slave    
INFO[0000] Successfully created deployment: frontend    
INFO[0000] Successfully created deployment: redis-master 
INFO[0000] Successfully created deployment: redis-slave 

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods' for details.
```

And once it was successfully deployed I did this, which successfully deleted all the components:

``` bash
$ kompose --file docker-guestbook.yml down                                                                                                                                           
INFO[0000] Successfully deleted service: redis-slave    
INFO[0003] Successfully deleted deployment: redis-slave 
INFO[0003] Successfully deleted service: frontend       
INFO[0006] Successfully deleted deployment: frontend    
INFO[0006] Successfully deleted service: redis-master   
INFO[0009] Successfully deleted deployment: redis-master 
```

And the version of openshift I am using:

``` bash
$ oc version
oc v1.3.0
kubernetes v1.3.0+52492b4
features: Basic-Auth GSSAPI Kerberos SPNEGO

Server https://127.0.0.1:8443
openshift v1.3.0
kubernetes v1.3.0+52492b4
```

So basically what happened here is kompose did talk to kubernetes running underneath openshift directly, so everything we saw above is kubernetes, not openshift. I doubt if deployments are directly supported by openshift origin 1.2.
.
 @surajssd will try and update soon.
.
 Any update @ashetty1  ?
.
 @surajssd what you said made sense. We could close this bug now.
.
 "
,,164,"kompose up - Get namespace from kubeconfig.
 fixes #162 
.
 "
,,163,"Add health checks.
 Automatically generate readiness and liveliness probes!
.
 This would be nice. But user will have to provide additional information for kompose, there is no health check information in docker-compose :-(
.
 Any chance for kompose label ?
.
 > Any chance for kompose label ?

Yes, labels are probably only option here.
.
 We can use `docker-compose` construct `depends_on` along with labels to define health checks..
 We have [heathcheck](https://docs.docker.com/compose/compose-file/#/healthcheck) in docker compose v2.1, should I go ahead and pick this up?.
 @containscafeine Should be easily mapped, we have https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/ available for us which (mostly) maps 1-1 to what compose has..
 @containscafeine I think this is possible if `libcompose` have added support for it? Isn't it?.
 @cdrage @surajssd yep, if libcompose has support for this, this can be mapped directly. I didn't try this out yet..
 problem is that libcompose is not yet supporting 2.1.
 @kadel , @surajssd can you please add label `compose v2.1` here ?.
 @surajnarwade libcompose supports this?.
 https://docs.docker.com/compose/compose-file/compose-file-v2/#healthcheck.
 @kadel my question was more in respect of libcompose because it is the upstream for us and if they have added support for it then we can go forward with supporting this one as well.
 ah, I don't know if libcompose supports that. 

But we could add healthchecks for v3, we don't use libcompose for that.
.
 @kadel @surajssd libcompose don't support health checks.
 However, `docker/cli` supports it as well as using the `healthcheck` key in Version 3..
 @cdrage , are you working on this issue ?.
 @surajnarwade Yes.
 There is work on this at #759 .
 #759 has been merged! Closing..
 "
,,162,"kompose up always deploys to default namespace.
 I have created new namespase and set it as default namespace for `kubectl`.
When I do `kubectl create ...` it creates object in that namespace.

But when I do `kompose up` it still deploys to `default` namespace.
.
 :+1: Exactly that's not a bug but enhancement :-) Actually for kompose up I'm fixing the default namespace. Let me take this one by investigating the default namespace config from kubectl.
.
 I've started to investigating that, as this blocks me from implementing `kompose up` for openshift :-(
.
 Ah that's okay. So I make a handover to you.
.
 "
,,161,"Proposal: make --dab/--bundle global flag.
 Currently it is kind of strange to do `kompose up --dab app.dab`  but for docker-compose you do `kompose -f compose.yml up`

Wouldn't it make more sense to move  `--dab` flag to same level as `--file`?

It would look like this:

```
kompose --dab app.dab up
kompose --dab app.dab  convert
```
.
 Yes we can much easier doing that than #153 but I'm not sure if this is good strategy in term of UX for supporting more input formats in future. But yeah we can apply that at this moment. I'm +1 for that.
.
 "
,,160,"OpenShift - generate DeploymentConfig with ImageStream.
 fixes #145 

TODO:
- [x] update tests
.
 "
,,159,"Add port protocol handing for docker-compose..
 fixes #158 
.
 :+1: 
.
 "
,,158,"Support for ""9995:9995/tcp"".
 WARN[0000] Unsupported key expose - ignoring  
WARN[0000] Unsupported key hostname - ignoring  
FATA[0000] ""pinpoint-collector"" failed to load ports from compose file: invalid container port ""9995:9995/tcp"" 
.
 Than you for reporting this. 

It looks like there is a bug in how Kompose parses ports.
It is not expecting that it could be in 'host:container:proto"" format.
https://github.com/skippbox/kompose/blob/0c33e7e96517dd85fb96d8ab87fa42ec827bb6cb/pkg/loader/compose/compose.go#L59
.
 "
,,157,"Handle Headless Services when no ports are present.
 Addresses #146 
.
 When I tried that I got error:

```
time=""2016-09-19T13:47:10+02:00"" level=warning msg=""[redis] No ports defined, we will create a Headless service."" 
error validating ""STDIN"": error validating data: found invalid field portalIP for v1.ServiceSpec; if you choose to ignore these errors, turn validation off with --validate=false
```

When I removed `portalIP` from generated service everything worked fine.
.
 what compose file did you give it ?
.
 ```
version: ""2""

services:
    web:
      image: tuna/docker-counter23
      ports:
        - ""5000:5000""
      links:
        - redis
      networks:
        - default

    redis:
      image: redis:3.0
      networks: 
        - default

```
.
 I've done some digging around to figure out where PortalIP is coming from, because PortalIP is old deprecated name for ClusterIP.

Because of OpenShift we are using  Kubernetes  from [openshift/kubernetes](https://github.com/openshift/kubernetes).
Problem is that they added [this](https://github.com/openshift/kubernetes/blob/57fb9acc109285378ecd0af925c8160eb8ca19e6/pkg/api/v1/conversion.go#L618) for backward compatibility :-(
Result of this is that Services with PortalIP can be deployed to OpenShift but it fails on Kubernetes :-(

We need to figure the way  how to use upstream Kubernetes for Kubernetes conversion. But I don't have idea how to do it :-( OpenShift is not doing import rewrite so it includes k8s.io/kubernetes but expect this to be their fork of k8s from  [openshift/kubernetes](https://github.com/openshift/kubernetes) :-(
.
 I just tested this with newer openshift version and PortalIP is gone.
OpenShift and K8S upgrade is part of #200.  As soon as #200 get merged we can merge this.
.
 And #200 is merged!
.
 and we are stuck on my CLA, even though I can probably override this...
.
 I will rebase tomorrow anyway
.
 @sebgoa could you check the failed test-cases ? That would be great to introduce handless svc support at kubecon talk.
.
 @kadel @surajssd you want to have a look at this ? I fixed the headless stuff, it is rebased....
 ok tests fixed.
 I've rebased this and added headless services for OpenShift.

ping @sebgoa @ngtuna .
 
[![Coverage Status](https://coveralls.io/builds/9503620/badge)](https://coveralls.io/builds/9503620)

Coverage decreased (-0.7%) to 45.9% when pulling **425df633d049bb289417a9f433cb10fcc5fe797b on sebgoa:headless** into **b059c447745fa3f2318d89294ecb1d0dec0fedaa on kubernetes-incubator:master**.
.
 👍 @kadel Could you add an unit test for this ?.
 Of course.
 
[![Coverage Status](https://coveralls.io/builds/9532008/badge)](https://coveralls.io/builds/9532008)

Coverage decreased (-0.7%) to 45.9% when pulling **ff8d6567c1d29a01d0c324dbf16485e5183983c9 on sebgoa:headless** into **6e260bab0bcc604fc907da2f15522ee2cf5ffb21 on kubernetes-incubator:master**.
.
 "
,,156,"integration with minikube/minishift.
 It would be nice to somehow add some support for a ""local"" use case where a user doesn't yet have k8s running. We don't want the scope of Kompose to creep too much but it would be interesting to be able to integrate with some other tools to help bring up a cluster and actually bring up the app.

an example would be:

```
$ kompose up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

--> We see you don't have a kube environment configured in ~/.kube/config, but minikube is installed. 
--> Would you like us to bring up a local cluster? (y/n) y
--> Bringing up local k8s cluster using minikube.....
--> Cluster up

INFO[0000] Successfully created service: web            
INFO[0000] Successfully created service: redis          
INFO[0000] Successfully created deployment: web         
INFO[0000] Successfully created deployment: redis       

Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods' for details.
```
.
 I haven't checked if we have this already, but I'd rather have a warning that says ""no k8s cluster available, bring one up...""
.
 > We don't want the scope of Kompose to creep too much but it would be interesting to be able to integrate with some other tools to help bring up a cluster and actually bring up the app.

Could I say kmachine ?
.
 Sadly with minikube, kmachine is ""obsolete"". If we do this, minikube is the choice.
.
 @cab105 another for you :)

kompose reads the k8s config file and targets the default context. We need to check a few things:

1-what happens if there is no default context ? Maybe offer the use the choice of setting the context based on the ones in the config file.
2-What happens if the default context is actually not running/available ?
3-if there is a minikube context, then check if it is running, if not start it and use that.
.
 @sebgoa Have been meaning to spend more time with minikube.  Added to the list.
.
 @sebgoa What I'm thinking about implementing is a new provider on par with openshift that the user could call by default, and the provide the appropriate check with kubernetes, where if the default path fails, then fallback to Minikube if it's installed.
.
 yes, that's a good idea.
.
 Okay opted to go with the original approach of attempting to load via the default kubernetes context, and if that fails, then try to find minikube, prompt and use that to bring up the instance.  This way if the default context also happens to be minikube, and its not running, we'll still prompt before firing up minikube.

Now the next question is when we want to do `kompose down` and we happen to be in a minikube context, do we prompt to bring minikube down as well?
.
 This seems like an odd feature to add and in my opinion it detracts from the goals of the project. This is going to be a nightmare supporting various configuration options, and kompose shouldn't be a tool for bringing up clusters. Such tools are incredibly hard to maintain and don't relate to converting compose files to kubernetes objects.

I'd strongly recommend just writing documentation like the following instead:

> # Getting started
> 
> The easiest way to kick the tires on kompose is to use minikube to start a local Kubernetes instance, then using kompose to run you Docker compose files as kubernetes manifests.
> 
> ```
> minikube start
> // use kompose
> ```

I think that kind of documentation saves you a ton of time and effort trying to maintain such a feature, and let's kompose focus on doing one thing well.
.
 @ericchiang You do raise a good point, and this is something that could be better addressed via documentation.  @sebgoa would this approach work out better instead?
.
 This is a feature creep! Let people using kompose take care of bringing up a cluster, kompose should not do it..
 I agree that this should be solved by documentation. For example we could write some kind of tutorial - Kompose 101 that will cover using minikube with kompose..
 we are all in agreement then, it does look like kompose trying to do too much.
I am closing the issue and the pr. thanks @cab105 for proposing a solution though..
 "
,,155,"preference file implementation.
 now user can provider a prefernce file where s(he) can mention what controllers to generate and what provider to default to.
.
 using following docker-compose file

``` yaml
$ cat docker-compose.yml 
version: ""2""

services:
  mariadb:
    image: centos/mariadb
    ports:
      - ""$DB_PORT""
    environment:
      MYSQL_ROOT_PASSWORD: $ROOT_PASS
      MYSQL_DATABASE: $DB_NAME
      MYSQL_PASSWORD: $DB_PASS
      MYSQL_USER: $DB_USER

  etherpad:
    image: centos/etherpad
    ports:
      - ""80:9001""
    depends_on:
      - mariadb
    environment:
      DB_HOST: $DB_HOST
      DB_DBID: $DB_NAME
      DB_PASS: $DB_PASS
      DB_PORT: $DB_PORT
      DB_USER: $DB_USER
```

and following preference file, right now this is default name `kompose.yml`

``` yaml
$ cat kompose.yml 
profiles:
  default:
    provider: kubernetes
    objects:
      - deployment
      - replicationcontroller

  test:
    provider: openshift
    objects:
      - deploymentconfig

current-profile: test
```

here it read from the kompose file that provider is `openshift` and the controller to be created is `deploymentconfig`

``` bash
$ kompose convert 
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deploymentconfig.json"" created 
INFO[0000] file ""etherpad-imagestream.json"" created     
INFO[0000] file ""mariadb-deploymentconfig.json"" created 
INFO[0000] file ""mariadb-imagestream.json"" created      
```

now if i give provider as `kubernetes` from commandline then the pref file gets over-ridden

``` bash
$ kompose --provider kubernetes convert --rc --d
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-deployment.json"" created       
INFO[0000] file ""mariadb-replicationcontroller.json"" created 
INFO[0000] file ""etherpad-deployment.json"" created      
INFO[0000] file ""etherpad-replicationcontroller.json"" created 
```

now i change the `current-profile` in `kompose.yml` to `default`

pref file looks like this now

``` yaml
$ cat kompose.yml 
profiles:
  default:
    provider: kubernetes
    objects:
      - deployment
      - replicationcontroller

  test:
    provider: openshift
    objects:
      - deploymentconfig

current-profile: default
```

normal conversion where data is read from `kompose.yml`, it creates `deployment` and `replicationcontroller` since it is mentioned in file

``` bash
$ kompose convert
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deployment.json"" created      
INFO[0000] file ""etherpad-replicationcontroller.json"" created 
INFO[0000] file ""mariadb-deployment.json"" created       
INFO[0000] file ""mariadb-replicationcontroller.json"" created 
```

i can also provide from commandline what all things i would want more, like here i ask to create `daemonset` as well using flag `--ds`

``` bash
$ kompose convert --ds                                                                                                       
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deployment.json"" created      
INFO[0000] file ""etherpad-daemonset.json"" created       
INFO[0000] file ""etherpad-replicationcontroller.json"" created 
INFO[0000] file ""mariadb-deployment.json"" created       
INFO[0000] file ""mariadb-daemonset.json"" created        
INFO[0000] file ""mariadb-replicationcontroller.json"" created 
```

i can always override from commandline

``` bash
$ kompose --provider openshift convert
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deploymentconfig.json"" created 
INFO[0000] file ""etherpad-imagestream.json"" created     
INFO[0000] file ""mariadb-deploymentconfig.json"" created 
INFO[0000] file ""mariadb-imagestream.json"" created   
```
.
 I will add tests and fix existing ones once I get a review that I am doing the right thing!
.
 Yes that looks like the behavior we want.

Make sure it works even if the kompose.yml file is not there.

Then if we can read a local kompose.yml it takes precedence.
.
 if kompose.yml file not provided, defaults to kubernetes as before

``` bash
$ kompose convert
WARN[0000] Error Unmarshalling file - kompose.yml: open kompose.yml: no such file or directory 
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deployment.json"" created      
INFO[0000] file ""mariadb-deployment.json"" created       
```

provider if mentioned

``` bash
$ kompose --provider openshift convert                                                                                       
WARN[0000] Error Unmarshalling file - kompose.yml: open kompose.yml: no such file or directory 
WARN[0000] Unsupported key depends_on - ignoring        
INFO[0000] file ""etherpad-service.json"" created         
INFO[0000] file ""mariadb-service.json"" created          
INFO[0000] file ""etherpad-deploymentconfig.json"" created 
INFO[0000] file ""etherpad-imagestream.json"" created     
INFO[0000] file ""mariadb-deploymentconfig.json"" created 
INFO[0000] file ""mariadb-imagestream.json"" created      
```

so if there is any kind of error while reading kompose.yml, rather than exiting it continues with defaults further.
.
 > WARN[0000] Error Unmarshalling file - kompose.yml: open kompose.yml: no such file or directory 

This should probably check if the file exists and giving a friendlier warning message than this or even no warning at all (maybe info instead) because it is a perfectly normal use case to not have a preference file
.
 @dustymabe @pradeepto addressed your concerns, also added tests!
.
 I don't think that Kompose should display warning if user didn't specified `--pref-file`. (default kompose.yml is used)
On the other hand it should be error if user explicitly set `--perf-file` to non-existing file.
.
 @kadel the problem here is that i have `pref-file` with default name, so there is no clean way to know if user has explicitly provided a value of not.
.
 So one option would be to check if `GlobalString(""pref-file"") == DefaultPreferenceFile` then ignore warning. But this is not going to work if user sets `pref-file=kompose.yml` :-).

Or we can remove default value from flag definition and then you can check if user set it or not.
.
 > Or we can remove default value from flag definition and then you can check if user set it or not.

But then this makes it mandatory for user to provide file with flag!
.
 > But then this makes it mandatory for user to provide file with flag!

Does it? I don't think so. If you remove `Value: app.DefaultPreferenceFile` from `CommonFlags`
than `pref-file` will be empty when user don't provide flag.
.
 @kadel what i mean by that is I cannot implicitly read a pref-file, user has to provide a file name/path with help of flag. So if you want to use pref file, it becomes mandatory to provide a file path for it.
.
 I'm lost :-(

This is how i think it should behave:

user runs `kompose convert` and `kompose.yml` doesn't exist - no warning no error everything is fine

user runs `kompose convert` and `kompose.yml` exists - no warning no error everything is fine, and `kopmose.yml` is used

user runs `kompose --pref-file=mykompose.yml` and `mykompose.yml` exists - no warning no error everything is fine and `mykompose.yml` is used

user runs `kompose --pref-file=mykompose.yml` and `mykompose.yml` desn't exists - show error and fail.
.
 @kadel changes done, as per your comments!
.
 @sebgoa @ngtuna rebased please give it a try once and let me know what is missing :)
.
 Updated with unit-tests.
.
 closing in favour ot https://github.com/kubernetes-incubator/kompose/pull/366.
 "
,,154,"RFE: choosing Service type.
 When I'm using `kompose up` sometimes I need to change Service type.
Right now we generate services that are `ClusterIP`, but sometimes I want to have service exposed to outside of the cluster, than I have to manually change type and set it to `LoadBalancer`.

It would be nice to have a way to specify type of services.
### Proposal:

Use image label in docker-compose.yml to set type of services.
By default we would still create `ClusterIP` services, but when there is a specific label we would create `LoadBalancer`

example:

``` yaml
version: ""2""
services:
    backend:
        image: backend
        ports:
                - 3000:3000
    frontend:
        image: frontend
        ports:
                - 8080:8080
        environment:
                API_URL: http://backend:3000/api
        labels:
                kompose.service.public: True
```

we could use labels to specify Ingress/Route https://github.com/skippbox/kompose/issues/140
.
 > Use image label in docker-compose.yml to set type of services.

+1. I wonder if we should make the labels kompose specific though. This would probably be a good thing for @pradeepto to weigh in on. 
.
 Otherwise, we can add `--external` flag ? I am also +1 for the kompose specific label.
.
 I was also thinking about about doing this via cmd flag.
But downside of using flag is that you have to always remember to add that flag.

Benefit of doing it via label is that you do it only once. You edit file, commit it and than you can forget about it, and you have everything in one file.

Now when I'm thinking about it,  this could be also in preference file.
Than we can avoid modifying original docker-compose.yml file.

it can be just list of public service names
and for Ingress we can extend it to hostnames

``` yaml
expose:
   - foo.bar.example.com=frontend # this will create Ingress/Route
   - frontend # this will create just LoadBalancer service
```
.
 Or how about the user mentions in preference file something like this:

``` yaml
profiles:
  default:
    provider: kubernetes
    objects:
      - deployment
      - replicaset
      - ingress
current-context: default
```

And we can have rules defined internally like if ingress is given what will be the service type?
.
 Ingress can be used with both ClusterIP or LoadBalancer. 
.
 I hit the same issue today. Labels would work for my usecase. Namespacing them to kompose makes sense.

Note that labels should ideally be reverse DNS namespaced (see https://docs.docker.com/engine/userguide/labels-custom-metadata/), so (unless you also own a specific kompose domain) something like:

```
com.skippbox.kompose.{name of label}
```
.
 while loadbalancer services are needed in prod, let's not forget about the dev use case who may want to create a nodeport.
.
 Agreed, once we do this we should support all three Service types.
.
 I like the use of labels for this.
.
 OK, lets do this via labels.
Using labels to provide additional data for conversion will also solve my problem with #39 :-)

Now we just need to figure out proper namespace for kompose labels as @garethr mentioned ideally it should be reverse DNS
.
 @kadel Can I work on this issue if no one else is working on it.
.
 Can someone assign this issue to @procrypt ? 
.
 @procrypt I just sent you an invite, you need to accept so that we can assign you tickets.
.
 @sebgoa I have accepted the invite.
.
 Is not clear for me, can I create an Ingress yet? using `expose`?.
 @juanpastas what do you mean by Ingress ?

If you mean an ingress rule (assuming you have an ingress controller running), the answer is no.

Every Docker _service_ in the compose file gets exposed via a Kubernetes service. By default this service is of cluster IP type. If you want to automatically generate a nodeport or load balancer type service you can specify that using a label in your compose file..
 @juanpastas you can have ingress created automatically for you once we have PR https://github.com/kubernetes-incubator/kompose/pull/285 merged.
 thanks @surajssd.

Do you know how is it possible to:

- Create volumes with an specified size?
- Delete old replica sets when using `kubectl apply -f my.yml`, I read that I need to specify `deployment.spec.revisionHistoryLimit` [here](https://github.com/kubernetes/kubernetes/issues/23597), is this something kompose helps me with?.
 Hi @juanpastas, currently none of those are possible to change with kompose.

In future we might add something to allow specifying size of volumes.
If you want to change those you can use `kompose convert` and then edit files before deploying using `kubectl`.
 "
,,153,"--file for all kinds of input.
 Playing with Kompose, I see it would be great to use `--file` flag for all kinds of input format such as `bundle` or `compose` like this. We can implement a format detection prior to loading the file into corresponding package.

``` console
$ kompose --file docker-compose.yml convert
$ kompose --file docker-bundle.dsb convert
```
.
 that's an interesting idea, even though I am bit weary of too much magic to detect file format...
.
 temporarily close as `--file` and `--bundle` are now global flags.
.
 "
,,152,"`kompose up`  for OpenShift.
 .
 ah, sorry :-(
duplicate of https://github.com/skippbox/kompose/issues/40
.
 "
,,151,"compose2kube.
 Somehow thought that compose2kube was not evolving , but it has some commits/dev in the past few months. It would be good to sync up.

https://github.com/kelseyhightower/compose2kube/issues/42
.
 I am closing this, now that we are in the incubator. .
 "
,,150,"Persistent Volumes.
 We should start thinking about proper volume implementation.

Kompose should create PersistentVolumeClaims and use those for pod volumes, instead of using EmptyDir.

Real persistent volumes might also solve `volumes_from` problem (#131)
.
 Since it was decided that for docker-compose volumes we create k8s PVCs, I am taking this up, so that I can continue the pending work of: https://github.com/skippbox/kompose/issues/14 and https://github.com/skippbox/kompose/pull/131
.
 "
,,149,"Ignoring network definitions.
 Currently we ignore networks definition in services , but looks like we don't properly parse and ignore global networks definitions.

```
version: '2'

services:
...
networks:
  foobar:
  barfoo:
```

kompose seems to fail if these networks are defined. We need to successfully parse but give a warning.
.
 I think it's not really an issue as the networks definition above seems not to be enough, then libcompose's parsing giving a panic.

I'm maybe wrong but it seems compose v2 requires at least one of these configs in network top-level definition: `driver`, `driver_opts`, `ipam` or `external`

If I try this below compose, it works:

``` console
$ cat networks.yml
version: ""2""

services:
  redis:
    image: redis
    command: redis-server
    ports:
      - ""6379""
    volumes:
      - /opt/redis:/redis
    networks:
      - foo

networks:
  foo:
    external: true

$ kompose --file networks.yml convert --out abc.txt 
WARN[0000] Unsupported network configuration of compose v2 - ignoring 
WARN[0000] Unsupported key networks - ignoring          
WARN[0000] Volume mount on the host ""/opt/redis"" isn't supported - ignoring path on the host
```
.
 > I'm maybe wrong but it seems compose v2 requires at least one of these configs in network top-level definition: driver, driver_opts, ipam or external

I'm not sure about that, I'm usually writing compose v2 files where only top-level definition is version and services.
.
 > I'm not sure about that, I'm usually writing compose v2 files where only top-level definition is version and services.

To be exact, it's a libcompose bug. If I only declare networks name without any parameter like below, docker-compose still works but libcompose doesn't.

``` console
version: ""2""

services:
  redis:
    image: redis
    command: redis-server
    ports:
      - ""6379""
    volumes:
      - /opt/redis:/redis
    networks:
      - foo

networks:
  foo:
```
.
 @ngtuna exactly. so do we need to add external:true for it to work.

We should file a bug upstream with lib compose.
.
 Double checked. Libcompose solved it at HEAD. We should somehow update libcompose ref.
.
 "
,,148,"[WIP] Add Socks Shop example.
 This is in progress.

Socks Shop is an example microservices applications that weave works uses to demo their products.
It is a fairly complete docker-compose file.

We should make sure kompose can convert it, it is a good example.
.
 Right now I get this error:

```
$ ./kompose convert -f ./examples/docker-sockshop.yml
WARN[0000] Unsupported network configuration of compose v2 - ignoring 
WARN[0000] Unsupported key networks - ignoring          
WARN[0000] Unsupported key dns - ignoring               
WARN[0000] Unsupported key dns_search - ignoring        
WARN[0000] Unsupported key hostname - ignoring          
panic: runtime error: index out of range

goroutine 1 [running]:
panic(0x1205580, 0x8223ca050)
    /usr/local/go/src/runtime/panic.go:464 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml.toMap(0x82286be30, 0x1, 0x1, 0x1481a70, 0x1, 0x40)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml/types_yaml.go:223 +0x187
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml.(*MaporEqualSlice).ToMap(0x822428150, 0x822428000)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/yaml/types_yaml.go:126 +0x4b
github.com/skippbox/kompose/pkg/loader/compose.(*Compose).LoadFile(0x1f9fc78, 0x82262f3e0, 0x1e, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/pkg/loader/compose/compose.go:155 +0x91d
github.com/skippbox/kompose/cli/app.Convert(0x822567cc0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/app/app.go:146 +0x4e8
github.com/skippbox/kompose/cli/command.ConvertCommand.func1(0x822567cc0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/command/command.go:32 +0x21
github.com/skippbox/kompose/vendor/github.com/urfave/cli.Command.Run(0x1486fc0, 0x7, 0x0, 0x0, 0x0, 0x0, 0x0, 0x82252a9b0, 0x4b, 0x0, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/command.go:179 +0x1399
github.com/skippbox/kompose/vendor/github.com/urfave/cli.(*App).Run(0x8225326e0, 0x8223c0400, 0x4, 0x4, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/app.go:196 +0x137c
main.main()
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/main/main.go:47 +0x337
```
.
 I did some debugging around this error and found out that this is caused by environment:

``` yaml
    environment:
      - reschedule:on-node-failure
```

there is missing space after `:`.
It should look like this:

``` yaml
    environment:
      - reschedule: on-node-failure
```

I don't think that this is bug in Kompose. If there is no space after colon it is parsed as one single string, `environment` is expected to be map.

We should add some kind of validation and tell users what is wrong in some nicer way. 
Kompose shouldn't throw ugly errors like this one.

Just for reference:
Discussion around validating docker-compose file is already happening in https://github.com/skippbox/kompose/issues/92
.
 thanks. We do need to check it this works OOTB with docker-compose.
.
 hmm that is strange, for me it fails with docker-compose

```
▶ docker-compose -v
docker-compose version 1.8.0, build f3628c7
```

```
▶ docker-compose -f  docker-sockshop.yml up
WARNING: The MYSQL_ROOT_PASSWORD variable is not set. Defaulting to a blank string.
ERROR: The Compose file './docker-sockshop.yml' is invalid because:
services.user.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.catalogue-db.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.cart.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.cart-db.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.catalogue.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.edge-router.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.front-end.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.orders.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.orders-db.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.payment.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.queue-master.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.rabbitmq.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.shipping.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
services.user-db.environment contains {""reschedule"": ""on-node-failure""}, which is an invalid type, it should be a string
```
.
 Oh noooo, sorry. My bad.
It really works :-) I had a modified file with space. And that fails with docker-compose.
You are right your original file works with docker-compose.
.
 In that case, something is wrong  in Kompose
.
 here is the source https://github.com/microservices-demo/microservices-demo
.
 ok so if we switch to:

```
    environment:
      - reschedule=on-node-failure
```

Then it works just fine (no need for space).

The faulty code seems to be in:
https://github.com/skippbox/kompose/blob/6cbdec444b06d9c0905b7c6fcc03b7b849b15a29/vendor/github.com/docker/libcompose/yaml/types_yaml.go#L124
.
 I think this is actually a docker-compose problem.
Docker-compose parses the yaml without errors and starts the containers but the environment variable does not get set.

for example if we look at this service:

```
  user:
    image: weaveworksdemos/user
    hostname: user
    dns: 172.17.0.1
    dns_search: weave.local
    restart: always
    environment:
      - MONGO_HOST=user-db:27017
      - reschedule:on-node-failure
```

the set environment looks like

```
$ docker exec -ti c74c4846b571 env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=user
MONGO_HOST=user-db:27017
no_proxy=*.local,169.254/16
HATEAOS=user
USER_DATABASE=mongodb
HOME=/root
```

So the `reschedule` env is not set. If we use equal sign it gets set.
.
 docker-compose in 1.8 version is still in Python and doesn't use libcompose.
This might be reason why it gets silently ignored there and Kompose panics.

I'm confused from all this. If this supposed to set `reschedule` env it should be like this:

```
environment:
  reschedule: on-node-failure
```

(environment as dict so no `-`)

```
environment:
  - reschedule=on-node-failure
```

(environment as array)

 I think that `reschedule:on-node-failure` is wrong and source of this is swarm [documentation](https://docs.docker.com/swarm/scheduler/rescheduling/#/rescheduling-policies).
They say: ""You can do this with the `reschedule` environment variable ""
and later on again: ""To set the on-node-failure policy with a reschedule environment variable:

```
$ docker run -d -e reschedule:on-node-failure redis
```

""
But his command doesn't set reschedule env variable.

```
▶ docker run -it -e reschedule:on-node-failure  busybox env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=a1ce60e6b16d
TERM=xterm
HOME=/root
```

There should be `=` instead of `:`
.
 agreed. and I filed a bug with the microservices demo guys to let them know...I don't think they tested this.
.
 Investigating the compose file, I found that currently we can't make the sock shop app running on kubernetes via kompose. The reason is that there are some services have not been created due to lack of ports configuration in the compose file, so ""micro-services"" can not find each other. Running the app with `docker-compose` would be very handy but `kompose` at this moment can not detect opened ports in images metadata until we resolve https://github.com/skippbox/kompose/issues/146
.
 @sebgoa Should we close this PR?.
 Hey @sebgoa I'm just going to close this PR for now :).
 "
,,147,"RFE can we get Kompose to have a --redeploy option.
 I would expect a --redeploy option that allows me to redeploy the entire app into openshift, without needing to instantiate a new project and do migrations ( as a way to keep the dev write code -> dev deploy code cycle going ).
.
 Its also worth walking through what the 'Kompose up' workflow and implementation might look like when compared with the specific demand to 'Kompose --redeploy'; In my view 'up' might be a superset of the functionality provided by 'redeploy'.

One key differentiator would be that the 'up' workflow should destory the existing app/project space and regenerate from scratch/scaffolding - whereas the 'redeploy' should only consider the service/container level metadata and initiate a refresh for those when things have changed. 

as an example: a ""Kompose redeploy --force-rebuild"" might be functionally similar to 'Kompose up"" where the --force option will rebuild the entire service, and all containers/pods inside it - regardless of change or not.
.
 > One key differentiator would be that the 'up' workflow should destory the existing app/project space and regenerate from scratch/scaffolding - whereas the 'redeploy' should only consider the service/container level metadata and initiate a refresh for those when things have changed.

Is it necessary that we delete all the resources and bring them back up again using **kompose**, because openshift and kubernetes clients support a directive called as apply (as @kadel mentioned yesterday)

``` bash
$ kubectl apply -h
Apply a configuration to a resource by filename or stdin.
The resource will be created if it doesn't exist yet. 
To use 'apply', always create the resource initially with either 'apply' or 'create --save-config'.

JSON and YAML formats are accepted.

Usage:
  kubectl apply -f FILENAME [flags]

Examples:
# Apply the configuration in pod.json to a pod.
kubectl apply -f ./pod.json

# Apply the JSON passed into stdin to a pod.
cat pod.json | kubectl apply -f -
```

Why this won't be a fix to redeploy problem, kompose can make calls to similar APIs here to re-deploy updated artifacts?
.
 @surajssd there are 2 different goals there : the 'up' directive -should- do a fresh app deployment where as the 'redeploy' should refresh changed content into the existing app and service  deployment.

there is an assumption here that the openshift interface is slightly abstracted away from the user, and have Kompose complete that piece rather than just be a connector in the process.
.
 > @surajssd there are 2 different goals there : the 'up' directive -should- do a fresh app deployment where as the 'redeploy' should refresh changed content into the existing app and service deployment.

I think that is what he was trying to say that `apply` should give us that: 

```
The resource will be created if it doesn't exist yet. 
To use 'apply', always create the resource initially with either 'apply' or 'create --save-config'.
```
.
 taking a clue from docker-compose:

-up -> builds and creates containers.
-down -> stops, removes containers _and_ images
-rm -> removes stopped containers (does not delete images)

So the gotchas that one falls into, is to docker-compose stop a service and then up it. Since the container is created it will just restart it and not trigger new builds or use new image...

For use we have:
- up -> kubectl create
- down -> kubectl delete

I think we can add a `kompose apply` which would do a `kubectl apply`, the redeploy mentioned by KB.

we need to think carefully about the workflow if new builds are made, and could make use of the ImagePullPolicy.
.
 Agreed,  we should start with adding  `kompose apply`.

If we want `kompose apply` for redeploy it should set `imagePullPolicy` to `Always`.
Otherwise its default value depends on how image is specified. (if image tag tag is latest - defaults to Always.  Otherwise defaults to IfNotPresent.). 
.
 I'm not sure if it's out of scope of this discussion but it recalled me a great feature of kubectl that I've used frequently. Whenever I would like to change something in k8s svc, I would prefer to edit directly by `kubetctl edit` then save, kubectl takes care of updating/applying immediately.
.
 @ngtuna agree; thats how i am using it in as well, but the edit/save workflow is hard to automate against. Specially in areas where the deployed endpoint would be abstracted away from the developer / coder
.
 ### Goal 

To introduce a top level command which will patch/update the already deployed resources with the newer updated configuration

### Issue

If the docker compose file is updated after the application is deployed using `kompose up`, the only way to deploy the updated artifacts using `kompose` is to either undeploy - deploy the application again using kompose up, or create another namespace for the new project and delete the older one. This breaks the development workflow.

It would be nice to have a `kompose apply/redeploy/patch` command which takes the updated configuration and patches the already deployed one.

This new command should -
- convert the docker compose file to the provider artifacts
- be able to check if the newer artifacts are different from the already deployed application
- patch the deployed application based on the decision made

### Proposed solution

- The `kubectl apply` way
`kubectl apply` checks all the above boxes and performs a strategic merge PATCH operation, however there is no endpoint for Apply like List, Get, Delete, Create, etc.
e.g. check out the fields in [`type DeploymentInterface interface`](https://github.com/openshift/origin/blob/v1.4.0-rc1/vendor/k8s.io/kubernetes/pkg/client/unversioned/deployment.go#L31-L40)

So, in order to implement this we either need to replicate or use the [`RunApply`](https://github.com/openshift/origin/blob/v1.4.0-rc1/vendor/k8s.io/kubernetes/pkg/kubectl/cmd/apply.go#L106) function from kubectl's cmd package.

This will not be very straightforward.

- The `kubectl update/replace way`
`kubectl replace` (`kubectl update` is now deprecated) replaces the resources instead of patching them with newer configuration. This is a PUT operation, not a PATCH operation.

This does have an [Update](https://github.com/openshift/origin/blob/v1.4.0-rc1/vendor/k8s.io/kubernetes/pkg/client/unversioned/deployment.go#L31-L40) endpoint for all resources and will be easier to implement, however this will also mean that the resources go down and come back up again (very quickly though), but it might interfere with availability of the application more than apply.

What should be the best way forward with this?
`apply` or `replace`? Or something else I might not have thought about till now?

Thoughts?
CC: @kadel @surajssd .
 There is also another option. Don't do it at all. Let users do it manually like using something like this `kompose convert --stdout | kubectl apply -f -`

But if we do it I would go with something simple like `replace`. It is not Kompose job to cover whole workflow..
 @kadel even `replace` will mean that changes made might be discarded, or connection to the current endpoints might be disrupted, since the resources are being created again.

That is why Kubernetes refuses to do a replace because `spec.ClusterIP` is set as an immutable field as it might cause issues to be unset and set again, unless we pass a `--force` with it. Not sure if `replace` is the best way forward.

However, +1 for maybe not doing this at all, since this just means re-implementing the behavior already done in kubectl client which is a superior tools wrt features.

`kompose convert --stdout | kubectl apply -f -` LGTM.

@kbsingh thoughts about this? Does piping to `oc apply` work for you?.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 There hasn't been much discussion on this as well as the fact that users can manually do: `kompose convert --stdout | kubectl apply -f -`

If there is interest in the future, we could add the `kompose replace` command as the equivalent of `kubectl apply`

Kompose isn't designed to replace the entire workflow, but rather, get a beginner started with Kubernetes..
 How does one do imagePullPolicy?.
 @posix4e AFAIK, you cannot do imagePullPolicy with Kompose. You can either create patch the generate artifacts using `kubectl patch` or define your application using a similar concise application definition format, like [Kedge](http://kedgeproject.org).
 "
,,146,"Detecting exposed ports in images.
 One of the issues I'm constantly facing when using Kompose with various docker-compose files is that they don't always specify `port`. With docker-compose this is not an issue but, for Kompose it is as we need to create service for every exposed port.

We should investigate if it is possible to get exposed ports from image metadata without downloading image itself. Or maybe if there is some other solution for this.
.
 So I looked into this a bit.

Lost of images do not have an exposed port, as you can reach a containerized service on any port even it is not 'EXPOSED'.

So even if we could introspect an image from a repo to figure out the EXPOSE, it may not even have one.

Case in point, the carts image form the sock shop example:

https://github.com/microservices-demo/carts/blob/master/Dockerfile

So I think we gonna have to create services with empty ports :( that will need to be edited by hand.
.
 yeah that's a problem, as we need a port to create a service. Not sure how to solve this.

We can create a basic service set port to ""1"" but it won't work.
.
 You are right. I forgot that when they are on the same network it doesn't mater what is in EXPOSE. :-(.

There is one solution that would probably work, but it is really ugly. We can generate Service with  all 65536 ports :laughing: 
.
 > There is one solution that would probably work, but it is really ugly. We can generate Service with all 65536 ports :laughing:

yeah. that could be our last resort. we could do this by default and then warn the user about this and tell them to either add port definition to docker compose file or edit the generated artifacts to put in the correct port. 
.
 that's pretty much impossible. afaik there is no wildcard for service ports in services. So that would mean creating 65k entries in the port definition of the service (so ugly). Plus pretty sure the proxy would run out of file descriptors somewhere, since it needs to listen on those ports...
.
 You can create a headless service (clusterIP: ""None"") and you should not be required to define ports.
.
 but DNS won't work ?
.
 DNS works for headless services.
.
 try this with a headless service:

```
apiVersion: v1
kind: Service
metadata:
  labels:
    app: sockshop
  name: front-end
spec:
  clusterIP: None
  ports: null
  selector:
    service: front-end
```

But the endpoint does not seem to get set with the Pod IP matching the selector. Hence no DNS.
I will keep looking into it.
.
 I have made a fix for this in https://github.com/skippbox/kompose/pull/148/commits/96493a5527bfc6b43e90e76feb39e2efb6f9333b

We need to use a ""dummy"" port in the headless service creation, otherwise the endpoint does not get populated and DNS entries do not get created.
.
 @runseb how about having a separate PR for this particular thing, rather than having it embedded in the ""Socks Shop example""?
.
 @surajssd ok, I broke things up. #157 addresses the headless service alone.
.
 @sebgoa thanks :+1: 
.
 @kadel https://github.com/kubernetes-incubator/kompose/pull/157 has been merged, would this be closed?.
 @cdrage yes this can be closed..
 "
,,145,"Generate ImageStream for every image in DeploymentConfig.
 We should generate ImageStream for every image that is used in DeploymentConfig, and use that ImageStream in DC. 
.
 @kadel do what is the approach you are following for doing this?
.
 it is better practice to use ImageStreams in Openshift. If you are using remote registries with DC you are missing some features, for example automatically triggering new deployments when image changes for this you need ImageStream
.
 "
,,144,"Investigate how to use HCL/Nomad as input object.
 In Nomad you define a containerized apps as a Job  in HCL:

https://www.nomadproject.io/docs/jobspec/index.html

we technically could convert from HCL jobs into deployments/services.
.
 I would like to take this one.
.
 If you're going to branch out from Compose format, you may want to join forces with https://github.com/micahhausler/container-transform.
 Honestly, considering that this tool is now in the Kubernetes org as well as been clearly defined with Kubernetes / OpenShift usage, I say that we close this issue for now. When the need arises (Nomad hasn't reached *that* large of user acquisition yet) we could possibly split this into a different tool / add new features..
 "
,,143,"Update README.md.
 fixed link
.
 thanks for that
.
 "
,,142,"Use libcompose project.Context{} instead of docker.Context{}.
 Fix #134
.
 Rebased
.
 Can someone check this tiny but helpful change? @kadel @runseb 
.
 I didn't  checked what are  differences between `project.Context` and `docker.Context`.
But if it compiles and works why not ;-)
LGTM
.
 @kadel Yeah, In #134 Weitenghuang explained the difference.

```
We don't need to use libcompose's docker pkg context, if kompose is not meant to build a docker client.
```

`project.Context` is just enough for kompose I believe.
.
 "
,,141,"update user guide: add `kompose up`, `kompose down`.
 small changes to user guide:
- kompose up, kompose down
.
 +1
.
 "
,,140,"Creating Routes for Services .
 OpenShift can expose Services using Routes.

It would be nice if Kompose created default Routes for some services.

User can specify for which services Route should be created for example like this:

```
kompose convert --expose-service=<service name>
```

cc: @kbsingh
.
 @kadel sounds good. Only issue will be how to handle this for multiple providers.

i.e for vanilla Kubernetes what will the behavior of this expose-service option ?

If we implement a --provider we could start adding provider specific options...
.
 k8s version of Route would be Ingress object
.
 I still like the idea of using labels to express some of this behavior rather than adding a ton of CLI options. 
.
 This could be solved in similar way as https://github.com/skippbox/kompose/issues/154

We decided that we are going to use labels to provide additional information for conversion.

label for this could look something like this `<kompose_namespace>.service.expose: foo.bar.example.com`
value can be also  empty and it would mean that dns name should be constructed automatically by OpenShift.

For Kubernetes same thing should be done, but it will create Ingress object instead of Route.
.
 sounds good, and would resolve this issue for me.
.
 I believe @containscafeine has volunteered to work on this in the next few weeks. can you assign him on this ? 
.
 @containscafeine any progress on this? 
.
 @dustymabe I've been trying to implement the route API from `openshift/origin/pkg/route/api` but hitting some issues. I will be away for some time, so I'm updating @surajssd about my progress just in case.
.
 @containscafeine @surajssd If you hit any bumps just ping me I'm happy to help.
.
 "
,,139,"make --file as global flag.
 Fix https://github.com/skippbox/kompose/issues/138

/cc @runseb 
.
 Looks like `-f` now needs to come right after `kompose` and before subcommands? We need to update all related docs as well (since we used `kompose convert -f` in our docs)
.
 @janetkuo Right. Will add a follow up commit.
.
 LGTM let's wait for @janetkuo to reply
.
 @ngtuna can you please rebase this to current master?
There are two new tests as part of https://github.com/skippbox/kompose/pull/127, they have to be updated also.
.
 @kadel Done
.
 thank you. lgtm
.
 So I'm gonna merge it now.
.
 "
,,138,"[PROPOSAL] Use -f as a global flag.
 While testing kompose with the guestbook app (now in the examples folder). I realized that docker-compose uses the -f as a global flag and we use it as an optional flag of the subcommand.

I think we should try to mimic docker-compose as much as we can. To that extent, could we use the  -f as a global flag so that we can do this:

```
kompose -f ./examples/docker-guestbook.yml up
```

Instead of the current behavior

```
kompose up -f ./examples/docker-guestbook.yml
```
.
 That would be very easy to do
.
 "
,,137,"update README with guestbook sample app.
 Add guestbook sample to README. 
/cc @runseb 
.
 I would move this to docs/user-guide.md

we should keep the main README relatively clean for the proposal review to join the incubator.
.
 Ah... OK so I should close this one and make a new PR adding guestbook to user-guide.md and also including a simple guideline for `kompose down`
.
 "
,,136,"improve messages of kompose up.
 Just some small improvements of the stdout messages of `kompose up`
.
 "
,,135,"New guestbook example.
 this adds the guestbook example.

It is really sweet, it works with docker-compose (v2) on a Docker for Mac, and straight up with `kompose up` on minikube.
.
 Great. Merge it.
.
 @runseb hi, just wonder how to expose the port 80 in minikube outside the vm. The kompose generates ""loadBalancer ""service load only while minikube can only expose port via NodePort. 
.
 @pydevops kompose should generate a cluster IP service. To access the app running in minikube you need to use 'kubectl proxy' or edit the service manually to become a nodePort ....or run the ingress controller in minikube and create an ingress.

check this blog:
http://www.skippbox.com/using-your-docker-compose-files-with-kubernetes/
.
 "
,,134,"Should we use libcompose project.Context{} instead of docker.Context{}?.
 I may miss something, but I don't understand why we will need to use `&docker.Context{}` when we load compose file in [loader pkg](https://github.com/skippbox/kompose/blob/master/pkg/loader/compose/compose.go#L95)
Isn't [`project.Context{}`](https://github.com/docker/libcompose/blob/master/project/context.go#L21) sufficient? The difference are:

``` go
    ClientFactory client.Factory
    ConfigDir     string
    ConfigFile    *configfile.ConfigFile
    AuthLookup    auth.Lookup
```
.
 I think we had discussion on similar lines at https://github.com/skippbox/kompose/pull/67#issuecomment-235262742 and https://github.com/skippbox/kompose/pull/67#issuecomment-235654824 please correct me if I got you all wrong?
.
 I propose we use `project.Context` for the same reason you referred in [#67 (comment)](https://github.com/skippbox/kompose/pull/67#issuecomment-235654824). We don't need to use libcompose's `docker` pkg context, if kompose is not meant to build a docker client.
Both support EnvironmentLookup. 
Furthermore, I will help to resolve libcompose [#372](https://github.com/docker/libcompose/issues/372), so we don't need to copy the code here as well.
.
 +1 @weitenghuang. I made a PR for that. Once your PR solving https://github.com/docker/libcompose/issues/372 get in, we can remove the copied code.
.
 "
,,133,"Validate/test artifacts generated by Kompose.
 I think that we need to work on a set of scripts which could be extended by the users of kompose to validate their converted applications against real providers (kubernetes, openshift). This will help the developers to deploy their converted applications with confidence.
### Proposed features
- **Easy to write**: with a strong base test suite, it should be easy for people to write test cases for their apps
- **High level assertions**: assert pods, services, endpoints, expected response, etc.
- **CI**: continuous integration on community platforms like CentOS CI

I have done some related work for [Atomic App](https://github.com/projectatomic/atomicapp) here: https://github.com/projectatomic/atomicapp/pull/655, which allows writing test cases for individual apps very easy, in a few lines: https://github.com/rtnpro/atomicapp/blob/2e6e72c221856abbca34f7779af70de5f490de25/tests/system/test_openshift_provider.py

Thanks to a comprehensive base test suite to allow for high level assertions: https://github.com/rtnpro/atomicapp/blob/2e6e72c221856abbca34f7779af70de5f490de25/tests/system/base.py#L425

I hope to be able to translate my experience in implementing something similar for **kompose** to help the developers using **kompose** to ship their converted apps with confidence.
.
 wouldn't `kubectl create --validate` be enough for this ?
.
 @runseb i guess it(kubectl create --validate) will validate the artifacts to be according to kubernetes' spec, but does not ensure that app will run and respond?
.
 Yes, the issue name: `Validating for artifacts generated by kompose` is a bit misleading. It's one part of my proposition and if `kubectl create --validate` does that, well and good. However, that does not replace the need for a functional test suite to help developers test their applications end to end. There could be bugs in the apps, container images,  compose spec files, which could lead to the application not running as expected on the target platform.

This is why, I think, that we should provide the developer with tools to test their applications end to end, which, in turn, could be run on a CI platform.
.
 but how can you ensure that app runs properly. k8s clusters may have many different setup (typical difference is DNS not installed). One app could run in one cluster but fail in another.

people may also use kompose, but start from a failing docker-compose.

There is a lot happening in that space with helm and charts. Charts (apps package), are being linted and are going through CI. I think it would make sense to expand the chart conversion to be inline with the helm packaging.
.
 On Wed, Aug 31, 2016 at 3:12 PM, runseb notifications@github.com wrote:

> but how can you ensure that app runs properly. k8s clusters may have many
> different setup (typical difference is DNS not installed). One app could run
> in one cluster but fail in another.
> True!
> 
> people may also use kompose, but start from a failing docker-compose.
> 
> There is a lot happening in that space with helm and charts. Charts (apps
> package), are being linted and are going through CI.
> :+1:
> 
> I think it would make
> sense to expand the chart conversion to be inline with the helm packaging.
> Yeah! It makes sense.
.
 I did look at your code in atomic app, I see what you are doing now.

As far as I know you are not really doing functional testing of the app itself in the sense of the app itself functioning, you are checking a few assertions around what pods, services and rc need to be running.

I suppose this could be implemented in kompose via a `kompose test` subcommand. But we would need to automatically detect what resources are supposed to have been created and be in running state.

Ideally, for the user a single `kompose up` should do the conversion, the creation and then report on the status. like `docker-compose up` in the foreground actually creates the containers and prints the logs of each container to stdout.
.
 On Wed, Aug 31, 2016 at 5:58 PM, runseb notifications@github.com wrote:

> I did look at your code in atomic app, I see what you are doing now.
> 
> As far as I know you are not really doing functional testing of the app
> itself in the sense of the app itself functioning, you are checking a few
> assertions around what pods, services and rc need to be running.

Yeah! Those were basic assertions that I had implemented. I was also
planning to extend it in the future to include helper assertions to
assert for endpoints and their responses.

> I suppose this could be implemented in kompose via a kompose test
> subcommand. But we would need to automatically detect what resources are
> supposed to have been created and be in running state.

I do not fancy doing much magic, as in to detect rcs, pods, svcs for
apps automatically. I'd rather prefer the code to be dumb, but empower
the application developer to use our helper assertions to write test
cases for their apps in a few lines. We can write test for some sample
applications for testing kompose itself, and show, encourage
developers to do the same.

> Ideally, for the user a single kompose up should do the conversion, the
> creation and then report on the status. like docker-compose up in the
> foreground actually creates the containers and prints the logs of each
> container to stdout.

mhm, however I am not able to get the context of it w.r.t. to tests.
.
 so from a UX perspective, what will a user have to do and how will they use `kompose` to run those tests ?
.
 On Fri, Sep 2, 2016 at 3:12 PM, runseb notifications@github.com wrote:

> so from a UX perspective, what will a user have to do and how will they use
> kompose to run those tests ?

To run test cases for Kompose

``` console
$kompose test
```

To run tests on any compose appication

``` console
$kompose test /path/to/application
```
.
 and where are the tests themselves ?
.
 On Fri, Sep 2, 2016 at 3:32 PM, runseb notifications@github.com wrote:

> and where are the tests themselves ?

I want the test cases for downstream applications to be in their code
base itself, in `tests` subdir. In upstream `kompose` source code,
it could be in `tests` subdir as well.

However, on a second thought, do we need a `kompose test` command.
AFAIK, people usually write functional tests for go applications in
shell scripts. And they could be run, without using the `kompose`
command directly. So, the application developers could run their tests
locally, by executing the local test runner script.
.
 > I think that we need to work on a set of scripts which could be extended by the users of kompose to validate their converted applications against real providers (kubernetes, openshift). This will help the developers to deploy their converted applications with confidence.

tests for users of kompose?
I'm not sure what you mean by that :-( or even if I understand it correctly :-(
For me it seems that you both are talking about different things :)

We need a lot more test, test for our-selfs, to make sure that we are not breaking features that are already working - unit tests, functional tests .....

Than I think we should focus on improving conversion rather that adding completely new features to kompose. We still don't support a lot of directives from docker-compose.yml ([this](https://github.com/skippbox/kompose/blob/14726f1a5320f905c713880875bddcd1102d9011/pkg/kobject/kobject.go#L25,L67) should be our todo list with build on the first place )
.
 I am pretty sure I understand what @kadel says. We definitely need more tests for `kompose` itself. agree with that 100% and we need to increase the functionality.

but what @rtnpro is proposing are tests for the actual containerized application.

So I fail to understand how we would package those (application specific) tests in a kompose release and even how we would implement it in Go in the kompose source. Since @rtnpro is now talking about independent shell scripts...
.
 > but what @rtnpro is proposing are tests for the actual containerized application.

I think that what he meant by this is that it would be nice to have whole workflow as part of our test suite.
One of the test would do actual deployment of some sample application to testing cluster (run in container or using minikube) and verify that deployed app is running and responding.

Or at least this is what he did for Atomic App.
.
 unless we are taking end-2-end tests for CI
.
 On Fri, Sep 2, 2016 at 5:31 PM, Tomas Kral notifications@github.com wrote:

> but what @rtnpro is proposing are tests for the actual containerized
> application.
> 
> I think that what he meant by this is that it would be nice to have whole
> workflow as part of our test suite.
> One of the test would do actual deployment of some sample application to
> testing cluster (run in container or using minikube) and verify that
> deployed app is running and responding.

Yeah :)
.
 @surajssd , @kadel , I think we have good set of test for kompose now, we can close this issue now ?.
 We can do validation on what kompose generates to check if it matches the k8s version using jsonschema or the tool called [kubeval](https://github.com/garethr/kubeval).
 @surajnarwade just found this issue as well. Kubeval is just about setup to be a Go library in https://github.com/garethr/kubeval/pull/15. Happy to help integrate that if of interest..
 @garethr :+1: .
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,132,"Moves examples to docs/user-guide and adds basic roadmap to main readme.
 A bit of tidy up:
- Moves all the examples from the main readme to a new doc user-guide.
- Changes a bit the readme to mention the API machinery SIG and a small roadmap.
.
 :+1:  LGTM
.
 thanks , I am merging
.
 "
,,131,"merging containers in pods with volumes_from directive.
 if docker-compose has a directive called `volumes_from` then user then those containers will be co-located in same pod under, k8s or openshift.
.
 There are bunch of problems with this approach though.

So what I have done right now is scan through all the services and see what all services do use `volume_from` docker-compose directive. If they use it then combine those services into single pod.

So to resolve the dependency, a graph(data structure) is created to resolve dependencies. Because there could be `volumes_from` for some service on `foo` and that `foo` could again have it on some service `bar`.

But the problems with this are as:
- when i merge two docker-compose services into one pod a k8s deployment artifact like (deployment/rc/dc) is created what should be the name of it?
- deployment artifacts' name does not matter much, but the service that we create what do we call them? a user might be calling a service from his/her application based on the name of the service and since that service no longer exists, because we have merged them to be one, user's application might fail on k8s, which we don't want.

Solution/suggestions:
- So right now we can ask user to add `labels` as a directive to tell kompose what all docker-compose services might be in same pod (credits: @dustymabe for suggestion)
- or introduce our own directive, but this will be hard to implement because using libcompose to do the parsing might cause problems with our own added directives

Please suggest what could be the right way to go with this.

@kadel @ngtuna @janetkuo 
.
 > deployment artifacts' name does not matter much, but the service that we create what do we call them? a user might be calling a service from his/her application based on the name of the service and since that service no longer exists, because we have merged them to be one, user's application might fail on k8s, which we don't want.

Yes you are right name of Deployment doesn't matter at all.
If you merge multiple docker-compose services to one pod/deploymentconfig you will still create multiple Services that are corresponding to ""old"" docker-compose services. So name and number of services will be same as before.
.
 > So right now we can ask user to add labels as a directive to tell kompose what all docker-compose services might be in same pod (credits: @dustymabe for suggestion)

I would like to avoid adding some Kompose specific labels to docker-compose unless it is really necessary. If we implement something like this it means that in some cases users will have to modify docker-compose.yml file before it can be used with Kompose.  It would be nice to keep it compatible with docker-files.yml files that are people already using as long as we can.
.
 Also rather than doing all these things from outside, should `KomposeObject` store information of dependencies?
.
 @kadel as you said we should create multiple services I am doing it now!
.
 @ngtuna @janetkuo what do you guys think about this ?
.
 Regarding to the name, what if we use interactive mode like this:

``` console
$ kompose --file compose.yml convert
Hey, we detect these compose services below can be grouped in a single pod.
<list them out>
Do you want to group them ? [Y/N] Y
What is name of the group ? [default: service1-service2-serviceN]
```

If user says N, then we keep generating objects for each compose service as usual.
.
 @ngtuna regarding using command line can we implement it in separate PR? With `preference` file, because it will streamline the flow of data? 
.
 Also added functional tests for `volumes_from` directive.
.
 @surajssd that's fine. Right now I have a small confusion. Maybe I'm wrong in some parts please correct me.

Once grouping compose services into a single pod, it means we are supposed to have these containers running in shared contexts (ip address, port space, volume) and call each other via `localhost`. So, creating multiple k8s services makes me confused, why not a single service for that group? I still see naming of k8s service is still a critical problem. Also, if there are two containers have the same container port but difference host port, how can we put them in a pod ?
.
 > So, creating multiple k8s services makes me confused, why not a single service for that group?

This is so other pods can communicate with that services. You still need proper Service (kubernetes), so other containers (from different pod) can connect to this service (docker-compose) using its name.
This is also reason why name of k8s Service must be same as name of service in docker-compose.
.
 > Also, if there are two containers have the same container port but difference host port, how can we put them in a pod ?

I'm afraid that there is a simple answer for that. We can't :-(
if we have docker-compose.yml like this

``` yml
version: ""2""
services:
    foo:
        image: nginx
        ports:
            - ""81:80""
        volumes:
            - ""./data:/data""
    bar:
        image: nginx
        ports:
            - ""82:80""
        volumes_from:
            - foo
```

Even this is valid for docker-compose it will fail to deploy to Kubernetes :(
I'm not sure if there is a solution for this.

We would have to stop putting those containers in the same pod and actually create proper shared volume.

This brings me to the question if putting containers to the same pod when they share volume is right think to do. Maybe we should give more thought volumes and try to handle then properly.
.
 > Also, if there are two containers have the same container port but difference host port, how can we put them in a pod ?

That is a highly unlikely situation in pragmatic terms, because why would anyone wanna run two web servers or two databases(of same kind which expose on same port) in a single pod?
.
 > Once grouping compose services into a single pod, it means we are supposed to have these containers running in shared contexts (ip address, port space, volume) and call each other via `localhost`. So, creating multiple k8s services makes me confused, why not a single service for that group? I still see naming of k8s service is still a critical problem.

So suppose someone has written an application, where she/he is making calls to services based on their names, this works all great in docker-compose all name resolution works fine, but when this is converted into a single pod and single service now what do we name that service? Now the app will break because they have no service endpoint to talk to. So having multiple services pointing to same set of pods makes sense here.
.
 > That is a highly unlikely situation in pragmatic terms, because why would anyone wanna run two web servers or two databases(of same kind which expose on same port) in a single pod?

Don't forget that if you are writing docker-compose file you are not thinking about pods.
In docker-compose you are thinking in term of separate containers so this might easily happen.
.
 @kadel true that :(
.
 > > So right now we can ask user to add labels as a directive to tell kompose what all docker-compose services might be in same pod (credits: @dustymabe for suggestion)
> 
> I would like to avoid adding some Kompose specific labels to docker-compose unless it is really necessary. If we implement something like this it means that in some cases users will have to modify docker-compose.yml file before it can be used with Kompose.  It would be nice to keep it compatible with docker-files.yml files that are people already using as long as we can.

Rancher compose allows users to enable rancher specific features by creating a rancher-compose.yml file that extends and overwrites the docker-compose.yml. See this [rancher-compose.yml](https://github.com/rancher/rancher-compose/blob/master/tests/integration/cattletest/core/assets/lb/rancher-compose.yml) file as an example: `scale` and `health_check` are those extended keywords. Do we want something similar?
.
 There are multiple issues we are trying to solve here, as I interpret from the comments:

> Two containers in a same pod having same container port https://github.com/skippbox/kompose/pull/131#issuecomment-245227794

I can error out on this discovery, because k8s will never allow it to happen! Even if fed to k8s.

> Should we do the co-location implicitly or provide a means for user to give the info? https://github.com/skippbox/kompose/pull/131#issuecomment-246527582 

About this I think we can have a separate issue and PR where explicit mention of pod colocation and extra info augmentation can be done.
.
 Can we solve this by implementing volumes (https://github.com/skippbox/kompose/issues/150)  and share one volume between two containers? 
Than those containers doesn't have to be in same pod.
.
 > Can we solve this by implementing volumes (#150) and share one volume between two containers?
> Than those containers doesn't have to be in same pod.

does that then require that the two separate pods be on the same host? 
.
 > does that then require that the two separate pods be on the same host?

If we do it as [PersistentVolumeClaim](http://kubernetes.io/docs/user-guide/volumes/#persistentvolumeclaim) it won't require for pods to be on same host.
Downside of this is that it assumes that cluster administrator already crated [PersistentVolumeClaims](http://kubernetes.io/docs/user-guide/persistent-volumes/)

There are also other [volume types](http://kubernetes.io/docs/user-guide/volumes/#types-of-volumes) like gcePersistentDisk, awsElasticBlockStore, nfs, cephfs etc.. but they are specific to cluster configuration or to cloud provider
.
 Closing in favour of https://github.com/skippbox/kompose/pull/190
.
 "
,,130,"services should be first in List .
 When generating List, Services should be first in the List to make sure they are created fist.
.
 "
,,129,"add tests when converting to separate files.
 Right now we have tests that only test `kompose convert --stdout`  - https://github.com/skippbox/kompose/blob/36aa6d8c3b4abcfd3779a76309cc084fe2b09ba7/script/test/cmd/tests.sh#L22

We should have also tests that are testing `kompose convert` as there are some differences how we get output for stdout and files.

this should prevent regression such as https://github.com/skippbox/kompose/pull/126 happening again
.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 /remove-lifecycle rotten.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 Stale issues rot after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle rotten`.
Rotten issues close after an additional 30d of inactivity.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle rotten
/remove-lifecycle stale.
 Rotten issues close after 30d of inactivity.
Reopen the issue with `/reopen`.
Mark the issue as fresh with `/remove-lifecycle rotten`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/close.
 "
,,128,"Add more owners.
 .
 +1 I am merging it 
.
 "
,,127,"docker-compose - Entrypoint support.
 We had Command and Args together with Entrypoint in Kompose object.
This doesn't make much sense, as Entrypoint and Command are same thing.
I've removed Entrypoint from Kompose object in favor of Command to keep
same naming convensions as in Kubernetes.

Entrypoint from docker-compose.yml is now saved to Command and Command
is saved to Args (http://kubernetes.io/docs/user-guide/containers/).

| docker-compose.yml | Kompose object |
| --- | --- |
| Entrypoint | Command |
| Command | Args |
.
 Heyo, can please someone review this?
@surajssd @ngtuna @janetkuo ?
.
 @kadel I think it is a bit more subtle than this. 

I haven't checked but I believe Kubernetes cmd/args overwrite the Dockerfile entrypoint.

you could have a compose file with a build instructions that also specifies a legitimate default entry point which would be different than the compose CMD being passed.

I maybe wrong though, but I would like to see some examples and manual testing.

what do you think ?
.
 @runseb I'm afraid that I'm not sure if I understand :-( 
Kubernetes can overwrite cmd/args from image and docker-compose is doing the same. 
It is used to overwrite default cmd/args from docker image.
What is in docker-compose.yml overwrites what is specified in image.
.
 so the command spec in a Pod overwrites the entrypoint of an Image ?
.
 ok I think I get it.

in compose entrypoint and command overwrite entrypoint and command :)
but in k8s the Pod does this by overwriting the entry point using what is in command, and overwrites command with what is in args .
.
 I will try to show some examples how I believe it should work.

I have image foo/bar that is build from this:

```
.....
ENTRYPOINT entrImg
CMD  cmdImg
```

compose file like this 

``` yml
services:
  foo:
    image: foo/bar
```

should run `foo/bar entrImg cmdImg`
in k8s PodSpec it should be:

``` json
""spec"": {
  ""containers"":  [  
    {""image"": ""foo/bar""}
   ]
}
```

docker-compose.yml

``` yml
services:
  foo:
    image:  foo/bar
    commnad: cmdCompose

```

should run `foo/bar entrImg cmdCompose`
podSpec:

``` json
""spec"": {
  ""containers"":  [  
    {""image"": ""foo/bar"",
      ""args"": [""cmdCompose""]}
   ]
}
```

docker-compose.yml

``` yml
services:
  foo:
    image:  foo/bar
    entrypoint: entrCompose

```

should run `foo/bar entrCompose cmdImage`
podSpec:

``` json
""spec"": {
  ""containers"":  [  
    {""image"": ""foo/bar"",
      ""command"": [""entrCompose""]}
   ]
}
```

docker-compose.yml

``` yml
services:
  foo:
    image:  foo/bar
    entrypoint: entrCompose
    command: cmdCompose

```

should run `foo/bar entrCompose cmdCompose`
podSpec:

``` json
""spec"": {
  ""containers"":  [  
    {""image"": ""foo/bar"",
      ""command"": [""entrCompose""],
      ""args"": [""cmdCompose""]}
   ]
}
```
.
 thanks

+1
.
 > in compose entrypoint and command overwrite entrypoint and command :)
> but in k8s the Pod does this by overwriting the entry point using what is in command, and overwrites command with what is in args .

exactly 

k8s names are different,  it uses same name for different things :-D 
[Here](http://kubernetes.io/docs/user-guide/containers/) is k8s documentation for what I tried to explain above :-D. 
.
 yeah, I think it is still a bit subtle because if an image does not have an entry point defined, it will use sh -c

and you can actually specify the command simply in args parameter of a pod...

confusing IMHO but nothing to do with your PR.
.
 Code looks good. Maybe add a test in test-cmd
.
 I've added tests, Merging now.
.
 "
,,126,"Fix conversion to OpenShift (invalid DeploymentConfig).
 fixes #124 by add missing conversion to versioned object when saving to files

I've also added commit that fixes #130 
.
 Mind adding a test to prevent regression?
.
 there are already tests that should catch this, but they are not working properly :-(
see #125

edit:
no this test couldn't catch that even if it would work, because it uses --stdout and that bug was only when converting to files.

I've created issue to fix the tests: https://github.com/skippbox/kompose/issues/129
.
 @kadel to address this issue in #73 I added a function called `sortServices` at that time somehow it seems to be out of code :(

This function was created because @ngtuna asked for it https://github.com/skippbox/kompose/pull/94#discussion_r74376944

Link to function in diff 
https://github.com/skippbox/kompose/commit/04d1d655525d88de0544a7554f995001927ccae4#diff-41d801ef80f1858d5e8e9695667e4dafR1302
.
 > @kadel to address this issue in #73 I added a function called sortServices at that time somehow it seems to be out of code :(
> 
> This function was created because @ngtuna asked for it #94 (comment)
> 
> Link to function in diff
> 04d1d65#diff-41d801ef80f1858d5e8e9695667e4dafR1302

ah, I missed that, I'll move that function to Kubernetes Transformer and use that
.
 Heyo, can please someone review this?
@surajssd @ngtuna  @janetkuo ?
.
 +1 looks ok, but did not test
.
 "
,,125,"cmd tests are not working properly.
 one example

test result:

```
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert --stdout -f /home/tomas/dev/goenv/kompose/src/github.com/skippbox/kompose/script/test/fixtures/etherpad/docker-compose.yml' expected_output: '/home/tomas/dev/goenv/kompose/src/github.com/skippbox/kompose/script/test/fixtures/etherpad/output-k8s.json' expected_warning: 'Unsupported key depends_on - ignoring'
PASS: converted output matches
PASS: warning found: 'Unsupported key depends_on - ignoring'

```

but if I run command manually it fails and there is no output:

```
▶ kompose convert --stdout -f /home/tomas/dev/goenv/kompose/src/github.com/skippbox/kompose/script/test/fixtures/etherpad/docker-compose.yml
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
WARN[0000] The DB_NAME variable is not set. Substituting a blank string. 
WARN[0000] The DB_PASS variable is not set. Substituting a blank string. 
WARN[0000] The DB_USER variable is not set. Substituting a blank string. 
WARN[0000] The ROOT_PASS variable is not set. Substituting a blank string. 
WARN[0000] The DB_PASS variable is not set. Substituting a blank string. 
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
WARN[0000] The DB_USER variable is not set. Substituting a blank string. 
WARN[0000] The DB_HOST variable is not set. Substituting a blank string. 
WARN[0000] The DB_NAME variable is not set. Substituting a blank string. 
FATA[0000] ""mariadb"" failed to load ports from compose file: invalid container port """"
```
.
 My bad, I forgot export env varibales. :flushed: 
When I export proper env variables that are specified in docker-compose.yml it works properly.

closing
.
 "
,,124,"OpenShift conversoin - invalid DeploymentConfig.
 When creating (`oc create -f ...`) DeploymentConfig created (`kompose convert --dc`) from this [docker-compose.yml](https://github.com/almighty/almighty-core/blob/master/docker-compose.yml)  I get following error:

```
The DeploymentConfig """" is invalid.

* metadata.name: Required value: name or generateName is required
* spec.template: Required value
* spec.selector: Invalid value: null: selector cannot be empty
```
.
 "
,,123,"clean code.
 - remove / comment unused code
- document functions
.
 LGTM
.
 "
,,122,"fix #121: update all objects, even when port is missing.
 Fix issue https://github.com/skippbox/kompose/issues/121
.
 I saw this issue and the created a code change locally, but then saw this PR! 
.
 "
,,121,"Wrong output when port is missing.
 The current convert function is not working correctly. When port is missing, objects are converted in init state.

``` console
$ cat docker-compose.yml.tuna 
web:
  image: tuna/docker-counter23
  environment:
    - version=1.0
  links:
    - redis
redis:
  image: redis:3.0
  ports:
    - ""6379""

$ kompose convert --file docker-compose.yml.tuna
WARN[0000] [web] Service cannot be created because of missing port. 
INFO[0000] file ""web-deployment.json"" created           
INFO[0000] file ""redis-deployment.json"" created         
INFO[0000] file ""redis-service.json"" created   

$ cat web-deployment.json 
{
  ""kind"": ""Deployment"",
  ""apiVersion"": ""extensions/v1beta1"",
  ""metadata"": {
    ""name"": ""web"",
    ""creationTimestamp"": null
  },
  ""spec"": {
    ""replicas"": 1,
    ""template"": {
      ""metadata"": {
        ""creationTimestamp"": null
      },
      ""spec"": {
        ""volumes"": null,
        ""containers"": [
          {
            ""name"": ""web"",
            ""image"": ""tuna/docker-counter23"",
            ""resources"": {},
            ""imagePullPolicy"": """"
          }
        ],
        ""serviceAccountName"": """"
      }
    },
    ""strategy"": {}
  },
  ""status"": {}
}
```

`environment` is missing in the deployment web.

The problem came from this line:
https://github.com/skippbox/kompose/blob/master/pkg/transformer/kubernetes/kubernetes.go#L243

If ports not provided in configuration we will not make service, but we will also not update objects.
.
 "
,,120,"Update architecture doc format.
 .
 "
,,119,"Improve error message for invalid port.
 .
 :+1: 
.
 "
,,118,"Remove hostPath and print warnings.
 Fixes #109
.
 "
,,117,"godep save ./... : cannot find package ""k8s.io/kubernetes/pkg/apis/authentication.k8s.io"".
 I added an import ""k8s.io/kubernetes/pkg/kubectl/cmd"" to `kubenetes.go`. For saving vendor, I need to run `script/godep-restore.sh` first. It works well. But the following `godep save ./...` get error:

``` console
$ godep save ./...
godep: Package (k8s.io/kubernetes/pkg/apis/authentication.k8s.io) not found

$ go get k8s.io/kubernetes/pkg/apis/authentication.k8s.io
package k8s.io/kubernetes/pkg/apis/authentication.k8s.io: cannot find package ""k8s.io/kubernetes/pkg/apis/authentication.k8s.io"" in any of:
    /usr/local/go/src/k8s.io/kubernetes/pkg/apis/authentication.k8s.io (from $GOROOT)
    /home/tuna/workspace/gocode-kompose-ngtuna/src/k8s.io/kubernetes/pkg/apis/authentication.k8s.io (from $GOPATH)
```

How do you think @kadel ?
.
 Hmm, I can't reproduce your `k8s.io/kubernetes/pkg/apis/authentication.k8s.io`. 

I get completely different error:

```
godep: Package (github.com/docker/docker/pkg/term/winconsole) not found
```

Reason for this error is that something down in `k8s.io/kubernetes/pkg/kubectl/cmd` requires `github.com/docker/docker/pkg/term/winconsole`, but `winconsole` pkg is only in old versions of docker that we can't use because we need bundlefile. 

I will look if we can solve this dependency conflict by using newer  k8s/origin
.
 It doesn't look good :-( Because of that dependency conflict I can't get `k8s.io/kubernetes/pkg/kubectl/cmd` working :-(
.
 I got totally different errors (failed to `godep restore`), I'm using godep v74. Any idea on how to fix this?

``` console
$ script/godep-restore.sh
Preloading some dependencies
fatal: remote github.com/openshift-remote already exists.
remote: Counting objects: 166, done.
remote: Compressing objects: 100% (55/55), done.
remote: Total 166 (delta 128), reused 144 (delta 108), pack-reused 0
Receiving objects: 100% (166/166), 41.73 KiB | 0 bytes/s, done.
Resolving deltas: 100% (128/128), completed with 83 local objects.
From https://github.com/kubernetes/kubernetes
   96916e4..6e5826a  release-1.3 -> upstream/release-1.3
 + bd2057a...854b7b9 refs/pull/28432/head -> origin/pr/28432  (forced update)
 + f9be0db...7029eaa refs/pull/29049/head -> origin/pr/29049  (forced update)
 + 3c5f68c...5af42f6 refs/pull/30153/head -> origin/pr/30153  (forced update)
 + 9c1ffd2...67b7c72 refs/pull/30838/head -> origin/pr/30838  (forced update)
   9ff3d8b..39fbd30  refs/pull/30959/head -> origin/pr/30959
 * [new ref]         refs/pull/31144/head -> origin/pr/31144
 * [new ref]         refs/pull/31145/head -> origin/pr/31145
 * [new ref]         refs/pull/31146/head -> origin/pr/31146
Starting to download all godeps. This takes a while
# cd /usr/local/google/home/username/go/src/github.com/docker/docker; git checkout e4a0dbc47232e3a9da4cfe6ce44f250e6e85ed43
fatal: reference is not a tree: e4a0dbc47232e3a9da4cfe6ce44f250e6e85ed43
... (lots of other similar errors)
```
.
 Yah, I tested it again from a fresh clone kompose and got the same issue with @janetkuo : 

``` console
$ script/godep-restore.sh
...
Starting to download all godeps. This takes a while
# cd /home/tuna/workspace/gocode-kompose-godep-problem/src/k8s.io/kubernetes; git checkout 57fb9acc109285378ecd0af925c8160eb8ca19e6
fatal: reference is not a tree: 57fb9acc109285378ecd0af925c8160eb8ca19e6
godep: error downloading dep (k8s.io/kubernetes/federation/apis/federation): exit status 128
godep: Error downloading some deps. Aborting restore and check.
Download finished into /home/tuna/workspace/gocode-kompose-godep-problem/
```
.
 That is strange, I've just tried that on clean GOPATH and it godep-restore.sh worked fine.

```
▶ mkdir -p kompose_GOPATH/src/github.com/skippbox

▶ export GOPATH=~/tmp/kompose_GOPATH 

▶ cd $GOPATH/src/github.com/skippbox 

▶ git clone https://bitbucket.org/ymotongpoo/goenv/pull-requests/
Cloning into 'pull-requests'...
remote: Counting objects: 471, done.
remote: Compressing objects: 100% (469/469), done.
remote: Total 471 (delta 239), reused 0 (delta 0)
Receiving objects: 100% (471/471), 1.15 MiB | 1.28 MiB/s, done.
Resolving deltas: 100% (239/239), done.
Checking connectivity... done.

▶ git clone https://github.com/skippbox/kompose                  
Cloning into 'kompose'...
remote: Counting objects: 4708, done.
remote: Total 4708 (delta 0), reused 0 (delta 0), pack-reused 4708
Receiving objects: 100% (4708/4708), 4.31 MiB | 967.00 KiB/s, done.
Resolving deltas: 100% (1658/1658), done.
Checking connectivity... done.

▶ cd kompose 

▶ ./script/godep-restore.sh 
Preloading some dependencies
remote: Counting objects: 5089, done.
remote: Total 5089 (delta 2728), reused 2728 (delta 2728), pack-reused 2361
Receiving objects: 100% (5089/5089), 2.51 MiB | 3.27 MiB/s, done.
Resolving deltas: 100% (3888/3888), completed with 1153 local objects.
From https://github.com/openshift/kubernetes
 * [new branch]      master     -> github.com/openshift-remote/master
 * [new branch]      release-1.0 -> github.com/openshift-remote/release-1.0
 * [new branch]      release-1.1 -> github.com/openshift-remote/release-1.1
 * [new branch]      release-1.2 -> github.com/openshift-remote/release-1.2
 * [new branch]      release-1.2-stable-20160309 -> github.com/openshift-remote/release-1.2-stable-20160309
 * [new branch]      release-1.2-stable-20160312 -> github.com/openshift-remote/release-1.2-stable-20160312
 * [new branch]      release-1.2-stable-20160316 -> github.com/openshift-remote/release-1.2-stable-20160316
 * [new branch]      stable     -> github.com/openshift-remote/stable
 * [new branch]      stable-20160127 -> github.com/openshift-remote/stable-20160127
 * [new branch]      stable-20160211 -> github.com/openshift-remote/stable-20160211
 * [new branch]      stable-20160309 -> github.com/openshift-remote/stable-20160309
 * [new branch]      stable-20160411 -> github.com/openshift-remote/stable-20160411
 * [new branch]      stable-20160510 -> github.com/openshift-remote/stable-20160510
 * [new branch]      stable-20160615 -> github.com/openshift-remote/stable-20160615
 * [new branch]      stable-20160624 -> github.com/openshift-remote/stable-20160624
 * [new branch]      stable-20160804 -> github.com/openshift-remote/stable-20160804
 * [new branch]      stable-9da202e -> github.com/openshift-remote/stable-9da202e
 * [new tag]         v1.1.0-origin -> v1.1.0-origin
 * [new tag]         v1.2.0-origin -> v1.2.0-origin
Starting to download all godeps. This takes a while
Download finished into /home/tomas/tmp/kompose_GOPATH

▶ make binary
CGO_ENABLED=0 ./script/make.sh binary
---> Making bundle: binary (in .)
Build successful. Program saved as ./kompose
```
.
 Yes that's strange. I did try on a clean GOPATH too. When I opened this issue, `script/godep-restore.sh` worked fine. 

Why did you do this one? 

``` console
git clone https://bitbucket.org/ymotongpoo/goenv/pull-requests/
```
.
 > Yes that's strange. I did try on a clean GOPATH too. When I opened this issue, script/godep-restore.sh worked fine.
> 
> Why did you do this one?
> 
> git clone https://bitbucket.org/ymotongpoo/goenv/pull-requests/

OH, that was copy/paste error. Its not supposed to be there :-D
.
 > Hmm, I can't reproduce your k8s.io/kubernetes/pkg/apis/authentication.k8s.io.
> 
> I get completely different error:
> 
> godep: Package (github.com/docker/docker/pkg/term/winconsole) not found
> 
> Reason for this error is that something down in k8s.io/kubernetes/pkg/kubectl/cmd requires github.com/docker/docker/pkg/term/winconsole, but winconsole pkg is only in old versions of docker that we can't use because we need bundlefile.
> 
> I will look if we can solve this dependency conflict by using newer k8s/origin

So I did some research around that.  I still can't reproduce your error with `authentication.k8s.io` pkg :-(

If I use `k8s.io/kubernetes/pkg/kubectl/cmd` then  `godep save ./...`  fails on

```
godep: Package (github.com/docker/docker/pkg/term/winconsole) not found
```

This error is because we have two things in Kompose dependency chain that requires different version of `github.com/docker/docker`.

Kompose requires `github.com/docker/docker`  > v1.12.0-rc1  for bundlefile support.
OpenShift and Kubernets 1.3.x require docker v1.4.1. And it is not possible to build them with v1.12 or v1.11.

This problem was in Kompose for some time (since we started using latest Docker), we didn't noticed that because we haven't used parts of Kubernetes that are calling Docker apis (or they call  parts of Docker api that didn't changed between v1.4 and v1.12). `k8s.io/kubernetes/pkg/kubectl/cmd` [uses](https://github.com/kubernetes/kubernetes/blob/v1.3.5/pkg/kubectl/cmd/exec.go#L27) `github.com/docker/docker/pkg/term` and that changed a lot between those versions.

Latest alpha release of Kubernetes (v1.4.0-alpha.2) is build with Docker version v1.11.2 so this might solve our problem (expecting that there is not much api changes between 1.11 and 1.12). But we have to wait till OpenShift Origin is rebased  with Kubernetes v1.4.0-alpha.2 or more :-(

Until than we can't use `k8s.io/kubernetes/pkg/kubectl/cmd` and maybe some other packages from Kubernetes, but its hard to tell which :-(
.
 This should be closed. As soon as we have k8s go client we should be good. Will reopen it whenever getting problem with godeps...
.
 "
,,116,"Create a pod of containers sharing volume.
 Right now the way we do conversion is more of one to one mapping. But when two services/containers share volume in docker-compose file we need to put those two containers in a single pod and make them share volume on kubernetes as well.

for e.g.: the following two services should be wound up into a single pod, by which I mean we will only create one deployment, which has one pod and both of those containers, and single service on top of them, if ports provided:

``` bash
version: '2'

services:
  db:
    image: postgres
    volumes:
      - data:/var/lib/postgresql/data

  foosvc:
    image: foosvcimage
    volumes:
      - data:/var/lib/my/mount/point

volumes:
  data:
    external: true
```
.
 That would be great if you can take it. I filed this issue before but have never tried. https://github.com/skippbox/kompose/issues/14
.
 @ngtuna oops sorry for the duplicate will close this, will work on #14 !
.
 "
,,115,"Reuse creation of controller object code.
 The repated controller creation code has been removed. And aggregated it into a single function, that Kubernetes and OpenShift providers' Transform code can call.
.
 LGTM
.
 Thanks for review, merging. :+1: 
.
 "
,,114,"Removed unwanted svcnames list.
 Transform function from both the providers has some unused data structure so removed it.
.
 LGTM
.
 cool, merging :)
.
 "
,,113,"support kompose down subcommand.
 Add new subcommand `kompose down`, in contrast with `kompose up`. There are two options:

``` console
$ kompose down --file <docker-compose>
$ kompose down --bundle <bundle-file>
```

It will delete corresponding services and deployments of converted application.

``` console
$ kompose down --all
Using flag --all/-a will delete all resources in the kubernetes cluster.
Are you sure to continue? (yes/no): yes
```

It will delete all resources (deployments, services, replication controllers, daemonsets) in the cluster. (only at default namespace, other namespaces are coming in follow-up PR).

Can you take a look @janetkuo ? I'm not sure if I missed something in calling kubernetes apis. For example, I set DeleteOptions = nil when deleting deployment. or ListOptions is empty. They are temporarily set until we find suitable customized options.
.
 Fixes https://github.com/skippbox/kompose/issues/41
.
 Do we really need `down --all`? If someone wants to clean whole namespace it can be done via `kubectl`. 
.
 Stuck at https://github.com/skippbox/kompose/issues/117 where I can't use ""k8s.io/kubernetes/pkg/kubectl/cmd"" for printing resources in format of `kubectl get`
.
 > Stuck at #117 where I can't use ""k8s.io/kubernetes/pkg/kubectl/cmd"" for printing resources in format of kubectl get

https://github.com/skippbox/kompose/issues/117#issuecomment-242029705
.
 @ngtuna  If it is just for printing, can we use something else for now?
.
 @kadel yes I'm also thinking about it
.
 "
,,112,"update Libcompose to v0.3.0.
 closes #95 
I've done some testing on top of our test suite, It shouldn't break anything.
But there was a lot of changes in libcompose, so who knows.
.
 +1. I suggest @janetkuo and @surajssd also should confirm then we can merge it to master.
.
 @kadel I think you need to rebase on current master before merge! Once done I will check again :)
.
 rebased
.
 LGTM, build and tests passes locally :+1: 
.
 LGTM too
.
 "
,,111,"Added flag `--suppress-warnings`, `--verbose`, `--error-on-warning` global flags.
 - `--suppress-warnings` it ignores all warnings.
- `--verbose` displays everything
- `--error-on-warning` with any warning exits displaying error.

Fixes #100
.
 @ngtuna @janetkuo apart from the flags mentioned above what all flags would you guys want?
.
 I'd suggest changing `-w` to `--quiet`
.
 We should choose short flags sparingly, only for the most frequently used options (since there are only 26 ones we can use). 
.
 @janetkuo updated comment above 
.
 So now with `--quiet` enabled it will fail on a single warning itself!
.
 Mistakenly pushed close PR button, sorry about that.

@janetkuo can you confirm about this PR with the flags that I have added?
.
 @surajssd , code looks good to me. I tested with `docker-voting.yml` , output below:

``` console
$ kompose --quiet convert --file docker-voting.yml --out voting.txt
Unsupported key build - ignoring

$ kompose convert --file docker-voting.yml --out voting.txt
WARN[0000] Unsupported key build - ignoring             
WARN[0000] Volume mount on the host ""./result"" isn't supported - ignoring path on the host 
WARN[0000] Volume mount on the host ""./vote"" isn't supported - ignoring path on the host 
WARN[0000] [worker] Service cannot be created because of missing port. 
WARN[0000] [db] Service cannot be created because of missing port.
```

Do we expect that output ?
.
 @ngtuna yes the behavior of `--quiet` flag is that it exits even on a single warning! (of-course showing the warning)

Rebased on current master.
.
 @surajssd yeah but how about volume mount & service warning ?
.
 @ngtuna what @janetkuo said [here](https://github.com/skippbox/kompose/issues/100#issuecomment-240857502) 

> ""Treating warnings as errors"" means that ""I expect myself to fix my config so that I won't see any warnings; but in case I missed anything, please give me error on those warnings"".

so i am exiting on any warning, so that user will have to fix those warnings before she/he can go forward. How do you perceive this? 
.
 @surajssd Ah ha... Sorry I missed it. +1 LGTM. Let's wait for @janetkuo reply.
.
 @ngtuna sure thanks :)
.
 Just realize we have missed it for the release `0.1.0`. So let's leave it at `0.1.1`
.
 > @ngtuna what @janetkuo said [here](https://github.com/skippbox/kompose/issues/100#issuecomment-240857502) 
> 
> > ""Treating warnings as errors"" means that ""I expect myself to fix my config so that I won't see any warnings; but in case I missed anything, please give me error on those warnings"".
> 
> so i am exiting on any warning, so that user will have to fix those warnings before she/he can go forward. How do you perceive this? 

@surajssd sorry I should've made this more clear. I meant:
- `--quiet`: don't display warnings. User use `--quiet` to suppress all warnings when they're aware of those warnings and choose to ignore them. 
- `--verbose` (`bool` or `int`): customized verbose level 
- `--error-on-warnings` (or some other name similar): make all warnings into errors (something like GCC [`-Werror`](https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html)). Users use `--error-on-warnings` when they believe they've fixed all warnings, and want `kompose` to treat warnings as errors so that they can fix them before continue. 
.
 @janetkuo yep changed code accordingly, and also updated https://github.com/skippbox/kompose/pull/111#issue-171707579 with the latest usage.
.
 Hi @surajssd thanks, I played around with it and have some more comments:
- `--quiet` isn't really quiet, suggest renaming it to `--suppress-warnings`:

``` console
$ kompose -f docker-voting.yml --quiet up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 


Your application has been deployed to Kubernetes. You can run 'kubectl get deployment,svc,pods' for details.
```
- `--quiet` (`--suppress-warnings`) hides errors too, which it shouldn't (it should only supress warnings):

``` console
# There's fatal error when the service already existed
$ kompose -f docker-voting.yml up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

WARN[0000] [worker] Service cannot be created because of missing port. 
FATA[0000] Error: 'services ""db"" already exists' while creating service: db

# `--quiet` suppressed the fatal errror 
$ kompose -f docker-voting.yml --quiet up
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

```
- `--error-on-warning` treated warnings as errors, but the error wasn't colored / formatted as other errors:

``` console
$ kompose -f docker-voting.yml --error-on-warning up 
We are going to create Kubernetes deployments and services for your Dockerized application. 
If you need different kind of resources, use the 'kompose convert' and 'kubectl create -f' commands instead. 

[worker] Service cannot be created because of missing port.
```

![image](https://cloud.githubusercontent.com/assets/4876867/18491484/779d0726-79bb-11e6-8b0c-838365cfc942.png)

Can we leverage `logrus.Fatalf` or `logrus.Errorf` here?
.
 @janetkuo 

Without any option normal warnings and errors

```
$ kompose -f ./script/test/fixtures/etherpad/docker-compose.yml convert --stdout 
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
WARN[0000] The DB_PASS variable is not set. Substituting a blank string. 
[SNIP]
WARN[0000] Unsupported key depends_on - ignoring        
FATA[0000] ""mariadb"" failed to load ports from compose file: invalid container port """" 
```

With `--suppress-warnings` flag all warnings are ignored, but errors out on any error

```
$ kompose --suppress-warnings -f ./script/test/fixtures/etherpad/docker-compose.yml convert --stdout 
FATA[0000] ""mariadb"" failed to load ports from compose file: invalid container port """" 
```

With `--error-on-warning` flag errors out on any warning

```
$ kompose --error-on-warning -f ./script/test/fixtures/etherpad/docker-compose.yml convert --stdout 
FATA[0000] The DB_PORT variable is not set. Substituting a blank string. 
```

With `--verbose` flag all logs shown

```
$ kompose --verbose -f ./script/test/fixtures/etherpad/docker-compose.yml convert --stdout 
DEBU[0000] Opening compose files: ./script/test/fixtures/etherpad/docker-compose.yml 
WARN[0000] The DB_PORT variable is not set. Substituting a blank string. 
[SNIP]
WARN[0000] The DB_HOST variable is not set. Substituting a blank string. 
DEBU[0000] [0/1] [etherpad]: Adding                     
DEBU[0000] [0/1] [mariadb]: Adding                      
WARN[0000] Unsupported key depends_on - ignoring        
FATA[0000] ""mariadb"" failed to load ports from compose file: invalid container port """" 
```
.
 Looks good. The change is awesome! Thanks :+1: 
.
 Merging! 
.
 "
,,110,"Fix output comparison for cmd tests.
 Now check on true as comparison output, then PASS, if anything else just fail on it. This avoids all the
false positives.
.
 LGTM
.
 Merging. Thanks @kadel for review.
.
 "
,,109,"hostPath volumes?.
 We use `hostPath` in volumes?
This doesn't really makes sense to me. When you are deploying to Kubernets cluster `hostPath` will **never** contain files that you have on your local machine from which you are running `kompose`. Unless you somehow copy them manually.
Another thing with `hostPath` is that even if you somehow upload you files to it, whenever pod is rescheduled to another node `hostPath` can contain completely different files.

Because of above I think that `hostPath` can confuse users instead of helping.

Ideally user should  be able to choose which type of volume he/she wants (this will usually depend on his environment setup (gcePersistentDisk, awsElasticBlockStore, nfs ....)).

For now I propose using emptyDir, and displaying warning or some message explaining why this is. And that right now you can't copy content of local directory to cluster volume. 
.
 > For now I propose using emptyDir, and displaying warning or some message explaining why this is. And that right now you can't copy content of local directory to cluster volume.

You're right. Let's remove `hostPath`.
.
 i need the hostPaht, even if i copy them manually.
can i push a merged about adding --hostPath option?.
 @xiaoping378 , can you please explain your use case ?.
 @surajnarwade 
i'm try to run hyperledger fabric on the k8s, but the [fabric samples](https://github.com/hyperledger/fabric-samples/blob/release/balance-transfer/artifacts/docker-compose.yaml) has too many volumes,  if kompose don't write hostpath, i will so plain to edit the k8s yaml..
 Hey @kadel @surajnarwade @xiaoping378 

I'm re-opening this issue for discussion.

As volumes are a very difficult area for converting, I suggest we add a different parameter, preferably, `--volumes`

For example, we'd have:

```
--volumes [none|host-path|empty,etc.]
```

What do you think?.
 @cdrage how does it help?
Or what is the requirement that will be solved with this feature? Adding this is only supporting anti-pattern in k8s world?.
 @surajssd Not exactly an anti-pattern, but more in regards to filling in the ""blanks"" between Kompose and its heavy use of volumes and the ""PersistentVolumeClaim"" method for Kubernetes.

Since we already have one parameter (emptyvols), it makes sense to combine them all into one parameter (volumes) so we don't have multiple similar params..
 In most cases `hostPath` and `emptyDir` will behave the same because pod would not be scheduled on same node. 

*Behave the same* means that it will most probably have empty storage.

Also `hostPath` is more error prone because user will have to make sure that path on the k8s node exists and container runtime has permissions to write there..
 @kadel thoughts?.
 Adding ` --volumes [none|host-path|empty,etc.]` and removing `--emptyvols` is good idea.
I would use Kubernetes naming so it should be `emptyDir` and `hostPath`.

But this will have one big limitation that might confuse pepole a bit.
If we add option for hostPath it means that all the volumes in given Dockerfile will be converted to hostPaths volumes. We need properly document and explain it in `--help`
I'm definetly agains adding some magic label or other logic that will allow specify this on per volume basic.
But global flag is OK.

.
 @kadel 

Okay, I will go through with it. First off is refactoring the code to `--volumes` and deprecating --emptyvols I shall also update and notify https://github.com/kubernetes/kompose/pull/734.
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or [fejta](https://github.com/fejta).
/lifecycle stale.
 /remove-lifecycle stale.
 This has been fixed in https://github.com/kubernetes/kompose/pull/957.
 "
,,108,"Create service function in kubernetes utils.
 This function can be used in both openshift and kubernetes and all the logic of creating service can be kept in this function.
.
 Should go in, after https://github.com/skippbox/kompose/pull/107 is merged and rebased on https://github.com/skippbox/kompose/pull/107
.
 This needs rebase on #106; please rename sc to svc (official short name for service)
.
 Rebased on #106
.
 ping @ngtuna 
.
 Yeah LGTM. I thought @janetkuo did add `lgtm` label.
.
 @ngtuna np, Thanks for reviewing :+1: Merging.
.
 "
,,107,"Abstracted port checking function.
 To reduce the inconsistency of message printing created a function which can be called from both kubernetes and openshift
.
 "
,,106,"Add more unit tests for Transform.
 Follow up #104; Ref #34
.
 Rebased
.
 "
,,105,"Support container name and args in kompose convert.
 .
 "
,,104,"Add unit test for komposeConvert.
 Ref #34 
.
 This PR is getting bigger than I thought. PTAL and I'll add more tests in follow-up PRs. 
.
 Checked. That looks great :+1:  @janetkuo 
.
 "
,,103,"Fix panic on v1 compose file.
 #102
.
 Closing since it's fixed in HEAD
.
 "
,,102,"kompose convert panic on v1 compose file.
 Converting examples/docker-compose.yml to k8s...

``` console
$ kompose convert 
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x8 pc=0x46be8a]
```

It's because of [this line](https://github.com/skippbox/kompose/blob/master/cli/app/app.go#L870) which references Networks (which is `nil`, since it's v1 compose file):

``` go
//FIXME: networks always contains one default element, even it isn't declared in compose v2.
if len(composeServiceConfig.Networks.Networks) > 0 &&
```

@surajssd we need to add those example files to the test 
.
 Fixing in #103, still need tests
.
 Super @janetkuo . I saw this panic error last night but immediately had to go to sleep so didn't fix.Thanks for your quick react :+1: 
.
 This issue also stopped me to finish my PR #91.
.
 This is fixed now
.
 "
,,101,"Update tests output files.
 With the recent changes in the output format as List, updated tests as well so they validate on the new format of output.
.
 Which `kompose` binary is the test using? Did it rebuild the binary before the test?
.
 Yes binary was rebuilt before test and it is put in system's `PATH`.
.
 Hey @surajssd , just a quick check (I am missing something, sorry that my head is struggling...). Did we cover the `docker-compose-no-image.yml` case in master branch? I got this fail (only this):

``` console
===> Starting test <===
convert::expect_failure: Running: 'kompose convert --stdout -f /home/travis/gopath/src/github.com/skippbox/kompose/script/test/fixtures/etherpad/docker-compose-no-image.yml'
FAIL: no error output, returned exit status 0
```
.
 Ah I found it. Still open https://github.com/skippbox/kompose/issues/80. So how can we bypass this case in the current travis-ci test ? Or just ignore it and merge like @kadel did yesterday?
.
 @ngtuna yes i think we need to ignore it for now or if you suggest I can comment the test for now and then uncomment it when it gets fixed?
.
 @surajssd yes please do.
.
 @ngtuna thanks :)
.
 "
,,100,"Add flags for sliencing warning and for treating warnings as error.
 Users would want to ignore known warnings when writing scripts with `kompose`. Users would also want to get errors when they try to remove all unsupported fields. 
.
 I would like to work on this! :)
.
 We can have a global flag `-w` to suppress all the warnings, but I am not clear of the second thing of ""treating warnings as error""?
.
 ""Treating warnings as errors"" means that ""I expect myself to fix my config so that I won't see any warnings; but in case I missed anything, please give me error on those warnings"". 
.
 "
,,99,"Build statically linked binaries in makefile; remove make clean.
 Fixes #98

Now `make binary`, `make all` or `make default` gives me statically linked binaries:

``` console
$ ldd bundles/kompose_linux-amd64/kompose 
    not a dynamic executable
$ file bundles/kompose_linux-amd64/kompose 
bundles/kompose_linux-amd64/kompose: ELF 64-bit LSB  executable, x86-64, version 1 (SYSV), statically linked, not stripped
```

Also removed `make clean` since the clean script doesn't exist.
.
 +1 @janetkuo . 
.
 @janetkuo @ngtuna  But we should have a `clean` directive, I think. Not sure how it works in Goland but, it definitely made a lot of sense in C/C++ world. We probably want something to make sure we have a pristine build. What do you all think?
.
 @pradeepto Yes we should support `make clean`, and we can add it back once we have the clean script
.
 "
,,98,"Release: kompose binary should be statically linked .
 The latest release binary is dynamically linked. We should distribute statically linked binaries instead. 

``` console
$ ldd kompose 
    linux-vdso.so.1 =>  (0x00007ffe937ea000)
    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f0a7dae5000)
    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f0a7d720000)
    /lib64/ld-linux-x86-64.so.2 (0x00007f0a7dd03000)

$ file kompose 
/usr/local/kompose: ELF 64-bit LSB  executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=86c6d2ff21297a06cc7319244f35e2671612beae, not stripped
```

Setting `CGO_ENABLED=0` should do the trick.

Ref #70
.
 "
,,97,"Define build strategy with Kubernetes.
 Kubernetes by default has no container image build mechanism, so what are the ways are we gonna support it?
.
 One point I would like to add here is the builds should be generic enough that image format is supported for both container runtimes that kubernetes supports i.e. docker and rkt
.
 you want to run kompose within a k8s cluster ?

I am not sure I get it. It is a client side tool.
.
 Hmm, I'm not sure I get it either.

Only way how to do builds with Kubernetes that I can think of right now is to build image (similarly as docker-compose would) and than push it to some registry that is also accessible by targeted Kubernetes cluster.
.
 I created this issue if we wanna give a end-to-end feel on k8s we will have to decide what we do with builds, are we gonna handle image builds for user? or right now keeping it out of our scope and giving user a warning and asking them to build themselves?

Our target users are gonna be developers who use kompose + k8s running locally in minikube like env, so how are we gonna handle this?

I want views of all of you folks.
.
 ok got it.

IMHO for now we should skip ""builds"" and define it as ""unsupported"".

Because for images to be used within a k8s cluster they would need to be uploaded to a registry as well. So it will be difficult to run out of the box with kompose. There will be manual intervention not matter what.
.
 thanks for making this clear, will wait for what @janetkuo and @ngtuna has to say then we can close this issue! :)
.
 I agree with @runseb :smiley: 
.
 I'm +1 for @runseb
.
 Just to be clear, I also agree with @surajssd that we should give an end-to-end feel and should support ""builds"" in the future. 

We can push to a registry specified in a preference file. K8s provides [private Docker registry addon](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/registry/README.md) that we can use. 
.
 With support for openshift **buildconfig** implemented, we are now in a position to complete the end-to-end build story by supporting local builds for kubernetes and openshift.

Below, I am documenting the local build feature.

## Goal

To support ``build`` directive in a Docker Compose service for Kubernetes (and hence Openshift) by building images locally and pushing it to a registry.

## Issue

Kubernetes has a registry addon to host container images privately, but it does not have a mechanism like Openshift's buildconfig to internally build images from source in an automated way and push it to the internal registry. As a result, a kompose user trying to convert a compose file with a build directive and deploy it to kubernetes will need to do the following:

- build the image locally
- push it to a registry in use by the kubernetes setup
- may need to tinker with the image names in the artifacts generated by kompose

In order to provide a good user experience to Kubernetes Kompose users, we need to automate local image build, image upload to Kuberenetes (or Openshift) accessible registry. This will also prove to be useful for Openshift as well by allowing Kompose users (developers) to deploy local code without pushing it to a public repository.

## Proposed solution

- Use system's docker command to build image locally
- Use service name as image name, or use service's metadata to override it
- Pushing image to remote registry:
   - Use ``docker push`` CLI to push image
   - You can push push to a non default registry by specifying it using CLI option ``--target-registry``
   - Kompose will not take care of logging in to remote registry. The user needs to ensure that Docker is setup/configured to push to the target registry. Refer to [1]
- Use built image's name in deployment artifacts as needed, so that the user does not need to edit them manually.

[1]: https://docs.docker.com/engine/reference/commandline/login/.
 @rtnpro Thank you for the proposal. 
I have one question though - one of the tenet of Kompose is that the user doesn't need docker engine / CLI installed / running. This proposal assumes that Docker engine / CLI is installed and running. Is that correct? 

To be clear, I am NOT against the proposal. In fact, I would like to see this done and will highly appreciate the end-to-end feature in Kompose. But just wanted to bring this though to the table so that we know what we are changing.

 Looks good otherwise but I would appreciate other folks who are more knowledgeable than me.
.
 On Mon, Jan 2, 2017 at 10:20 AM, Pradeepto Bhattacharya
<notifications@github.com> wrote:
> @rtnpro Thank you for the proposal.
> I have one question though - one of the tenet of Kompose is that the user
> doesn't need docker engine / CLI installed / running. This proposal assumes
> that Docker engine / CLI is installed and running. Is that correct?

Yes
.
 @pradeepto 
> I have one question though - one of the tenet of Kompose is that the user doesn't need docker engine / CLI installed / running.

If we assume that Kompose is used by developers developing containerized applications that they will need Docker anyway. (More so if they have docker-compose file with `build`. So I would say that Docker as requirement for supporting  builds is fair.

Kompose will be still useful without Docker (it will be required only if build is used)


@rtnpro 
> Use service name as image name, or use service's metadata to override it

We don't need any metadata to override it. 
Yes by default service name is used as image name, but it can be overridden by `image` field in docker-compose file.

Ff you have docker-compose file like this:
```yaml
 version: '2'
 services:
   foo:
     build: .
     image: myregistry.example.com/myimage:v0.1
```
You don't need any additional information you have everything that you need. (Expecting that docker is already authenticated to access myregistr.example.com)
.
 +1. I think that makes sense to have Kompose triggers the `docker build`, then having docker installed or not is out of kompose's scope. I suggest to define kompose label for target repository instead of flag..
 >  I suggest to define kompose label for target repository instead of flag.

we don't need label for that. As repository is part of the image name and that can be set by `image` keyword in docker-compose file.

.
 > we don't need label for that. As repository is part of the image name and that can be set by image keyword in docker-compose file.

Yes I agree. If user doesn't set repository in the image name then we make the default to docker hub..
 But also consider the part where images need to be pushed to registry? Who will do that user does manually or kompose does build and push both(using docker in backend)?.
 > But also consider the part where images need to be pushed to registry? Who will do that user does manually or kompose does build and push both(using docker in backend)?

Kompose will do it. It will use docker engine to do build and push.



.
 okay so we are assuming here that user will have:

- docker daemon running locally
- setup docker-registry
- docker daemon is set up to push to private registry by adding registry info in `/etc/sysconfig/docker`
- user is authenticated with the registry
.
 > docker daemon running locally

Yes, it will be usually local docker or boot2docker on mac.
Technically he need just docker client configured to connect to any docker daemon.

> setup docker-registry

That is one of the options that user has. He can use some hosted registry like Docker Hub or quay.io
In case of OpenShift, it is possible to use integrated registry, if it is exposed.

> docker daemon is set up to push to private registry by adding registry info in /etc/sysconfig/docker

If his registry is signed by untrusted certification authority or selfsigned, than yes.

> user is authenticated with the registry

yes


But overall it is yes to your list. It is not that great UX as with just docker-compose but this is by design more complicated thing. We can do this to start with it, and than improve it if we figure out how..
 Initial work pushed to #372 .
 In case of supporting local builds for openshift, let's add an optional flag: ``--local-build`` for ``convert`` for openshift provider. By default, Openshift will use buildconfig..
 I would probably do it other way around. As BuildConfig requires relaxed
permissions on OpenShift cluster that are not in default configurations. I
think that we should use local build as default for OpenShift.

On Wed, Jan 11, 2017 at 1:58 PM, Ratnadeep Debnath <notifications@github.com
> wrote:

> In case of supporting local builds for openshift, let's add an optional
> flag: --local-build for convert for openshift provider. By default,
> Openshift will use buildconfig.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/kubernetes-incubator/kompose/issues/97#issuecomment-271862027>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AADfdpJEWRSr9dbV_v_G_nekGyuFp_rIks5rRNIDgaJpZM4JhUBg>
> .
>
.
 #521 Has been merged! :tada: :tada: :tada: Let's close this! :+1: .
 "
,,96,"Support BuildConfigs for openshift provider.
 When the provider is selected as `openshift` and if docker-compose file has `build` directive then create a `buildconfig` out of it, along with `deploymentconfig` and `service`
.
 I want to work on this issue.
.
 @rtnpro I am thinking of handling builds in multiple ways:
- When user has git repo create a [buildconfig](https://docs.openshift.org/latest/dev_guide/builds.html) and [imagestream](https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#image-streams) using that git directory info
- But a user might also wanna do a local build, so he wants build to happen using dockerfile, so i am working on a parallel build story which will build docker images using [imagebuilder](https://github.com/openshift/imagebuilder/) and that image names can be added to [deploymentconfig](https://docs.openshift.com/enterprise/3.0/dev_guide/deployments.html) and made to use those images rather than pulling it from docker hub, so I am planning to add a flag to kompose cli which does this, but this assumes that user will be running a single node cluster using minikube or minishift or CDK and user will have to export some variables that enables us to talk to remote docker daemon.
.
 > But a user might also wanna do a local build, so he wants build to happen using dockerfile, so i am working on a parallel build story which will build docker images using imagebuilder and that image names can be added to deploymentconfig and made to use those images rather than pulling it from docker hub, so I am planning to add a flag to kompose cli which does this, but this assumes that user will be running a single node cluster using minikube or minishift or CDK and user will have to export some variables that enables us to talk to remote docker daemon.

To  be honest, I don't like assumption that user is using single node cluster. 
And even than I don't think that majority of users are going to run kompose on same machine where their single node cluster is running. For example if I'm using minikube I'm never going to run kompose in minikube VM.
.
 @kadel 
- We assume that user will run a single node only when that flag is provided
- We can do builds on that cluster machine, only if the environment variables are exported, using imagebuilder. Remote builds are possible once we export those environments.
- User will be running kompose on his machine not on the cluster machine.
.
 My issue with this is that it is quite limiting :-( This requires that you have single node cluster, and that you have remote access to that docker daemon. 

Wouldn't be better to build that image locally and that push it to OpenShift's registry? We have done similar thing in [OpenShift2Nulecule](https://github.com/projectatomic/openshift2nulecule). This will also work with clusters. OpenShift has already internal registry and for Kubernetes  we can use its registry addon as mentioned in https://github.com/skippbox/kompose/issues/97#issuecomment-239018220
.
 So going ahead we right now only implement what OpenShift by default provides, which is detect the source code's git remote and create buildConfigs with that info in buildconfig artifact.

Further we still have to work on doing local builds without having to rely on remote git repo.
.
 > So going ahead we right now only implement what OpenShift by default provides, which is detect the source code's git remote and create buildConfigs with that info in buildconfig artifact.

Just to explain this more deeply how this is example who will work:
I have cloned repo github.com/foo/bar on my local machine.
In this repo is docker-compose.yml that looks like this:

``` yaml
versoin: 2
services:
   foo:
      build: ./
```

When you run kompose on this file, kompose will try to detect remote of this git and use it as source for build.
generated BuildConfig will probably look something like this:

``` yml
  apiVersion: v1
  kind: BuildConfig
  metadata:
    name: foo
  spec:
    output:
      to:
        kind: ImageStreamTag
        name: foo:latest
    source:
      type: Git
      git:
        ref: master
        uri: http://github.com/foo/bar
      contextDir: ./
    strategy:
      dockerStrategy:
        type: Docker
        from:
          kind: ImageStreamTag
          name: foo:from
    triggers:
      - type: ConfigChange
      - type: ImageChange
```

**This means that build is not from local directory but from remote git repository. 
Only what is committed and pushed to remote is build.**
.
 @sebgoa can you please assign @rtnpro to this issue? 
.
 @rtnpro you need to accept the invitation to the kompose contributor team
.
 just a thought, is there a way to run docker in docker in a Kubernetes pod ?
.
 > just a thought, is there a way to run docker in docker in a Kubernetes pod ?

it would require root access, so it depends on how you have the cluster set up. I think overall it's not going to be an option, though. 
.
 Hi @bgrant0607, what was reason for removing @rtnpro  from this? Or it was just something that happened during move to incubator?
.
 @kadel It just happened during the move. Only org members can be assigned to issues and PRs. I had to invite all kompose contributors to the kubernetes-incubator org.
.
 @bgrant0607 Thank you. I thought that this was it.
.
 Can this issue be closed via https://github.com/kubernetes-incubator/kompose/pull/206 ? cc @surajssd @rtnpro .
 since https://github.com/kubernetes-incubator/kompose/pull/206 is merged, closing this in favour of more specific issue https://github.com/kubernetes-incubator/kompose/issues/353.
 "
,,95,"Update libcompose to v0.3.0.
 There is new release of libcompose with support for v2 compose.
We should update our dependencies to use this release.
.
 please do libcompose head once https://github.com/docker/libcompose/pull/358 gets in! beause it will fix https://github.com/skippbox/kompose/issues/92 as well :)
.
 :ok_hand: 
.
 I have created PR #112 that updates to libcompose v0.3.0.
After fix for #92 is merged to libcompose we can do another separate update
.
 @kadel sure not a problem :+1: 
.
 "
,,94,"Output List kind object when using stdout.
 Now user gets a `List` kind object when putting eveything on stdout or in a single file.

Fixes #73
.
 @ngtuna rebased on the current master and now working to make charts output workable
.
 There are currently two issues with the chart creation, first it 
- creates the converted files in json in the directory you are calling kompose from
- then creates helm directory structure in the directory where docker-compose file resides
.
 For the thing about having services first I have created a function https://github.com/skippbox/kompose/pull/94/files#diff-41d801ef80f1858d5e8e9695667e4dafR1302 called from Up https://github.com/skippbox/kompose/pull/94/files#diff-41d801ef80f1858d5e8e9695667e4dafR1281
.
 "
,,93,"Run tests on travis-ci.
 related to #34 
-  run commandline tests and unit test on travis-ci (`make test-unit` and `make test-cmd`)
- `make binary` builds only binary for current arch platform where script is running (no cross compiling)
- added `make binary-cross` same as former `make binary` (cross compile for mac/linux/win 386/amd65)

command line test is failing because of #88 and #92 
.
 +1, we just need to check the tests
.
 👍 @kadel. I will check this after dinner.
.
 @kadel I tested on ubuntu 16.04.
- `make binary-cross` doesn't output binaries.
- `make binary-cross` and `make binary` doesn't print anything. It would be better to print output then user can see what's happening like this:

``` console
$ make binary
./script/make.sh binary
---> Making bundle: binary (in .)

Number of parallel builds: 1

-->   windows/amd64: github.com/skippbox/kompose/cli/main
-->       linux/386: github.com/skippbox/kompose/cli/main
-->      darwin/386: github.com/skippbox/kompose/cli/main
-->    darwin/amd64: github.com/skippbox/kompose/cli/main
-->     linux/amd64: github.com/skippbox/kompose/cli/main
-->     windows/386: github.com/skippbox/kompose/cli/main
```
.
 ahh my bad :smile: `make binary-cross` points to `makes.sh binary`, to it just builds for current platform :-) I'll fix that and I'll also add info about successful build for `make binary`.

Thank you for noticing that.
.
 "
,,92,"Image name not given still kompose does not errors out.
 Using docker-compose file that has no field for image, so this should error out, but this still works.

``` yaml
$ cat /tmp/docker-compose-no-image.yml 
version: ""2""

services:
  mariadb:
    ports:
      - 3306
```

output

``` yaml
$ kompose convert --stdout -y -f /tmp/docker-compose-no-image.yml                                                                                                                       
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  ports:
  - name: ""3306""
    port: 3306
    protocol: TCP
    targetPort: 3306
  selector:
    service: mariadb
status:
  loadBalancer: {}

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  replicas: 1
  selector:
    matchLabels:
      service: mariadb
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        service: mariadb
    spec:
      containers:
      - name: mariadb
        ports:
        - containerPort: 3306
          protocol: TCP
        resources: {}
      restartPolicy: Always
status: {}

---
```
.
 is there a way to validate the docker-compose file with lib compose ?
.
 @runseb : `docker-compose` has this validation. `libcompose` should have. 

``` console
$ cat docker-compose.yml
web:
  links:
   - redis
redis:

$ docker-compose up
ERROR: The Compose file is invalid because:
Service web has neither an image nor a build context specified. At least one must be provided.
```
.
 Found it.
https://github.com/docker/libcompose/blob/master/config/validation.go#L263

@surajssd you will see `kompose` currently use function Parse() of `libcompose` in order to read compose file. It should then call to `validateServiceConstraints()` above.
.
 @ngtuna thanks for that pointer :-)
.
 @ngtuna now when I started working on this, looks like function [`validateServiceConstraints`](https://github.com/docker/libcompose/blob/master/config/validation.go#L263) is not exported so, we might need different way to validate the values.
.
 Also with libcompose I found this thing:

``` yaml
[vagrant@fedora tmp]$ cat docker-compose.yml 
version: ""2""

services:
  mariadb:
    ports:
      - 3306
```

somehow the docker-compose warning is not what I get

``` bash
[vagrant@fedora tmp]$ libcompose up
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
INFO[0000] [0/1] [mariadb]: Starting                    
ERRO[0000] Failed Starting mariadb : Error: No such image: tmp_mariadb 
ERRO[0000] Failed to start: mariadb : Error: No such image: tmp_mariadb 
Error: No such image: tmp_mariadb
```

Using following libcompose version

``` bash
$ libcompose version
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
Version:      0.3.0-dev (HEAD)
Go version:   go1.6.3
```

It didn't tell me that I have not put image name!
.
 But for a docker-compose file of v1 like this

``` yaml
[vagrant@fedora tmp]$ cat docker-compose.yml
mariadb:
  ports:
    - 3306
```

I get errors similar to docker-compose

``` bash
[vagrant@fedora tmp]$ libcompose up
WARN[0000] Note: This is an experimental alternate implementation of the Compose CLI (https://github.com/docker/compose) 
ERRO[0000] Could not parse config for project tmp : Service 'mariadb' has neither an image nor a build path specified. Exactly one must be provided. 
FATA[0000] Failed to read project: Service 'mariadb' has neither an image nor a build path specified. Exactly one must be provided.
```
.
 Filed issue in libcompose https://github.com/docker/libcompose/issues/357
.
 @surajssd @ngtuna looks like lib compose now got validation for v2 https://github.com/docker/libcompose/pull/371

We should try to close this.
.
 Well yeah, upgrade libcompose will help solving couple of problems. 
Hey @kadel , I could help to do that while you are taking care of k8s go client.
.
 @ngtuna sure, go ahead
.
 closed via https://github.com/skippbox/kompose/pull/195
.
 @ngtuna this is issue is not fixed yet!
.
 docker-compose file

``` yaml
$ cat docker-compose-no-image.yml 
version: ""2""

services:
  mariadb:
    ports:
      - 3306

  etherpad:
    ports:
      - ""80:9001""
```

output

``` yaml
$ kompose -f docker-compose-no-image.yml convert --stdout -y
apiVersion: v1
items:
- apiVersion: v1
  kind: Service
[SNIP]
    loadBalancer: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    name: mariadb
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          service: mariadb
      spec:
        containers:
        - name: mariadb
          ports:
          - containerPort: 3306
            protocol: TCP
          resources: {}
        restartPolicy: Always
  status: {}
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    creationTimestamp: null
    name: etherpad
  spec:
    replicas: 1
    strategy: {}
    template:
      metadata:
        creationTimestamp: null
        labels:
          service: etherpad
      spec:
        containers:
        - name: etherpad
          ports:
          - containerPort: 9001
            protocol: TCP
          resources: {}
        restartPolicy: Always
  status: {}
kind: List
metadata: {}
```
.
 Oh you're right. Thanks @surajssd good catch. If that's compose version 1, kompose worked. But it seems does not work on version 2. Let me check.
.
 @ngtuna any news on this.

.
 @sebgoa it's still there. Just tested with libcompose HEAD. Let me just tackling it directly without libcompose.
.
 This issue just be solved in libcompose https://github.com/docker/libcompose/issues/415. Will check that piece of code shortly..
 "
,,91,"loader-transformer.
 Fixes #55 

Added:
- loader, transformer interfaces
  - LoadFile(file string) KomposeObject
  - Transform(KomposeObject, ConvertOptions)
- bundlefile, compose packages
- kubernetes, openshift packages

@kadel Please take a review and give me your comments.
.
 I think that it would be great to clean up `pkg/transformer/utils.go` a little bit more (see my inline comment) But otherwise it looks good :+1: 

It would be great if @janetkuo could also check this.
.
 And our only unit test now fails :smiley: 

```
# github.com/skippbox/kompose/cli/app
cli/app/app_test.go:102: undefined: parseVolume
FAIL    github.com/skippbox/kompose/cli/app [build failed]
```
.
 Thanks @kadel .

Originally, I put all Init\* functions into kubernetes package. However, from my viewpoint, kompose support converting input to kubernetes-based providers' primitives. So I moved all basic functions (like Init*) to transformer's utils.
.
 Well it should fail as `parseVolume()` now is moved to `transformer` package :smile_cat: 
.
 > Originally, I put all Init\* functions into kubernetes package. However, from my viewpoint, kompose support converting input to kubernetes-based providers' primitives. So I moved all basic functions (like Init*) to transformer's utils.

I don't know, for me it seems inconsistent, because you have `Init*` functions in generic `transformer` package but for example `UpdateController`, that operates on those objects, is in `kubernetes`.

For me it seems to be more logical to have everything that works with kubernetes together.
.
 > I don't know, for me it seems inconsistent, because you have Init\* functions in generic transformer package but for example UpdateController, that operates on those objects, is in kubernetes.
> For me it seems to be more logical to have everything that works with kubernetes together.

Okay, I agree. That would be very easy to fix. I will move them to Kubernetes except non-related k8s functions such as `print()`, `createOutFile()` or `randStringBytes()` So I will stay tuned for @janetkuo 's comments prior to get it merged.
.
 Ah, I totally missed this PR...
.
 "
,,90,"enhance warning: networks, network config, volume config. Fixes #88, #71.
 @janetkuo : I added warning for `volume config` and `network config`.
@surajssd : `networks` key is checked. However, please take a look at [FIXME](https://github.com/ngtuna/kompose/blob/unsupported-keys/cli/app/app.go#L869) and leave me your thought.
.
 Fixes #75 as well
.
 Nice LGTM!
.
 Thanks @surajssd . It needs one more `+1` from @janetkuo to get the PR merged :wink: 
.
 @janetkuo: I added a `fixing-typos` commit. I'm gonna merge this PR for accelerating the progress. If we test and find somehow the networks warning is still not good enough (as you mentioned the case of default/custom network above), we can always open issue for that.
.
 "
,,89,"Functional Testing for kompose cmdline.
 Shell scripts to test k8s and os conversion
.
 Super! Thanks @surajssd for the patch.
.
 @surajssd I ran the test by executing `test/cmd/tests.sh` and got fails look similar this one:

``` console
===> Starting test <===
convert::expect_success_and_warning: Running: 'kompose convert --stdout -f /home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/test/fixtures/etherpad/docker-compose.yml' expected_output: '/home/tuna/workspace/gocode-kompose/src/github.com/skippbox/kompose/test/fixtures/etherpad/output-k8s.json' expected_warning: 'Unsupported key depends_on - ignoring'
jq: Unknown option --argfile
Use jq --help for help with command-line options,
or see the jq documentation at http://stedolan.github.com/jq
FAIL: converted output does not match
```

Also note: `jq` is prerequisite. We should mention it in README.
.
 Also, could you move test/ to script's subfolder ? Thanks.
.
 @ngtuna I am using `jq - commandline JSON processor [version 1.5]` what version are you using?
.
 @surajssd mine is `jq 1.3` (latest on ubuntu 14.04). So it needs `jq` 1.5. If you mention this requirement in `test/README.md` then we should be good.
.
 I have moved this under `script` directory.
.
 "
,,88,"Wrong warning about networks.
 wrong warning about networks not supported, even if networks not provided: `WARN[0000] Unsupported key networks - ignoring`

using `docker-compose.yml`

``` yaml
$ cat docker-compose.yml 
version: ""2""

services:
  redis:
    image: dharmit/redis
    command: redis-server
    ports:
      - ""6379""
    volumes:
      - /opt/redis:/redis

  flask:
    image: dharmit/flask
    ports:
      - ""31000:5000""
    depends_on:
      - redis
    environment:
      REDIS_PORT: 6379
      REDIS_HOST: redis
```

Output

``` yaml
$ kompose convert --stdout -f docker-compose.yml -y
WARN[0000] Unsupported key depends_on - ignoring        
WARN[0000] Unsupported key networks - ignoring          
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: redis
  name: redis
spec:
  ports:
  - name: ""6379""
    port: 6379
```
.
 Good catch @surajssd . And I believe only `networks` field causes this issue as it is pointer (only) in `ServiceConfig` struct. 
.
 "
,,87,"Validate input args .
 I found myself often do this `kompose convert abc.yml` (should be `kompose convert -f abc.yml`) and kompose will convert docker-compose.yml for me without any warning (unexpectedly and surprisingly, if I don't pay attention). 

`kompose` should print some error messages in this case to prevent misuse/confusion. 
.
 @janetkuo this has been fixed in https://github.com/kubernetes-incubator/kompose/pull/211

``` bash
$ kompose convert abc.yml
FATA[0000] Unknown Argument(s): abc.yml 
```
.
 closing.
 ```
$ kompose convert abc.yml
FATA[0000] Unknown Argument(s): abc.yml
```
This may be called ""fixed"" as for _""will convert docker-compose.yml for me without any warning""_, but it's really a very confusing error message.

Show Case
--------------
I found myself in the situation that the usage is actually not matching the real behavior:
```
$ kompose path/to/docker-compose.yml 
Error: unknown command ""path/to/docker-compose.yml"" for ""kompose""
Run 'kompose --help' for usage.
unknown command ""path/to/docker-compose.yml"" for ""kompose""
$ kompose --help
Kompose is a tool to help users who are familiar with docker-compose move to Kubernetes.

Usage:
  kompose [command]

Available Commands:
  completion  Output shell completion code
  convert     Convert a Docker Compose file
  down        Delete instantiated services/deployments from kubernetes
  help        Help about any command
  up          Deploy your Dockerized application to a container orchestrator.
  version     Print the version of Kompose

Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
  -h, --help                help for kompose
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output

Use ""kompose [command] --help"" for more information about a command.
$ kompose convert --help
Convert a Docker Compose file

Usage:
  kompose convert [file] [flags]

Kubernetes Flags:
      --daemon-set               Generate a Kubernetes daemonset object (deprecated, use --controller instead)
  -d, --deployment               Generate a Kubernetes deployment object (deprecated, use --controller instead)
  -c, --chart                    Create a Helm chart for converted objects
      --replication-controller   Generate a Kubernetes replication controller object (deprecated, use --controller instead)

OpenShift Flags:
      --build-branch             Specify repository branch to use for buildconfig (default is current branch name)
      --build-repo               Specify source repository for buildconfig (default is current branch's remote url)
      --deployment-config        Generate an OpenShift deployment config object
      --insecure-repository      Specify to use insecure docker repository while generating Openshift image stream object

Flags:
      --build string        Set the type of build (""local""|""build-config""(OpenShift only)|""none"") (default ""none"")
      --controller string   Set the output controller (""deployment""|""daemonSet""|""replicationController"")
  -h, --help                help for convert
  -j, --json                Generate resource files into JSON format
  -o, --out string          Specify a file name to save objects to
      --replicas int        Specify the number of replicas in the generated resource spec (default 1)
      --stdout              Print converted objects to stdout
      --volumes string      Volumes to be generated (""persistentVolumeClaim""|""emptyDir""|""hostPath"") (default ""persistentVolumeClaim"")

Global Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output
```
Alright, the file name after the ""convert"" command should be fine, shouldn't it? Let's try:
```
$ kompose convert path/to/docker-compose.yml
FATA Unknown Argument(s): path/to/docker-compose.yml
$ cd path/to/
$ kompose convert docker-compose.yml
FATA Unknown Argument(s): path/to/docker-compose.yml
$ kompose convert
WARN Unsupported depends_on key - ignoring
INFO Kubernetes file ""web-service.yaml"" created
INFO Kubernetes file ""db-deployment.yaml"" created
INFO Kubernetes file ""web-deployment.yaml"" created
```

It's simply not clear from the usage why specifying a file name after the ""convert"" command results in an ""unknown argument"".

Version Info
------------

```
$ kompose --version
Error: unknown flag: --version
Usage:
  kompose [command]

Available Commands:
  completion  Output shell completion code
  convert     Convert a Docker Compose file
  down        Delete instantiated services/deployments from kubernetes
  help        Help about any command
  up          Deploy your Dockerized application to a container orchestrator.
  version     Print the version of Kompose

Flags:
      --error-on-warning    Treat any warning as an error
  -f, --file stringArray    Specify an alternative compose file
  -h, --help                help for kompose
      --provider string     Specify a provider. Kubernetes or OpenShift. (default ""kubernetes"")
      --suppress-warnings   Suppress all warnings
  -v, --verbose             verbose output

Use ""kompose [command] --help"" for more information about a command.

unknown flag: --version
$ kompose version
1.13.0 (84fa826)
```

:woman_facepalming: :see_no_evil: .
 "
,,86,"New behavior of kompose up.
 Fix https://github.com/skippbox/kompose/issues/40

/cc @janetkuo 
.
 How do we handle the case that the converted k8s object is invalid (missing required fields)? Users would enter a weird state that their dockerized / kubernized apps are created partially. 

``` console
$ kompose up -f docker-voting.yml 
We are going to create deployment controller and service for your dockerized application. 
If you need more kind of controllers, consider to use kompose convert and kubectl. 

WARN[0000] Unsupported key networks - ignoring          
WARN[0000] Unsupported key build - ignoring             
WARN[0000] [worker] Service cannot be created because of missing port. 
WARN[0000] [db] Service cannot be created because of missing port. 
Service result has been created.
Service vote has been created.
FATA[0000] Failed to unmarshal worker to service object: unexpected end of JSON input
```

Something to think about. We may fix it in a follow-up PR. 
.
 Thanks @janetkuo . I added a commit https://github.com/skippbox/kompose/pull/86/commits/82495e8c2b09d7602472a88a0473b20d05e5c79f based on your comments. The last comment of handling invalid converted k8s object will be fixed in a follow-up PR.
.
 Thanks @janetkuo. I fixed it with an 'amended' commit.
.
 "
,,85,"The example .dsb file doesn't work .
 ``` console
$ kompose convert -f docker-compose-bundle.dsb
ERRO[0000] Could not parse config for project examples : Unknown resolution for '0.1' using <config.RawService Value> at line 23, column 13 
FATA[0000] Failed to load compose file: Unknown resolution for '0.1' using <config.RawService Value> at line 23, column 13
```

I guess it's due to recent libcompose update to v2, and updating .dsb to .dab with the latest docker-compose should fix it. 
.
 Hey @janetkuo , `dsb` is bundle format, you should use `kompose convert --bundle docker-compose-bundle.dsb`
.
 Ah... I totally forgot :smile: 
.
 "
,,84,"Converting compose labels to k8s annotations.
 Fixes #81
.
 "
,,83,"Clean up kompose help, remove support for unimplemented commands.
 Fixes #76 
1. Updated `kompose`: command name becomes ""kompose - A tool helping Docker Compose users move to Kubernetes."".  Removed support for `up`, `scale`, `delete`, `ps` (we'll add them back once they're implemented).  Removed global options not in-use (`--debug`, `-f`)
2. Updated `kompose convert help`: name becomes ""kompose convert - Convert Docker Compose file (e.g. docker-compose.yml) to Kubernetes objects""
3. Removed `kompose up` from README
.
 "
,,82,"We should have a table / document for docker-compose to k8s / openshift conversion  .
 It'll be helpful for developers and users to have such docs. 
.
 We can probably auto-generate this. 
.
 @janetkuo You should talk to @kadel I remember him doing something similar for henge.
.
 so @kadel can you help ?
.
 I started this for Henge, but I just had rough draft, you can see it in Henge's wiki https://github.com/redhat-developer/henge/wiki/Mappings We also had some internal document describing this with more details. I will try to find it and see if we can use that.

I really like @janetkuo idea of auto-generating this. How would you like to do that? 
.
 I'm thinking about using yaml tags of each field of different struct (libcompose, kobject, and kubernetes objects) and creating `map[string]string` that maps one yaml tag to another (e.g. libcompose ServiceConfig's `image` maps to kobject's `image` which maps to k8s Container `image`). We can use that in code for conversion as well as auto-generate the table by printing the map. WDYT?
.
 I never thought about using tags like this. It sounds cool.
.
 @kadel as we have conversion table at http://kompose.io/conversion/, we can close this issue..
 @surajnarwade :+1: Closin'.
 "
,,81,"docker-compose labels should be converted to k8s annotations instead of labels .
 Compose labels are just metadata, unlike k8s labels, which is used to organize / categorize objects. 
.
 "
,,80,"Add warnings/error for image not specified .
 Follow-up https://github.com/skippbox/kompose/pull/79#issuecomment-237332663:

`image` is a required field in Kubernetes and without it the generated file can't be used. 

From [compose spec](https://docs.docker.com/compose/compose-file), v1 doesn't allow `image` being specified with `build`, and v2 allows you to do that but the `image` will be built from `build`. 

We can print an error when we see `build` in the compose file. Would love to hear more thoughts. 
.
 With Kubernetes:
- `image` is must, until we come up with a build story

With OpenShift:
- If `build` given we can create `buildconfig`
- if `image` given well and good

cc: @kadel 
.
 Currently there is an unsupported key message if we see `build` in the compose file.
@surajssd : while working on the issue https://github.com/skippbox/kompose/issues/92 of having `image` and `build` in the same compose service, you can also add a check for required fields like `image`
.
 Closed via https://github.com/skippbox/kompose/pull/195
.
 "
,,79,"Enable warnings in stdout.
 Ref #71

With this change, you see warnings even when `--stdout` is specified:

``` console
$ kompose convert -f docker-voting.yml -y --stdout | kubectl create -f - 
time=""2016-08-03T11:39:37-07:00"" level=warning msg=""Unsupported key build - ignoring"" 
time=""2016-08-03T11:39:37-07:00"" level=warning msg=""Unsupported key networks - ignoring"" 
time=""2016-08-03T11:39:37-07:00"" level=warning msg=""[worker] Service cannot be created because of missing port."" 
time=""2016-08-03T11:39:37-07:00"" level=warning msg=""[db] Service cannot be created because of missing port."" 
service ""redis"" created
service ""result"" created
service ""vote"" created
deployment ""db"" created
deployment ""redis"" created
Error from server: error when creating ""STDIN"": Deployment.extensions ""vote"" is invalid: spec.template.spec.containers[0].image: Required value
Error from server: error when creating ""STDIN"": Deployment.extensions ""worker"" is invalid: spec.template.spec.containers[0].image: Required value
Error from server: error when creating ""STDIN"": Deployment.extensions ""result"" is invalid: spec.template.spec.containers[0].image: Required value
```
.
 However we need to solve this in a separate PR/issue; filed #80

```
Error from server: error when creating ""STDIN"": Deployment.extensions ""vote"" is invalid: spec.template.spec.containers[0].image: Required value
Error from server: error when creating ""STDIN"": Deployment.extensions ""worker"" is invalid: spec.template.spec.containers[0].image: Required value
Error from server: error when creating ""STDIN"": Deployment.extensions ""result"" is invalid: spec.template.spec.containers[0].image: Required value
```
.
 Ah... so it means we can still print warning message and the pipeline ignores it... So actually my previous commit https://github.com/skippbox/kompose/commit/72fc1a2f4279f3ca15ebadcb60fb5562d29ba1dc is unnecessary...
.
 Yes, I believe those warnings are printed to stderr so it won't mingle with real output
.
 "
,,78,"Convert volumes in [name:][host:]container[:access_mode] format.
 #75
.
 @janetkuo did you test with compose v1 which doesn't include volume name ?
.
 Yes, I tested against `docker-gitlab.yml`, and an example output is:

``` console
$ kompose convert -f docker-gitlab.yml -y 
file ""postgresql-svc.yaml"" created
file ""redisio-svc.yaml"" created
file ""gitlab-svc.yaml"" created
file ""redisio-deployment.yaml"" created
file ""gitlab-deployment.yaml"" created
file ""postgresql-deployment.yaml"" created

$ cat redisio-deployment.yaml 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    service: redisio
  name: redisio
spec:
  replicas: 1
  selector:
    matchLabels:
      service: redisio
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        service: redisio
    spec:
      containers:
      - image: sameersbn/redis
        name: redisio
        ports:
        - containerPort: 6379
          protocol: TCP
        resources: {}
        volumeMounts:
        - mountPath: /var/lib/redis
          name: ls6k1hh2gdnyxxvi7hvs
      restartPolicy: Always
      volumes:
      - hostPath:
          path: /srv/docker/gitlab/redis
        name: ls6k1hh2gdnyxxvi7hvs
status: {}
```
.
 Just rebased. 
.
 I added a unit test, tested locally with `go test -tags experimental` (how do we enable testing in travis?)
.
 "
,,77,"Volumes default not read-only.
 #75
.
 "
,,76,"Kompose help needs improvment.
 Current `kompose help` gives me:

```
$ ./kompose -h 
NAME:
   kompose - Command line interface for Skippbox.

USAGE:
   kompose [global options] command [command options] [arguments...]

VERSION:
   0.0.1-beta (HEAD)

AUTHOR(S):
   Skippbox Compose Contributors <https://github.com/skippbox/kompose> 

COMMANDS:
    convert Convert docker-compose.yml to Kubernetes objects
    up      Submit rc, svc objects to kubernetes API endpoint
    ps      Get active data in the kubernetes cluster
    delete  Remove instantiated services/rc from kubernetes
    scale   Globally scale instantiated replication controllers

GLOBAL OPTIONS:
   --verbose, --debug           
   --file, -f ""docker-compose.yml""  Specify an alternate compose file (default: docker-compose.yml) [$COMPOSE_FILE]
   --help, -h               show help
   --generate-bash-completion       
   --version, -v            print the version
```

A few things need improvement:
1. ""Command line interface for Skippbox"" is vague to me as a description of `kompose` (users may ask: so what does this CLI do?). 
2. up/ps/delete/scale didn't work for now, but still shows up in help 
3. Global options aren't actually global. They only belong to `kompose` but not its subcommands (except for `--help, -h`, but it's not shown in subcommand help). 
.
 "
,,75,"Problems of converting volumes.
 A few problems I discovered specific to `volumes`:
1. In kompose conversion logic, a volume is created as read-only by default. However, in Kubernetes spec, container volumeMounts is read-write by default; same as docker-compose (I believe so from looking at the file format, please correct me if not). 
2. We create `emptyDir` for volumes, but if host is specified (i.e. `HOST:CONTAINER`, see [spec](https://docs.docker.com/compose/compose-file/#/volumes-volume-driver)), shouldn't we use `hostPath` instead?
3. We create a random string (length of 20) for volume names, which it's not readable; also, volume names defined in docker-compose.yml file is ignored. 
.
 Thanks @janetkuo for pointing this out. This is an important part of kompose conversion. Firstly I would say the current volume conversion was outdated a little bit. I just have a quick look at this.
1. Originally compose defined a volume is in ro mode by default (correct me if I am wrong). Now I see it set to rw mode. 
2. I believe there was something missing on volume part when I did refactoring app.go. Take a look into the original code: https://github.com/skippbox/kompose/blob/9bdc4cf2dd516590135cd12bd6bf27816f0bbffd/cli/app/app.go#L415. I will check your PR immediately.
3. Volume name is not defined in [compose v1 format](https://docs.docker.com/compose/compose-file/#/version-1). That's why I created random name. Now with v2 we have named volume. Could you add a switch/check for volume conversion if the compose file is version 1 or 2 as there are some options in volume definition of compose v2 I haven't covered yet.
.
 I looked closer at the spec and libcompose, the v2 volume you mentioned are in `Project.VolumeConfigs`, which we don't support. The logic I added in #78 is to parse `Project.ServiceConfigs.Volumes` and use the volume name specified there. 

We should add warnings for not supporting VolumeConfigs too (we don't have that yet). 
.
 @janetkuo Can we close this issue by your merged PRs?
.
 Yes
.
 "
,,74,"Correctly log error.
 .
 "
,,73,"`--stdout` output as `List` kind.
 When user applies `--stdout` as commandline arg then we can output all the objects as encapsulated in `kind: List`.

So this is what openshift with `oc import docker-compose` does
I believe we can use `metadata` in `List` to display warnings!

``` yaml
apiVersion: v1
kind: List
metadata: {}
items:
- apiVersion: v1
  kind: ImageStream
[SNIP]
    dockerImageRepository: """"
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
[SNIP]
      type: ImageChange
  status: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
[SNIP]
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
[SNIP]
    selector:
      deploymentconfig: mariadb
  status:
    loadBalancer: {}
```
.
 +1 for this 
.
 +1 for this
.
 "
,,72,"Modularize convert into loader & transformer.
 This is an initial step of modularizing convert function into loader and transformer. I found a bit difficult to create the komposeObject interface due to `Go import cycle` problem. The easiest thing I can do is creating the shared struct `komposeObject` in a separate package which loader and transformer can use. Although I think komposeObject interface is still a good idea.

@kadel I'm looking for comment from your side.
.
 #55 
.
 Hi @ngtuna I just give quick look to this PR.

kobject pkg looks goot.
But with loaders and transformers I had something little bit else in my mind.
I thought that every loader and every transformer would be in its own package.
so we would have kubernets, openshift, dockercompose and bundle packages.

Decisions which loader or transformer to use would be in app.go. You are on good track with [loaders switch](https://github.com/ngtuna/kompose/blob/8cbdeded61fec9806f2385196d05b00ad54944d2/cli/app/app.go#L251) I think that there should be something similar for transformers also. If we put all that decisions outsde of tranfromers packages, it will be easy to add more transformers in the future.
But i guess this is little bit harder to do right now, as openshift and kubernetes are tight together right now :-( - but I can help with that.
.
 @kadel Agreed. I suggest that I should add one more commit to the PR for creating separate packages for every loader and transformer, then we can merge it upstream and let people contribute more based on this construction.
.
 I'm creating shared functions (lot of) for both k8s and openshift packages then we should be good. For the switch decision of which output provider that transformer should refer to, I think at this moment if `--deploymentconfig` is used, then go to openshift, otherwise go by default to k8s.
.
 @kadel There are things happened on my mind:
- Loader and transformer would be sit in their own packages no doubt. So we have at this time bundlefile, dockercompose, kubernetes, openshift packages. 
- With bundlefile & dockercompose, they shared the same sort of functions such as: 
  - loadImage()
  - loadEnvvars()
  - loadPorts()
  - others: loadWorkingDir(), loadCommand(), loadVolumes(), etc
- Similar to k8s and openshift, they also looks the same. Even they shared lot of common functions.
  - initRC()
  - initSC()
  - initDC()
  - initDS()
  - initDeploymentConfig() (OpenShift only)
  - configEnvvars()
  - configPorts()
  - configServicePorts()
  - configVolumes()
  - others: configWorkingDir(), configCommand(), etc

So, I would suggest to create loader and transformer interfaces. Then let bundlefile, dockercompose, k8s, openshift implement the interface they belong to. Upcoming providers and input formats will be implemented following this structure.

Thought?
/cc @runseb @janetkuo 
.
 :+1:  @ngtuna 
I would only suggest to make those interfaces smaller and generic so it is easy to add more transformers/loaders in future.

for loader I can image just something like this:

``` go
loadFiles(files []string) (KomposeObject, err)
```

for transformer:

``` go
loadKomopse(kobject KomposeObject, format string) (map[string]string, err)
```

returned `map[string]string` would look for example like this:

```
{ 
   ""foobar-rc.yaml"": ""
apiVersion: v1
kind: ReplicationController
.........
"",
   ""foobar-service.yaml"": ""
apiVersion: v1
kind: service
.........
}
```

That this returned map could be either saved to files, or displayed to stdout.
But I'm not sure if returning it as this big map is good idea. :-(
.
 @kadel I'm gonna merge this PR to `skippbox:loader-transfomer` and then switch to work on that branch, because there are some changes of convert function I would like to rebase from `skippbox:master`. I will send another PR for that work.
.
 "
,,71,"Print warning for unsupported fields in docker-compose format  .
 Follow up #3

We're now printing warnings of unsupported fields in their names defined in [libcompose](https://github.com/docker/libcompose/blob/release/0.2.0/config/types.go#L68), but not their names in [docker-compose file format](https://docs.docker.com/compose/compose-file/).  

For example, this 

``` console
$ cat nginx.yml
nginx:
  image: nginx
  dockerfile: foobar
  build: ./foobar
  cap_add:
    - ALL
  container_name: foobar

$ kompose convert -f nginx.yml
WARNING: Unsupported key Build - ignoring
WARNING: Unsupported key CapAdd - ignoring
WARNING: Unsupported key ContainerName - ignoring
WARNING: Unsupported key Dockerfile - ignoring
```

should give me the following warnings instead:

``` console
$ kompose convert -f nginx.yml
WARNING: Unsupported key build - ignoring
WARNING: Unsupported key cap_add - ignoring
WARNING: Unsupported key container_name - ignoring
WARNING: Unsupported key dockerfile - ignoring
```
.
 @janetkuo and @ngtuna why can we use `logrus.Warningf` instead of `fmt.Println` at https://github.com/skippbox/kompose/blob/master/cli/app/app.go#L1076 ?
.
 Also when doing `--stdout` the warnings should be either printed in  a way so that user can still pipe the output to a `kubectl`. I am not sure if I should create a new issue for this?
.
 Using following docker-compose file

``` yaml
$ cat docker-compose.yml 
version: ""2""

services:
  mariadb:
    image: centos/mariadb
    container_name: mariadb
    ports:
      - ""3306""
    environment:
      MYSQL_ROOT_PASSWORD: etherpad
      MYSQL_DATABASE: etherpad
      MYSQL_PASSWORD: etherpad
      MYSQL_USER: etherpad
```

When directly piped fails

``` bash
$ kompose convert  --stdout | kubectl --namespace=kompose create -f -
yaml: line 2: could not find expected ':'
```

Because the output starts with 

``` json
$ kompose convert  --stdout
WARNING: Unsupported key Networks - ignoring
{
  ""kind"": ""Service"",
  ""apiVersion"": ""v1"",
[SNIP]
```
.
 Good catch @janetkuo and @surajssd . Thanks. I will update shortly
.
 Closing as this is now fixed by https://github.com/skippbox/kompose/commit/55ae6e75383a3024e6ad5196d8d1280be9c7e39f
.
 Right now there are unsupported keys / fields not covered by warnings, such as [volume configs](https://docs.docker.com/compose/compose-file/#/volume-configuration-reference).  
.
 @ngtuna yes its good that we have we now don't print the output to `stdout` so I can pipe output right now! :+1: 
And this can be closed it seems.
.
 @janetkuo Agree. We haven't covered both [volume configs](https://docs.docker.com/compose/compose-file/#/volume-configuration-reference) and [network configs](https://docs.docker.com/compose/compose-file/#/network-configuration-reference).
.
 Closed by https://github.com/skippbox/kompose/commit/14cf356a08374bc069477aa47a46b340abb782b4
.
 "
,,70,"Release process .
 Follow up https://github.com/skippbox/kompose/issues/64#issuecomment-235107109:

> In the release note we can provide checksums and installation guide, something like this:
> ## Installation
> ### Linux
> 
> ```
> curl -Lo kompose https://github.com/skippbox/kompose/releases/download/v0.0.1-beta.1/kompose_linux-amd64 && chmod +x kompose && sudo mv kompose /usr/local/bin/
> ```
> ## Checksums
> ### Linux
> 
> ```
> $ openssl sha1 /usr/local/bin/kompose
> SHA1(/usr/local/bin/kompose)= 826c247a4bdca44d2b68bef48d6649dd86813ef2
> ```

We should have a release process (or did I miss it?)
.
 Just found it https://github.com/skippbox/kompose/blob/master/RELEASE.md but it seems to be copied from other project (Kubernetes)?
.
 I agree we should have release process defined.

I think that current [RELEASE.md](https://github.com/skippbox/kompose/blob/master/RELEASE.md) is from some kind of Kubernetes repo template that this was this repo based on.
.
 We should follow [semantic versioning](http://semver.org/) and test if the released binaries will work on different platforms. 
.
 Also discuss schedule of releases
.
 How about doing time based releases?

We could do release every month.
Everything that has been merged to master would be included in the release.

Thoughts?
@sebgoa @ericchiang @ngtuna @janetkuo @surajssd @cdrage .
 :+1: for timely releases @kadel .
 We discussed this at yesterday's  community meeting.
We will try to do release every month, on the last week of the given month. Versioning will follow semantic versioning standard.
.
 I'm going to eventually update the RELEASE.md document to better outline how we do releases (run the script, add SHA, etc.).
 @cdrage , are we gonna use goreleaser ?.
 @surajnarwade Eventually :) Right now the release.sh script works wonders.
 @cdrage , cool.
 With the newest release, I have added SHA256 Sums as well as installation instructions to the `release.sh` script. Hopefully this covers everything!

https://github.com/kubernetes/kompose/releases/tag/v1.0.0

.
 "
,,69,"Remove the support for converting to Replica Sets.
 Fixes #63
.
 :+1: LGTM
.
 "
,,68,"Warning on missing port information and no service created.
 Now when user will not provide any port information a warning will be shown and also service will not be created.

Fixes #58
.
 Merging since got lgtm! :)
.
 "
,,67,"Support for environment variables substitution.
 Now user can put environment variables in docker-compose file and it will be read by kompose from environment

Fixes #56
.
 The code in this PR is from https://github.com/docker/libcompose/blob/master/docker/project.go#L25

So I needed some discussion around this PR, so I checked the code in kompose [here](https://github.com/skippbox/kompose/blob/master/cli/app/app.go#L738), it is similar to code in libcompose [here](https://github.com/docker/libcompose/blob/master/docker/project.go#L25). So I was hoping we can use the function [`NewProject`](https://github.com/docker/libcompose/blob/master/docker/project.go#L25) from libcompose which is under docker package not under [project package](https://github.com/docker/libcompose/blob/master/project/project.go#L43).

So the downside of using `docker` package's `NewProject` is it returns `project.APIProject` and I would like to have a method in `project.APIProject` that returns internal data structure of type `*Project` and we don't need to repeat the code. So I will be working with libcompose to get this done. If that works out this PR will change!
.
 @surajssd I see you are changing libcompose code in `/vendor`. Is it possible to just work on kompose code base and keep libcompose as a dependency ?
.
 @ngtuna I did `godep save` to get latest code from libcompose. Is it not the right way to do it?
.
 @surajssd Ah okay you changed libcompose revision to HEAD. OK let me check it.
.
 @ngtuna @kadel How can I convert a [`APIProject`](https://github.com/docker/libcompose/blob/master/project/interface.go#L12) interface object type to [`Project`](https://github.com/docker/libcompose/blob/master/project/project.go#L23) type? Is there a way to do it?
.
 @surajssd  The reason I didn't use [NewProject](https://github.com/docker/libcompose/blob/master/docker/project.go#L25) function because I don't want kompose to be constrained by libcompose. Basically we only need its parsing function in order to parse docker compose file into komposeObject, nothing more. Otherwise, we have to follow libcompose's constraints such as it's required to have a `docker-compose.yml` file handy at the same folder.

Did you check whether your changes in cli/app/app.go still works with the current libcompose revision at HEAD master? If yes then I suggest to keep the vendoring stable and just apply your changes in app.go. I can't check it now but will do tomorrow morning.
.
 @ngtuna I checked with the vendored libcompose available I am not able to build, because I need https://github.com/skippbox/kompose/pull/67/files#diff-41d801ef80f1858d5e8e9695667e4dafR749 and it is not in the vendored `libcompose`
.
 Checked! Thanks @surajssd . Please go ahead to merge upstream.
.
 @ngtuna thank you :)
.
 "
,,66,"Development Guide: use script/godep-restore.sh.
 .
 Also one question @kadel 
In root directory if I do `godep save` it fails and when I removed the `vendor` and `Godeps` it didn't create new `vendor` and `Godeps`, I had to fo `godep save ./cli/main` and it ran alright.
.
 you have to run `godep save ./...` from project root directory
.
 Actually I got confused because docs everywhere suggests just `godep save`.
.
 @surajssd check this: https://github.com/tools/godep#multiple-packages
.
 @kadel thanks for the pointer
.
 "
,,65,"Allow --chart and --out to be specified together.
 Support `kompose convert --chart --out=<file_name>` 
.
 "
,,64,"Bug: incorrect version .
 Downloaded release file from https://github.com/skippbox/kompose/releases/tag/v0.0.1-beta.1

``` console
$ kompose --version 
kompose version 0.0.1-alpha (HEAD)
```

It should instead give me:

``` console
$ kompose --version 
kompose version 0.0.1-beta (fa0930d)
```

Related code https://github.com/skippbox/kompose/blob/master/version/version.go
.
 Also in the release note we can provide checksums and installation guide, something like this:

## Installation

### Linux

```
curl -Lo kompose https://github.com/skippbox/kompose/releases/download/v0.0.1-beta.1/kompose_linux-amd64 && chmod +x kompose && sudo mv kompose /usr/local/bin/
```

## Checksums

### Linux

```
$ openssl sha1 /usr/local/bin/kompose
SHA1(/usr/local/bin/kompose)= 826c247a4bdca44d2b68bef48d6649dd86813ef2
```
.
 closed by https://github.com/skippbox/kompose/commit/bc7705157ade6dbf2e8d5c7b142257e0b38ec223
.
 The latest release gives me 

```
$ kompose --version 
kompose version 0.0.1-beta (HEAD)
```

Shouldn't HEAD be replaced with commit number (in this case, https://github.com/skippbox/kompose/commit/c4d62c99eeeccbaaa7dbf838e79dcaf4e346c4b8)?
.
 Which release are u trying ? @janetkuo From my side:

``` console
$ wget https://github.com/skippbox/kompose/releases/download/v0.0.1-beta.2/kompose_linux-amd64.tar.gz
$ tar zxvf kompose_linux-amd64.tar.gz
$ kompose_linux-amd64/kompose --version
kompose version 0.0.1-beta (HEAD)
```

0.0.1-beta is correct, isn't it?
.
 Yes it's correct, but `HEAD` should be a commit number, right?
.
 Ah.. I missed it. You're totally right. I made a straight-forward commit to master https://github.com/skippbox/kompose/commit/1b501619b7826892155625b30a8548117d883ce3
.
 "
,,63,"Should we support converting to Replica Sets?.
 Since we discourage people from using Replica Sets directly (instead they should use Deployments), how about removing the support for converting to RS? On the other hand, converting to Replication Controllers makes sense for people haven't adopted Deployments. 
.
 I was also thinking about this and I agree completely, we should discourage people from using Replica Sets directly.
.
 Or can we have it on k8s's version ? Like for k8s 1.2 we support `Deployments` by default and for before we use replication controllers. Or introduce some kinda flag?
.
 @surajssd That will add unnecessary complications to the code base. Since kompose is new upcoming tool, I wonder if it makes sense to support features that are being actively discouraged/deprecated.

:+1:  @janetkuo with this suggestion.
.
 +1 @janetkuo 
.
 "
,,62,"Add --replicas flag and changed --rc from string to bool.
 Now we can do `kompose convert -rc` or `kompose convert --replicas=3`.

Fixes #52 
.
 Got lgtm, so merging
.
 "
,,61,"Add --bundle,-dab flag for specifying dab file.
 Now we can specify a dab file with `--bundle` or `-dab`:

``` console
$ kompose convert --bundle=docker-compose-bundle.dsb 
file ""redis-svc.json"" created
file ""web-svc.json"" created
file ""redis-deployment.json"" created
file ""web-deployment.json"" created
```

`--bundle` can't be used with `--file`: 

``` console
$ kompose convert --bundle=docker-compose-bundle.dsb --file=docker-gitlab.yml
FATA[0000] Error: compose file and dab file cannot be specified at the same time
```

Fixes #53 
.
 I add another commit for copying bundle file names for charts 
.
 "
,,60,"`targetPort` is 0 in a converted service definition.
 targetPort is 0 in a service

When doing the conversion, if a port is defined as ""3306"" it sets the service's `port` as `3306` but sets `targetPort` as `0`. This artifact works with k8s, when deployed, but the concern is of wrong/misleading info, generated. We can do a thing if a port is given as `X` set `X` as both `port` and `targetPort`. But if port given as `X:Y` we can set `targetPort` as `Y` and `port` as `X`.

I am using `docker-compose.yml` as:

``` yaml
$ cat docker-compose.yml
version: ""2""

services:
  mariadb:
    image: centos/mariadb
    ports:
      - ""3306""
    environment:
      MYSQL_ROOT_PASSWORD: etherpad
      MYSQL_DATABASE: etherpad
      MYSQL_PASSWORD: etherpad
      MYSQL_USER: etherpad
```

convert:

``` bash
$ ./kompose convert  -o output -y
file ""output"" created
```

wrong output

``` yaml
$ cat output 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  ports:
  - name: ""3306""
    port: 3306
    protocol: TCP
    targetPort: 0
  selector:
    service: mariadb
status:
  loadBalancer: {}

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  replicas: 1
  selector:
    matchLabels:
      service: mariadb
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        service: mariadb
    spec:
      containers:
      - env:
        - name: MYSQL_USER
          value: etherpad
        - name: MYSQL_DATABASE
          value: etherpad
        - name: MYSQL_PASSWORD
          value: etherpad
        - name: MYSQL_ROOT_PASSWORD
          value: etherpad
        image: centos/mariadb
        name: mariadb
        ports:
        - containerPort: 3306
          protocol: TCP
        resources: {}
      restartPolicy: Always
status: {}

---
```
.
 One more example of wrong mapping, the following docker-compose file has port mapping as ""80:9001"" so `80` should be service's `port` field value and `9001` as `targetPort` here its doing exactly opposite.

docker-compose file

``` yaml
$ cat docker-compose-two-ports.yml 
version: ""2""

services:
  etherpad:
    build: ""./myphp""
    ports:
      - ""80:9001""
```

convert

``` bash
$ ./kompose convert  -o output -y -f docker-compose-two-ports.yml 
file ""output"" created
```

output:

Observe here the value in service of `port` and `targetPort` are swapped. But in `deployment` the container definition has `containerPort` defined correctly.

``` yaml
$ cat output 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: etherpad
  name: etherpad
spec:
  ports:
  - name: ""9001""
    port: 9001
    protocol: TCP
    targetPort: 80
  selector:
    service: etherpad
status:
  loadBalancer: {}
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    service: etherpad
  name: etherpad
spec:
  replicas: 1
  selector:
    matchLabels:
      service: etherpad
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        service: etherpad
    spec:
      containers:
      - name: etherpad
        ports:
        - containerPort: 9001
          protocol: TCP
        resources: {}
      restartPolicy: Always
status: {}
---
```
.
 That's my ugly mistake. I think the `0.0.1-alpha` doing it right. But when refactoring code, I made it wrong. That would be very easy to fix.
.
 "
,,59,"panic: runtime error: invalid memory address or nil pointer dereference.
 Tried with v0.0.1-beta.1:

```
$ kompose convert -f docker-compose.yml -y
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x64c354]

goroutine 1 [running]:
panic(0x11e6760, 0xc820012110)
    /usr/local/go/src/runtime/panic.go:464 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate.func1(0xc820273df0, 0xf, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:145 +0x84
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseVariableWithBraces(0xc82018e240, 0x24, 0x11, 0xc8204cfbf8, 0x0, 0x0, 0x0, 0xc82044a0e0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:53 +0x14c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseInterpolationExpression(0xc82018e240, 0x24, 0x1, 0xc8204cfbf8, 0x0, 0x0, 0x3113, 0x410d38)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:71 +0x9b
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseLine(0xc82018e240, 0x24, 0xc8204cfbf8, 0x0, 0x0, 0x134d001)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:90 +0xbf
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseConfig(0xc8202c1b80, 0x5, 0xc8202c1b60, 0xc, 0xc8204cfb78, 0xc8204cfbf8, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:110 +0x532
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate(0x0, 0x0, 0xc8204cfd48, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:144 +0x1c4
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.MergeServicesV2(0xc820459840, 0x0, 0x0, 0x0, 0x0, 0xc820459820, 0x12, 0xc8203f7500, 0x3113, 0x3313, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge_v2.go:22 +0x12a
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Merge(0xc820459840, 0x0, 0x0, 0x0, 0x0, 0xc820459820, 0x12, 0xc8203f7500, 0x3113, 0x3313, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge.go:40 +0x24c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc82045ad00, 0xc820459820, 0x12, 0xc8203f7500, 0x3113, 0x3313, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:178 +0xe5
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc82045ad00, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:86 +0x335
github.com/skippbox/kompose/cli/app.loadComposeFile(0xc820459820, 0x12, 0xc820349180, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/app/app.go:733 +0x1b6
github.com/skippbox/kompose/cli/app.Convert(0xc820349180)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/app/app.go:1028 +0x4b9
github.com/skippbox/kompose/cli/command.ConvertCommand.func1(0xc820349180)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/command/command.go:30 +0x21
github.com/skippbox/kompose/vendor/github.com/urfave/cli.Command.Run(0x13e2208, 0x7, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1593620, 0x30, 0x0, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/command.go:179 +0x1399
github.com/skippbox/kompose/vendor/github.com/urfave/cli.(*App).Run(0xc8204806e0, 0xc82000a0f0, 0x5, 0x5, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/app.go:196 +0x137c
main.main()
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/main/main.go:46 +0x5fe
```
.
 thanks for reporting the issue.
Probably a build issue with the pre-release I just uploaded.

What OS and arch are you on ?
.
 @sdouche also share the docker-compose file so that we can recreate it.
.
 This look related to to env variables. 
trace looks same as one in https://github.com/skippbox/kompose/issues/56 
.
 @runseb sorry I forgot: Ubuntu 16.04 x64_86. @surajssd I can't share the file, it's explain the internal stack we use. I'll investigate to know what is the cause.
.
 @sdouche That is ok if you can't share it.
Can you confirm my hunch that you have variable substation  in your docker-compose file?
Something similar to this?

``` yaml
    environment:
      FOO : $BAR
```
.
 Good hint @kadel  I've a bunch of `image: ${DOCKER_REGISTRY}redis`. But I've the same error with `komposer convert` (w/o any argument): 

```
$ kompose convert
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x64c354]

goroutine 1 [running]:
panic(0x11e6760, 0xc820014120)
    /usr/local/go/src/runtime/panic.go:464 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate.func1(0xc820196c70, 0xf, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:145 +0x84
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseVariableWithBraces(0xc8202a96e0, 0x23, 0x11, 0xc82052bbf8, 0x0, 0x0, 0x0, 0xc82036c380)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:53 +0x14c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseInterpolationExpression(0xc8202a96e0, 0x23, 0x1, 0xc82052bbf8, 0x0, 0x0, 0x3113, 0x410d38)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:71 +0x9b
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseLine(0xc8202a96e0, 0x23, 0xc82052bbf8, 0x0, 0x0, 0xc82052bbf8)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:90 +0xbf
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseConfig(0xc8201ff730, 0x5, 0xc8201ff6c8, 0x7, 0xc82052bb78, 0xc82052bbf8, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:110 +0x532
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate(0x0, 0x0, 0xc82052bd48, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:144 +0x1c4
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.MergeServicesV2(0xc8204cef20, 0x0, 0x0, 0x0, 0x0, 0xc8204cef00, 0x12, 0xc82043d500, 0x3113, 0x3313, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge_v2.go:22 +0x12a
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Merge(0xc8204cef20, 0x0, 0x0, 0x0, 0x0, 0xc8204cef00, 0x12, 0xc82043d500, 0x3113, 0x3313, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge.go:40 +0x24c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc820494a90, 0xc8204cef00, 0x12, 0xc82043d500, 0x3113, 0x3313, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:178 +0xe5
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc820494a90, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:86 +0x335
github.com/skippbox/kompose/cli/app.loadComposeFile(0xc8204cef00, 0x12, 0xc8203c2f00, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/app/app.go:733 +0x1b6
github.com/skippbox/kompose/cli/app.Convert(0xc8203c2f00)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/app/app.go:1028 +0x4b9
github.com/skippbox/kompose/cli/command.ConvertCommand.func1(0xc8203c2f00)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/command/command.go:30 +0x21
github.com/skippbox/kompose/vendor/github.com/urfave/cli.Command.Run(0x13e2208, 0x7, 0x0, 0x0, 0x0, 0x0, 0x0, 0x1593620, 0x30, 0x0, ...)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/command.go:179 +0x1399
github.com/skippbox/kompose/vendor/github.com/urfave/cli.(*App).Run(0xc8204991e0, 0xc82000a4c0, 0x2, 0x2, 0x0, 0x0)
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/app.go:196 +0x137c
main.main()
    /Users/sebastiengoasguen/Documents/go/src/github.com/skippbox/kompose/cli/main/main.go:46 +0x5fe
```
.
 @sdouche so I have reported similar issue before see here https://github.com/skippbox/kompose/issues/56
.
 Opps.. just notice that the issue log showing your info @runseb 
.
 yeah @ngtuna I noticed that, which is why I am thinking it is a build issue. dynamic linking of sorts ?
.
 @sdouche I tested your case with HEAD master including @surajssd 's patch https://github.com/skippbox/kompose/commit/a63d641384280e2a0473a30405c9c3cadc9e31d5, it worked. 

``` console
$ export DOCKER_REGISTRY=""http://foo.bar/""
$ cat sdouche.yml
nginx:
  image: ${DOCKER_REGISTRY}redis
$ kompose convert --file sdouche.yml
WARN[0000] [nginx] Service cannot be created because of missing port. 
file ""nginx-deployment.json"" created
$ cat redis-deployment.json
...
""spec"": {
        ""containers"": [
          {
            ""name"": ""redis"",
            ""image"": ""http://foo.bar/redis"",
            ""resources"": {}
          }
        ],
...
```

So I assume you should be good with that. The next release is coming soon this week so you can either check the master now or stay a little bit for the release.
.
 @sdouche Check out the latest release: https://github.com/skippbox/kompose/releases/tag/v0.0.1-beta.2

I'm going to close this issue. Feel free to reopen if it can't solve your case as we can't test your private compose file :-).
.
 "
,,58,"docker-compose service with no ports is mapped to k8s svc with no ports.
 When a docker-compose service is given with no ports, a corresponding k8s service is created with no port info, and this is wrong config, because port is required value.

`docker-compose.yml` file I used.

``` yaml
$ cat docker-compose-no-ports.yml 
  mariadb:
    image: centos/mariadb
    environment:
      MYSQL_ROOT_PASSWORD: etherpad
      MYSQL_DATABASE: etherpad
      MYSQL_PASSWORD: etherpad
      MYSQL_USER: etherpad
```

convert

``` bash
$ ./kompose convert -f docker-compose-no-ports.yml -o output -y
file ""output"" created
$ cat output 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  ports: []
  selector:
    service: mariadb
status:
  loadBalancer: {}

---
[SNIP]
```

When this definition is fed to kubernetes it says:

``` bash
$ kubectl create -f svc 
The Service ""mariadb"" is invalid.
spec.ports: Required value
```

Where `svc` is:

``` bash
$ cat svc 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    service: mariadb
  name: mariadb
spec:
  ports: []
  selector:
    service: mariadb
status:
  loadBalancer: {}
```

IMO this should error out or should not create service, give warning loud and clear that service is not created, but still we can have `deployment` or `ReplicationController` depending on the provider(k8s/openshift).
.
 @surajssd Good catch. Thanks for that. I will add a validation.
.
 @ngtuna maybe @surajssd wants to assign this one to himself :)
.
 In Henge we have solved this by interactively asking user to provide missing information.
But I don't think that interactive mode is good fit for Kompose.
.
 Somehow, sometimes we might need interactive mode... but I am not sure at this moment we need it..
.
 @surajssd can you take this one ?
.
 @ngtuna sorry for late comment I will take this one!
.
 "
,,57,"`depends_on` is not supported.
 I am using following `docker-compose.yml` and when running it errors out saying `depends_on` not supported.

``` yaml
$ cat docker-compose.yml
  mariadb:
    image: centos/mariadb
    ports:
      - ""3306""
    environment:
      MYSQL_ROOT_PASSWORD: etherpad
      MYSQL_DATABASE: etherpad
      MYSQL_PASSWORD: etherpad
      MYSQL_USER: etherpad

  etherpad:
    build: ""./myphp""
    ports:
      - ""80:9001""
    depends_on:
      - mariadb
    environment:
      DB_HOST: mariadb
      DB_DBID: etherpad
      DB_PASS: etherpad
      DB_USER: etherpad
```

running it

``` bash
$ ./kompose convert -o output
ERRO[0000] Could not parse config for project etherpad : Unsupported config option for etherpad service: 'depends_on' 
FATA[0000] Failed to load compose file%!(EXTRA *errors.errorString=Unsupported config option for etherpad service: 'depends_on') 
```
.
 There are some keys we have not covered. I'm gonna submit a patch for the warning message. Please stay turned :-)
.
 https://github.com/skippbox/kompose/issues/3
.
 Closed by https://github.com/skippbox/kompose/commit/278a8af04f991308f3402d6c0eb9a579b12aa77a
.
 "
,,56,"Environment Variable substitution not working.
 I am using following `docker-compose.yml` file

``` yaml
$ cat docker-compose.yml 
version: ""2""

services:
  mariadb:
    image: centos/mariadb
    ports:
      - ""$DB_PORT""
    environment:
      MYSQL_ROOT_PASSWORD: $ROOT_PASS
      MYSQL_DATABASE: $DB_NAME
      MYSQL_PASSWORD: $DB_PASS
      MYSQL_USER: $DB_USER

  etherpad:
    image: centos/etherpad
    ports:
      - ""80:9001""
    depends_on:
      - mariadb
    environment:
      DB_HOST: $DB_HOST
      DB_DBID: $DB_NAME
      DB_PASS: $DB_PASS
      DB_PORT: $DB_PORT
      DB_USER: $DB_USER
```

and following envs

``` bash
$ cat envs 
DB_HOST=mariadb
ROOT_PASS=etherpad
DB_NAME=etherpad
DB_PASS=etherpad
DB_USER=etherpad
DB_PORT=3306
```

error

```
$ export $(cat envs)
$ ./kompose convert -o output
panic: runtime error: invalid memory address or nil pointer dereference
[signal 0xb code=0x1 addr=0x20 pc=0x64e144]

goroutine 1 [running]:
panic(0x11ef080, 0xc820010140)
    /usr/local/go/src/runtime/panic.go:481 +0x3e6
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate.func1(0xc8204acc88, 0x7, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:145 +0x84
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseVariable(0xc8204ac790, 0x8, 0x8, 0xc82015fbe8, 0x0, 0x0, 0x0, 0xc8204ba150)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:36 +0x120
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseInterpolationExpression(0xc8204ac790, 0x8, 0x1, 0xc82015fbe8, 0x0, 0x0, 0xc82015f7a8, 0x4127d8)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:74 +0x10f
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseLine(0xc8204ac790, 0x8, 0xc82015fbe8, 0x0, 0x0, 0x412672)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:90 +0xbf
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseConfig(0xc8204ac718, 0x5, 0xc8204ac6f0, 0x7, 0xc82015f990, 0xc82015fbe8, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:110 +0x532
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.parseConfig(0xc8204ac718, 0x5, 0xc8204ac6f0, 0x7, 0xc82015fb68, 0xc82015fbe8, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:117 +0x1d3
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Interpolate(0x0, 0x0, 0xc82015fd38, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/interpolation.go:144 +0x1f3
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.MergeServicesV2(0xc8204638c0, 0x0, 0x0, 0x0, 0x0, 0xc820463880, 0x12, 0xc82049c000, 0x1d9, 0x3d9, ...)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge_v2.go:22 +0x12a
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config.Merge(0xc8204638c0, 0x0, 0x0, 0x0, 0x0, 0xc820463880, 0x12, 0xc82049c000, 0x1d9, 0x3d9, ...)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/config/merge.go:40 +0x24c
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).load(0xc8204651e0, 0xc820463880, 0x12, 0xc82049c000, 0x1d9, 0x3d9, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:178 +0xe5
github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project.(*Project).Parse(0xc8204651e0, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/docker/libcompose/project/project.go:86 +0x335
github.com/skippbox/kompose/cli/app.loadComposeFile(0xc820463880, 0x12, 0xc820347180, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/cli/app/app.go:733 +0x1b6
github.com/skippbox/kompose/cli/app.Convert(0xc820347180)
    /home/vagrant/work/src/github.com/skippbox/kompose/cli/app/app.go:1028 +0x4b9
github.com/skippbox/kompose/cli/command.ConvertCommand.func1(0xc820347180)
    /home/vagrant/work/src/github.com/skippbox/kompose/cli/command/command.go:30 +0x21
github.com/skippbox/kompose/vendor/github.com/urfave/cli.Command.Run(0x13eb378, 0x7, 0x0, 0x0, 0x0, 0x0, 0x0, 0x159d920, 0x30, 0x0, ...)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/command.go:179 +0x1399
github.com/skippbox/kompose/vendor/github.com/urfave/cli.(*App).Run(0xc82048ab00, 0xc82000a940, 0x4, 0x4, 0x0, 0x0)
    /home/vagrant/work/src/github.com/skippbox/kompose/vendor/github.com/urfave/cli/app.go:196 +0x137c
main.main()
    /home/vagrant/work/src/github.com/skippbox/kompose/cli/main/main.go:46 +0x5fe
```

version

``` bash
$ ./kompose -v
kompose version 0.0.1-alpha (HEAD)
```
.
 @ngtuna I would like to fix this one :) to get started with the project.
.
 Go ahead @surajssd, you already fixed same or at least similar bug once :wink: 
.
 @surajssd I guess this bug comes from libcompose. See it: https://github.com/skippbox/kompose/blob/master/cli/app/app.go#L733. 
I just call to libcompose parsing function.

If that's the main cause, then you can also make a PR to them :-)
.
 "
,,55,"Breaking code in app.go to multiple packags.
 What if we would break `app.go` to multiple packages?

I suggest creating notion of loaders and transformers.
Loader would load input file and convert it to komposeObject.
Transformer would convert komposeObject to target format.
Every loader and every transformer would live in its own package.

```
pkg/loader/dockercompose/
pkg/loader/boundlefile/

pkg/transformer/kubernetes/
pkg/transformer/openshift/
```

It could look like this:

```
                  +------+          +-----------+
input file -----> |loader|          |transformer| -----> output files
                  +------+          +-----------+
                     |                    ^
                     |                    |
                     |                    |
                     +--> komposeObject --+
```
.
 Big +1 @kadel . It makes our code looks brighter and motivate new comers who would like to step forward. I will create `docs` folder then we can put all thoughts into. I can give a hand to implement this design if you'd prefer.
.
 @kadel are you working on it? I can take this one if you'd prefer to keep working on OpenShift support #36  and preference file #39 .
.
 I haven't stared on this yet. But I think we should do this before #39 and #36  because breaking app.go will probably involve a lot of code moving.

We can try together design some interfaces around `komposeObject` than it should be easy to break code and one of us can do loaders and other transformers.
.
 "
,,54,"update README for bundles, compose v2.
 .
 Just reminder that we should also update Building section in README and add note about  requiring running `go build` with `-tags experimental` because we depended on dab support, that is still experimental feature in docker.
.
 @kadel Here you are https://github.com/skippbox/kompose/commit/fa0930de062bf6951af0010dae6c0394311ba3fa
.
 Closed by https://github.com/skippbox/kompose/commit/0e891f5b328b850db1f241d1bf9037a51b77226e
.
 "
,,53,"Consider changing `--from-bundles` (bool) to `--bundle-file` (string).
 How about we make the flag for specifying bundles to something similar to `--file` (e.g. `--bundle-file`)? It'll be easier to specify than `--from-bundles` + `--file=xxx`. We can validate the flags so that either `--file` or `--bundle-file` can be specified at a time. 
.
 +1. when adding --from-bundles flag I was just thinking about reusing --file flag. Could you make a commit for this?
.
 Sure
On Thu, Jul 21, 2016 at 7:30 PM Tuna notifications@github.com wrote:

> +1. when adding --from-bundles flag I was just thinking about reusing
> --file flag. Could you make a commit for this?
> 
> —
> You are receiving this because you authored the thread.
> 
> Reply to this email directly, view it on GitHub
> https://github.com/skippbox/kompose/issues/53#issuecomment-234439048,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AEpqQ0kV4Xg4hzgoc7scb2OhlRBBDzGFks5qYCtKgaJpZM4JSVqW
> .
.
 so +1 I confirm, this is not very intuitive:

```
$ ./kompose convert --from-bundles ./docker-compose-bundle.dsb 
FATA[0000] Failed to parse bundles file: %!(EXTRA *errors.errorString=JSON syntax error at byte 1: invalid character 'm' looking for beginning of value) 
$ ./kompose convert --from-bundles --file docker-compose-bundle.dsb 
file ""web-svc.json"" created
file ""redis-svc.json"" created
file ""web-deployment.json"" created
file ""redis-deployment.json"" created
```
.
 @janetkuo: after you finish the patch to introduce `--bundle-file` flag, I will update README for both bundlefile and compose v2 guidances

https://github.com/skippbox/kompose/issues/54
.
 "
,,52,"Consider changing `--rc` flag to bool and adding `--replicas`.
 Right now all flags for specifying controller types are `bool`, except for `--rc`, which is `int`. 

This is confusing because I cannot do this 

``` console
$ ../kompose convert --rc -y
Incorrect Usage.
```

And this (surprisingly) gives me a deployment 

``` console
$ ../kompose convert --rc=""0"" -y
file ""redis-svc.yaml"" created
file ""web-svc.yaml"" created
file ""redis-deployment.yaml"" created
file ""web-deployment.yaml"" created
```

I propose that we change `--rc` back to `bool` and add another `int` flag for specifying replicas, since other controllers also take `replicas` in their spec. We can default it to `-1` as unset, and then we don't specify it in spec (and let K8s API server decide the default value). If it's set to something >= 0, we set it explicitly.  
.
 +1. Are u going to do or shoud I take it?
.
 I can take this one
On Thu, Jul 21, 2016 at 7:33 PM Tuna notifications@github.com wrote:

> +1. Are u going to do or shoud I take it?
> 
> —
> You are receiving this because you authored the thread.
> 
> Reply to this email directly, view it on GitHub
> https://github.com/skippbox/kompose/issues/52#issuecomment-234439429,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AEpqQxaBI4-E2R7SXy2ICxUnr-k2ARuEks5qYCwRgaJpZM4JSVIn
> .
.
 "
,,51,"Fix some nits in README.
 .
 "
,,50,"Add a bundle example file.
 .
 "
,,49,"Unable to go build .
 ``` console
$ go build -o kompose ./cli/main/
cli/app/app.go:29:2: no buildable Go source files in go/src/github.com/skippbox/kompose/vendor/github.com/docker/docker/api/client/bundlefile
```

This is because of a recent change to vendor/github.com/docker/docker/api/client/bundlefile/bundlefile.go:

``` go
// +build experimental

package bundlefile
```

Build error went away after removing `// +build experimental`. 

cc @kadel 
.
 @janetkuo correct. I also have to remove // +build experimental when doing build locally. However @kadel submitted a patch to support building with experimental packages with gox. So it's no problem at all.
.
 @ngtuna I am doing this to get it built, what is it I am doing wrong?

``` go
$ gox -osarch=""linux/amd64"" ./cli/main/main.go 
Number of parallel builds: 3

-->     linux/amd64: command-line-arguments

1 errors occurred:
--> linux/amd64 error: exit status 1
Stderr: can't load package: package command-line-arguments: cannot find package ""command-line-arguments"" in any of:
    /usr/local/go/src/command-line-arguments (from $GOROOT)
    /home/vagrant/work/src/command-line-arguments (from $GOPATH)
```
.
 @surajssd can you try `gox -osarch=""linux/amd64"" ./cli/main/` ?
.
 @janetkuo If you add experimental build tag you can build it without modifying boundlefile.go like this: 

```
go build -tags experimental -o kompose ./cli/main/
```
.
 Closed by https://github.com/skippbox/kompose/commit/fa0930de062bf6951af0010dae6c0394311ba3fa
.
 "
,,48,"Fix failing windows build.
 .
 "
,,47,"convert file fail.
 i've just use ""kompose convert"" from an docker-compose.yaml file to new file yml of k8s, but it went wrong, and show me the error: 
""ERRO[0000] Failed to unmarshall: Cannot unmarshal '30' of type int64 into a string value""

Is this new issue? Or i did wrong?

@ngtuna 
.
 @wayarmy Could you please upload your compose file ?
.
 `redis:
  image: redis:latest
  ports:
    - ""6379:6379""

elasticsearch:
  image: elasticsearch:latest
  ports:
    - ""9200:9200""
    - ""9300:9300""
static:
  image: wayarmy/jackfruit:0.1
  ports:
    - ""80:8080""

jackfruit: &app_base
  image: wayarmy/jackfruit:0.1
  ports:
    - ""8080""
  links: &app_links
    - redis:redis.local
    - elasticsearch:elasticsearch.local
    - static:static.local
  environment:
    RAILS_ENV: 'production'
    RAILS_SERVE_STATIC_FILES: 'true'
    UNICORN_PORT: '8080'
    UNICORN_PROCESSES: '2'
    UNICORN_TIMEOUT: '30'
    UNICORN_WORKING_DIR: '/home/rails/jackfruit/'
    UNICORN_PID: '/home/rails/jackfruit/shared/pids/unicorn.pid'
    UNICORN_ERR_LOG: '/home/rails/jackfruit/shared/log/unicorn.stderr.log'
    UNICORN_LOG: '/home/rails/jackfruit/shared/log/unicorn.stdout.log'`

something like this?? Is this OK?
.
 This works for me on HEAD:

With this test-compose.yml file

``` yaml
redis:
  image: redis:latest
  ports:
    - ""6379:6379""

elasticsearch:
  image: elasticsearch:latest
  ports:
    - ""9200:9200""
    - ""9300:9300""
static:
  image: wayarmy/jackfruit:0.1
  ports:
    - ""80:8080""

jackfruit: &app_base
  image: wayarmy/jackfruit:0.1
  ports:
    - ""8080""
  links: &app_links
    - redis:redis.local
    - elasticsearch:elasticsearch.local
    - static:static.local
  environment:
    RAILS_ENV: 'production'
    RAILS_SERVE_STATIC_FILES: 'true'
    UNICORN_PORT: '8080'
    UNICORN_PROCESSES: '2'
    UNICORN_TIMEOUT: '30'
    UNICORN_WORKING_DIR: '/home/rails/jackfruit/'
    UNICORN_PID: '/home/rails/jackfruit/shared/pids/unicorn.pid'
    UNICORN_ERR_LOG: '/home/rails/jackfruit/shared/log/unicorn.stderr.log'
    UNICORN_LOG: '/home/rails/jackfruit/shared/log/unicorn.stdout.log'
```

``` console
$ kompose convert -f test-compose.yml
file ""jackfruit-svc.json"" created
file ""redis-svc.json"" created
file ""static-svc.json"" created
file ""elasticsearch-svc.json"" created
file ""redis-deployment.json"" created
file ""static-deployment.json"" created
file ""elasticsearch-deployment.json"" created
file ""jackfruit-deployment.json"" created
```
.
 I can reproduce this error with the `v0.0.1-alpha` release binary 
.
 Thanks @janetkuo. Could you verify it and close the issue? @wayarmy
.
 i download this binary for darwin amd64, but i don't know what i need to do any more. I don't have experience with go and go-binary, did it work on MacOsx???. I still get this error. 
.
 @wayarmy you're right. This error happens on the pre-release 0.0.1-alpha. Can you try to build kompose on HEAD master ? @janetkuo run it success, so do I.

Build instruction: https://github.com/skippbox/kompose#building
.
 let's just cut a 0.0.1-beta.1 release 
.
 @runseb will do tonight. I'm fixing some bugs with unsupported key and labels mapping.
.
 @wayarmy I uploaded a new release just for you:
https://github.com/skippbox/kompose/releases/tag/v0.0.1-beta.1

Could you download it and test it, it should fix your issue.

thanks.
.
 ah. Thank @ngtuna and @runseb so much. I will test it, if it run success for you, it will run with me :)) . Thanks so much
.
 @dmilind Download the newest Kompose :) `go get -u github.com/kubernetes-incubator/kompose` and it'll output yaml..
 thanks @cdrage .
 "
,,46,"Inital support for Openshift..
 Right now this is implemented as another option  (type of controller) for convert command.
As discussed in #36 we will probably add preference file with profiles in future.

Currently it can be used simply like this:

```
kompose convert --deploymentconfig
```

```
▶ ./kompose convert -h      
.....
   --deploymentconfig, --dc     Generate a DeploymentConfig for OpenShift
......
```
.
 "
,,45,"Write an architecture document for kompose.
 Kompose is getting a lot of traction. Would be a nice thing to have an architecture document that will help document kompose internals and also help new contributors to get ramped up. 
.
 link to #55 
.
 So I tried to put something together. here is first draft: https://docs.google.com/document/d/1p3QUpMlCOHfncfemcja3ArNb9-aLbTc0foHYJ5QdCgM/edit?usp=sharing
.
 Close by https://github.com/skippbox/kompose/commit/45c482977822e82453f49f2a3ec1d729cde55776
.
 "
,,44,"[Discuss] Optimize convert function.
 In order to support different types of input format (dab, compose v1, compose v2, etc) and break down the convert function as well, I am thinking about creating a generic struct like this:

```
type komposeSet struct {
  Image string
  Name  string
  Volume  []Volumes
  Network []Networks
  Environment []string
  Port  []Ports
  Command string
}
```

I will think more on mandatory fields need to be declared of this struct.

Idea behind is that we take file from different input, build corresponding `parsing` function to map it to `komposeSet` struct. Then the main convert function will only do the transformation from `komposeSet` to k8s controllers and service. With that strategy, we also can cut-off the dependency on libcompose's structs between versions.

Thought ?
.
 /cc @janetkuo @runseb @kadel 
.
 +1 . except the name. Maybe komposeMap or komposeObject
.
 +1 I really like idea of intermediate format.

The struct would need to be little bit bigger to catch more things like cpu, memory limits and builds.

Maybe we could base this on libcompose [ServiceConfig](https://godoc.org/github.com/docker/libcompose/config#ServiceConfig). Not that we would use this directly, but only base our struct on this. I think that this captures most of the options that container can have.
.
 @kadel Agreed. I'm building this struct. Try to get as many common fields as possible.
.
 +1 on adding this struct, and +1 on naming it `komposeObject`
.
 "
,,43,"[Discuss] Find a good way to vendoring dependencies.
 Guys,

The current issue I am facing in kompose is finding a good solution to vendoring dependencies. As you know, kompose refers to some structs of libcompose and kubernetes in order to do mapping fields between them. While kompose depends on libcompose and kubernetes, both of them are sharing lot of common dependencies but with different revisions. The current code base is quite stable, but let's say now I have to upgrade libcompose revision in order to solve #11 and #4 (which I also have to upgrade docker/docker revision in order to get bundlefile struct), also in future we have to support k8s 1.4, 1.5, etc. 
# vendoring seems to be a hot issue to be discussed at GopherCon afaik...

Someone introduces me https://github.com/sdboyer/gps. I will take a look on it tomorrow.

Any idea?
.
 Right now I'm facing same problem with OpenShift.
It gets even worse because OpenShift has dependency on its own fork of Kubernetes, I only hope that parts that we need, are going to work with upstream Kubernetes.

But I don't have any good solution so far :-(
.
 Yeah. Well, finding a solution to tackle the problem completely is impossible at this moment. It is known as the diamond problem for dependencies. Somehow `godep` can help to flatten the vendored code. It takes a bit more time to discover alternative choices.

https://github.com/golang/go/wiki/PackageManagementTools
.
 this might help https://github.com/rancher/trash
.
 @runseb That's interesting to take a look. Let me see.
.
 @ngtuna found one more golang vendor manager https://github.com/Masterminds/glide not sure how good or bad it is, but [Kubernetes Helm](https://github.com/kubernetes/helm) uses it.
.
 Still haven't started looking into them. At least we are still good with `Godeps`. 

@surajssd Yeah I know there are lot of projects using `Glide` for vendoring.. It seems to be a powerful tool to do that..
.
 I should close this. We have chosen an alternative sword - glide. 
.
 "
,,42,"Refactor how we update controllers.
 Refactor so that we don't need to copy & paste code for updating each controller. 
.
 Not sure what happened, it seems I added a label while I was sleeping, weird.

@janetkuo is it ready for review+merge or are you still working on it ?
.
 Thanks @janetkuo . Nice to see a generic update function for controllers. Shall we keep discussing to optimize `convert` function in order to look better ? It's simply too long.
.
 Yes it's ready for review. Agree with Tuna, I'd love to optimize convert as
well.
On Sat, Jul 16, 2016 at 10:27 AM Tuna notifications@github.com wrote:

> Thanks @janetkuo https://github.com/janetkuo . Nice to see a generic
> update function for controllers. Shall we keep discussing to optimize
> convert function in order to look better ? It's simply too long.
> 
> —
> You are receiving this because you were mentioned.
> 
> Reply to this email directly, view it on GitHub
> https://github.com/skippbox/kompose/pull/42#issuecomment-233141320, or mute
> the thread
> https://github.com/notifications/unsubscribe-auth/AEpqQx66tM1mFtCGEvljhRUlovCGzBPQks5qWRR8gaJpZM4JN33Z
> .
.
 @janetkuo @runseb I checked out the PR. It looks good to me. 
.
 "
,,41,"new behavior of `kompose delete`.
 Adding flag `-a/--all` in order to delete all resources.
Consider to rename to `kompose rm` 
.
 `docker-compose rm` is used for removing ""stopped"" service containers, whereas `kubectl delete` can (and often) be used to remove the running ones. 
.
 Thanks @janetkuo for pointing it out. I am not thinking about `kompose delete` much right now. Paying more attention on `kompose up`. However, let's say we can have `kompose rm` to firstly stop containers running on k8s and then remove them. Don't want to be duplicated with `kubectl delete` but somehow we can add `kompose stop` to only do stop action. However, we should be very careful to not going into the same way last time when we overlapped `kubectl` functions. Interactive mode still be good option to go.
.
 So, after some investigating, I see we need a thing is in contrast with `kompose up`. So I suggest:

``` console
- kompose down --file/--bundle <input_file> : delete deployment and svc (default: docker-compose.yml)
- kompose down --all : delete all resources (deployment, rc, svc, ds)
```

Anything else ?
/cc @janetkuo @runseb 
.
 Is `kompose down --all` going to delete all resources in the system, regardless if it's created by kompose or not? Not sure if it's expected behavior from the users' perspective -- depends on their work flow 
.
 Yes it's a critical action. We can ask for confirmation like this:

``` console
$ kompose down --all
This action is going to delete all resources in all namespaces (except kube-system) in the kubernetes cluster. 
Are you sure to continue ? (y/n)
```
.
 I don't think `kompose down` should delete everything. It should only delete the resources that the conversion created.

```
kompose down -f docker-voting.yml
```

should delete the deployments and services that it creates.

At least that's what I would expect.
.
 So I will go merging `kompose down` without supporting `--all` flag. We can make a follow-up PR for this later.
.
 Close via https://github.com/skippbox/kompose/pull/113
.
 "
,,40,"new behavior of `kompose up`.
 Like `docker-compose up`, `kompose up` transparently generates default objects and deploy to kubernetes.
.
 Also, print suggestion to use kubectl to deploy other controllers and include non-supported fields warning
.
 As `kompose` supports more than one provider, we should have `--provider` flag like this:

``` console
kompose up --provider openshift
```

Default: Kubernetes (without --provider).
.
 Reopen it for further enhancement:
- add `--provider` flag
- handling invalid converted k8s object
.
 @surajssd how can `kompose` read OpenShift endpoint config ?
.
 @ngtuna OpenShift endpoint config as in similar to `~/.kube/config` ?
.
 Really? OK so I'm thinking how we can add `kompose up --provider openshift`. What is the process ? We need to have a `~/.kube/config` pre-configured to openshift endpoint. Then let kompose does the same with kubernetes. Does it make sense ?
.
 I even think  that we can use same deploy function (from kubernetes) for deploying  to OpenShift. 
We just need to make sure that proper api all installed such as (`_ ""github.com/openshift/origin/pkg/deploy/api/install""`)
We might change that to `_ ""github.com/openshift/origin/pkg//api/install""` to make sure that all openshift objects are included in schema
.
 Ah.... I remember we discussed about preference file at https://github.com/skippbox/kompose/issues/39. So, if the preference file is used, we don't need `--provider` anymore, right ?
.
 I've started working on adding `kompose up` for openshift.
I will brake it to multiple PRs and in every PR I'm going to reference this issue.
.
 I think this can be closed now? 
.
 Yes
.
 "
,,39,"Investigate a preference file.
 for example

```
[default]
provider=kubernetes
objects=deployments

[test]
provider=openshift
objects=petsets
```
.
 @ngtuna What will be group in preference file used for?

We don't need to add command line flags to chose between group, do we?
.
 @Gnouc yes we don't need flags in preference file. Let's go first with provider and default objects to be generated. Then we can discuss what should be added more.
.
 @ngtuna i would like to work on this issue!

Some questions regarding this, with prefernce file are we gonna have alternative to all the command line flags(not in the immediate PR but in the long run)?
.
 @surajssd the original idea was to use this to create some profiles that would define defaults behavior. kind of like `kubectl` contexts.

for example

```
[default]

[oc]
provider=openshit
resource=replicationcontrollers

[sebgoa]
provider=kubernetes
resource=deployments
```

then maybe calling `kompose profile sebgoa` would make `kompose up` use k8s provider and deployments.
but `kompose profile oc` would make `kompose up` use openshift and RC.

things like --f, --q, --stdout,--y etc...don't need to change. They could be set in the context to shorten the kompose command but right now, I don't see it as necessary.

The big feature is to be able to switch provider but keep the `kompose up` UX.
.
 @surajssd great to know you're stepping forward with this.

I don't think we are gonna have alternative to all flags. Basically preference file is a kind of `kompose context` which helps us easily switch between providers. Flags are still declared along with kompose commands. At this moment I suggest we should cover these below configurations in preference file:
- provider
- default objects to be generated

Look at the example file I put above.

Right now we are relying on kubectl configuration at ~/.kube/config. I'm not really sure but somehow IMO we should put API endpoint and authentication info into preference file as well.
.
 @ngtuna sure that example file is a great reference, on which I can base my work on! We can add more things going forward!
.
 @ngtuna about file format why can't the file format be `yaml`, as oppose to `ini`?
I certainly understand that `ini` file format is easy to write as opposed to `yaml`, but considering future additions, is `ini` file format a right way to go?

This will also need more feedback from all the folks.
Ping: @kadel @janetkuo 
.
 +1 for yml. If not for other reasons that at least so we don't introduce new file format.
docker-compose definition is already in yaml, it would be nice to have this in same format.
.
 Just a brain dump: right from the start of this file format creation we define a schema for it, and [`gojsonschema`](https://github.com/xeipuuv/gojsonschema) can help us with it going forward, even libcompose has defined a schema for docker-compose format here https://github.com/docker/libcompose/blob/35cdb15b37b0b7b471f382c4e0c5152d4414d902/config/schema.go
.
 hey @ngtuna @runseb its cool if we go ahead with yaml right? I needed views of you guys so that I can start to work on it?
.
 yaml or .ini file...
.
 cool i will start working with `yaml` as our input file, thanks!
.
 how complicated does the config file need to be? might be easier on user if it is ini file.. if we think it will get complicated over time then yaml is best. 
.
 I think that at begging it might be fairly easy and simple, but will grow in the future.
I don't think that ini is that easier on user compared to simple yaml.

For example ini mentioned in https://github.com/skippbox/kompose/issues/39#issuecomment-245009076 could look in yaml  like this:

``` yaml

oc:
  provider: openshit
  resource: replicationcontrollers

sebgoa:
  provider: kubernetes
  resource: deployments
```
.
 > I don't think that ini is that easier on user compared to simple yaml.

ok
.
 About this one more question,
- Where is this file situated? Is it similar to Kubernetes(`~/.kube/config`) like a `~/.kompose/config`? or `~/.kompose/defaults`
.
 I think it should be right next to docker-compose.yaml file, in the same directory. You will have separate preference files for each project.
.
 @runseb 

> the original idea was to use this to create some profiles that would define defaults behavior. kind of like kubectl contexts.

Do we really need profiles? What would be use case for having multiple profiles?
I would expect that most people are going to use only one profile anyway. 

If user requires to have multiple configuration he could just have multiple preference files, and we can have option to chose which file to use, similar to how it is done with `docker-compose.yaml`. By default we read that but you can always use your own with `-f`.
We could do similar thing for preferences. By default it can be in `kompose.yaml` and you can choose different file with `--conf` option.
.
 I could see myself having a k8s cluster and an oc endpoint, then wanting to switch between them.

But you are right I think, in any case we would need to pass an arg to specify which profile to use.

I have a preference to keep a single configuration file `~/.kompose` that can have multiple profile, rather than asking users to write their own configuration file.

need more thinking on this, we need to have a good feel for the UX.
.
 is it possible that we could add ""profile"" information to the `~/.kube/config` file similar to the way a user can add content to a `.gitconfig` file that isn't specific to git, but specific to tools that surround git 
.
 > I have a preference to keep a single configuration file ~/.kompose that can have multiple profile, rather than asking users to write their own configuration file.

It depends what will be in that file. I was imagining that there might be some project specific stuff, like discussed in https://github.com/skippbox/kompose/issues/154 , than it wouldn't make much sense to have one global file. 
I expect that we will find more and more cases where we need provide some additional values on top of docker-compose.yaml  file, it that case it would be better to have per project config file. 
But we can also go with labels approach and modify docker-compose.yaml file in that case it would probably make more sense to have one global config.

> I could see myself having a k8s cluster and an oc endpoint, then wanting to switch between them.
> 
> But you are right I think, in any case we would need to pass an arg to specify which profile to use.

This is probably just a matter of taste :-). For me it is just more clear to switch between files that are kept with project, than  to have everything in one file with multiple sections.
.
 Since we had a discussion also about having registry info in your pref file, it makes sense to have single global file, with URL to registry, auth info, etc.

Because a user will not like having to copy things around?
.
 sone of that information can be in docker-compose.yml like url to registry.
URL of registry is part of image name and you can specify image name when doing build in docker-compose file.
I don't know if you can do auth in docker-compose, so this might be trickier. 
.
 We should probably agree what this preference file should be for.

I see it as configuration for how kompose does conversion and deploy for given project.
When multiple people works on same project this file is committed with source so everyone is using same config and have same conversion result. Similar to  how everyone is using same docker-compose file. This file acts as docker-compose extension providing additional information needed for conversion to k8s and it is specific for given project.

If I understand it correctly than @sebgoa sees it as global config file for `kompose` program.
What other thinks will be configured as global values for kompose?
Right now I can see only one thing, and that is provider. Maybe default controller object? But I think  that controller object should be also per project configuration. Fo one project I might want DaemonSets and for other just regular Deployments.
If it is just about provider, that we can use global flag that can be set from env variable so user doesn't have to type it every time.
.
 This is starting to block us a little bit.

I'm still convinced that this should be file in project directory (next to docker-compose.yml). 
Doing it like this all settings can be easily shared between developers and it can contain additional data required for proper conversion to k8s. This will also solve problems like  #163 #154.
.
 While the location of pref file still in conversation, I am not sure if everybody agrees with me that keep the `docker-compose` file unchanged would be a good taste for UX. People bring their compose (or bundle) file in and use kompose in order to convert things, they won't expect have to edit the original file as an additional requirement for the conversion. 
.
 Ah... we still have #154 for the labels...
.
 I'm still  not sure what benefit this brings to users. :confused: 

For me it just adds unnecessary complexity.

When will user need multiple profiles with different settings (like different controller object or different provider)? Is there a real use-case for it?

I can think only one case and profiles is overkill for it:
I'm using old Kubernetes  and I don't want to use Deployments. Than it is annoying to always remembering  adding `--rc` or I'm using OpenShift than I have to always use `-p openshift`.
But this can be easily  solved  if we have ENV variable for every option in commandline. Users than can do `export KOMPOSE_PROVIDER=openshift` or `export KOMPOSE_RC=true` in their `.bashrc`.
Or if we don't want that than it can be preference file, but only think that it will do is change defaults,  nothing more.

I don't think that we need complicate this with multiple profiles.






 

.
 @kadel Yes I agree the preference file is now a bit of overcomplicating. The idea of this file originally happened during summer when @sebgoa would like to see a good way to switch between providers and default objects. But now kompose has changed a lot. So now we should again investigate the advantages and disadvantages of having a preference file and probably define an alternative solution.

- Advantages:
  + user get rid of typing flags
  + a good place for general settings of kompose. Which settings are general would probably be defined more in future but now we only have two settings: default objects and provider. Definitely we can apply ENV as @kadel mentioned above. I see it's commonly used.

- Disadvantages:
  + Overcomplicating by adding a file need to be managed -> We can dim it by introducing `kompose setting` command for example.

I'd like to take a look at the case user want to deploy composed-app to multiple k8s environments. Kompose is relying on kube config, that means he need to switch context first (by kubectl) prior to run kompose up. So, probably switching context would be a setting..
 Issues go stale after 90d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 "
,,38,"Default objects of `kompose convert`.
 `$ Kompose convert` will generate deploymentSet and service by default.
.
 typo: `deployment` 
.
 "
,,37,"bash completion for kompose .
 A nice-to-have feature. 
.
 First commit https://github.com/skippbox/kompose/commit/f09b640e90015dc559af1d6c45d2570940d56b7c
.
 Havent' tested this, can we close this ticket based on the commit ?
.
 We still should cover bash completion for flags. The first commit supports subcommands only.
.
 @cab105 maybe you can take that one as well...
.
 @sebgoa Sure I'll take a look at it.
.
 @cab105 @sebgoa I can take this over once #304 is merged, as it has implemented support for bash completion..
 closing, this was done in #370 .
 "
,,36,"Add OpenShift support.
 We would like to contribute OpenShift support to kompose2.
In core OpenShift is basically Kubernetes with some additional objects like `BuildConfig`, `DeploymentConfig`, `ImageStream` or `Route`.
With `BuildConfig` OpenShift can even support docker-compose `build` directive.

I guess that this first design question would be how command line is going to look like.
What if we use provider (orchestration  tool) name  as command and actions as subcommands?
Examples how it would look like:

```
kompose kubernetes convert
kompose kubernetes up

kompose openshift convert
kompose openshift up
```

When we do it like this, than in future different providers could even have different actions.
.
 @kadel  I suggest to go with:

`kompose convert --provider openshift`

Then we can support different providers with a small change of the current code base. Also IMHO adding `--provider` flag looks better
.
 +1 on adding flag 
.
 I was thinking about this a bit, especially considering that I feel the options are getting a bit ""crazy"".

Maybe we should use subcommands to have a better structure and avoid so many boolean definition and if statements.

We could use subcommands for objects and keep the option for --stdout --out --yaml and --provider.

something like:

```
kompose convert daemonset
kompose convert daemonset --provider openshift
kompose convert rc
kompose convert rc --provider openshift
```

By default we create a service for every docker-compose service.

thoughts ?
.
 @runseb I like your proposal. Will we still provide default controller (i.e. deployment) when `kompose convert` is executed without specifying which controller? I'm leaning toward yes, since users don't need to figure out which to choose if they're new to kubernetes.
.
 @runseb does your proposal imply that converting compose to multiple types of controllers (e.g. `kompose convert -d -ds`) won't be supported anymore?
.
 I'm afraid that this might get little messy :cry: 

As OpenShift adds few thinks on top of Kubernetes you will get options that are not valid for all providers.
For example:
`kompose convert deploymentconfig` -  This will be valid only for OpenShift and not for Kubernetes.
.
 I also like Sebastien's approach. Currently convert functiin doesn't look good because of many boolean variables and if statements. Need to think a bit more in order to cover multiple controllers generation.

We can add validation for subcommand relating to Openshift primitives only.
.
 I think that we should think about this more from users perspective than from code perspective.

For me it seems little strange because it emphasize choosing controller object to much.
I think of choosing controller object as optional configuration how convert should behave.
With syntax like this I would expect that controller is required. But that shouldn't be the case.

I expect that most user will use default one and won't care that much about others.
.
 I suggest to @kadel assigns this issues to himself and starts working in a branch.

For the configuration, we need to investigate #39 , using a `.kompose` preference file, which can have multiple profiles.

The idea being that using kubernetes or openshift or any other future provider could be hidden and made default. That way users familiar with docker-compose can use `kompose up` at the beginning without worrying about providers or default objects.
.
 +1 for preference file, this will keep command-line clean and simple.

I will keep in my mind that we might go this way when working on openshift provider.
.
 Can we close this one? @kadel @surajssd 
.
 I think we can close this. Basic OpenShift support has been merged. We can always open new issues to track adding additional features.
.
 "
,,35,"Generate only controllers set by flag.
 fixes #33 

After this function `ProjectKuberUp` needs to be updated, because right now it deploys only `svc` and `rc`
.
 LGTM. It's no problem at this moment, `ProjectKuberUp` is low priority. Enhancing `convert` function is the first serve.
.
 "
,,34,"We don't have any tests.
 We should add a few test fixtures and run tests on Travis/circleCI.
.
 I am working on creating functional tests right now, will work on the unit tests once, the code refactor and code moving thing that @kadel and @ngtuna are working on, is done.

So one question: What framework are we using to do the functional testing? Plain shell scripts or framework like [avocado](https://avocado-framework.github.io/) or anything else?
.
 Added functional tests: https://github.com/skippbox/kompose/pull/89
.
 We also need to add unit tests.
.
 @ngtuna yes will work on them once your refactor is in! So we can keep this open.
.
 I'm adding unit test for komposeConvert in #104
.
 Thanks @janetkuo for adding some unit tests and we will keep adding more. This issue can be closed now.
.
 "
,,33,"Default controller object is always generated..
 Right now default controller is always generated. 
When I do `kompose convert --replicaset` I get Services, Deployments and ReplicaSets.
I think that this is little bit confusing (even if they are in different files).
When I run above command I would expect only Services and ReplicaSets. In most cases you need only one controller object.

When I do `kompose convert --replicaset --deployment` than I would expect both (ReplicaSets and Deployments)
.
 yes confirmed:

```
$ kompose convert --rs
file ""toto-replicaset.json"" created
file ""toto-rc.json"" created
sebair: kompose2 (master)$ kompose convert --rs --d
file ""toto-deployment.json"" created
file ""toto-replicaset.json"" created
file ""toto-rc.json"" created
```

Even though the default has now changed. It generates deployments and services.

0bcec2aa23dd1cb3a873414de4b01391567c93b9
.
 "
,,32,"Make deployment the default controller, create -rc for rc, and enable copying all types of controller to chart templates.
 Fixes #30
.
 "
,,31,"Generating both ReplicationControllers and Deployments.
 Running `kompose convert --deployment` generates files with Services, Deployments and also Replication Controllers.

Shouldn't this generate just Deployments and Services?

Some for Daemon Sets and Replica Sets.
.
 This dup with #30 
.
 Close as dup.
.
 "
,,30,"Generating both ReplicationControllers and Deployments.
 Running `kompose convert --deployment` generates files with Services, Deployments and also Replication Controllers.

Shouldn't this generate just Deployments and Services?

Some for Daemon Sets and Replica Sets.
.
 +1
.
 A fix for this is easy. Here are some more things to think about:
1. This breaks backward compatibility. 
2. How'd a user create an RC and other controllers at the same time? One can do `kompose convert --d --ds`, but there's no flag for RC (since it's the default controller). 
3. Should we change Deployment to be default controller being created instead?
.
 +1

@kadel Originally kompose generates rc, svc by default but yes we should do that. I will work on that or you can also freely go ahead to send us PR
.
 @janetkuo @kadel the tricky point here is just for `--stdout` option where user would like to pipe with `kubectl`. Otherwise, generating RC by default does not harm anymore as user has option to pick up files he want for further operation.
.
 @ngtuna `--stdout` and `--out` stop multiple controllers from being created already. 
.
 @janetkuo Ah... yes you're right. I totally agree to change `DeploymentSet` to be default controller being created. Then we can keep RC as optional `--rc` 😺 
.
 "
,,29,"update OpenShift dependency .
 Origin has already been rebased to Kubernetes 1.3.
We should update our Origin dependency
.
 I'm sorry, this issue was meant for different repository :flushed: 
.
 "
,,28,"Validate flags when generating charts, and prints message for file created.
 .
 "
,,27,"Idea: kompose up, ps, delete, scale redirect to kubectl .
 `kompose up`, `ps`, `delete`, `scale` are duplicate of `kubectl`, but are easier to learn from compose users perspective. 

How about we suggest users the right kubectl command for each kompose command so that we don't need to reinvent the wheel? Something like:

``` console
$ kompose up
To initiate your compose services, run ""kubectl create -f web-rc.json -f web-svc.json"".
```

Thoughts?
.
 I like it but maybe we shouldn't make it so manual by making them copy/paste. Maybe something like:

```
$ kompose up
To initiate your compose services, run ""kubectl create -f web-rc.json -f web-svc.json"".
Would you like us to run that command for you now? (y/n) 
```
.
 Ah ha, that makes more sense to me @dustymabe 
.
 @dustymabe Thanks that sounds good!
.
 yes +1
we can support _up_, _ps_ and _delete_ via a simple wrapper to kubectl
and focus on the conversion for now.
.
 Open question: what's the right behavior of `kompose up`? 
1. If there's no existing converted k8s files: it should tell the users to run `kompose convert`
2. If there's multiple existing k8s files: should it just create whatever config files we have? What if those files are stale (docker-compose.yaml updated since last conversion)? What if we have more than one k8s files (.yaml, .json, different controllers...)? We can just convert again and then create those k8s primitives, but we don't have the `options` in `kompose up` like we do in `kompose convert`. 
.
 > Open question: what's the right behavior of kompose up?

Update per earlier discussion with @runseb and @ngtuna: `kompose up` will do the equivalent of `kompose convert && kubectl create -f <svc_files> -f <deployment_files> ...` (note that we only support default convert behavior, i.e. converting to deployments)
.
 link to https://github.com/skippbox/kompose/issues/40
.
 Close as dup #40 #41 
.
 @ngtuna what about `kompose ps` and `kompose scale`?
.
 @janetkuo By closing this issue, I just wanna make some clean up on issues. We can have another discussion on `kompose ps` and `kompose scale`, then we open the corresponding issues for them later.
.
 "
,,26,"Support creating Charts when --yaml set.
 Ref #25 
.
 "
,,25,"Bug: chart only expect .json files .
 This example in README doesn't work since it expects only `.json` files 

``` console
$ ./kompose convert -c -y
file ""redis-rc.yaml"" created
file ""web-rc.yaml"" created
file ""redis-svc.yaml"" created
file ""web-svc.yaml"" created
INFO[0000] Error reading redis-rc.yaml: open redis-rc.json: no such file or directory

FATA[0000] Failed to create Chart data: open redis-rc.json: no such file or directory
```

We should support `-c -y`. 

Should we support `-c -o`? Should we support `-c -dc` (copy template files of other types of controller) and `-c -dc -rs` (multiple types of contollers)?
.
 "
,,24,"Fix the 'failed to write to file' error when --out is set.
 Fix this:

``` console
$ ./kompose convert -o abc.yaml 
FATA[0000] Failed to write rc to file: write abc.yaml: bad file descriptor
```
.
 "
,,23,"Services only get created when there is a links key present.
 We made this assumption prior to compose v2.

We need to discuss whether we want to create a k8s service for every compose service or some other heuristics.
.
 The current strategy is based on `link` definitely. I will spend time to make some documents then we don't miss anything.
.
 Generating every compose services would be fine.
.
 "
,,22,"Allow multiple types of controllers be generated unless --out or --stdout is set.
 Follow up https://github.com/skippbox/kompose2/pull/5#issuecomment-230162553
1. Validate when --out and --stdout, only one controller type is specified. 
2. Allow multiple controller types otherwise. 

``` console
$ ./kompose convert -d -ds -rs -y --stdout 
FATA[0000] Error: only one type of Kubernetes controller can be generated when --out or --stdout is specified

$./kompose convert -d -rs -y --out=abc.yaml 
FATA[0000] Error: only one type of Kubernetes controller can be generated when --out or --stdout is specified

$ ./kompose convert -d -ds -y 
file redis-deployment.yaml has been created
file redis-daemonset.yaml has been created
file redis-rc.yaml has been created
file web-deployment.yaml has been created
file web-daemonset.yaml has been created
file web-rc.yaml has been created
file redis-svc.yaml has been created
file web-svc.yaml has been created
```

cc @ngtuna 
.
 Thanks @janetkuo 
.
 "
,,21,"Services should be created first.
 Follow up https://github.com/skippbox/kompose2/pull/5#issuecomment-230162553

The fix to this should fix #20 also 
.
 "
,,20,"Sometimes redundant services are printed/converted in `kompose convert`.
 Note that there's a redundant `file ""web-svc.json"" created` message. 

``` console
➜ examples(master)$ ../kompose convert 
file ""web-rc.json"" created
file ""web-svc.json"" created
file ""redis-rc.json"" created
file ""web-svc.json"" created
file ""redis-svc.json"" created

➜ examples(master)$ ../kompose convert 
file ""redis-rc.json"" created
file ""web-rc.json"" created
file ""redis-svc.json"" created
file ""web-svc.json"" created
```
.
 Yup. Also I have to re-structure convert function. It's too long and difficult to follow somehow.
.
 Done. Convert function is now more easier to keep track. Issue is also fixed by https://github.com/skippbox/kompose2/commit/2e986b61e7d80617fb29265d70cf167ee1fa4990
.
 "
,,19,"Remove redundant file creation message, and always overwirte files when converting.
 Fixes #18

cc @runseb @ngtuna 
.
 I found out somehow `os.Create()` causes this below issue:

```
$ kompose convert -o abc.txt -f docker-gitlab.yml
FATA[0000] Failed to write svc to file: write abc.txt: bad file descriptor 
```
.
 @ngtuna no, it's because the file is closed early, see the fix #24
.
 Ah my bad. Thanks @janetkuo 
.
 "
,,18,"Redundant file creation message.
 ``` console
$ ../kompose convert 
file abc.yaml has been created
file abc.yaml has been created
file abc.yaml has been created
file abc.yaml has been created
```

I'll send a PR for this.
.
 Another issue: when the file is already present, the converted objects will be appended to the file -- it should instead overwrite what's in `abc.yaml` with what's converted from `docker-compose.yml`. 
.
 "
,,17,"specify Deployment policy.
 .
 @ngtuna closing in favour of https://github.com/kubernetes-incubator/kompose/issues/264.
 "
,,16,"support PetSet.
 .
 Closing in favour of #698 (since PetSet has been renamed).
 "
,,15,"specify replica count.
 It should be very easy to do `kompose convert --replica <number>`
.
 Why do you want to do this ?
convert creates the objects, we can scale it with `kubectl`
.
 To be exact, I implemented kompose convert --rc replica_number

Adding replicas count was added in our shared document so I implemented it. This is a tiny change in code and also in user experience which instead of specifying --rc only user can also directly define number of replica with  --rc replica_number. I see it has benefit for example in case of doing pipe with kubectl. After that, user can also verify and reset replicas by editing rc files. Other hand, it also has a drawback that replica number is set equally to all pods/containers.
.
 "
,,14,"determine which containers should be in the same pod.
 e.g., the ones share the same volume should be in the same pod; the ones link to each other may or may not be in the same pod 
.
 Ref: https://github.com/redhat-developer/henge/blob/master/pkg/transformers/kubernetes/generate.go#L142
.
 Will be working on this one!
.
 @surajssd feel free to update `priority/P1` label if you are working on it now. That would be great to have it implemented in the next release.
.
 #131 right now only addresses `volumes_from` directive!
.
 Should we close this ?
.
 @ngtuna we have not implemented it yet so lets keep it.
.
 Do we know about another case which would resolve in putting two containers to the same pod?
.
 Issues go stale after 30d of inactivity.
Mark the issue as fresh with `/remove-lifecycle stale`.
Stale issues rot after an additional 30d of inactivity and eventually close.

Prevent issues from auto-closing with an `/lifecycle frozen` comment.

If this issue is safe to close now please do so with `/close`.

Send feedback to sig-testing, kubernetes/test-infra and/or `@fejta`.
/lifecycle stale.
 we should not do anything that deviates from the base docker-compose file format so let's not do this one!.
 @surajssd agreed, let's close.
 "
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  13,"Output for what happened after command execution.
 such as, “file A is created”
.
 "
12,"Support k8s 1.3.
 Upgrade k8s dependency to v1.3, support to post k8s objects to 1.3 endpoint
.
 #6 
.
 "
11,"Support compose v2..v3? versions.
 There is some v2 support now in lib compose upstream:

https://github.com/docker/libcompose/pull/292

we need to support all versions
.
 Closed by https://github.com/skippbox/kompose/commit/91d981858f595243a7ea2b699d0fd064a6dff682
.
 "
10,"Change template dir for Helm charts.
 it used to be manifests/ now it is under templates/
.
 "
9,"Document unsupported fileds.
 with warnings now given for unsupported fields.
It might be good to document it a bit:

```
$ cat nginx.yml 
nginx:
  image: nginx
  dockerfile: ""1""
  build: ./foobar
  cap_add:
    - foobar
  container_name: foobar
$ ./kompose convert -f nginx.yml
WARNING: Unsupported key Build - ignoring
WARNING: Unsupported key CapAdd - ignoring
WARNING: Unsupported key ContainerName - ignoring
WARNING: Unsupported key Dockerfile - ignoring
```
.
 Done by https://github.com/skippbox/kompose2/commit/ce32befbb27e232022fb90c96a20e30562d163ce
.
 "
8,"if random docker-compose file is not present --file option does not work.
 I found out, that even though we use the `--file` option, we still need to have a somewhat valid docker-compose file present.

```
sebair: kompose2 (master)$ cat docker-compose.yml 
toto:
  image: toto
sebair: kompose2 (master)$ cat mongo.yml 
mongo:
  image: mongo
sebair: kompose2 (master)$ ./kompose convert -f mongo.yml --stdout
{
  ""kind"": ""ReplicationController"",
  ""apiVersion"": ""v1"",
  ""metadata"": {
    ""name"": ""mongo"",
    ""creationTimestamp"": null,
    ""labels"": {
      ""service"": ""mongo""
```

if you remove the docker-compose file:

```
$ ./kompose convert -f mongo.yml --stdout
ERRO[0000] Failed to find docker-compose.yml            
FATA[0000] Failed to read project: open docker-compose.yml: no such file or directory 
```
.
 "
7,"Decide status of skippbox/kompose.
 Now that things are cleaner with kompose2 , shall we just remove github/kompose and rename this repo to kompose ?

I don't really see the need to keep the original fork of lib compose.
.
 +1. Totally agree.
.
 "
6,"travis build failed because ""speter.net/go/exp/math/dec/inf"" has been removed.
 .
 Going to upgrade k8s 1.2 to 1.3 which automatically solves this issue. k8s 1.3 depends on new location of the package at  ""gopkg.in/inf.v0"".

Ref: https://github.com/kubernetes/kubernetes/blob/v1.3.0/Godeps/Godeps.json#L2131
.
 "
5,"Support printing to stdout.
 Fixes #2

Add a `-out` / `-stdout` flag for printing to stdout. Doesn't support printing helm chart since it doesn't make sense (or does it?). I think the naming of the flag could be better but I couldn't think of a better one for now. 

Some unsolved issues found while developing:
1. Services should be created first if possible
2. It seems output to helm chart is only supported when there's `xxx-rc.json` (not yaml, not other controllers)
3. Right now we don't stop users from creating more than one type of controllers (rc, rs, deployment, ...), but this won't work while printing to stdout and pipe to kubectl, so I changed the logic to just use the first flag specified. Does that sound good? We'll need some verification for incorrect flag usage also. 

@runseb @ngtuna 
.
 Thanks @janetkuo . LGTM.

1 - Yes agree, services should be created first, specially when writing them to stdout help the pipe to kubectl working better.
3 - Yes, should have a verification on input flags and also printing a warning. The logic IMO would be only accepting the first flag in case of printing to stdout, otherwise keep the current support.
.
 @janetkuo I kept output to stdout option flag `--stdout` (removed `--out`) and added output to single file with flag `-o/--out` at https://github.com/skippbox/kompose2/commit/bea0e4b7c3cbccca1bf1a976416e2dec0fb1c868. They can't be declared together at the same time.
.
 "
4,"Support docker bundles format as input.
 .
 https://github.com/docker/docker/pull/23522
.
 There is an issue with package `github.com/docker/docker/api/client/bundlefile`: at this moment it is marked `// +build experimental`. That means go can't see it as a normal lib thus the building is fail.

```
$ go build -o kompose2 ./cli/main  
cli/app/app.go:30:2: no buildable Go source files in ...github.com/docker/docker/api/client/bundlefile
```
.
 I think this library allows you to generate bundles from compose file. We might add that.

But what we want is to be able to take a bundle and transform it into k8s primitives. It might be tricky because the image reference in a bundle is the sha of the layer...and not the image tag (which is not immutable).
.
 No Sebastien, that lib supports us to take a dab file and parse to `Bundlefile` struct. Then we are able to map to k8s objects.

Yes you're right. Image reference would be a tricky point.
.
 ok good to know.

as a first pass, we might just extract an image name from docker hub and use the latest tag. Since k8s does not support referencing specific layers in the image field.
.
 Working on `dab-support` branch
.
 @runseb Figure out the current revision of `libcompose` is too old in order to support mapping `bundles` fields to `compose` fields then to k8s primitives... This's such a pain if we keep enforcing it. I'm going to level up `libcompose` revision. It should be good as we can solve #11 in the meantime.
.
 you mean update the godeps hash for lib compose ?
will this break the current code ?
.
 Correct. No it doesn't harm the current code much. But I keep master branch stable and mainly work in separate dab-support branch. Then we can decide to merge when it done.
.
 Closed by https://github.com/skippbox/kompose/commit/91d981858f595243a7ea2b699d0fd064a6dff682
.
 "
3,"Print out warning for undefined fields.
 .
 Example

```
$ docker-compose bundle
WARNING: Unsupported key 'network_mode' in services.nsqd - ignoring
WARNING: Unsupported key 'links' in services.nsqd - ignoring
WARNING: Unsupported key 'volumes' in services.nsqd - ignoring
```
.
 "
2,"Support output to stdout to pipe to kubectl.
 .
 Solving in #5
.
 "
1,"Support output in a single file.
 .
 `kompose convert -o <filename>`. Need to validate `-o` and `--stdout` can't be put at the same time.
.
 "
