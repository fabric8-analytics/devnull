{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "import smart_open\n",
    "import collections\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Testing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(data, tokens_only=False):\n",
    "    for i, line in enumerate(data):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(line)\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"processed_comments.pkl\",\"rb\"))\n",
    "# train = data[:-10000]\n",
    "# test = data[-10000:]\n",
    "train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec object created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build_vocab_from_freq(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open(\"gensim_model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get inference out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0038966 , -0.12413467, -0.00088628,  0.04547637,  0.02487027,\n",
       "        0.2914945 , -0.1413551 ,  0.15388733,  0.11048101,  0.08213618,\n",
       "        0.06864414,  0.0151264 , -0.06750699, -0.07717273,  0.20570303,\n",
       "       -0.11310355,  0.12889908,  0.11036842,  0.03827285, -0.09396256,\n",
       "        0.1627588 , -0.06848573, -0.16042966, -0.00045034, -0.03100291,\n",
       "        0.26734978,  0.01682843, -0.01205921,  0.06844009, -0.02830203,\n",
       "        0.35193312,  0.13214266,  0.05767069,  0.31941187, -0.23206793,\n",
       "        0.06590673, -0.25150767,  0.0613074 ,  0.28405052, -0.02775035,\n",
       "        0.09447619,  0.04961845, -0.17056474,  0.05519173, -0.13871287,\n",
       "       -0.07159866,  0.01847048,  0.14687994,  0.10511759, -0.00843077,\n",
       "        0.0471995 ,  0.0183151 ,  0.07935549,  0.06730979,  0.09077326,\n",
       "        0.06307517, -0.03231017, -0.10422688,  0.07281328, -0.10892303,\n",
       "        0.23522893, -0.29230562,  0.01566891,  0.1784539 , -0.25520617,\n",
       "        0.15966111, -0.01766184, -0.01766215,  0.3377682 ,  0.03387546,\n",
       "       -0.17332558,  0.01234814,  0.1602972 , -0.10295907,  0.04699989,\n",
       "       -0.01474561,  0.05379114,  0.01095076,  0.05848291,  0.00815944,\n",
       "        0.01312794, -0.14960162,  0.31800282, -0.22533679,  0.14456296,\n",
       "       -0.26952475,  0.01730658,  0.0784173 ,  0.11395991,  0.22927594,\n",
       "        0.02916149, -0.14723754, -0.02906947, -0.21979631,  0.19640349,\n",
       "       -0.0420875 , -0.13862164, -0.17770858,  0.13866426,  0.14271969,\n",
       "       -0.03464512, -0.03929624,  0.13843529,  0.12171615, -0.01776979,\n",
       "       -0.20222563, -0.03032097, -0.16684549,  0.00630712,  0.17273593,\n",
       "        0.23077628,  0.09191031, -0.0338514 ,  0.25332746, -0.04457866,\n",
       "       -0.24467391,  0.24471492,  0.28987554, -0.3641047 ,  0.2398956 ,\n",
       "       -0.29395157,  0.1727014 ,  0.01757331,  0.06825642,  0.11073843,\n",
       "       -0.02052471, -0.32865912,  0.06551673, -0.05836647,  0.12543349,\n",
       "        0.02267698,  0.1981483 ,  0.06900272, -0.0984306 , -0.02985324,\n",
       "        0.05027063, -0.06323747,  0.13270627, -0.00494676, -0.01652154,\n",
       "        0.24274021,  0.09162425, -0.17037019, -0.15831214, -0.3050494 ,\n",
       "        0.11620753,  0.02410621, -0.13979961, -0.02917426, -0.08515541,\n",
       "       -0.02341302,  0.13326755,  0.14066109, -0.0648772 , -0.01666225,\n",
       "       -0.13087727, -0.0232418 , -0.15336198,  0.14375174,  0.0195917 ,\n",
       "       -0.10886369, -0.0347663 ,  0.1856727 ,  0.17522019,  0.07254404,\n",
       "        0.24612734, -0.02479466, -0.01205876, -0.02587446, -0.21534275,\n",
       "       -0.20887184,  0.26555777, -0.10624623,  0.07414602, -0.02696108,\n",
       "       -0.16952047, -0.11524192, -0.0809105 ,  0.02799567,  0.02844174,\n",
       "        0.13902001,  0.18542472,  0.02301432, -0.08710144,  0.1693468 ,\n",
       "       -0.04559682,  0.01343388, -0.00547062, -0.04897525, -0.09635084,\n",
       "        0.2748993 ,  0.03028007, -0.03671904, -0.04053409,  0.18491006,\n",
       "       -0.18351349, -0.0764249 , -0.07737534,  0.05379828,  0.09392899,\n",
       "        0.0392337 , -0.02539754,  0.28432453, -0.15773562, -0.04749464,\n",
       "       -0.02286561, -0.08917172, -0.18451487, -0.00197156,  0.00999931,\n",
       "       -0.05223588,  0.07644749, -0.12924072,  0.02116801, -0.15931006,\n",
       "        0.02434061, -0.1733714 ,  0.06559126, -0.06025728,  0.04952849,\n",
       "       -0.07022606,  0.10327084, -0.03356542, -0.09685203, -0.1132863 ,\n",
       "       -0.0410417 ,  0.03352619, -0.23905659,  0.2634017 ,  0.19316371,\n",
       "       -0.08393513,  0.07237535, -0.14004634,  0.23677579, -0.25302696,\n",
       "       -0.00729653, -0.05002683,  0.05439457,  0.044068  , -0.02387326,\n",
       "       -0.00505202, -0.0102731 ,  0.04720745, -0.07427941,  0.1474718 ,\n",
       "       -0.01624935, -0.0119908 ,  0.06672211,  0.0652297 ,  0.29275128,\n",
       "       -0.1732487 ,  0.03161637,  0.00843282,  0.07500129,  0.00765192,\n",
       "        0.08640755,  0.19613586,  0.13677481,  0.15882629,  0.02168102,\n",
       "       -0.12524104, -0.26218784,  0.07242143,  0.01212788,  0.06784977,\n",
       "       -0.04198351,  0.0628725 ,  0.3237955 ,  0.00332294,  0.056128  ,\n",
       "       -0.15644391,  0.11428578,  0.05184377,  0.17844714, -0.045651  ,\n",
       "        0.09346777, -0.14997178,  0.18455058, -0.16738102, -0.07374335,\n",
       "       -0.04189076,  0.18342066,  0.19039826,  0.09701318, -0.07726504,\n",
       "        0.23873113,  0.23339525,  0.09724641, -0.29083374,  0.09307196,\n",
       "       -0.18202405,  0.12442677, -0.09987445, -0.11936728,  0.07405306,\n",
       "        0.13121109,  0.07929952, -0.07438458,  0.17920452, -0.2073356 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector([\"how\",\"you\",\"doing\",\"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.infer_vector(\"This is a fix for lower volume limits on m5 and c5 instance types while we wait for kubernetes/enhancements#554 to land GA.This problem became urgent because many of our users are trying to migrate to those instance types in light of spectre/meltdown vulnerability but lower volume limit on those instance types often causes cluster instability. Yes they can workaround by configuring the scheduler with lower limit but often this becomes somewhat difficult to do when cluster is mixed.The newer default limits were picked from Text about spectre/meltdown is available on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(data)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "1246\n",
      "1625\n",
      "4183\n",
      "5181\n",
      "6073\n",
      "18304\n",
      "26104\n",
      "31265\n",
      "31694\n",
      "32617\n",
      "40582\n",
      "43692\n",
      "43887\n",
      "46364\n",
      "48336\n",
      "55190\n",
      "59903\n",
      "69029\n",
      "71831\n",
      "73907\n",
      "84102\n",
      "84990\n",
      "87091\n",
      "87644\n",
      "88939\n",
      "90324\n",
      "93190\n",
      "95292\n",
      "97248\n",
      "101131\n",
      "110105\n",
      "113508\n",
      "117323\n",
      "117324\n",
      "117331\n",
      "117379\n",
      "117386\n",
      "117395\n",
      "117413\n",
      "117419\n",
      "117929\n",
      "120032\n",
      "120475\n",
      "120496\n",
      "120497\n",
      "120532\n",
      "120570\n",
      "120592\n",
      "120622\n",
      "120640\n",
      "125384\n",
      "125967\n",
      "126367\n",
      "126493\n",
      "126500\n",
      "126855\n",
      "135296\n",
      "139407\n",
      "139478\n",
      "139497\n",
      "141205\n",
      "143989\n",
      "144708\n",
      "146679\n",
      "146700\n",
      "147935\n",
      "148232\n",
      "148316\n",
      "148869\n",
      "149727\n",
      "150573\n",
      "160151\n",
      "162377\n"
     ]
    }
   ],
   "source": [
    "word = \"vulnerability\"\n",
    "for i,doc in enumerate(data):\n",
    "    if word in doc:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 162377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «cve dashboard vulnerable to dns rebinding attack minikube exposes the service with configuration that makes it vulnerable to attacks thanks to alex kaskasoli for reporting this problem vulnerable versions minikube vulnerable configurations vm environments which use predictable ip address such as virtualbox or vulnerability impact if an attacker gets victim to visit malicious web page the attacker may be able to execute arbitrary code within the victim minikube cluster minikube exposes the kubernetes dashboard listening on the vm ip at port in vm environments where the ip is easy to predict the attacker can use to indirectly make requests to the kubernetes dashboard without violating the same origin policy the attacker can generate csrf token from the endpoint and pass this token to the endpoint to create new kubernetes deployment running payload of their choosing this vulnerability can be combined with vm specific vulnerability to escape to the host operating system if is in use the attacker could also directly access the host filesystem fixed versions fixed in by fix impact network access to the dashboard service is now provided on an as needed basis and is managed by which enforces http header checks to protect against dns rebinding attacks mitigations before upgrading disable the dashboard entirely additional information»\n",
      "\n",
      "(162439, 0.34016916155815125) (142288, 0.33872729539871216)\n",
      "Similar Document (162439, 0.34016916155815125): «failed pulling image get net request canceled while waiting for connection thanks for filing an issue before hitting the button please answer these questions bug report if this is bug report please fill in as much of the template below as you can if you leave out information we can help you as well if this is feature request please describe in detail the feature behavior change you like to see in both cases be ready for followup questions and please respond in timely manner if we can reproduce bug or think feature already exists we might close your issue if we re wrong please feel free to reopen it and explain why please provide the following details minikube version os name fedora version id fedora version id platform id pretty name ansi color cpe name home url support url bug report url redhat bugzilla product redhat bugzilla product version redhat support product redhat support product version privacy policy url variant variant id workstation vm driver iso version hangs at the starge it not to hang this appears to be firewalling issue where the vm can talk to the public internet dupe of»\n",
      "\n",
      "Similar Document (142288, 0.33872729539871216): «docker api version for libnetwork should fix this issue with coreos tested it on the same vm with this fix»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "\n",
    "print(second_rank,third_rank)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «how to use the public dataset paddlecloud provides some public dataset for the developer how to usage we can install python package in the runtime docker image and use it as how to block the data leakage because of developers can upload trainer python package to the paddlecloud so think the most effective way to block the data leakage is blocking all connections of kubernetes nodes to the exteranl internal this is security issue here is several things to consider about can nodes pods access the internet users may need to download dependencies or public data but also being able to upload public datasets to other places by injecting some code in the maybe no internet access from nodes pods is good idea users can save training output models to their own cloud storage space and then download the models this is another possible vulnerability users can inject code to to save the original data directly to the storage space we can avoid this by the following ways validate the user uploaded program to find encrypt public datasets and store the key in secure place on cloud which can only be read by we need to know if their attack occurred this may be really hard we can starting from inspecting network bandwidth to inference the unusual traffics about network policies we don have network policies currently so one user can sniff around the network or connect to any opened ports in the whole cluster this may not lead to data leakage directly but still problem it seems that after networking control there leaves the following potential leakage path user programs should be able to read the data user programs should be able to write data to cephfs and users are allowed to upload and download data from cephfs how could we prevent data leakage alone above pipeline as mentioned above in no encrypt public datasets and store the key in secure place on cloud which can only be read by reader more details users must use special reader to pass public datasets to trainer this reader returns encrypted data which is decrypted by or in the side we need to implement encrypt tool to encrypt data and upload them to cloud and then implement functions to decrypt decrypting can not be accessed by users store the encrypt key as storage in kubernetes and keep it secretly do we allow user to use custom built paddle if so user can easily access the decrypted data by writing custom layer do we allow user to use custom built paddle if so user can easily access the decrypted data by writing custom layer good point if we allow the user to use custom paddle binary file he she can always print the decrypted data and discussed this question at yesterday maybe prevent custom paddle binary files and prevent custom runtime docker image is good choice»\n",
      "\n",
      "Similar Document (159588, 0.35148751735687256): «bypassing aufs storage overhead is there an equivalent persistent volume type in kubernetes to the use of docker what currently see is that the use of is superior to the use of due to significant performance impact that think is caused from the following one final point data volumes provide the best and most predictable performance this is because they bypass the storage driver and do not incur any of the potential overheads introduced by thin provisioning and copy on write for this reason you may want to place heavy write workloads on data volumes which is quoted at the very bottom of here is an example of this performance impact vs where maven repo is data container with declared that actually has more content than the host mounted volume the above is purely docker but the slow performance is also exhibited when tried creating so suppose the ask is what is the equivalent way in kubernetes to for persistent storage or perhaps is emptydir and multiple containers in pod the correct workaround relevant docker thread on the issue relevant stackoverflow thread thanks for the detailed bug we ll look into whether there is anything we can do in kubernetes to fix this or whether we ll need to add something in minikube don think there anything we can do here in minikube»\n",
      "\n",
      "Similar Document (149076, 0.32041728496551514): «how to prevent data leaks after meeting of data security team there is some suggestion for preventing data leaks prohibit the public network access for each node limit log lines for each command store all user command logs for audit use more secure authentication methods on dlnel such as baidu passport»\n",
      "\n",
      "Similar Document (149076, 0.32041728496551514): «secret content should not be viewable retreiveable by openshift admins it should not be possible for cluster admin to view the coded decoded content of project secrets for example openshift admin should not be able to decode project application database password another example where this is problematic is when developer has configured their sti process to authenticate against git using their personal git credentials openshift admin can easily retrieve user login details by decoding the base secret content there is chicken and egg problem with this in order for containers to use the secret data one of the following has to happen the data is decrypted by the infrastructure before being injected into the container in which case admins would have access to the decrypting keys the data is injected into the container encrypted and the container decrypts it which can only happen if the container has decrypting keys built in which means admins can read them and decrypt or the container retrieves decrypting keys from somewhere using some credentials built in to the container which the admins could also read use to retrieve and decrypt secrets just contain binary data if you want to inject encrypted secrets and have your containers decrypt the data using one of the latter methods you can already do that but the system can really help you with decrypting your data while simultaneously ensuring that admins who are in control of the system can decrypt your data we generally recommend not creating full openshift admin accounts you can for instance create cluster role that cannot retrieve secrets globally and use that for most administrative actions closing this issue in favor of upstream issues about alternate secret storage mechanisms and or encrypting secrets at rest but still don think those solve the issue of getting secret data into container without any way of cluster admin gaining access to it either directly or transitively»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 148869\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "forth_rank = sims[3]\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[forth_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «pick better random port to listen on in integration tests trying to reduce flakes in ci where we randomly pick port to listen on if we are unluckly its already in use and we fail the test let the os pick free random port to listen on we can set the listener early and the apiserver framework will reuse it ideally the issue is resolved by upstream letting us use the standard convention of using which means the travis build failed with there are patterns that catch this error and keep trying to pick port until the server starts maybe it is now time to add that type of logic yep agree let me give this shot debated about it originally and figured the range was wide enough what the chance ve reworked would you take another look when force it to fail can see it initially fail and then on the nd attempt it always successfully listens on the new random port and the tests are successful think the vulnerability we have is that if it happens to pick random port where another controller is already listening we ll have errors as the test client thread will likely connect ok and run the test but that not much of random number generator then ve added plenty of logging that should make failures of this kind pretty obvious if they should happen in test nice find re much to my surprise that works for us as well much better method of getting the test api server on random port»\n",
      "\n",
      "Similar Document (73907, 0.924923300743103): «pick better random port to listen on in integration tests trying to reduce flakes in ci where we randomly pick port to listen on if we are unluckly its already in use and we fail the test let the os pick free random port to listen on we can set the listener early and the apiserver framework will reuse it ideally the issue is resolved by upstream letting us use the standard convention of using which means the travis build failed with there are patterns that catch this error and keep trying to pick port until the server starts maybe it is now time to add that type of logic yep agree let me give this shot debated about it originally and figured the range was wide enough what the chance ve reworked would you take another look when force it to fail can see it initially fail and then on the nd attempt it always successfully listens on the new random port and the tests are successful think the vulnerability we have is that if it happens to pick random port where another controller is already listening we ll have errors as the test client thread will likely connect ok and run the test but that not much of random number generator then ve added plenty of logging that should make failures of this kind pretty obvious if they should happen in test nice find re much to my surprise that works for us as well much better method of getting the test api server on random port»\n",
      "\n",
      "Similar Document (101772, 0.3412019908428192): «test ssss»\n",
      "\n",
      "Similar Document (101772, 0.3412019908428192): «should adhere to three laws of controllers flake sig master kind test flake priority assign»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 144708\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "forth_rank = sims[3]\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[forth_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «generic build error just tried to move my project from openshift to openshift online but if try to build it just get check logs for details so check the logs and there isn single error just npm warn entries though my local build works oc kubernetes features basic auth server openshift kubernetes version steps to reproduce just hit build now current result generic build error without error logs expected result successful build through additional information use and have successfully setup webhook triggers and pulling from private gitlap repos works too though my build fails with following non sense log cloning commit bb ca bab ce author andreas deuschlinger date fri oct installing application source building your node application from source npm warn deprecated bower psst your project can stop working at any moment because its dependencies can change prevent this by migrating to yarn npm warn deprecated email templates has been released try it out and view the new docs at it supports promises browser previews has cleaner api and much more npm warn deprecated nodemailer all versions below of nodemailer are deprecated see npm warn deprecated gulp css globbing this package is no longer actively maintained npm warn deprecated gulp uncss use uncss through gulp postcss instead npm warn deprecated gulp minify css please use gulp clean css npm warn deprecated jade jade has been renamed to pug please install the latest version of pug instead of jade npm warn deprecated transformers deprecated use jstransformer npm warn deprecated minimatch please update to minimatch or higher to avoid regexp dos issue npm warn deprecated minimatch please update to minimatch or higher to avoid regexp dos issue npm warn deprecated graceful fs graceful fs and before will fail on node releases please update to graceful fs as soon as possible use npm ls graceful fs to find it in the tree npm warn deprecated tough cookie redos vulnerability parsing set cookie npm warn deprecated node uuid use uuid module instead npm warn deprecated swig this package is no longer maintained it looks like dependencies issue with you application try to install your app on same version os which you are trying to use here you will get better idea thanks for your feedback well locally develop on os and works as expected there use node only found that there has been known bugs at openshift regarding as dependency management tool though can find information regarding openshift in general would consider missing error logs as bug as this link suggest it is not openshift bug it is npm and bower version compatiblity issue easy way to resolve this is you can build container image on your mac and test the app if that work then you can push the image there or use same steps in dockerfile thanks will try creating my own dockerfile and see what happens localy though my initial plan was to use is good option but you will face issue there too first create the proper working docker file closing as not an openshift issue thanks for the assist you can also debug by building your application locally all the build process is doing is basically invoking on your repository»\n",
      "\n",
      "Similar Document (52117, 0.2958667278289795): «unable to build zookeeper docker container thanks updated zookeeper dockerfile to the latest please try again thanks it works now can you pls check the kafka building it ending up with the same error just tried it and it worked well it might be temporary issue when wget the kafka package could you please try it again yeah this time it worked well thanks»\n",
      "\n",
      "Similar Document (96106, 0.2915879487991333): «openshift stuck at cloning repo cloning commit ef dc abad author geng chen nicosoftware date thu aug want to build simple java app on openshift web console but after create project add to project select wildfly filled github repo url start build and deploy it stucks at cloning as above can anyone figure out how to solve such problem can clone the repo from my either master or node but stucks at openshift web console openshift version openshift ba faec kubernetes ce bc etcd have the same problem cloning pulling image timed out after more log here cloning commit ef dc abad author geng chen nicosoftware date thu aug pulling image error pulling image timed out after error build error unable to get docker io openshift wildfly centos fc fbe bbfe bd but the main problem is that git clone is so slow if git clone directly on master or slave node the speed is fast but if use web console to deploy the git clone could be very very slow the web console isn doing anything special here everything is happening on the backend its just streaming the build logs to the console if you get the logs for that same build through the cli does it still look stuck sig developer experience sig user interface based on this it is not the clone that is timing out it is docker attempting to pull an image can you successfully pull this image from your docker daemon on your host nodes hi think the git clone now works fine maybe these days have poor network thanks your help on this issue»\n",
      "\n",
      "Similar Document (96106, 0.2915879487991333): «update build process for npm packaging deployment update the existing build process to be prepared for npm repository release that is part of closing this issue here»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 93190\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "forth_rank = sims[3]\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[forth_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «clairctl generates empty reports with clair pre yesterday upgraded to clair pre to try out the alpine support but clairctl generates empty reports all my report that had vulnerabilities when running clair now show empty analyze shows some vulnerabilities but the report generated shows nothing thanks for reporting will have look on that le ven vr julien del piccolo notifications crit yesterday upgraded to clair pre to try out the alpine support but clairctl generates empty reports all my report that had vulnerabilities when running clair now show empty analyze shows some vulnerabilities but the report generated shows nothing clairctl analyze registry mydomain net core custom nginx image registry mydomain net registry mydomain net core custom nginx latest layers found analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities analysis found vulnerabilities you are receiving this because you are subscribed to this thread reply to this email directly view it on github or mute the thread ok the vulnerability type change between and to will push branch for version that would be great thanks to be closed clairctl master works well with clair»\n",
      "\n",
      "Similar Document (163340, 0.36975032091140747): «policy controller should be able to report its own version»\n",
      "\n",
      "Similar Document (116393, 0.3444725275039673): «allow policy controller to report version fixes»\n",
      "\n",
      "Similar Document (116393, 0.3444725275039673): «can build without being logged in registry expected behavior build actual behavior information skaffold version docker version ce operating system darwin contents of skaffold yaml steps to reproduce the behavior in this directory structure skaffold dev can you share your on my machine it empty and everything works well ok ran and then and it now fails here the»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 117323\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "forth_rank = sims[3]\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[forth_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : «update kubedns dnsmasq vulnerability cve requires upgrade to patched version was about to make same pr thanks report merging into will coverage the diff coverage is coverage arrow up powered by last update read the»\n",
      "\n",
      "Similar Document (5181, 0.9168679118156433): «update kubedns dnsmasq vulnerability cve requires upgrade to patched version was about to make same pr thanks report merging into will coverage the diff coverage is coverage arrow up powered by last update read the»\n",
      "\n",
      "Similar Document (164455, 0.5626943111419678): «make update libcalico»\n",
      "\n",
      "Similar Document (164455, 0.5626943111419678): «make update libcalico»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 5181\n",
    "a = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.docvecs.most_similar([a], topn=len(model.docvecs))\n",
    "print('Document {}: «{}»\\n'.format(\"\", ' '.join(train_corpus[doc_id].words)))\n",
    "rank = [docid for docid, sim in sims].index(doc_id)\n",
    "second_rank = sims[1]\n",
    "third_rank = sims[2]\n",
    "forth_rank = sims[3]\n",
    "print('Similar Document {}: «{}»\\n'.format(second_rank, ' '.join(train_corpus[second_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[third_rank[0]].words)))\n",
    "print('Similar Document {}: «{}»\\n'.format(third_rank, ' '.join(train_corpus[forth_rank[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
