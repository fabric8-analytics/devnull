{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_file_2_list(folder_path):\n",
    "    repo_list = os.listdir(folder_path)\n",
    "    issue = []\n",
    "    for file_name in repo_list:\n",
    "        issue_dict = pickle.load(open(folder_path + file_name, \"rb\"))\n",
    "#         issue_comment = \"\"\n",
    "        issue_no = list(issue_dict.keys())\n",
    "        issue_no.sort()\n",
    "        for idx in issue_no:\n",
    "            issue.append(issue_dict[idx])\n",
    "#             issue_comment = \"\".join([issue_comment,issue_dict[idx]])\n",
    "#         issue.append(issue_comment)\n",
    "    return issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue = pickle_file_2_list(\"./repo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_issue(file_name):\n",
    "    issue = []\n",
    "    issue_dict = pickle.load(open(file_name, \"rb\"))\n",
    "    issue_no = list(issue_dict.keys())\n",
    "    issue_no.sort()\n",
    "    for idx in issue_no:\n",
    "        issue.append(issue_dict[idx])\n",
    "    return issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue = dict_issue(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(issue,open(\"data1.pkl\",\"wb\"))\n",
    "# issue = pickle.load(open(\"data1.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n```\\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code \\'401\\'\" context=acme host=my-host.com \\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme \\ntime=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of http://my-host.com/.well-known/acme-challenge/_selftest\" context=acme host=my-host.com\\n```\\n\\nI\\'m using [nginx controller with http auth](https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/auth).\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- `kubectl get ingress -o yaml --all-namespaces`\\n- nginx-ingress config and version tag\\n.\\n I\\'m having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path\\n.\\n @pdoreau additionally please post the `nginx.conf` from the ingress controller\\n.\\n @aledbf : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$(POD_NAMESPACE)\" while kube-lego was in its own (different) namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn\\'t a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn\\'t try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That\\'s why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with `/remove-lifecycle stale`.\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with `/close`.\\nSend feedback to [jetstack](https://github.com/jetstack).\\n/lifecycle stale.\\n '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed(issue):\n",
    "    # \" isn\\'t -> isn't \"\n",
    "    issue = [re.sub(r\"'\",\"'\",issue_comment) for issue_comment in issue]\n",
    "    # \" \\n -> \" \" \"\n",
    "    issue = [re.sub(r\"\\s\",\" \",issue_comment) for issue_comment in issue]\n",
    "    # \" @anme -> \" \" \"\n",
    "    issue = [re.sub(r\"@(\\.|\\w)*\",\" \",issue_comment) for issue_comment in issue]\n",
    "    # \" ``` jjkknk ```,`dwadwa` -> \"\" \"\n",
    "    issue = [re.sub(r\"```(.*?)```|`(.*?)`|\\*\\*(.*?)\\*\\*|\\((.*?)\\)\", \" \", issue_comment) for issue_comment in issue]\n",
    "    # \" \"dawaddwadw\" -> \"\" \"\n",
    "    issue = [re.sub(r'\"(.*?)\"', \" \", issue_comment) for issue_comment in issue]\n",
    "    # \" [],http**** -> \"\" \"\n",
    "    issue = [re.sub(r'\\[(.*?)\\]|http\\S+', \" \", issue_comment) for issue_comment in issue]\n",
    "    # \" [a-zA-Z0-9\\?] \"\n",
    "    issue = [re.sub(r\"[^A-Za-z0-9\\?]+\", \" \", issue_comment) for issue_comment in issue]\n",
    "    # remove spaces\n",
    "    issue = [re.sub(r\"\\s\",\" \",issue_comment) for issue_comment in issue]\n",
    "    return issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue = preprocessed(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test Hello After adding the kube lego deployment these lines are printed I m using Can this be the cause ? How can pass the reachabily test ? I think that might be a regression of using http auth Can you add more information nginx ingress config and version tag I m having the same problem It looks like nginx is claiming the well known path additionally please post the from the ingress controller In my case there is no location for in the generated nginx conf in the controller Could it just be that kube lego needs to be started before the controller? Or a namespace issue ? Right for me the problem was caused by starting the ingress controller with while kube lego was in its own namespace Removing watch namespace to allow the controller to watch everything fixes that however this isn t a good long term solution for people who use namespaces to isolate different environments and require an instance of the nginx controller in each I suppose I could also keep watch namespace and start kube lego in the same namespace as the controller so they can see each other however in order to keep environment isolation this would require an equivalent to added for kube lego so that it doesn t try grabbing all ingress objects regardless of namespace Right this is indeed a namespace problem My nginx rc is configured with watch namespace so the challenge request was handled by one of my service and not the kube lego nginx service That s why 401 was responded It works well with a kube lego deployment service declared in the same namespace as my nginx rc ingress Issues go stale after 90d of inactivity Mark the issue as fresh with Stale issues rot after an additional 30d of inactivity and eventually close If this issue is safe to close now please do so with Send feedback to lifecycle stale '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test Hello After adding the kube lego deployment these lines are printed I m using Can this be the cause ? How can pass the reachabily test ? I think that might be a regression of using http auth Can you add more information nginx ingress config and version tag I m having the same problem It looks like nginx is claiming the well known path additionally please post the from the ingress controller In my case there is no location for in the generated nginx conf in the controller Could it just be that kube lego needs to be started before the controller? Or a namespace issue ? Right for me the problem was caused by starting the ingress controller with while kube lego was in its own namespace Removing watch namespace to allow the controller to watch everything fixes that however this isn t a good long term solution for people who use namespaces to isolate different environments and require an instance of the nginx controller in each I suppose I could also keep watch namespace and start kube lego in the same namespace as the controller so they can see each other however in order to keep environment isolation this would require an equivalent to added for kube lego so that it doesn t try grabbing all ingress objects regardless of namespace Right this is indeed a namespace problem My nginx rc is configured with watch namespace so the challenge request was handled by one of my service and not the kube lego nginx service That s why 401 was responded It works well with a kube lego deployment service declared in the same namespace as my nginx rc ingress Issues go stale after 90d of inactivity Mark the issue as fresh with Stale issues rot after an additional 30d of inactivity and eventually close If this issue is safe to close now please do so with Send feedback to lifecycle stale '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'\\((.*?)\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"```(.*?)```|`(.*?)`|\\*\\*(.*?)\\*\\*|\\((.*?)\\)|@(\\.|\\w)*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\\s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n```\\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code @401@\" context=acme host=my-host.com \\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme \\ntime=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of http://my-host.com/.well-known/acme-challenge/_selftest\" context=acme host=my-host.com\\n```\\n\\nI@m using [nginx controller with http auth](https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/auth).\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- `kubectl get ingress -o yaml --all-namespaces`\\n- nginx-ingress config and version tag\\n.\\n I@m having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path\\n.\\n @pdoreau additionally please post the `nginx.conf` from the ingress controller\\n.\\n @aledbf : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$(POD_NAMESPACE)\" while kube-lego was in its own (different) namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn@t a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn@t try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That@s why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with `/remove-lifecycle stale`.\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with `/close`.\\nSend feedback to [jetstack](https://github.com/jetstack).\\n/lifecycle stale.\\n '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"'\",\" **** \",issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.  Hello.  After adding the kube lego deployment these lines are printed :  ``` time=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code \\'401\\'\" context=acme host=my-host.com  time=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme  time=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of http://my-host.com/.well-known/acme-challenge/_selftest\" context=acme host=my-host.com ```  I\\'m using [nginx controller with http auth](https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/auth). Can this be the cause ? How can pass the reachabily test ?  .  I think that might be a regression of using http auth. Can you add more information: - `kubectl get ingress -o yaml --all-namespaces` - nginx-ingress config and version tag .  I\\'m having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path .  @pdoreau additionally please post the `nginx.conf` from the ingress controller .  @aledbf : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller. Could it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ? .  Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$(POD_NAMESPACE)\" while kube-lego was in its own (different) namespace.  Removing watch-namespace to allow the controller to watch everything fixes that, however this isn\\'t a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.  I suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn\\'t try grabbing all ingress objects regardless of namespace. .  Right, this is indeed a namespace problem. My nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That\\'s why 401 was responded.  It works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress. .  Issues go stale after 90d of inactivity. Mark the issue as fresh with `/remove-lifecycle stale`. Stale issues rot after an additional 30d of inactivity and eventually close. If this issue is safe to close now please do so with `/close`. Send feedback to [jetstack](https://github.com/jetstack). /lifecycle stale.  '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\s\",\" \",issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n```\\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code \\'401\\'\" context=acme host=my-host.com \\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme \\ntime=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of http://my-host.com/.well-known/acme-challenge/_selftest\" context=acme host=my-host.com\\n```\\n\\nI\\'m using [nginx controller with http auth](https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/auth).\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- `kubectl get ingress -o yaml --all-namespaces`\\n- nginx-ingress config and version tag\\n.\\n I\\'m having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path\\n.\\n  *******  additionally please post the `nginx.conf` from the ingress controller\\n.\\n  *******  : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$(POD_NAMESPACE)\" while kube-lego was in its own (different) namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn\\'t a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn\\'t try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That\\'s why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with `/remove-lifecycle stale`.\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with `/close`.\\nSend feedback to [jetstack](https://github.com/jetstack).\\n/lifecycle stale.\\n '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"@(\\.|\\w)*\",\" ******* \",issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n`\\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code \\'401\\'\" context=acme host=my-host.com \\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme \\ntime=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of http://my-host.com/.well-known/acme-challenge/_selftest\" context=acme host=my-host.com\\n`\\n\\nI\\'m using [nginx controller with http auth].\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- \\n- nginx-ingress config and version tag\\n.\\n I\\'m having the same problem. It looks like nginx  is claiming the /.well-known/ path\\n.\\n @pdoreau additionally please post the  from the ingress controller\\n.\\n @aledbf : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue  ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$\" while kube-lego was in its own  namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn\\'t a good long term solution for people who use namespaces to isolate different environments  and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn\\'t try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service  and not the kube-lego-nginx service. That\\'s why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with .\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with .\\nSend feedback to [jetstack].\\n/lifecycle stale.\\n '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"```(.*?)```|`(.*?)`|\\*\\*(.*?)\\*\\*|\\((.*?)\\)\", \"\", issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n```\\ntime= level=warning msg= context=acme host=my-host.com \\ntime= level=warning msg= context=acme \\ntime= level=debug msg= context=acme host=my-host.com\\n```\\n\\nI'm using [nginx controller with http auth](https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/auth).\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- `kubectl get ingress -o yaml --all-namespaces`\\n- nginx-ingress config and version tag\\n.\\n I'm having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path\\n.\\n @pdoreau additionally please post the `nginx.conf` from the ingress controller\\n.\\n @aledbf : In my case there is no location for  in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with  while kube-lego was in its own (different) namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn't a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to  added for kube-lego, so that it doesn't try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That's why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with `/remove-lifecycle stale`.\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with `/close`.\\nSend feedback to [jetstack](https://github.com/jetstack).\\n/lifecycle stale.\\n \""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\"(.*?)\"', \"\", issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test.\\n Hello.\\n\\nAfter adding the kube lego deployment these lines are printed :\\n\\n```\\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"wrong status code \\'401\\'\" context=acme host=my-host.com \\ntime=\"2016-09-21T16:30:18Z\" level=warning msg=\"Error while obtaining certificate: reachabily test failed for this cert\" context=acme \\ntime=\"2016-09-21T16:30:23Z\" level=debug msg=\"testing reachablity of 000000 context=acme host=my-host.com\\n```\\n\\nI\\'m using 000000(000000\\nCan this be the cause ? How can pass the reachabily test ? \\n.\\n I think that might be a regression of using http auth. Can you add more information:\\n- `kubectl get ingress -o yaml --all-namespaces`\\n- nginx-ingress config and version tag\\n.\\n I\\'m having the same problem. It looks like nginx (instead of kube-lego) is claiming the /.well-known/ path\\n.\\n @pdoreau additionally please post the `nginx.conf` from the ingress controller\\n.\\n @aledbf : In my case there is no location for \"/.well-known/acme-challenge/\" in the generated nginx.conf in the controller.\\nCould it just be that kube-lego needs to be started before the controller? Or a namespace issue (I have kube-lego in its own namespace, different from the nginx one) ?\\n.\\n Right, for me the problem was caused by starting the ingress controller with \"--watch-namespace=$(POD_NAMESPACE)\" while kube-lego was in its own (different) namespace.\\n\\nRemoving watch-namespace to allow the controller to watch everything fixes that, however this isn\\'t a good long term solution for people who use namespaces to isolate different environments (staging/prod, etc) and require an instance of the nginx controller in each.\\n\\nI suppose I could also keep watch-namespace, and start kube-lego in the same namespace as the controller so they can see each other, however in order to keep environment isolation this would require an equivalent to \"watch-namespace\" added for kube-lego, so that it doesn\\'t try grabbing all ingress objects regardless of namespace.\\n.\\n Right, this is indeed a namespace problem.\\nMy nginx rc is configured with watch-namespace so the challenge request was handled by one of my service (which is protected by http auth) and not the kube-lego-nginx service. That\\'s why 401 was responded.\\n\\nIt works well with a kube-lego deployment & service declared in the same namespace as my nginx rc / ingress.\\n.\\n Issues go stale after 90d of inactivity.\\nMark the issue as fresh with `/remove-lifecycle stale`.\\nStale issues rot after an additional 30d of inactivity and eventually close.\\nIf this issue is safe to close now please do so with `/close`.\\nSend feedback to 000000(000000\\n/lifecycle stale.\\n '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\[(.*?)\\]|http\\S+', \"000000\", issue[37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test   Hello   After adding the kube lego deployment these lines are printed      time 2016 09 21T16 30 18Z  level warning msg wrong status code  401  context acme host my host com  time 2016 09 21T16 30 18Z  level warning msg Error while obtaining certificate  reachabily test failed for this cert  context acme  time 2016 09 21T16 30 23Z  level debug msg testing reachablity of http my host com  well known acme challenge selftest  context acme host my host com    I m using  nginx controller with http auth https github com kubernetes contrib tree master ingress controllers nginx examples auth   Can this be the cause   How can pass the reachabily test       I think that might be a regression of using http auth  Can you add more information     kubectl get ingress  o yaml  all namespaces    nginx ingress config and version tag    I m having the same problem  It looks like nginx  instead of kube lego  is claiming the   well known  path     pdoreau additionally please post the  nginx conf  from the ingress controller     aledbf   In my case there is no location for   well known acme challenge  in the generated nginx conf in the controller  Could it just be that kube lego needs to be started before the controller  Or a namespace issue  I have kube lego in its own namespace  different from the nginx one       Right  for me the problem was caused by starting the ingress controller with  watch namespace POD NAMESPACE  while kube lego was in its own  different  namespace   Removing watch namespace to allow the controller to watch everything fixes that  however this isn t a good long term solution for people who use namespaces to isolate different environments  staging prod  etc  and require an instance of the nginx controller in each   I suppose I could also keep watch namespace  and start kube lego in the same namespace as the controller so they can see each other  however in order to keep environment isolation this would require an equivalent to  watch namespace  added for kube lego  so that it doesn t try grabbing all ingress objects regardless of namespace     Right  this is indeed a namespace problem  My nginx rc is configured with watch namespace so the challenge request was handled by one of my service  which is protected by http auth  and not the kube lego nginx service  That s why 401 was responded   It works well with a kube lego deployment   service declared in the same namespace as my nginx rc   ingress     Issues go stale after 90d of inactivity  Mark the issue as fresh with  remove lifecycle stale   Stale issues rot after an additional 30d of inactivity and eventually close  If this issue is safe to close now please do so with  close   Send feedback to  jetstack https github com jetstack    lifecycle stale   '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_1 = re.sub(r\"\\n|\\.\", \"\", issue[37])\n",
    "re.sub(r\"[^A-Za-z0-9 ]+\", \" \", temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Status code 401 during reachabily test Hello After adding the kube lego deployment these lines are printed I m using Can this be the cause ? How can pass the reachabily test ? I think that might be a regression of using http auth Can you add more information nginx ingress config and version tag I m having the same problem It looks like nginx is claiming the well known path additionally please post the from the ingress controller In my case there is no location for in the generated nginx conf in the controller Could it just be that kube lego needs to be started before the controller? Or a namespace issue ? Right for me the problem was caused by starting the ingress controller with while kube lego was in its own namespace Removing watch namespace to allow the controller to watch everything fixes that however this isn t a good long term solution for people who use namespaces to isolate different environments and require an instance of the nginx controller in each I suppose I could also keep watch namespace and start kube lego in the same namespace as the controller so they can see each other however in order to keep environment isolation this would require an equivalent to added for kube lego so that it doesn t try grabbing all ingress objects regardless of namespace Right this is indeed a namespace problem My nginx rc is configured with watch namespace so the challenge request was handled by one of my service and not the kube lego nginx service That s why 401 was responded It works well with a kube lego deployment service declared in the same namespace as my nginx rc ingress Issues go stale after 90d of inactivity Mark the issue as fresh with Stale issues rot after an additional 30d of inactivity and eventually close If this issue is safe to close now please do so with Send feedback to lifecycle stale '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(issue,open(\"processed_issues.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_issue = preprocessed(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_issue,open(\"test_issue.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
